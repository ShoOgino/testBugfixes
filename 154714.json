{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","commits":[{"id":"cc41b743423981e7ec17a024ce7e107096e472fe","date":1349975327,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), true, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"673d1479bcc124ba45b876b686d19f67435bca90","date":1351013999,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), true, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // nocommit this is putting fox in charge of hen\n      // house!  ie maybe we have a bug in suggester.toLevA ...\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), true, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"62e52115b56781006682fd92c6938efaf174304d","date":1351014780,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // nocommit this is putting fox in charge of hen\n      // house!  ie maybe we have a bug in suggester.toLevA ...\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), true, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // nocommit this is putting fox in charge of hen\n      // house!  ie maybe we have a bug in suggester.toLevA ...\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0ba222c174ec1943d8d14d012d1d6e24a1cc4972","date":1351522220,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3, true);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                          preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // nocommit this is putting fox in charge of hen\n      // house!  ie maybe we have a bug in suggester.toLevA ...\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"31b5edc7f41e0c481513ce8881696e3e042ff493","date":1351528983,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3, true);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b","date":1351615637,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7530de27b87b961b51f01bd1299b7004d46e8823","date":1355236261,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70728fc5d87dc51506cd3f763d68d2c16948e127","date":1363037076,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n              } else {\n                analyzedKey += s;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n        } else {\n          builder.append(token);\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6","date":1374158194,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3, unicodeAware);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":["31b5edc7f41e0c481513ce8881696e3e042ff493","cc41b743423981e7ec17a024ce7e107096e472fe"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3, unicodeAware);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && analyzedKey.charAt(analyzedKey.length()-1) != ' ') {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ada2f7352a7f964fe49bccd13227c4ec38563d39","date":1381659982,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<TermFreqPayload2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreqPayload[] keys = new TermFreqPayload[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreqPayload(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<TermFreqPayload2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3, unicodeAware);\n    suggester.build(new TermFreqPayloadArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreq2> slowCompletor = new ArrayList<TermFreq2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreq[] keys = new TermFreq[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreq(key, weight);\n\n      slowCompletor.add(new TermFreq2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreq2> sorted = new ArrayList<TermFreq2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreq2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3, unicodeAware);\n    suggester.build(new TermFreqArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreq2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"41aee74b5f91a096e3fd950f4a336bc763f0e7a7","date":1381772070,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<TermFreqPayload2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<TermFreqPayload2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<TermFreqPayload2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    TermFreqPayload[] keys = new TermFreqPayload[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new TermFreqPayload(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<TermFreqPayload2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3, unicodeAware);\n    suggester.build(new TermFreqPayloadArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4e0095ef720d1b8e7406847147af69f19af3ab6","date":1383131477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<TermFreqPayload2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<TermFreqPayload2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, false, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<TermFreqPayload2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<TermFreqPayload2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"33f87fe6faf49dfc1e66f45e841e24838c2f725c","date":1383142987,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<TermFreqPayload2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<TermFreqPayload2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<TermFreqPayload2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<TermFreqPayload2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, false, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<TermFreqPayload2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<TermFreqPayload2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<TermFreqPayload2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = _TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = _TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<TermFreqPayload2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = _TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(_TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<TermFreqPayload2>();\n    final TreeSet<String> allPrefixes = new TreeSet<String>();\n    final Set<String> seen = new HashSet<String>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<TermFreqPayload2>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<LookupResult>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"75ac8571c2d82c574e446c3729251b994c69a55c","date":1402523781,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      LightAutomaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(BasicOperations.isDeterministic(automaton));\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a67285d1a68175d877eb9fd1624fccad3db028ff","date":1402779028,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      LightAutomaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      LightAutomaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(BasicOperations.isDeterministic(automaton));\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4ca1c732df8923f5624f6c06b1dcca9e69d98c96","date":1402957391,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      LightAutomaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5c84485629d80d203608e8975a1139de9933cc38","date":1403166128,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          State p = automaton.getInitialState();\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            State q = p.step(ref.bytes[i] & 0xff);\n            if (q == null) {\n              break;\n            } else if (q.isAccept()) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && p.isAccept()) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare.get(), tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRef spare = new BytesRef();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare, tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":["cc41b743423981e7ec17a024ce7e107096e472fe"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","date":1419400138,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare.get(), tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but its slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare.get(), tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare.get(), tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n    a.close();\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare.get(), tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare.get(), tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n    a.close();\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare.get(), tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"35fa550f45857d99d3d6d743420ee54b4d0c37f8","date":1436039255,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        FiniteStringsIterator finiteStrings =\n            new FiniteStringsIterator(suggester.toAutomaton(spare.get(), tokenStreamToAutomaton));\n        for (IntsRef string; (string = finiteStrings.next()) != null;) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(string, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n    a.close();\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        Set<IntsRef> finiteStrings = suggester.toFiniteStrings(spare.get(), tokenStreamToAutomaton);\n        for (IntsRef intsRef : finiteStrings) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(intsRef, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"867e3d9153fb761456b54a9dcce566e1545c5ef6","date":1444903098,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    Directory tempDir = getDirectory();\n    FuzzySuggester suggester = new FuzzySuggester(tempDir, \"fuzzy\",a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        FiniteStringsIterator finiteStrings =\n            new FiniteStringsIterator(suggester.toAutomaton(spare.get(), tokenStreamToAutomaton));\n        for (IntsRef string; (string = finiteStrings.next()) != null;) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(string, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n    IOUtils.close(a, tempDir);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    FuzzySuggester suggester = new FuzzySuggester(a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        FiniteStringsIterator finiteStrings =\n            new FiniteStringsIterator(suggester.toAutomaton(spare.get(), tokenStreamToAutomaton));\n        for (IntsRef string; (string = finiteStrings.next()) != null;) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(string, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","date":1579652839,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#testRandom().mjava","sourceNew":"  @Slow\n  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(20);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    Directory tempDir = getDirectory();\n    FuzzySuggester suggester = new FuzzySuggester(tempDir, \"fuzzy\",a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        FiniteStringsIterator finiteStrings =\n            new FiniteStringsIterator(suggester.toAutomaton(spare.get(), tokenStreamToAutomaton));\n        for (IntsRef string; (string = finiteStrings.next()) != null;) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(string, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n    IOUtils.close(a, tempDir);\n  }\n\n","sourceOld":"  public void testRandom() throws Exception {\n\n    int numQueries = atLeast(100);\n    \n    final List<TermFreqPayload2> slowCompletor = new ArrayList<>();\n    final TreeSet<String> allPrefixes = new TreeSet<>();\n    final Set<String> seen = new HashSet<>();\n    \n    Input[] keys = new Input[numQueries];\n\n    boolean preserveSep = random().nextBoolean();\n    boolean unicodeAware = random().nextBoolean();\n\n    final int numStopChars = random().nextInt(10);\n    final boolean preserveHoles = random().nextBoolean();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + numQueries + \" words; preserveSep=\" + preserveSep + \" ; unicodeAware=\" + unicodeAware + \" numStopChars=\" + numStopChars + \" preserveHoles=\" + preserveHoles);\n    }\n    \n    for (int i = 0; i < numQueries; i++) {\n      int numTokens = TestUtil.nextInt(random(), 1, 4);\n      String key;\n      String analyzedKey;\n      while(true) {\n        key = \"\";\n        analyzedKey = \"\";\n        boolean lastRemoved = false;\n        for(int token=0;token < numTokens;token++) {\n          String s;\n          while (true) {\n            // TODO: would be nice to fix this slowCompletor/comparator to\n            // use full range, but we might lose some coverage too...\n            s = TestUtil.randomSimpleString(random());\n            if (s.length() > 0) {\n              if (token > 0) {\n                key += \" \";\n              }\n              if (preserveSep && analyzedKey.length() > 0 && (unicodeAware ? analyzedKey.codePointAt(analyzedKey.codePointCount(0, analyzedKey.length())-1) != ' ' : analyzedKey.charAt(analyzedKey.length()-1) != ' ')) {\n                analyzedKey += \" \";\n              }\n              key += s;\n              if (s.length() == 1 && isStopChar(s.charAt(0), numStopChars)) {\n                if (preserveSep && preserveHoles) {\n                  analyzedKey += '\\u0000';\n                }\n                lastRemoved = true;\n              } else {\n                analyzedKey += s;\n                lastRemoved = false;\n              }\n              break;\n            }\n          }\n        }\n\n        analyzedKey = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n\n        if (preserveSep && lastRemoved) {\n          analyzedKey += \" \";\n        }\n\n        // Don't add same surface form more than once:\n        if (!seen.contains(key)) {\n          seen.add(key);\n          break;\n        }\n      }\n\n      for (int j = 1; j < key.length(); j++) {\n        allPrefixes.add(key.substring(0, j));\n      }\n      // we can probably do Integer.MAX_VALUE here, but why worry.\n      int weight = random().nextInt(1<<24);\n      keys[i] = new Input(key, weight);\n\n      slowCompletor.add(new TermFreqPayload2(key, analyzedKey, weight));\n    }\n\n    if (VERBOSE) {\n      // Don't just sort original list, to avoid VERBOSE\n      // altering the test:\n      List<TermFreqPayload2> sorted = new ArrayList<>(slowCompletor);\n      Collections.sort(sorted);\n      for(TermFreqPayload2 ent : sorted) {\n        System.out.println(\"  surface='\" + ent.surfaceForm + \" analyzed='\" + ent.analyzedForm + \"' weight=\" + ent.weight);\n      }\n    }\n\n    Analyzer a = new MockTokenEatingAnalyzer(numStopChars, preserveHoles);\n    Directory tempDir = getDirectory();\n    FuzzySuggester suggester = new FuzzySuggester(tempDir, \"fuzzy\",a, a,\n                                                  preserveSep ? AnalyzingSuggester.PRESERVE_SEP : 0, 256, -1, true, 1, false, 1, 3, unicodeAware);\n    suggester.build(new InputArrayIterator(keys));\n\n    for (String prefix : allPrefixes) {\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: prefix=\" + prefix);\n      }\n\n      final int topN = TestUtil.nextInt(random(), 1, 10);\n      List<LookupResult> r = suggester.lookup(TestUtil.stringToCharSequence(prefix, random()), false, topN);\n\n      // 2. go thru whole set to find suggestions:\n      List<LookupResult> matches = new ArrayList<>();\n\n      // \"Analyze\" the key:\n      String[] tokens = prefix.split(\" \");\n      StringBuilder builder = new StringBuilder();\n      boolean lastRemoved = false;\n      for(int i=0;i<tokens.length;i++) {\n        String token = tokens[i];\n        if (preserveSep && builder.length() > 0 && !builder.toString().endsWith(\" \")) {\n          builder.append(' ');\n        }\n\n        if (token.length() == 1 && isStopChar(token.charAt(0), numStopChars)) {\n          if (preserveSep && preserveHoles) {\n            builder.append(\"\\u0000\");\n          }\n          lastRemoved = true;\n        } else {\n          builder.append(token);\n          lastRemoved = false;\n        }\n      }\n\n      String analyzedKey = builder.toString();\n\n      // Remove trailing sep/holes (TokenStream.end() does\n      // not tell us any trailing holes, yet ... there is an\n      // issue open for this):\n      while (true) {\n        String s = analyzedKey.replaceAll(\"(^| )\\u0000$\", \"\");\n        s = s.replaceAll(\"\\\\s+$\", \"\");\n        if (s.equals(analyzedKey)) {\n          break;\n        }\n        analyzedKey = s;\n      }\n\n      if (analyzedKey.length() == 0) {\n        // Currently suggester can't suggest from the empty\n        // string!  You get no results, not all results...\n        continue;\n      }\n\n      if (preserveSep && (prefix.endsWith(\" \") || lastRemoved)) {\n        analyzedKey += \" \";\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  analyzed: \" + analyzedKey);\n      }\n      TokenStreamToAutomaton tokenStreamToAutomaton = suggester.getTokenStreamToAutomaton();\n\n      // NOTE: not great that we ask the suggester to give\n      // us the \"answer key\" (ie maybe we have a bug in\n      // suggester.toLevA ...) ... but testRandom2() fixes\n      // this:\n      Automaton automaton = suggester.convertAutomaton(suggester.toLevenshteinAutomata(suggester.toLookupAutomaton(analyzedKey)));\n      assertTrue(automaton.isDeterministic());\n\n      // TODO: could be faster... but it's slowCompletor for a reason\n      BytesRefBuilder spare = new BytesRefBuilder();\n      for (TermFreqPayload2 e : slowCompletor) {\n        spare.copyChars(e.analyzedForm);\n        FiniteStringsIterator finiteStrings =\n            new FiniteStringsIterator(suggester.toAutomaton(spare.get(), tokenStreamToAutomaton));\n        for (IntsRef string; (string = finiteStrings.next()) != null;) {\n          int p = 0;\n          BytesRef ref = Util.toBytesRef(string, spare);\n          boolean added = false;\n          for (int i = ref.offset; i < ref.length; i++) {\n            int q = automaton.step(p, ref.bytes[i] & 0xff);\n            if (q == -1) {\n              break;\n            } else if (automaton.isAccept(q)) {\n              matches.add(new LookupResult(e.surfaceForm, e.weight));\n              added = true;\n              break;\n            }\n            p = q;\n          }\n          if (!added && automaton.isAccept(p)) {\n            matches.add(new LookupResult(e.surfaceForm, e.weight));\n          } \n        }\n      }\n\n      assertTrue(numStopChars > 0 || matches.size() > 0);\n\n      if (matches.size() > 1) {\n        Collections.sort(matches, new Comparator<LookupResult>() {\n            @Override\n            public int compare(LookupResult left, LookupResult right) {\n              int cmp = Float.compare(right.value, left.value);\n              if (cmp == 0) {\n                return left.compareTo(right);\n              } else {\n                return cmp;\n              }\n            }\n          });\n      }\n\n      if (matches.size() > topN) {\n        matches = matches.subList(0, topN);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  expected:\");\n        for(LookupResult lr : matches) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n\n        System.out.println(\"  actual:\");\n        for(LookupResult lr : r) {\n          System.out.println(\"    key=\" + lr.key + \" weight=\" + lr.value);\n        }\n      }\n      \n      assertEquals(prefix + \"  \" + topN, matches.size(), r.size());\n      for(int hit=0;hit<r.size();hit++) {\n        //System.out.println(\"  check hit \" + hit);\n        assertEquals(prefix + \"  \" + topN, matches.get(hit).key.toString(), r.get(hit).key.toString());\n        assertEquals(matches.get(hit).value, r.get(hit).value, 0f);\n      }\n    }\n    IOUtils.close(a, tempDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"75ac8571c2d82c574e446c3729251b994c69a55c":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b","7530de27b87b961b51f01bd1299b7004d46e8823"],"a67285d1a68175d877eb9fd1624fccad3db028ff":["75ac8571c2d82c574e446c3729251b994c69a55c"],"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6":["70728fc5d87dc51506cd3f763d68d2c16948e127"],"31b5edc7f41e0c481513ce8881696e3e042ff493":["0ba222c174ec1943d8d14d012d1d6e24a1cc4972"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["5c84485629d80d203608e8975a1139de9933cc38"],"673d1479bcc124ba45b876b686d19f67435bca90":["cc41b743423981e7ec17a024ce7e107096e472fe"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","a56958d7f71a28824f20031ffbb2e13502a0274e"],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0ba222c174ec1943d8d14d012d1d6e24a1cc4972":["62e52115b56781006682fd92c6938efaf174304d"],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["a67285d1a68175d877eb9fd1624fccad3db028ff"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["70728fc5d87dc51506cd3f763d68d2c16948e127"],"5c84485629d80d203608e8975a1139de9933cc38":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["867e3d9153fb761456b54a9dcce566e1545c5ef6"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"6613659748fe4411a7dcf85266e55db1f95f7315":["33f87fe6faf49dfc1e66f45e841e24838c2f725c"],"33f87fe6faf49dfc1e66f45e841e24838c2f725c":["d4e0095ef720d1b8e7406847147af69f19af3ab6"],"35fa550f45857d99d3d6d743420ee54b4d0c37f8":["a56958d7f71a28824f20031ffbb2e13502a0274e"],"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","31b5edc7f41e0c481513ce8881696e3e042ff493"],"70728fc5d87dc51506cd3f763d68d2c16948e127":["7530de27b87b961b51f01bd1299b7004d46e8823"],"62e52115b56781006682fd92c6938efaf174304d":["673d1479bcc124ba45b876b686d19f67435bca90","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cc41b743423981e7ec17a024ce7e107096e472fe":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"7530de27b87b961b51f01bd1299b7004d46e8823":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["35fa550f45857d99d3d6d743420ee54b4d0c37f8"],"d4e0095ef720d1b8e7406847147af69f19af3ab6":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6"]},"commit2Childs":{"75ac8571c2d82c574e446c3729251b994c69a55c":["a67285d1a68175d877eb9fd1624fccad3db028ff"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"a67285d1a68175d877eb9fd1624fccad3db028ff":["4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["d4e0095ef720d1b8e7406847147af69f19af3ab6"],"2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"31b5edc7f41e0c481513ce8881696e3e042ff493":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"673d1479bcc124ba45b876b686d19f67435bca90":["62e52115b56781006682fd92c6938efaf174304d"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"0ba222c174ec1943d8d14d012d1d6e24a1cc4972":["31b5edc7f41e0c481513ce8881696e3e042ff493"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b","62e52115b56781006682fd92c6938efaf174304d","cc41b743423981e7ec17a024ce7e107096e472fe"],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["5c84485629d80d203608e8975a1139de9933cc38"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"5c84485629d80d203608e8975a1139de9933cc38":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["75ac8571c2d82c574e446c3729251b994c69a55c","5c84485629d80d203608e8975a1139de9933cc38"],"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"33f87fe6faf49dfc1e66f45e841e24838c2f725c":["6613659748fe4411a7dcf85266e55db1f95f7315"],"35fa550f45857d99d3d6d743420ee54b4d0c37f8":["867e3d9153fb761456b54a9dcce566e1545c5ef6"],"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","7530de27b87b961b51f01bd1299b7004d46e8823"],"70728fc5d87dc51506cd3f763d68d2c16948e127":["2efd1b8e67185b5bb2dbdfa435b9f085a0c659f6","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"62e52115b56781006682fd92c6938efaf174304d":["0ba222c174ec1943d8d14d012d1d6e24a1cc4972"],"cc41b743423981e7ec17a024ce7e107096e472fe":["673d1479bcc124ba45b876b686d19f67435bca90"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","35fa550f45857d99d3d6d743420ee54b4d0c37f8"],"7530de27b87b961b51f01bd1299b7004d46e8823":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","70728fc5d87dc51506cd3f763d68d2c16948e127"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"d4e0095ef720d1b8e7406847147af69f19af3ab6":["33f87fe6faf49dfc1e66f45e841e24838c2f725c"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}