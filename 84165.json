{"path":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","commits":[{"id":"93124590c6e2a8b45898cbae46f96c3a05d9bce0","date":1399415098,"type":1,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(String,int,int).mjava","sourceNew":"  /** Constructs a Token with the given term text, and start\n   *  & end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","sourceOld":"  /** Constructs a Token with the given term text, and start\n   *  & end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(String text, int start, int end) {\n    checkOffsets(start, end);\n    append(text);\n    startOffset = start;\n    endOffset = end;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b1eb427f2c6beed80d1724555fc1db003ccf3030","date":1417137397,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","sourceNew":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","sourceOld":"  /** Constructs a Token with the given term text, and start\n   *  & end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f1a421c5a6934704db5f8be705bc74f42e679ba","date":1498207865,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","sourceNew":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","sourceOld":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f1a421c5a6934704db5f8be705bc74f42e679ba","date":1498207865,"type":6,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/Token#Token(CharSequence,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","sourceNew":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","sourceOld":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":5,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","sourceNew":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","sourceOld":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":6,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/Token#Token(CharSequence,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","sourceNew":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","sourceOld":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","sourceNew":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","sourceOld":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":6,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/Token#Token(CharSequence,int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/analysis/Token#Token(CharSequence,int,int).mjava","sourceNew":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","sourceOld":"  /** Constructs a Token with the given term text, start\n   *  and end offsets.  The type defaults to \"word.\"\n   *  <b>NOTE:</b> for better indexing speed you should\n   *  instead use the char[] termBuffer methods to set the\n   *  term text.\n   *  @param text term text\n   *  @param start start offset in the source text\n   *  @param end end offset in the source text\n   */\n  public Token(CharSequence text, int start, int end) {\n    append(text);\n    setOffset(start, end);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"93124590c6e2a8b45898cbae46f96c3a05d9bce0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b1eb427f2c6beed80d1724555fc1db003ccf3030":["93124590c6e2a8b45898cbae46f96c3a05d9bce0"],"1f1a421c5a6934704db5f8be705bc74f42e679ba":["b1eb427f2c6beed80d1724555fc1db003ccf3030"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["b1eb427f2c6beed80d1724555fc1db003ccf3030","1f1a421c5a6934704db5f8be705bc74f42e679ba"],"28288370235ed02234a64753cdbf0c6ec096304a":["b1eb427f2c6beed80d1724555fc1db003ccf3030","1f1a421c5a6934704db5f8be705bc74f42e679ba"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["28288370235ed02234a64753cdbf0c6ec096304a"]},"commit2Childs":{"93124590c6e2a8b45898cbae46f96c3a05d9bce0":["b1eb427f2c6beed80d1724555fc1db003ccf3030"],"b1eb427f2c6beed80d1724555fc1db003ccf3030":["1f1a421c5a6934704db5f8be705bc74f42e679ba","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"1f1a421c5a6934704db5f8be705bc74f42e679ba":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["93124590c6e2a8b45898cbae46f96c3a05d9bce0"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"28288370235ed02234a64753cdbf0c6ec096304a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}