{"path":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#flushAllThreads(boolean,boolean).mjava","commits":[{"id":"9b832cbed6eb3d54a8bb9339296bdda8eeb53014","date":1279708040,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#flushAllThreads(boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  final boolean flushAllThreads(final boolean flushDocStores, final boolean flushDeletes)\n      throws IOException {\n    return threadPool.executeAllThreads(new DocumentsWriterThreadPool.AllThreadsTask<Boolean>() {\n      @Override\n      public Boolean process(Iterator<DocumentsWriterPerThread> threadsIterator) throws IOException {\n        boolean anythingFlushed = false;\n        \n        if (flushDeletes) {\n          synchronized (indexWriter) {\n            if (applyDeletes(indexWriter.segmentInfos)) {\n              indexWriter.checkpoint();\n            }\n          }\n        }\n\n        while (threadsIterator.hasNext()) {\n          boolean perThreadFlushDocStores = flushDocStores;\n          DocumentsWriterPerThread perThread = threadsIterator.next();\n          final int numDocs = perThread.getNumDocsInRAM();\n          \n          // Always flush docs if there are any\n          boolean flushDocs = numDocs > 0;\n          \n          String docStoreSegment = perThread.getDocStoreSegment();\n          if (docStoreSegment == null) {\n            perThreadFlushDocStores = false;\n          }\n          int docStoreOffset = perThread.getDocStoreOffset();\n          boolean docStoreIsCompoundFile = false;\n          if (perThreadFlushDocStores\n              && (!flushDocs || !perThread.getSegment().equals(perThread.getDocStoreSegment()))) {\n            // We must separately flush the doc store\n            if (infoStream != null) {\n              message(\"  flush shared docStore segment \" + docStoreSegment);\n            }\n            docStoreIsCompoundFile = flushDocStores(perThread);\n            flushDocStores(perThread);\n            perThreadFlushDocStores = false;\n          }\n\n          String segment = perThread.getSegment();\n\n          // If we are flushing docs, segment must not be null:\n          assert segment != null || !flushDocs;\n    \n          if (flushDocs) {\n            SegmentInfo newSegment = perThread.flush(perThreadFlushDocStores);\n            \n            if (newSegment != null) {\n              anythingFlushed = true;\n              \n              if (0 == docStoreOffset && perThreadFlushDocStores) {\n                // This means we are flushing private doc stores\n                // with this segment, so it will not be shared\n                // with other segments\n                assert docStoreSegment != null;\n                assert docStoreSegment.equals(segment);\n                docStoreOffset = -1;\n                docStoreSegment = null;\n                docStoreIsCompoundFile = false;\n              }\n              newSegment.setDocStore(docStoreOffset, docStoreSegment, docStoreIsCompoundFile);\n              \n              IndexWriter.setDiagnostics(newSegment, \"flush\");\n              finishFlushedSegment(newSegment, perThread);\n            }\n          }\n        }\n\n        if (anythingFlushed) {\n          clearThreadBindings();\n\n          sequenceIDLock.lock();\n          try {\n            flushedSequenceID = sequenceID;\n          } finally {\n            sequenceIDLock.unlock();\n          }\n          numDocsInRAM.set(0);\n        }\n        \n        if (flushDeletes) {\n          deletesInRAM.clear();\n        }\n\n\n        return anythingFlushed;\n      }\n    });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"334c1175813aea771a71728cd2c4ee4754fd0603","date":1279710173,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#flushAllThreads(boolean,boolean).mjava","sourceNew":null,"sourceOld":"  final boolean flushAllThreads(final boolean flushDocStores, final boolean flushDeletes)\n      throws IOException {\n    return threadPool.executeAllThreads(new DocumentsWriterThreadPool.AllThreadsTask<Boolean>() {\n      @Override\n      public Boolean process(Iterator<DocumentsWriterPerThread> threadsIterator) throws IOException {\n        boolean anythingFlushed = false;\n        \n        if (flushDeletes) {\n          synchronized (indexWriter) {\n            if (applyDeletes(indexWriter.segmentInfos)) {\n              indexWriter.checkpoint();\n            }\n          }\n        }\n\n        while (threadsIterator.hasNext()) {\n          boolean perThreadFlushDocStores = flushDocStores;\n          DocumentsWriterPerThread perThread = threadsIterator.next();\n          final int numDocs = perThread.getNumDocsInRAM();\n          \n          // Always flush docs if there are any\n          boolean flushDocs = numDocs > 0;\n          \n          String docStoreSegment = perThread.getDocStoreSegment();\n          if (docStoreSegment == null) {\n            perThreadFlushDocStores = false;\n          }\n          int docStoreOffset = perThread.getDocStoreOffset();\n          boolean docStoreIsCompoundFile = false;\n          if (perThreadFlushDocStores\n              && (!flushDocs || !perThread.getSegment().equals(perThread.getDocStoreSegment()))) {\n            // We must separately flush the doc store\n            if (infoStream != null) {\n              message(\"  flush shared docStore segment \" + docStoreSegment);\n            }\n            docStoreIsCompoundFile = flushDocStores(perThread);\n            flushDocStores(perThread);\n            perThreadFlushDocStores = false;\n          }\n\n          String segment = perThread.getSegment();\n\n          // If we are flushing docs, segment must not be null:\n          assert segment != null || !flushDocs;\n    \n          if (flushDocs) {\n            SegmentInfo newSegment = perThread.flush(perThreadFlushDocStores);\n            \n            if (newSegment != null) {\n              anythingFlushed = true;\n              \n              if (0 == docStoreOffset && perThreadFlushDocStores) {\n                // This means we are flushing private doc stores\n                // with this segment, so it will not be shared\n                // with other segments\n                assert docStoreSegment != null;\n                assert docStoreSegment.equals(segment);\n                docStoreOffset = -1;\n                docStoreSegment = null;\n                docStoreIsCompoundFile = false;\n              }\n              newSegment.setDocStore(docStoreOffset, docStoreSegment, docStoreIsCompoundFile);\n              \n              IndexWriter.setDiagnostics(newSegment, \"flush\");\n              finishFlushedSegment(newSegment, perThread);\n            }\n          }\n        }\n\n        if (anythingFlushed) {\n          clearThreadBindings();\n\n          sequenceIDLock.lock();\n          try {\n            flushedSequenceID = sequenceID;\n          } finally {\n            sequenceIDLock.unlock();\n          }\n          numDocsInRAM.set(0);\n        }\n        \n        if (flushDeletes) {\n          deletesInRAM.clear();\n        }\n\n\n        return anythingFlushed;\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8fe956d65251358d755c56f14fe8380644790e47","date":1279711318,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#flushAllThreads(boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  final boolean flushAllThreads(final boolean flushDocStores, final boolean flushDeletes)\n      throws IOException {\n    return threadPool.executeAllThreads(new DocumentsWriterThreadPool.AllThreadsTask<Boolean>() {\n      @Override\n      public Boolean process(Iterator<DocumentsWriterPerThread> threadsIterator) throws IOException {\n        boolean anythingFlushed = false;\n        \n        if (flushDeletes) {\n          synchronized (indexWriter) {\n            if (applyDeletes(indexWriter.segmentInfos)) {\n              indexWriter.checkpoint();\n            }\n          }\n        }\n\n        while (threadsIterator.hasNext()) {\n          boolean perThreadFlushDocStores = flushDocStores;\n          DocumentsWriterPerThread perThread = threadsIterator.next();\n          final int numDocs = perThread.getNumDocsInRAM();\n          \n          // Always flush docs if there are any\n          boolean flushDocs = numDocs > 0;\n          \n          String docStoreSegment = perThread.getDocStoreSegment();\n          if (docStoreSegment == null) {\n            perThreadFlushDocStores = false;\n          }\n          int docStoreOffset = perThread.getDocStoreOffset();\n          boolean docStoreIsCompoundFile = false;\n          if (perThreadFlushDocStores\n              && (!flushDocs || !perThread.getSegment().equals(perThread.getDocStoreSegment()))) {\n            // We must separately flush the doc store\n            if (infoStream != null) {\n              message(\"  flush shared docStore segment \" + docStoreSegment);\n            }\n            docStoreIsCompoundFile = flushDocStores(perThread);\n            flushDocStores(perThread);\n            perThreadFlushDocStores = false;\n          }\n\n          String segment = perThread.getSegment();\n\n          // If we are flushing docs, segment must not be null:\n          assert segment != null || !flushDocs;\n    \n          if (flushDocs) {\n            SegmentInfo newSegment = perThread.flush(perThreadFlushDocStores);\n            \n            if (newSegment != null) {\n              anythingFlushed = true;\n              \n              if (0 == docStoreOffset && perThreadFlushDocStores) {\n                // This means we are flushing private doc stores\n                // with this segment, so it will not be shared\n                // with other segments\n                assert docStoreSegment != null;\n                assert docStoreSegment.equals(segment);\n                docStoreOffset = -1;\n                docStoreSegment = null;\n                docStoreIsCompoundFile = false;\n              }\n              newSegment.setDocStore(docStoreOffset, docStoreSegment, docStoreIsCompoundFile);\n              \n              IndexWriter.setDiagnostics(newSegment, \"flush\");\n              finishFlushedSegment(newSegment, perThread);\n            }\n          }\n        }\n\n        if (anythingFlushed) {\n          clearThreadBindings();\n\n          sequenceIDLock.lock();\n          try {\n            flushedSequenceID = sequenceID;\n          } finally {\n            sequenceIDLock.unlock();\n          }\n          numDocsInRAM.set(0);\n        }\n        \n        if (flushDeletes) {\n          deletesInRAM.clear();\n        }\n\n\n        return anythingFlushed;\n      }\n    });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"833a7987bc1c94455fde83e3311f72bddedcfb93","date":1279951470,"type":5,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#flushAllThreads(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#flushAllThreads(boolean,boolean).mjava","sourceNew":"  final boolean flushAllThreads(final boolean flushDeletes)\n      throws IOException {\n    return threadPool.executeAllThreads(new DocumentsWriterThreadPool.AllThreadsTask<Boolean>() {\n      @Override\n      public Boolean process(Iterator<DocumentsWriterPerThread> threadsIterator) throws IOException {\n        boolean anythingFlushed = false;\n        \n        if (flushDeletes) {\n          if (applyDeletes(indexWriter.segmentInfos)) {\n            indexWriter.checkpoint();\n          }\n        }\n\n        while (threadsIterator.hasNext()) {\n          DocumentsWriterPerThread perThread = threadsIterator.next();\n          final int numDocs = perThread.getNumDocsInRAM();\n          \n          // Always flush docs if there are any\n          boolean flushDocs = numDocs > 0;\n          \n          String segment = perThread.getSegment();\n\n          // If we are flushing docs, segment must not be null:\n          assert segment != null || !flushDocs;\n    \n          if (flushDocs) {\n            SegmentInfo newSegment = perThread.flush();\n            \n            if (newSegment != null) {\n              anythingFlushed = true;\n              \n              IndexWriter.setDiagnostics(newSegment, \"flush\");\n              finishFlushedSegment(newSegment, perThread);\n            }\n          }\n        }\n\n        if (anythingFlushed) {\n          clearThreadBindings();\n\n          sequenceIDLock.lock();\n          try {\n            flushedSequenceID = sequenceID;\n          } finally {\n            sequenceIDLock.unlock();\n          }\n          numDocsInRAM.set(0);\n        }\n        \n        if (flushDeletes) {\n          deletesInRAM.clear();\n        }\n\n\n        return anythingFlushed;\n      }\n    });\n  }\n\n","sourceOld":"  final boolean flushAllThreads(final boolean flushDocStores, final boolean flushDeletes)\n      throws IOException {\n    return threadPool.executeAllThreads(new DocumentsWriterThreadPool.AllThreadsTask<Boolean>() {\n      @Override\n      public Boolean process(Iterator<DocumentsWriterPerThread> threadsIterator) throws IOException {\n        boolean anythingFlushed = false;\n        \n        if (flushDeletes) {\n          synchronized (indexWriter) {\n            if (applyDeletes(indexWriter.segmentInfos)) {\n              indexWriter.checkpoint();\n            }\n          }\n        }\n\n        while (threadsIterator.hasNext()) {\n          boolean perThreadFlushDocStores = flushDocStores;\n          DocumentsWriterPerThread perThread = threadsIterator.next();\n          final int numDocs = perThread.getNumDocsInRAM();\n          \n          // Always flush docs if there are any\n          boolean flushDocs = numDocs > 0;\n          \n          String docStoreSegment = perThread.getDocStoreSegment();\n          if (docStoreSegment == null) {\n            perThreadFlushDocStores = false;\n          }\n          int docStoreOffset = perThread.getDocStoreOffset();\n          boolean docStoreIsCompoundFile = false;\n          if (perThreadFlushDocStores\n              && (!flushDocs || !perThread.getSegment().equals(perThread.getDocStoreSegment()))) {\n            // We must separately flush the doc store\n            if (infoStream != null) {\n              message(\"  flush shared docStore segment \" + docStoreSegment);\n            }\n            docStoreIsCompoundFile = flushDocStores(perThread);\n            flushDocStores(perThread);\n            perThreadFlushDocStores = false;\n          }\n\n          String segment = perThread.getSegment();\n\n          // If we are flushing docs, segment must not be null:\n          assert segment != null || !flushDocs;\n    \n          if (flushDocs) {\n            SegmentInfo newSegment = perThread.flush(perThreadFlushDocStores);\n            \n            if (newSegment != null) {\n              anythingFlushed = true;\n              \n              if (0 == docStoreOffset && perThreadFlushDocStores) {\n                // This means we are flushing private doc stores\n                // with this segment, so it will not be shared\n                // with other segments\n                assert docStoreSegment != null;\n                assert docStoreSegment.equals(segment);\n                docStoreOffset = -1;\n                docStoreSegment = null;\n                docStoreIsCompoundFile = false;\n              }\n              newSegment.setDocStore(docStoreOffset, docStoreSegment, docStoreIsCompoundFile);\n              \n              IndexWriter.setDiagnostics(newSegment, \"flush\");\n              finishFlushedSegment(newSegment, perThread);\n            }\n          }\n        }\n\n        if (anythingFlushed) {\n          clearThreadBindings();\n\n          sequenceIDLock.lock();\n          try {\n            flushedSequenceID = sequenceID;\n          } finally {\n            sequenceIDLock.unlock();\n          }\n          numDocsInRAM.set(0);\n        }\n        \n        if (flushDeletes) {\n          deletesInRAM.clear();\n        }\n\n\n        return anythingFlushed;\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":["5ef87af8c7bd0f8429622b83aa74202383f2e757"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8fe956d65251358d755c56f14fe8380644790e47":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"334c1175813aea771a71728cd2c4ee4754fd0603":["9b832cbed6eb3d54a8bb9339296bdda8eeb53014"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["334c1175813aea771a71728cd2c4ee4754fd0603"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["8fe956d65251358d755c56f14fe8380644790e47"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8fe956d65251358d755c56f14fe8380644790e47","9b832cbed6eb3d54a8bb9339296bdda8eeb53014"],"8fe956d65251358d755c56f14fe8380644790e47":["833a7987bc1c94455fde83e3311f72bddedcfb93"],"334c1175813aea771a71728cd2c4ee4754fd0603":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["334c1175813aea771a71728cd2c4ee4754fd0603"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"833a7987bc1c94455fde83e3311f72bddedcfb93":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","833a7987bc1c94455fde83e3311f72bddedcfb93"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}