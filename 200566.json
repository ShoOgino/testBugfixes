{"path":"lucene/core/src/java/org/apache/lucene/search/DisjunctionMatchesIterator#fromTermsEnum(LeafReaderContext,int,String,BytesRefIterator).mjava","commits":[{"id":"657704b225b01c6ff4bada5b6667f1f60aaaad0f","date":1523436207,"type":0,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DisjunctionMatchesIterator#fromTermsEnum(LeafReaderContext,int,String,BytesRefIterator).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Create a {@link DisjunctionMatchesIterator} over a list of terms extracted from a {@link BytesRefIterator}\n   *\n   * Only terms that have at least one match in the given document will be included\n   */\n  static MatchesIterator fromTermsEnum(LeafReaderContext context, int doc, String field, BytesRefIterator terms) throws IOException {\n    Objects.requireNonNull(field);\n    List<MatchesIterator> mis = new ArrayList<>();\n    Terms t = context.reader().terms(field);\n    if (t == null)\n      return null;\n    TermsEnum te = t.iterator();\n    PostingsEnum reuse = null;\n    for (BytesRef term = terms.next(); term != null; term = terms.next()) {\n      if (te.seekExact(term)) {\n        PostingsEnum pe = te.postings(reuse, PostingsEnum.OFFSETS);\n        if (pe.advance(doc) == doc) {\n          // TODO do we want to use the copied term here, or instead create a label that associates all of the TMIs with a single term?\n          mis.add(new TermMatchesIterator(BytesRef.deepCopyOf(term), pe));\n          reuse = null;\n        }\n        else {\n          reuse = pe;\n        }\n      }\n    }\n    if (mis.size() == 0)\n      return null;\n    if (mis.size() == 1)\n      return mis.get(0);\n    return new DisjunctionMatchesIterator(mis);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"43345f1452f9510f8aaadae6156fe0c834e7d957","date":1523483670,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DisjunctionMatchesIterator#fromTermsEnum(LeafReaderContext,int,String,BytesRefIterator).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Create a {@link DisjunctionMatchesIterator} over a list of terms extracted from a {@link BytesRefIterator}\n   *\n   * Only terms that have at least one match in the given document will be included\n   */\n  static MatchesIterator fromTermsEnum(LeafReaderContext context, int doc, String field, BytesRefIterator terms) throws IOException {\n    Objects.requireNonNull(field);\n    List<MatchesIterator> mis = new ArrayList<>();\n    Terms t = context.reader().terms(field);\n    if (t == null)\n      return null;\n    TermsEnum te = t.iterator();\n    PostingsEnum reuse = null;\n    for (BytesRef term = terms.next(); term != null; term = terms.next()) {\n      if (te.seekExact(term)) {\n        PostingsEnum pe = te.postings(reuse, PostingsEnum.OFFSETS);\n        if (pe.advance(doc) == doc) {\n          // TODO do we want to use the copied term here, or instead create a label that associates all of the TMIs with a single term?\n          mis.add(new TermMatchesIterator(BytesRef.deepCopyOf(term), pe));\n          reuse = null;\n        }\n        else {\n          reuse = pe;\n        }\n      }\n    }\n    if (mis.size() == 0)\n      return null;\n    if (mis.size() == 1)\n      return mis.get(0);\n    return new DisjunctionMatchesIterator(mis);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70f096f495a4a51c97c82cf6fd06e107c12f797b","date":1523545198,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DisjunctionMatchesIterator#fromTermsEnum(LeafReaderContext,int,String,BytesRefIterator).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DisjunctionMatchesIterator#fromTermsEnum(LeafReaderContext,int,String,BytesRefIterator).mjava","sourceNew":"  /**\n   * Create a {@link DisjunctionMatchesIterator} over a list of terms extracted from a {@link BytesRefIterator}\n   *\n   * Only terms that have at least one match in the given document will be included\n   */\n  static MatchesIterator fromTermsEnum(LeafReaderContext context, int doc, String field, BytesRefIterator terms) throws IOException {\n    Objects.requireNonNull(field);\n    List<MatchesIterator> mis = new ArrayList<>();\n    Terms t = context.reader().terms(field);\n    if (t == null)\n      return null;\n    TermsEnum te = t.iterator();\n    PostingsEnum reuse = null;\n    for (BytesRef term = terms.next(); term != null; term = terms.next()) {\n      if (te.seekExact(term)) {\n        PostingsEnum pe = te.postings(reuse, PostingsEnum.OFFSETS);\n        if (pe.advance(doc) == doc) {\n          // TODO do we want to use the copied term here, or instead create a label that associates all of the TMIs with a single term?\n          mis.add(new TermMatchesIterator(BytesRef.deepCopyOf(term), pe));\n          reuse = null;\n        }\n        else {\n          reuse = pe;\n        }\n      }\n    }\n    return fromSubIterators(mis);\n  }\n\n","sourceOld":"  /**\n   * Create a {@link DisjunctionMatchesIterator} over a list of terms extracted from a {@link BytesRefIterator}\n   *\n   * Only terms that have at least one match in the given document will be included\n   */\n  static MatchesIterator fromTermsEnum(LeafReaderContext context, int doc, String field, BytesRefIterator terms) throws IOException {\n    Objects.requireNonNull(field);\n    List<MatchesIterator> mis = new ArrayList<>();\n    Terms t = context.reader().terms(field);\n    if (t == null)\n      return null;\n    TermsEnum te = t.iterator();\n    PostingsEnum reuse = null;\n    for (BytesRef term = terms.next(); term != null; term = terms.next()) {\n      if (te.seekExact(term)) {\n        PostingsEnum pe = te.postings(reuse, PostingsEnum.OFFSETS);\n        if (pe.advance(doc) == doc) {\n          // TODO do we want to use the copied term here, or instead create a label that associates all of the TMIs with a single term?\n          mis.add(new TermMatchesIterator(BytesRef.deepCopyOf(term), pe));\n          reuse = null;\n        }\n        else {\n          reuse = pe;\n        }\n      }\n    }\n    if (mis.size() == 0)\n      return null;\n    if (mis.size() == 1)\n      return mis.get(0);\n    return new DisjunctionMatchesIterator(mis);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ffb7b0a1201e65140f72d01a08b2bc34b0cfc364","date":1524498677,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DisjunctionMatchesIterator#fromTermsEnum(LeafReaderContext,int,String,BytesRefIterator).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DisjunctionMatchesIterator#fromTermsEnum(LeafReaderContext,int,String,BytesRefIterator).mjava","sourceNew":"  /**\n   * Create a {@link DisjunctionMatchesIterator} over a list of terms extracted from a {@link BytesRefIterator}\n   *\n   * Only terms that have at least one match in the given document will be included\n   */\n  static MatchesIterator fromTermsEnum(LeafReaderContext context, int doc, String field, BytesRefIterator terms) throws IOException {\n    Objects.requireNonNull(field);\n    List<MatchesIterator> mis = new ArrayList<>();\n    Terms t = context.reader().terms(field);\n    if (t == null)\n      return null;\n    TermsEnum te = t.iterator();\n    PostingsEnum reuse = null;\n    for (BytesRef term = terms.next(); term != null; term = terms.next()) {\n      if (te.seekExact(term)) {\n        PostingsEnum pe = te.postings(reuse, PostingsEnum.OFFSETS);\n        if (pe.advance(doc) == doc) {\n          mis.add(new TermMatchesIterator(pe));\n          reuse = null;\n        }\n        else {\n          reuse = pe;\n        }\n      }\n    }\n    return fromSubIterators(mis);\n  }\n\n","sourceOld":"  /**\n   * Create a {@link DisjunctionMatchesIterator} over a list of terms extracted from a {@link BytesRefIterator}\n   *\n   * Only terms that have at least one match in the given document will be included\n   */\n  static MatchesIterator fromTermsEnum(LeafReaderContext context, int doc, String field, BytesRefIterator terms) throws IOException {\n    Objects.requireNonNull(field);\n    List<MatchesIterator> mis = new ArrayList<>();\n    Terms t = context.reader().terms(field);\n    if (t == null)\n      return null;\n    TermsEnum te = t.iterator();\n    PostingsEnum reuse = null;\n    for (BytesRef term = terms.next(); term != null; term = terms.next()) {\n      if (te.seekExact(term)) {\n        PostingsEnum pe = te.postings(reuse, PostingsEnum.OFFSETS);\n        if (pe.advance(doc) == doc) {\n          // TODO do we want to use the copied term here, or instead create a label that associates all of the TMIs with a single term?\n          mis.add(new TermMatchesIterator(BytesRef.deepCopyOf(term), pe));\n          reuse = null;\n        }\n        else {\n          reuse = pe;\n        }\n      }\n    }\n    return fromSubIterators(mis);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41ebc07bccf12a902ca6a0077910d18ee38b695f","date":1532336521,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DisjunctionMatchesIterator#fromTermsEnum(LeafReaderContext,int,Query,String,BytesRefIterator).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DisjunctionMatchesIterator#fromTermsEnum(LeafReaderContext,int,String,BytesRefIterator).mjava","sourceNew":"  /**\n   * Create a {@link DisjunctionMatchesIterator} over a list of terms extracted from a {@link BytesRefIterator}\n   *\n   * Only terms that have at least one match in the given document will be included\n   */\n  static MatchesIterator fromTermsEnum(LeafReaderContext context, int doc, Query query, String field, BytesRefIterator terms) throws IOException {\n    Objects.requireNonNull(field);\n    List<MatchesIterator> mis = new ArrayList<>();\n    Terms t = context.reader().terms(field);\n    if (t == null)\n      return null;\n    TermsEnum te = t.iterator();\n    PostingsEnum reuse = null;\n    for (BytesRef term = terms.next(); term != null; term = terms.next()) {\n      if (te.seekExact(term)) {\n        PostingsEnum pe = te.postings(reuse, PostingsEnum.OFFSETS);\n        if (pe.advance(doc) == doc) {\n          mis.add(new TermMatchesIterator(query, pe));\n          reuse = null;\n        }\n        else {\n          reuse = pe;\n        }\n      }\n    }\n    return fromSubIterators(mis);\n  }\n\n","sourceOld":"  /**\n   * Create a {@link DisjunctionMatchesIterator} over a list of terms extracted from a {@link BytesRefIterator}\n   *\n   * Only terms that have at least one match in the given document will be included\n   */\n  static MatchesIterator fromTermsEnum(LeafReaderContext context, int doc, String field, BytesRefIterator terms) throws IOException {\n    Objects.requireNonNull(field);\n    List<MatchesIterator> mis = new ArrayList<>();\n    Terms t = context.reader().terms(field);\n    if (t == null)\n      return null;\n    TermsEnum te = t.iterator();\n    PostingsEnum reuse = null;\n    for (BytesRef term = terms.next(); term != null; term = terms.next()) {\n      if (te.seekExact(term)) {\n        PostingsEnum pe = te.postings(reuse, PostingsEnum.OFFSETS);\n        if (pe.advance(doc) == doc) {\n          mis.add(new TermMatchesIterator(pe));\n          reuse = null;\n        }\n        else {\n          reuse = pe;\n        }\n      }\n    }\n    return fromSubIterators(mis);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ffb7b0a1201e65140f72d01a08b2bc34b0cfc364":["70f096f495a4a51c97c82cf6fd06e107c12f797b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"657704b225b01c6ff4bada5b6667f1f60aaaad0f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","657704b225b01c6ff4bada5b6667f1f60aaaad0f"],"70f096f495a4a51c97c82cf6fd06e107c12f797b":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["41ebc07bccf12a902ca6a0077910d18ee38b695f"],"41ebc07bccf12a902ca6a0077910d18ee38b695f":["ffb7b0a1201e65140f72d01a08b2bc34b0cfc364"]},"commit2Childs":{"ffb7b0a1201e65140f72d01a08b2bc34b0cfc364":["41ebc07bccf12a902ca6a0077910d18ee38b695f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["657704b225b01c6ff4bada5b6667f1f60aaaad0f","43345f1452f9510f8aaadae6156fe0c834e7d957"],"657704b225b01c6ff4bada5b6667f1f60aaaad0f":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["70f096f495a4a51c97c82cf6fd06e107c12f797b"],"70f096f495a4a51c97c82cf6fd06e107c12f797b":["ffb7b0a1201e65140f72d01a08b2bc34b0cfc364"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"41ebc07bccf12a902ca6a0077910d18ee38b695f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}