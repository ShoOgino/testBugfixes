{"path":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","commits":[{"id":"b1add9ddc0005b07550d4350720aac22dc9886b3","date":1295549635,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW.finishTerm seg=\" + segment + \" term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fd1bfe3cedf815c14939d170d53031c88eb5c444","date":1295896578,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW.finishTerm seg=\" + segment + \" term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW.finishTerm seg=\" + segment + \" term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","date":1297938719,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW.finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","sourceOld":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW.finishTerm seg=\" + segment + \" term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW.finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","sourceOld":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW.finishTerm seg=\" + segment + \" term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW.finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","sourceOld":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW.finishTerm seg=\" + segment + \" term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60ba444201d2570214b6fcf1d15600dc1a01f548","date":1313868045,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","sourceOld":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW.finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e6e919043fa85ee891123768dd655a98edbbf63c","date":1322225413,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","sourceOld":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copy(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsWriter.TermsWriter#finishTerm(BytesRef,TermStats).mjava","sourceNew":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","sourceOld":"    @Override\n    public void finishTerm(BytesRef text, TermStats stats) throws IOException {\n\n      assert stats.docFreq > 0;\n      //System.out.println(\"BTW: finishTerm term=\" + fieldInfo.name + \":\" + text.utf8ToString() + \" \" + text + \" seg=\" + segment + \" df=\" + stats.docFreq);\n\n      final boolean isIndexTerm = fieldIndexWriter.checkIndexTerm(text, stats);\n\n      if (isIndexTerm) {\n        if (pendingCount > 0) {\n          // Instead of writing each term, live, we gather terms\n          // in RAM in a pending buffer, and then write the\n          // entire block in between index terms:\n          flushBlock();\n        }\n        fieldIndexWriter.add(text, stats, out.getFilePointer());\n        //System.out.println(\"  index term!\");\n      }\n\n      if (pendingTerms.length == pendingCount) {\n        final TermEntry[] newArray = new TermEntry[ArrayUtil.oversize(pendingCount+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(pendingTerms, 0, newArray, 0, pendingCount);\n        for(int i=pendingCount;i<newArray.length;i++) {\n          newArray[i] = new TermEntry();\n        }\n        pendingTerms = newArray;\n      }\n      final TermEntry te = pendingTerms[pendingCount];\n      te.term.copyBytes(text);\n      te.stats = stats;\n\n      pendingCount++;\n\n      postingsWriter.finishTerm(stats);\n      numTerms++;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"60ba444201d2570214b6fcf1d15600dc1a01f548":["4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"],"fd1bfe3cedf815c14939d170d53031c88eb5c444":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["29ef99d61cda9641b6250bf9567329a6e65f901d","4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"],"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762":["b1add9ddc0005b07550d4350720aac22dc9886b3"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b1add9ddc0005b07550d4350720aac22dc9886b3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b1add9ddc0005b07550d4350720aac22dc9886b3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["e6e919043fa85ee891123768dd655a98edbbf63c"],"e6e919043fa85ee891123768dd655a98edbbf63c":["60ba444201d2570214b6fcf1d15600dc1a01f548"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["fd1bfe3cedf815c14939d170d53031c88eb5c444","4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"]},"commit2Childs":{"60ba444201d2570214b6fcf1d15600dc1a01f548":["e6e919043fa85ee891123768dd655a98edbbf63c"],"fd1bfe3cedf815c14939d170d53031c88eb5c444":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":[],"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762":["60ba444201d2570214b6fcf1d15600dc1a01f548","f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["f1bdbf92da222965b46c0a942c3857ba56e5c638"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fd1bfe3cedf815c14939d170d53031c88eb5c444","29ef99d61cda9641b6250bf9567329a6e65f901d","b1add9ddc0005b07550d4350720aac22dc9886b3"],"b1add9ddc0005b07550d4350720aac22dc9886b3":["4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","29ef99d61cda9641b6250bf9567329a6e65f901d"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e6e919043fa85ee891123768dd655a98edbbf63c":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}