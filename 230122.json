{"path":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"/dev/null","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n    add.allowDups = !overwrite;\n    add.overwriteCommitted = overwrite;\n    add.overwritePending = overwrite;\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    System.out.println(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    System.out.println(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":null,"sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n    add.allowDups = !overwrite;\n    add.overwriteCommitted = overwrite;\n    add.overwritePending = overwrite;\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    System.out.println(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    System.out.println(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n    add.allowDups = !overwrite;\n    add.overwriteCommitted = overwrite;\n    add.overwritePending = overwrite;\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    System.out.println(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    System.out.println(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n    add.allowDups = !overwrite;\n    add.overwriteCommitted = overwrite;\n    add.overwritePending = overwrite;\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    System.out.println(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    System.out.println(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"/dev/null","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n    add.allowDups = !overwrite;\n    add.overwriteCommitted = overwrite;\n    add.overwritePending = overwrite;\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    System.out.println(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    System.out.println(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"043b67f0af6b47d4946d52b3d754e09b81dbb1cd","date":1274220737,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n    add.allowDups = !overwrite;\n    add.overwriteCommitted = overwrite;\n    add.overwritePending = overwrite;\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n    add.allowDups = !overwrite;\n    add.overwriteCommitted = overwrite;\n    add.overwritePending = overwrite;\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    System.out.println(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    System.out.println(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5653af107efef582afd0bc6aff175972359fdd6","date":1293390698,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n    add.allowDups = !overwrite;\n    add.overwriteCommitted = overwrite;\n    add.overwritePending = overwrite;\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5ae62bcdfd4a0689a745ab1d38c6bd1c7c390cfa","date":1293733647,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c","date":1294014627,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n    add.allowDups = !overwrite;\n    add.overwriteCommitted = overwrite;\n    add.overwritePending = overwrite;\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f78c4193e9cdb55c470990e3b32f3a02c446812b","date":1294090250,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Fieldable f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Fieldable f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand();\n    add.allowDups = !overwrite;\n    add.overwriteCommitted = overwrite;\n    add.overwritePending = overwrite;\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand());\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Fieldable f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Field f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Fieldable f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Fieldable f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Fieldable f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Fieldable f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","pathOld":"solr/src/test/org/apache/solr/update/TestIndexingPerformance#testIndexingPerf().mjava","sourceNew":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Fieldable f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","sourceOld":"  public void testIndexingPerf() throws IOException {\n    int iter=1000;\n    String iterS = System.getProperty(\"iter\");\n    if (iterS != null) iter=Integer.parseInt(iterS);\n    boolean includeDoc = Boolean.parseBoolean(System.getProperty(\"includeDoc\",\"true\")); // include the time to create the document\n    boolean overwrite = Boolean.parseBoolean(System.getProperty(\"overwrite\",\"false\"));\n    String doc = System.getProperty(\"doc\");\n    if (doc != null) {\n      StrUtils.splitSmart(doc,\",\",true);\n    }\n\n\n    SolrQueryRequest req = lrf.makeRequest();\n    IndexSchema schema = req.getSchema();\n    UpdateHandler updateHandler = req.getCore().getUpdateHandler();\n\n    String[] fields = {\"text\",\"simple\"\n            ,\"text\",\"test\"\n            ,\"text\",\"how now brown cow\"\n            ,\"text\",\"what's that?\"\n            ,\"text\",\"radical!\"\n            ,\"text\",\"what's all this about, anyway?\"\n            ,\"text\",\"just how fast is this text indexing?\"\n    };\n\n\n  /***\n    String[] fields = {\n            \"a_i\",\"1\"\n            ,\"b_i\",\"2\"\n            ,\"c_i\",\"3\"\n            ,\"d_i\",\"4\"\n            ,\"e_i\",\"5\"\n            ,\"f_i\",\"6\"\n            ,\"g_i\",\"7\"\n            ,\"h_i\",\"8\"\n            ,\"i_i\",\"9\"\n            ,\"j_i\",\"0\"\n            ,\"k_i\",\"0\"\n    };\n   ***/\n\n    long start = System.currentTimeMillis();\n\n    AddUpdateCommand add = new AddUpdateCommand(req);\n\n    Field idField=null;\n\n    for (int i=0; i<iter; i++) {\n      if (includeDoc || add.doc==null) {\n        add.doc = new Document();\n        idField = new Field(\"id\",\"\", Field.Store.YES, Field.Index.NOT_ANALYZED);\n        add.doc.add(idField);\n        for (int j=0; j<fields.length; j+=2) {\n          String field = fields[j];\n          String val = fields[j+1];\n          Fieldable f = schema.getField(field).createField(val, 1.0f);\n          add.doc.add(f);\n        }\n      }\n      idField.setValue(Integer.toString(i));\n      updateHandler.addDoc(add);\n    }\n    long end = System.currentTimeMillis();\n    log.info(\"includeDoc=\"+includeDoc+\" doc=\"+ Arrays.toString(fields));\n    log.info(\"iter=\"+iter +\" time=\" + (end-start) + \" throughput=\" + ((long)iter*1000)/(end-start));\n\n    //discard all the changes\n    updateHandler.rollback(new RollbackUpdateCommand(req));\n\n    req.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["043b67f0af6b47d4946d52b3d754e09b81dbb1cd","f78c4193e9cdb55c470990e3b32f3a02c446812b"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["f78c4193e9cdb55c470990e3b32f3a02c446812b","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c":["043b67f0af6b47d4946d52b3d754e09b81dbb1cd","5ae62bcdfd4a0689a745ab1d38c6bd1c7c390cfa"],"043b67f0af6b47d4946d52b3d754e09b81dbb1cd":["1da8d55113b689b06716246649de6f62430f15c0"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["f78c4193e9cdb55c470990e3b32f3a02c446812b"],"b5653af107efef582afd0bc6aff175972359fdd6":["043b67f0af6b47d4946d52b3d754e09b81dbb1cd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["f78c4193e9cdb55c470990e3b32f3a02c446812b"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"5ae62bcdfd4a0689a745ab1d38c6bd1c7c390cfa":["b5653af107efef582afd0bc6aff175972359fdd6"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c","f78c4193e9cdb55c470990e3b32f3a02c446812b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"],"f78c4193e9cdb55c470990e3b32f3a02c446812b":["5ae62bcdfd4a0689a745ab1d38c6bd1c7c390cfa"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":[],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"1da8d55113b689b06716246649de6f62430f15c0":["043b67f0af6b47d4946d52b3d754e09b81dbb1cd"],"ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"043b67f0af6b47d4946d52b3d754e09b81dbb1cd":["70ad682703b8585f5d0a637efec044d57ec05efb","ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c","b5653af107efef582afd0bc6aff175972359fdd6"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"b5653af107efef582afd0bc6aff175972359fdd6":["5ae62bcdfd4a0689a745ab1d38c6bd1c7c390cfa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"5ae62bcdfd4a0689a745ab1d38c6bd1c7c390cfa":["ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c","f78c4193e9cdb55c470990e3b32f3a02c446812b"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"f78c4193e9cdb55c470990e3b32f3a02c446812b":["70ad682703b8585f5d0a637efec044d57ec05efb","c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee","868da859b43505d9d2a023bfeae6dd0c795f5295"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["70ad682703b8585f5d0a637efec044d57ec05efb","a258fbb26824fd104ed795e5d9033d2d040049ee","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}