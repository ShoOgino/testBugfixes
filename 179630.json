{"path":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","commits":[{"id":"283ff02f401ec3e7a2fad73643970f052383fb0c","date":1411407953,"type":1,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,String,DocSet,boolean,String[]).mjava","sourceNew":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n    final boolean calcDistinct = statsField.getCalcDistinct();\n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getAtomicReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getAtomicReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiSortedDocValues) {\n        ordinalMap = ((MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      AtomicReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          final SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","sourceOld":"  public static StatsValues getCounts(SolrIndexSearcher searcher, String fieldName, DocSet docs, boolean calcDistinct, String[] facet) throws IOException {\n    SchemaField schemaField = searcher.getSchema().getField(fieldName);\n    FieldType ft = schemaField.getType();\n    StatsValues res = StatsValuesFactory.createStatsValues(schemaField, calcDistinct);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetField, schemaField, facetSchemaField, calcDistinct);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getAtomicReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getAtomicReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiSortedDocValues) {\n        ordinalMap = ((MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      AtomicReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          final SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","sourceNew":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n    final boolean calcDistinct = statsField.getCalcDistinct();\n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getLeafReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getLeafReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiSortedDocValues) {\n        ordinalMap = ((MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          final SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","sourceOld":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n    final boolean calcDistinct = statsField.getCalcDistinct();\n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getAtomicReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getAtomicReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiSortedDocValues) {\n        ordinalMap = ((MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      AtomicReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          final SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d12bbc45d641864ffe03291bc30f178eb34e434c","date":1426001646,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","sourceNew":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getLeafReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getLeafReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiSortedDocValues) {\n        ordinalMap = ((MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          final SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","sourceOld":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n    final boolean calcDistinct = statsField.getCalcDistinct();\n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getLeafReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getLeafReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiSortedDocValues) {\n        ordinalMap = ((MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          final SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","sourceNew":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getLeafReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getLeafReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiSortedDocValues) {\n        ordinalMap = ((MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          final SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","sourceOld":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n    final boolean calcDistinct = statsField.getCalcDistinct();\n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getLeafReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getLeafReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiSortedDocValues) {\n        ordinalMap = ((MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          final SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","sourceNew":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getLeafReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiDocValues.MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getLeafReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiDocValues.MultiSortedDocValues) {\n        ordinalMap = ((MultiDocValues.MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","sourceOld":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getLeafReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getLeafReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiSortedDocValues) {\n        ordinalMap = ((MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          final SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","sourceNew":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getLeafReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiDocValues.MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getLeafReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiDocValues.MultiSortedDocValues) {\n        ordinalMap = ((MultiDocValues.MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","sourceOld":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getLeafReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getLeafReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiSortedDocValues) {\n        ordinalMap = ((MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          final SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e07c409cff8701e4dc3d45934b021a949a5a8822","date":1475694629,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","sourceNew":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getSlowAtomicReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiDocValues.MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getSlowAtomicReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiDocValues.MultiSortedDocValues) {\n        ordinalMap = ((MultiDocValues.MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","sourceOld":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getLeafReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiDocValues.MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getLeafReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiDocValues.MultiSortedDocValues) {\n        ordinalMap = ((MultiDocValues.MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/DocValuesStats#getCounts(SolrIndexSearcher,StatsField,DocSet,String[]).mjava","sourceNew":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getSlowAtomicReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiDocValues.MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getSlowAtomicReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiDocValues.MultiSortedDocValues) {\n        ordinalMap = ((MultiDocValues.MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","sourceOld":"  public static StatsValues getCounts(SolrIndexSearcher searcher, StatsField statsField, DocSet docs, String[] facet) throws IOException {\n\n    final SchemaField schemaField = statsField.getSchemaField(); \n\n    assert null != statsField.getSchemaField()\n      : \"DocValuesStats requires a StatsField using a SchemaField\";\n\n    final String fieldName = schemaField.getName();\n    final FieldType ft = schemaField.getType();\n    final StatsValues res = StatsValuesFactory.createStatsValues(statsField);\n    \n    //Initialize facetstats, if facets have been passed in\n    final FieldFacetStats[] facetStats = new FieldFacetStats[facet.length];\n    int upto = 0;\n       \n    for (String facetField : facet) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      SchemaField facetSchemaField = searcher.getSchema().getField(facetField);\n      facetStats[upto++] = new FieldFacetStats(searcher, facetSchemaField, statsField);\n    }\n    // TODO: remove multiValuedFieldCache(), check dv type / uninversion type?\n    final boolean multiValued = schemaField.multiValued() || ft.multiValuedFieldCache();\n\n    SortedSetDocValues si; // for term lookups only\n    OrdinalMap ordinalMap = null; // for mapping per-segment ords to global ones\n    if (multiValued) {\n      si = searcher.getLeafReader().getSortedSetDocValues(fieldName);\n      \n      if (si instanceof MultiSortedSetDocValues) {\n        ordinalMap = ((MultiSortedSetDocValues)si).mapping;\n      }\n    } else {\n      SortedDocValues single = searcher.getLeafReader().getSortedDocValues(fieldName);\n      si = single == null ? null : DocValues.singleton(single);\n      if (single instanceof MultiSortedDocValues) {\n        ordinalMap = ((MultiSortedDocValues)single).mapping;\n      }\n    }\n    if (si == null) {\n      si = DocValues.emptySortedSet();\n    }\n    if (si.getValueCount() >= Integer.MAX_VALUE) {\n      throw new UnsupportedOperationException(\"Currently this stats method is limited to \" + Integer.MAX_VALUE + \" unique terms\");\n    }\n    \n    int missingDocCountTotal = 0;\n    final int nTerms = (int) si.getValueCount();    \n    // count collection array only needs to be as big as the number of terms we are\n    // going to collect counts for.\n    final int[] counts = new int[nTerms];\n    \n    Filter filter = docs.getTopFilter();\n    List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    \n    for (int subIndex = 0; subIndex < leaves.size(); subIndex++) {\n      LeafReaderContext leaf = leaves.get(subIndex);\n      DocIdSet dis = filter.getDocIdSet(leaf, null); // solr docsets already exclude any deleted docs\n      DocIdSetIterator disi = null;\n      \n      if (dis != null) {\n        disi = dis.iterator();\n      }\n      if (disi != null) {\n        int docBase = leaf.docBase;\n        \n        if (multiValued) {\n          SortedSetDocValues sub = leaf.reader().getSortedSetDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySortedSet();\n          }\n          final SortedDocValues singleton = DocValues.unwrapSingleton(sub);\n          if (singleton != null) {\n            // some codecs may optimize SORTED_SET storage for single-valued fields\n            missingDocCountTotal += accumSingle(counts, docBase, facetStats, singleton, disi, subIndex, ordinalMap);\n          } else {\n            missingDocCountTotal += accumMulti(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n          }\n        } else {\n          SortedDocValues sub = leaf.reader().getSortedDocValues(fieldName);\n          if (sub == null) {\n            sub = DocValues.emptySorted();\n          }\n          missingDocCountTotal += accumSingle(counts, docBase, facetStats, sub, disi, subIndex, ordinalMap);\n        }\n      }\n    }\n    // add results in index order\n    for (int ord = 0; ord < counts.length; ord++) {\n      int count = counts[ord];\n\n      if (count > 0) {\n        final BytesRef value = si.lookupOrd(ord);\n        res.accumulate(value, count);\n        for (FieldFacetStats f : facetStats) {\n          f.accumulateTermNum(ord, value);\n        }\n      }\n    }\n    res.addMissing(missingDocCountTotal);\n    \n    if (facetStats.length > 0) {\n      for (FieldFacetStats f : facetStats) {\n        Map<String,StatsValues> facetStatsValues = f.facetStatsValues;\n        f.accumulateMissing();\n        res.addFacet(f.name, facetStatsValues);\n      }\n    }\n    \n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"283ff02f401ec3e7a2fad73643970f052383fb0c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["c9fb5f46e264daf5ba3860defe623a89d202dd87","d12bbc45d641864ffe03291bc30f178eb34e434c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["d12bbc45d641864ffe03291bc30f178eb34e434c","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["d12bbc45d641864ffe03291bc30f178eb34e434c"],"d12bbc45d641864ffe03291bc30f178eb34e434c":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"e07c409cff8701e4dc3d45934b021a949a5a8822":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["283ff02f401ec3e7a2fad73643970f052383fb0c"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["d12bbc45d641864ffe03291bc30f178eb34e434c","e07c409cff8701e4dc3d45934b021a949a5a8822"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e07c409cff8701e4dc3d45934b021a949a5a8822"]},"commit2Childs":{"283ff02f401ec3e7a2fad73643970f052383fb0c":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["283ff02f401ec3e7a2fad73643970f052383fb0c"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["e07c409cff8701e4dc3d45934b021a949a5a8822"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d12bbc45d641864ffe03291bc30f178eb34e434c":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"e07c409cff8701e4dc3d45934b021a949a5a8822":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","d12bbc45d641864ffe03291bc30f178eb34e434c"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}