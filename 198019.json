{"path":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","commits":[{"id":"addc47115aa3376d79985cd4abc9f8c6e212a032","date":1354202882,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","pathOld":"/dev/null","sourceNew":"  @Ignore(\"broken until we fix e.g. Lucene41's impl to actually handle suffixes correctly\")\n  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // TODO: Fix the CFS/suffixing of Lucene41DocValues so it actually works with this\n    final SimpleDocValuesFormat fast = SimpleDocValuesFormat.forName(\"Lucene41\");\n    final SimpleDocValuesFormat slow = SimpleDocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public SimpleDocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f6a1da6006901627fce15b90f0de569abdb1a4b","date":1354577328,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","sourceNew":"  // nocommit: fix e.g. Lucene41's impl to actually handle suffixes correctly\n  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // TODO: Fix the CFS/suffixing of Lucene41DocValues so it actually works with this\n    final SimpleDocValuesFormat fast = SimpleDocValuesFormat.forName(\"Memory\");\n    final SimpleDocValuesFormat slow = SimpleDocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public SimpleDocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  @Ignore(\"broken until we fix e.g. Lucene41's impl to actually handle suffixes correctly\")\n  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // TODO: Fix the CFS/suffixing of Lucene41DocValues so it actually works with this\n    final SimpleDocValuesFormat fast = SimpleDocValuesFormat.forName(\"Lucene41\");\n    final SimpleDocValuesFormat slow = SimpleDocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public SimpleDocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d751a328c5ac3a5d629d3c22667ca1617652e83e","date":1357735254,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","sourceNew":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // TODO: Fix the CFS/suffixing of Lucene41DocValues so it actually works with this\n    final SimpleDocValuesFormat fast = SimpleDocValuesFormat.forName(\"Memory\");\n    final SimpleDocValuesFormat slow = SimpleDocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public SimpleDocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // nocommit: fix e.g. Lucene41's impl to actually handle suffixes correctly\n  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // TODO: Fix the CFS/suffixing of Lucene41DocValues so it actually works with this\n    final SimpleDocValuesFormat fast = SimpleDocValuesFormat.forName(\"Memory\");\n    final SimpleDocValuesFormat slow = SimpleDocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public SimpleDocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200","date":1358521790,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","sourceNew":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // TODO: Fix the CFS/suffixing of Lucene41DocValues so it actually works with this\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Memory\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // TODO: Fix the CFS/suffixing of Lucene41DocValues so it actually works with this\n    final SimpleDocValuesFormat fast = SimpleDocValuesFormat.forName(\"Memory\");\n    final SimpleDocValuesFormat slow = SimpleDocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public SimpleDocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8f06b860886fc48ea071171354835b8aed8a94de","date":1358789970,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","sourceNew":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene41\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    // TODO: Fix the CFS/suffixing of Lucene41DocValues so it actually works with this\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Memory\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3fe3dfb6cc2d72874c6ebeee5cf8b6818434714e","date":1358793943,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","sourceNew":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene41\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef","date":1358808656,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","sourceNew":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new LongDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new PackedLongDocValuesField(\"dv1\", 5));\n    doc.add(new StraightBytesDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"423d89a2b3cc419b647c07c2b3fdbc54311d07f9","date":1358836612,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","sourceNew":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new LongDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2ec08217282b5e9df023dcdff55c745ff68b1c7d","date":1359392781,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/perfield/TestPerFieldDocValuesFormat#testTwoFieldsTwoFormats().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoTwoFieldsTwoFormats().mjava","sourceNew":"  // just a simple trivial test\n  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  // nocommit: if we are going to pass down suffixes to segmentread/writestate,\n  // then they should be respected by *all* codec apis!\n  public void testDemoTwoFieldsTwoFormats() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    final DocValuesFormat fast = DocValuesFormat.forName(\"Lucene42\");\n    final DocValuesFormat slow = DocValuesFormat.forName(\"SimpleText\");\n    iwc.setCodec(new Lucene42Codec() {\n      @Override\n      public DocValuesFormat getDocValuesFormatForField(String field) {\n        if (\"dv1\".equals(field)) {\n          return fast;\n        } else {\n          return slow;\n        }\n      }\n    });\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new NumericDocValuesField(\"dv1\", 5));\n    doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv1\");\n      assertEquals(5, dv.get(hits.scoreDocs[i].doc));\n      BinaryDocValues dv2 = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv2\");\n      dv2.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"addc47115aa3376d79985cd4abc9f8c6e212a032":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200":["d751a328c5ac3a5d629d3c22667ca1617652e83e"],"3fe3dfb6cc2d72874c6ebeee5cf8b6818434714e":["8f06b860886fc48ea071171354835b8aed8a94de"],"8f06b860886fc48ea071171354835b8aed8a94de":["b8acf0807ca5f38beda8e0f7d5ab46ff39f81200"],"d751a328c5ac3a5d629d3c22667ca1617652e83e":["1f6a1da6006901627fce15b90f0de569abdb1a4b"],"ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef":["3fe3dfb6cc2d72874c6ebeee5cf8b6818434714e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"423d89a2b3cc419b647c07c2b3fdbc54311d07f9":["ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef"],"1f6a1da6006901627fce15b90f0de569abdb1a4b":["addc47115aa3376d79985cd4abc9f8c6e212a032"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2ec08217282b5e9df023dcdff55c745ff68b1c7d":["423d89a2b3cc419b647c07c2b3fdbc54311d07f9"]},"commit2Childs":{"addc47115aa3376d79985cd4abc9f8c6e212a032":["1f6a1da6006901627fce15b90f0de569abdb1a4b"],"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200":["8f06b860886fc48ea071171354835b8aed8a94de"],"3fe3dfb6cc2d72874c6ebeee5cf8b6818434714e":["ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef"],"d751a328c5ac3a5d629d3c22667ca1617652e83e":["b8acf0807ca5f38beda8e0f7d5ab46ff39f81200"],"8f06b860886fc48ea071171354835b8aed8a94de":["3fe3dfb6cc2d72874c6ebeee5cf8b6818434714e"],"ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef":["423d89a2b3cc419b647c07c2b3fdbc54311d07f9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["addc47115aa3376d79985cd4abc9f8c6e212a032","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"423d89a2b3cc419b647c07c2b3fdbc54311d07f9":["2ec08217282b5e9df023dcdff55c745ff68b1c7d"],"1f6a1da6006901627fce15b90f0de569abdb1a4b":["d751a328c5ac3a5d629d3c22667ca1617652e83e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"2ec08217282b5e9df023dcdff55c745ff68b1c7d":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","2ec08217282b5e9df023dcdff55c745ff68b1c7d"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}