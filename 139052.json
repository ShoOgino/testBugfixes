{"path":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","pathOld":"modules/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","sourceNew":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    TokenStream source;\n\n    if (analyzerIn == null) analyzerIn = analyzer;\n\n    try {\n      source = analyzerIn.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze multiTerm term: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing multiTerm term: \" + part, e);\n    }\n    \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","sourceOld":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    TokenStream source;\n\n    if (analyzerIn == null) analyzerIn = analyzer;\n\n    try {\n      source = analyzerIn.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze multiTerm term: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing multiTerm term: \" + part, e);\n    }\n    \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","sourceNew":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    TokenStream source;\n\n    if (analyzerIn == null) analyzerIn = analyzer;\n\n    try {\n      source = analyzerIn.tokenStream(field, part);\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze multiTerm term: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing multiTerm term: \" + part, e);\n    }\n    \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","sourceOld":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    TokenStream source;\n\n    if (analyzerIn == null) analyzerIn = analyzer;\n\n    try {\n      source = analyzerIn.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze multiTerm term: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing multiTerm term: \" + part, e);\n    }\n    \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","bugFix":["f8d5405ac4f2510f9f83e07236792d1056c19640"],"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","sourceNew":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    TokenStream source;\n\n    if (analyzerIn == null) analyzerIn = analyzer;\n\n    try {\n      source = analyzerIn.tokenStream(field, part);\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze multiTerm term: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing multiTerm term: \" + part, e);\n    }\n    \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","sourceOld":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    TokenStream source;\n\n    if (analyzerIn == null) analyzerIn = analyzer;\n\n    try {\n      source = analyzerIn.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze multiTerm term: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing multiTerm term: \" + part, e);\n    }\n    \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"782ed6a4b4ba50ec19734fc8db4e570ee193d627","date":1381127065,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","sourceNew":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    if (analyzerIn == null) analyzerIn = analyzer;\n\n    try (TokenStream source = analyzerIn.tokenStream(field, part)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Error analyzing multiTerm term: \" + part, e);\n    }\n  }\n\n","sourceOld":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    TokenStream source;\n\n    if (analyzerIn == null) analyzerIn = analyzer;\n\n    try {\n      source = analyzerIn.tokenStream(field, part);\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze multiTerm term: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing multiTerm term: \" + part, e);\n    }\n    \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","bugFix":["3e492fb0f2bb0b4b47208286f9331ff55963c656","e6e919043fa85ee891123768dd655a98edbbf63c","b3d07f1ae3b58102f36f3393c397d78ba4e547a4","f8d5405ac4f2510f9f83e07236792d1056c19640","c83d6c4335f31cae14f625a222bc842f20073dcd"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1c1dd5dce93e4fa48898dabc7e012560acda425","date":1381334364,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","sourceNew":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    if (analyzerIn == null) analyzerIn = getAnalyzer();\n\n    try (TokenStream source = analyzerIn.tokenStream(field, part)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Error analyzing multiTerm term: \" + part, e);\n    }\n  }\n\n","sourceOld":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    if (analyzerIn == null) analyzerIn = analyzer;\n\n    try (TokenStream source = analyzerIn.tokenStream(field, part)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Error analyzing multiTerm term: \" + part, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"804b857d1066ab5185b3b9101bde41b0b71426ec","date":1435846169,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","sourceNew":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    if (analyzerIn == null) analyzerIn = getAnalyzer();\n\n    try (TokenStream source = analyzerIn.tokenStream(field, part)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      BytesRef bytes = BytesRef.deepCopyOf(termAtt.getBytesRef());\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n      source.end();\n      return bytes;\n    } catch (IOException e) {\n      throw new RuntimeException(\"Error analyzing multiTerm term: \" + part, e);\n    }\n  }\n\n","sourceOld":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    if (analyzerIn == null) analyzerIn = getAnalyzer();\n\n    try (TokenStream source = analyzerIn.tokenStream(field, part)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Error analyzing multiTerm term: \" + part, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ea4107f60b9f95623c16025c9c247412ff809092","date":1468333987,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","sourceNew":null,"sourceOld":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    if (analyzerIn == null) analyzerIn = getAnalyzer();\n\n    try (TokenStream source = analyzerIn.tokenStream(field, part)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      BytesRef bytes = BytesRef.deepCopyOf(termAtt.getBytesRef());\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n      source.end();\n      return bytes;\n    } catch (IOException e) {\n      throw new RuntimeException(\"Error analyzing multiTerm term: \" + part, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","sourceNew":null,"sourceOld":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    if (analyzerIn == null) analyzerIn = getAnalyzer();\n\n    try (TokenStream source = analyzerIn.tokenStream(field, part)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      BytesRef bytes = BytesRef.deepCopyOf(termAtt.getBytesRef());\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n      source.end();\n      return bytes;\n    } catch (IOException e) {\n      throw new RuntimeException(\"Error analyzing multiTerm term: \" + part, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["c1c1dd5dce93e4fa48898dabc7e012560acda425"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c1c1dd5dce93e4fa48898dabc7e012560acda425":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["b89678825b68eccaf09e6ab71675fc0b0af1e099","c83d6c4335f31cae14f625a222bc842f20073dcd"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"ea4107f60b9f95623c16025c9c247412ff809092":["804b857d1066ab5185b3b9101bde41b0b71426ec"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["804b857d1066ab5185b3b9101bde41b0b71426ec","ea4107f60b9f95623c16025c9c247412ff809092"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ea4107f60b9f95623c16025c9c247412ff809092"]},"commit2Childs":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["ea4107f60b9f95623c16025c9c247412ff809092","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"c1c1dd5dce93e4fa48898dabc7e012560acda425":["804b857d1066ab5185b3b9101bde41b0b71426ec"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"c83d6c4335f31cae14f625a222bc842f20073dcd":["37a0f60745e53927c4c876cfe5b5a58170f0646c","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["c1c1dd5dce93e4fa48898dabc7e012560acda425"],"ea4107f60b9f95623c16025c9c247412ff809092":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}