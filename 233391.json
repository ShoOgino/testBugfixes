{"path":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","commits":[{"id":"67ed9fd4da5f37b8d0e9f22418cc6eb3dfa26c0f","date":1279037830,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15bbd254c1506df5299c4df8c148262c7bd6301e","date":1279913113,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b103252dee6afa1b6d7a622c773d178788eb85a","date":1280180143,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3242a09f703274d3b9283f2064a1a33064b53a1b","date":1280263474,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    Random random = newRandom();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Random random = newRandom();\n    Directory dir = newDirectory(random);\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    Random random = newRandom();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Random random = newRandom();\n    Directory dir = newDirectory(random);\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(newRandom(), dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(new Field(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(new Field(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","date":1308670974,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    Term pkTerm = new Term(\"pk\", \"\");\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(pkTerm.createTerm(value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), StringField.TYPE_STORED));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, StringField.TYPE_STORED));\n      doc.add(newField(\"text\", \"foo\", StringField.TYPE_STORED));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), Store.YES, Index.ANALYZED_NO_NORMS));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, Store.YES, Index.ANALYZED_NO_NORMS));\n      doc.add(newField(\"text\", \"foo\", Store.YES, Index.ANALYZED_NO_NORMS));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c5b026d03cbbb03ca4c0b97d14e9839682281dc","date":1323049298,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), StringField.TYPE_STORED));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, StringField.TYPE_STORED));\n      doc.add(newField(\"text\", \"foo\", StringField.TYPE_STORED));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), StringField.TYPE_STORED));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, StringField.TYPE_STORED));\n      doc.add(newField(\"text\", \"foo\", StringField.TYPE_STORED));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), StringField.TYPE_STORED));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, StringField.TYPE_STORED));\n      doc.add(newField(\"text\", \"foo\", StringField.TYPE_STORED));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), StringField.TYPE_STORED));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, StringField.TYPE_STORED));\n      doc.add(newField(\"text\", \"foo\", StringField.TYPE_STORED));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), StringField.TYPE_STORED));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, StringField.TYPE_STORED));\n      doc.add(newField(\"text\", \"foo\", StringField.TYPE_STORED));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), StringField.TYPE_STORED));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, StringField.TYPE_STORED));\n      doc.add(newField(\"text\", \"foo\", StringField.TYPE_STORED));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir, true);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollback#testRollbackIntegrityWithBufferFlush().mjava","sourceNew":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), StringField.TYPE_STORED));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, StringField.TYPE_STORED));\n      doc.add(newField(\"text\", \"foo\", StringField.TYPE_STORED));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2536\n  public void testRollbackIntegrityWithBufferFlush() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter rw = new RandomIndexWriter(random, dir);\n    for (int i = 0; i < 5; i++) {\n      Document doc = new Document();\n      doc.add(newField(\"pk\", Integer.toString(i), StringField.TYPE_STORED));\n      rw.addDocument(doc);\n    }\n    rw.close();\n\n    // If buffer size is small enough to cause a flush, errors ensue...\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setOpenMode(IndexWriterConfig.OpenMode.APPEND));\n\n    for (int i = 0; i < 3; i++) {\n      Document doc = new Document();\n      String value = Integer.toString(i);\n      doc.add(newField(\"pk\", value, StringField.TYPE_STORED));\n      doc.add(newField(\"text\", \"foo\", StringField.TYPE_STORED));\n      w.updateDocument(new Term(\"pk\", value), doc);\n    }\n    w.rollback();\n\n    IndexReader r = IndexReader.open(dir);\n    assertEquals(\"index should contain same number of docs post rollback\", 5, r.numDocs());\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3242a09f703274d3b9283f2064a1a33064b53a1b":["5f4e87790277826a2aea119328600dfb07761f32","4b103252dee6afa1b6d7a622c773d178788eb85a"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["67ed9fd4da5f37b8d0e9f22418cc6eb3dfa26c0f","15bbd254c1506df5299c4df8c148262c7bd6301e"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["1509f151d7692d84fae414b2b799ac06ba60fcb4","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["67ed9fd4da5f37b8d0e9f22418cc6eb3dfa26c0f"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["132903c28af3aa6f67284b78de91c0f0a99488c2","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"5f4e87790277826a2aea119328600dfb07761f32":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","67ed9fd4da5f37b8d0e9f22418cc6eb3dfa26c0f"],"962d04139994fce5193143ef35615499a9a96d78":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"2553b00f699380c64959ccb27991289aae87be2e":["a3776dccca01c11e7046323cfad46a3b4a471233","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["3242a09f703274d3b9283f2064a1a33064b53a1b","132903c28af3aa6f67284b78de91c0f0a99488c2"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["f2c5f0cb44df114db4228c8f77861714b5cabaea","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"67ed9fd4da5f37b8d0e9f22418cc6eb3dfa26c0f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a3776dccca01c11e7046323cfad46a3b4a471233":["132903c28af3aa6f67284b78de91c0f0a99488c2","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["1509f151d7692d84fae414b2b799ac06ba60fcb4","1c5b026d03cbbb03ca4c0b97d14e9839682281dc"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3242a09f703274d3b9283f2064a1a33064b53a1b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["3242a09f703274d3b9283f2064a1a33064b53a1b","b21422ff1d1d56499dec481f193b402e5e8def5b"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"1c5b026d03cbbb03ca4c0b97d14e9839682281dc":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"5f4e87790277826a2aea119328600dfb07761f32":["3242a09f703274d3b9283f2064a1a33064b53a1b"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea","a3776dccca01c11e7046323cfad46a3b4a471233"],"962d04139994fce5193143ef35615499a9a96d78":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["962d04139994fce5193143ef35615499a9a96d78"],"2553b00f699380c64959ccb27991289aae87be2e":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","d083e83f225b11e5fdd900e83d26ddb385b6955c","a3776dccca01c11e7046323cfad46a3b4a471233"],"67ed9fd4da5f37b8d0e9f22418cc6eb3dfa26c0f":["4b103252dee6afa1b6d7a622c773d178788eb85a","15bbd254c1506df5299c4df8c148262c7bd6301e","5f4e87790277826a2aea119328600dfb07761f32"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"a3776dccca01c11e7046323cfad46a3b4a471233":["2553b00f699380c64959ccb27991289aae87be2e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5f4e87790277826a2aea119328600dfb07761f32","67ed9fd4da5f37b8d0e9f22418cc6eb3dfa26c0f"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","1c5b026d03cbbb03ca4c0b97d14e9839682281dc","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}