{"path":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSamping().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSamping().mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSamping().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSamping() throws Exception, IOException {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSamping() throws Exception, IOException {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSamping().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSamping().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSamping() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSamping() throws Exception, IOException {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":["95535508327351a4c38a0dc7711075dfabe5941f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSamping().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSamping().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSamping() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSamping() throws Exception, IOException {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c0af45b07833be5922ae261245816cc39091b6d","date":1354907459,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSampling().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSamping().mjava","sourceNew":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSampling() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSamping() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/sampling/BaseSampleTestTopK#testCountUsingSamping().mjava","sourceNew":null,"sourceOld":"  /**\n   * Try out faceted search with sampling enabled and complements either disabled or enforced\n   * Lots of randomly generated data is being indexed, and later on a \"90% docs\" faceted search\n   * is performed. The results are compared to non-sampled ones.\n   */\n  public void testCountUsingSamping() throws Exception {\n    boolean useRandomSampler = random().nextBoolean();\n    for (int partitionSize : partitionSizes) {\n      try {\n        initIndex(partitionSize);\n        // Get all of the documents and run the query, then do different\n        // facet counts and compare to control\n        Query q = new TermQuery(new Term(CONTENT_FIELD, BETA)); // 90% of the docs\n        ScoredDocIdCollector docCollector = ScoredDocIdCollector.create(indexReader.maxDoc(), false);\n        \n        FacetSearchParams expectedSearchParams = searchParamsWithRequests(K, partitionSize); \n        FacetsCollector fc = new FacetsCollector(expectedSearchParams, indexReader, taxoReader);\n        \n        searcher.search(q, MultiCollector.wrap(docCollector, fc));\n        \n        List<FacetResult> expectedResults = fc.getFacetResults();\n        \n        FacetSearchParams samplingSearchParams = searchParamsWithRequests(K, partitionSize); \n        \n        // try several times in case of failure, because the test has a chance to fail \n        // if the top K facets are not sufficiently common with the sample set\n        for (int nTrial=0; nTrial<RETRIES; nTrial++) {\n          try {\n            // complement with sampling!\n            final Sampler sampler = createSampler(nTrial, docCollector.getScoredDocIDs(), useRandomSampler);\n            \n            assertSampling(expectedResults, q, sampler, samplingSearchParams, false);\n            assertSampling(expectedResults, q, sampler, samplingSearchParams, true);\n            \n            break; // succeeded\n          } catch (NotSameResultError e) {\n            if (nTrial>=RETRIES-1) {\n              throw e; // no more retries allowed, must fail\n            }\n          }\n        }\n      } finally { \n        closeAll();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["b89678825b68eccaf09e6ab71675fc0b0af1e099","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","5c0af45b07833be5922ae261245816cc39091b6d"],"5c0af45b07833be5922ae261245816cc39091b6d":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5c0af45b07833be5922ae261245816cc39091b6d"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"5c0af45b07833be5922ae261245816cc39091b6d":["407687e67faf6e1f02a211ca078d8e3eed631027","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["fe33227f6805edab2036cbb80645cc4e2d1fa424","407687e67faf6e1f02a211ca078d8e3eed631027","5c0af45b07833be5922ae261245816cc39091b6d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fe33227f6805edab2036cbb80645cc4e2d1fa424","407687e67faf6e1f02a211ca078d8e3eed631027","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}