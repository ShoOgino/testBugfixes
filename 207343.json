{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsProducer#CompletionFieldsProducer(SegmentReadState).mjava","commits":[{"id":"07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a","date":1427495869,"type":0,"author":"Areek Zillur","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsProducer#CompletionFieldsProducer(SegmentReadState).mjava","pathOld":"/dev/null","sourceNew":"  CompletionFieldsProducer(SegmentReadState state) throws IOException {\n    String indexFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, INDEX_EXTENSION);\n    delegateFieldsProducer = null;\n    boolean success = false;\n\n    try (ChecksumIndexInput index = state.directory.openChecksumInput(indexFile, state.context)) {\n      // open up dict file containing all fsts\n      String dictFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, DICT_EXTENSION);\n      dictIn = state.directory.openInput(dictFile, state.context);\n      CodecUtil.checkIndexHeader(dictIn, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // just validate the footer for the dictIn\n      CodecUtil.retrieveChecksum(dictIn);\n\n      // open up index file (fieldNumber, offset)\n      CodecUtil.checkIndexHeader(index, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // load delegate PF\n      PostingsFormat delegatePostingsFormat = PostingsFormat.forName(index.readString());\n      delegateFieldsProducer = delegatePostingsFormat.fieldsProducer(state);\n\n      // read suggest field numbers and their offsets in the terms file from index\n      int numFields = index.readVInt();\n      readers = new HashMap<>(numFields);\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = index.readVInt();\n        long offset = index.readVLong();\n        FieldInfo fieldInfo = state.fieldInfos.fieldInfo(fieldNumber);\n        // we don't load the FST yet\n        readers.put(fieldInfo.name, new CompletionsTermsReader(offset));\n      }\n      CodecUtil.checkFooter(index);\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.closeWhileHandlingException(delegateFieldsProducer, dictIn);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsProducer#CompletionFieldsProducer(SegmentReadState).mjava","pathOld":"/dev/null","sourceNew":"  CompletionFieldsProducer(SegmentReadState state) throws IOException {\n    String indexFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, INDEX_EXTENSION);\n    delegateFieldsProducer = null;\n    boolean success = false;\n\n    try (ChecksumIndexInput index = state.directory.openChecksumInput(indexFile, state.context)) {\n      // open up dict file containing all fsts\n      String dictFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, DICT_EXTENSION);\n      dictIn = state.directory.openInput(dictFile, state.context);\n      CodecUtil.checkIndexHeader(dictIn, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // just validate the footer for the dictIn\n      CodecUtil.retrieveChecksum(dictIn);\n\n      // open up index file (fieldNumber, offset)\n      CodecUtil.checkIndexHeader(index, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // load delegate PF\n      PostingsFormat delegatePostingsFormat = PostingsFormat.forName(index.readString());\n      delegateFieldsProducer = delegatePostingsFormat.fieldsProducer(state);\n\n      // read suggest field numbers and their offsets in the terms file from index\n      int numFields = index.readVInt();\n      readers = new HashMap<>(numFields);\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = index.readVInt();\n        long offset = index.readVLong();\n        FieldInfo fieldInfo = state.fieldInfos.fieldInfo(fieldNumber);\n        // we don't load the FST yet\n        readers.put(fieldInfo.name, new CompletionsTermsReader(offset));\n      }\n      CodecUtil.checkFooter(index);\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.closeWhileHandlingException(delegateFieldsProducer, dictIn);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8c33f6677a2078739058f81eca1df69d12cd62b0","date":1432799589,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsProducer#CompletionFieldsProducer(SegmentReadState).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsProducer#CompletionFieldsProducer(SegmentReadState).mjava","sourceNew":"  CompletionFieldsProducer(SegmentReadState state) throws IOException {\n    String indexFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, INDEX_EXTENSION);\n    delegateFieldsProducer = null;\n    boolean success = false;\n\n    try (ChecksumIndexInput index = state.directory.openChecksumInput(indexFile, state.context)) {\n      // open up dict file containing all fsts\n      String dictFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, DICT_EXTENSION);\n      dictIn = state.directory.openInput(dictFile, state.context);\n      CodecUtil.checkIndexHeader(dictIn, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // just validate the footer for the dictIn\n      CodecUtil.retrieveChecksum(dictIn);\n\n      // open up index file (fieldNumber, offset)\n      CodecUtil.checkIndexHeader(index, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // load delegate PF\n      PostingsFormat delegatePostingsFormat = PostingsFormat.forName(index.readString());\n      delegateFieldsProducer = delegatePostingsFormat.fieldsProducer(state);\n\n      // read suggest field numbers and their offsets in the terms file from index\n      int numFields = index.readVInt();\n      readers = new HashMap<>(numFields);\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = index.readVInt();\n        long offset = index.readVLong();\n        long minWeight = index.readVLong();\n        long maxWeight = index.readVLong();\n        byte type = index.readByte();\n        FieldInfo fieldInfo = state.fieldInfos.fieldInfo(fieldNumber);\n        // we don't load the FST yet\n        readers.put(fieldInfo.name, new CompletionsTermsReader(dictIn, offset, minWeight, maxWeight, type));\n      }\n      CodecUtil.checkFooter(index);\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.closeWhileHandlingException(delegateFieldsProducer, dictIn);\n      }\n    }\n  }\n\n","sourceOld":"  CompletionFieldsProducer(SegmentReadState state) throws IOException {\n    String indexFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, INDEX_EXTENSION);\n    delegateFieldsProducer = null;\n    boolean success = false;\n\n    try (ChecksumIndexInput index = state.directory.openChecksumInput(indexFile, state.context)) {\n      // open up dict file containing all fsts\n      String dictFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, DICT_EXTENSION);\n      dictIn = state.directory.openInput(dictFile, state.context);\n      CodecUtil.checkIndexHeader(dictIn, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // just validate the footer for the dictIn\n      CodecUtil.retrieveChecksum(dictIn);\n\n      // open up index file (fieldNumber, offset)\n      CodecUtil.checkIndexHeader(index, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // load delegate PF\n      PostingsFormat delegatePostingsFormat = PostingsFormat.forName(index.readString());\n      delegateFieldsProducer = delegatePostingsFormat.fieldsProducer(state);\n\n      // read suggest field numbers and their offsets in the terms file from index\n      int numFields = index.readVInt();\n      readers = new HashMap<>(numFields);\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = index.readVInt();\n        long offset = index.readVLong();\n        FieldInfo fieldInfo = state.fieldInfos.fieldInfo(fieldNumber);\n        // we don't load the FST yet\n        readers.put(fieldInfo.name, new CompletionsTermsReader(offset));\n      }\n      CodecUtil.checkFooter(index);\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.closeWhileHandlingException(delegateFieldsProducer, dictIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d80ba6c8861a5835a6f2b776183e774c4ef13f02","date":1561540611,"type":5,"author":"jimczi","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsProducer#CompletionFieldsProducer(SegmentReadState,FSTLoadMode).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/CompletionFieldsProducer#CompletionFieldsProducer(SegmentReadState).mjava","sourceNew":"  CompletionFieldsProducer(SegmentReadState state, FSTLoadMode fstLoadMode) throws IOException {\n    String indexFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, INDEX_EXTENSION);\n    delegateFieldsProducer = null;\n    boolean success = false;\n\n    try (ChecksumIndexInput index = state.directory.openChecksumInput(indexFile, state.context)) {\n      // open up dict file containing all fsts\n      String dictFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, DICT_EXTENSION);\n      dictIn = state.directory.openInput(dictFile, state.context);\n      CodecUtil.checkIndexHeader(dictIn, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // just validate the footer for the dictIn\n      CodecUtil.retrieveChecksum(dictIn);\n\n      // open up index file (fieldNumber, offset)\n      CodecUtil.checkIndexHeader(index, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // load delegate PF\n      PostingsFormat delegatePostingsFormat = PostingsFormat.forName(index.readString());\n      delegateFieldsProducer = delegatePostingsFormat.fieldsProducer(state);\n\n      // read suggest field numbers and their offsets in the terms file from index\n      int numFields = index.readVInt();\n      readers = new HashMap<>(numFields);\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = index.readVInt();\n        long offset = index.readVLong();\n        long minWeight = index.readVLong();\n        long maxWeight = index.readVLong();\n        byte type = index.readByte();\n        FieldInfo fieldInfo = state.fieldInfos.fieldInfo(fieldNumber);\n        // we don't load the FST yet\n        readers.put(fieldInfo.name, new CompletionsTermsReader(dictIn, offset, minWeight, maxWeight, type, fstLoadMode));\n      }\n      CodecUtil.checkFooter(index);\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.closeWhileHandlingException(delegateFieldsProducer, dictIn);\n      }\n    }\n  }\n\n","sourceOld":"  CompletionFieldsProducer(SegmentReadState state) throws IOException {\n    String indexFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, INDEX_EXTENSION);\n    delegateFieldsProducer = null;\n    boolean success = false;\n\n    try (ChecksumIndexInput index = state.directory.openChecksumInput(indexFile, state.context)) {\n      // open up dict file containing all fsts\n      String dictFile = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, DICT_EXTENSION);\n      dictIn = state.directory.openInput(dictFile, state.context);\n      CodecUtil.checkIndexHeader(dictIn, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // just validate the footer for the dictIn\n      CodecUtil.retrieveChecksum(dictIn);\n\n      // open up index file (fieldNumber, offset)\n      CodecUtil.checkIndexHeader(index, CODEC_NAME, COMPLETION_CODEC_VERSION, COMPLETION_VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n      // load delegate PF\n      PostingsFormat delegatePostingsFormat = PostingsFormat.forName(index.readString());\n      delegateFieldsProducer = delegatePostingsFormat.fieldsProducer(state);\n\n      // read suggest field numbers and their offsets in the terms file from index\n      int numFields = index.readVInt();\n      readers = new HashMap<>(numFields);\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = index.readVInt();\n        long offset = index.readVLong();\n        long minWeight = index.readVLong();\n        long maxWeight = index.readVLong();\n        byte type = index.readByte();\n        FieldInfo fieldInfo = state.fieldInfos.fieldInfo(fieldNumber);\n        // we don't load the FST yet\n        readers.put(fieldInfo.name, new CompletionsTermsReader(dictIn, offset, minWeight, maxWeight, type));\n      }\n      CodecUtil.checkFooter(index);\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.closeWhileHandlingException(delegateFieldsProducer, dictIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a"],"07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d80ba6c8861a5835a6f2b776183e774c4ef13f02":["8c33f6677a2078739058f81eca1df69d12cd62b0"],"8c33f6677a2078739058f81eca1df69d12cd62b0":["07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d80ba6c8861a5835a6f2b776183e774c4ef13f02"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","8c33f6677a2078739058f81eca1df69d12cd62b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a"],"d80ba6c8861a5835a6f2b776183e774c4ef13f02":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8c33f6677a2078739058f81eca1df69d12cd62b0":["d80ba6c8861a5835a6f2b776183e774c4ef13f02"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}