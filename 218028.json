{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/path/TestPathHierarchyTokenizer#testStartOfCharEndOfDelimiter().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/path/TestPathHierarchyTokenizer#testStartOfCharEndOfDelimiter().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/path/TestPathHierarchyTokenizer#testStartOfCharEndOfDelimiter().mjava","sourceNew":"  public void testStartOfCharEndOfDelimiter() throws Exception {\n    String path = \"a/b/c/\";\n    PathHierarchyTokenizer t = new PathHierarchyTokenizer( new StringReader(path) );\n    assertTokenStreamContents(t,\n        new String[]{\"a\", \"a/b\", \"a/b/c\", \"a/b/c/\"},\n        new int[]{0, 0, 0, 0},\n        new int[]{1, 3, 5, 6},\n        new int[]{1, 0, 0, 0},\n        path.length());\n  }\n\n","sourceOld":"  public void testStartOfCharEndOfDelimiter() throws Exception {\n    String path = \"a/b/c/\";\n    PathHierarchyTokenizer t = new PathHierarchyTokenizer( new StringReader(path) );\n    assertTokenStreamContents(t,\n        new String[]{\"a\", \"a/b\", \"a/b/c\", \"a/b/c/\"},\n        new int[]{0, 0, 0, 0},\n        new int[]{1, 3, 5, 6},\n        new int[]{1, 0, 0, 0},\n        path.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/path/TestPathHierarchyTokenizer#testStartOfCharEndOfDelimiter().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/path/TestPathHierarchyTokenizer#testStartOfCharEndOfDelimiter().mjava","sourceNew":"  public void testStartOfCharEndOfDelimiter() throws Exception {\n    String path = \"a/b/c/\";\n    PathHierarchyTokenizer t = new PathHierarchyTokenizer( );\n    t.setReader( new StringReader(path) );\n    assertTokenStreamContents(t,\n        new String[]{\"a\", \"a/b\", \"a/b/c\", \"a/b/c/\"},\n        new int[]{0, 0, 0, 0},\n        new int[]{1, 3, 5, 6},\n        new int[]{1, 0, 0, 0},\n        path.length());\n  }\n\n","sourceOld":"  public void testStartOfCharEndOfDelimiter() throws Exception {\n    String path = \"a/b/c/\";\n    PathHierarchyTokenizer t = new PathHierarchyTokenizer( new StringReader(path) );\n    assertTokenStreamContents(t,\n        new String[]{\"a\", \"a/b\", \"a/b/c\", \"a/b/c/\"},\n        new int[]{0, 0, 0, 0},\n        new int[]{1, 3, 5, 6},\n        new int[]{1, 0, 0, 0},\n        path.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75","date":1399205975,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/path/TestPathHierarchyTokenizer#testStartOfCharEndOfDelimiter().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/path/TestPathHierarchyTokenizer#testStartOfCharEndOfDelimiter().mjava","sourceNew":"  public void testStartOfCharEndOfDelimiter() throws Exception {\n    String path = \"a/b/c/\";\n    PathHierarchyTokenizer t = new PathHierarchyTokenizer(newAttributeFactory(), DEFAULT_DELIMITER, DEFAULT_DELIMITER, DEFAULT_SKIP);\n    t.setReader( new StringReader(path) );\n    assertTokenStreamContents(t,\n        new String[]{\"a\", \"a/b\", \"a/b/c\", \"a/b/c/\"},\n        new int[]{0, 0, 0, 0},\n        new int[]{1, 3, 5, 6},\n        new int[]{1, 0, 0, 0},\n        path.length());\n  }\n\n","sourceOld":"  public void testStartOfCharEndOfDelimiter() throws Exception {\n    String path = \"a/b/c/\";\n    PathHierarchyTokenizer t = new PathHierarchyTokenizer( );\n    t.setReader( new StringReader(path) );\n    assertTokenStreamContents(t,\n        new String[]{\"a\", \"a/b\", \"a/b/c\", \"a/b/c/\"},\n        new int[]{0, 0, 0, 0},\n        new int[]{1, 3, 5, 6},\n        new int[]{1, 0, 0, 0},\n        path.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["923f36bb0db6f793cf62dbb68723ae3bfbaf1d75"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["923f36bb0db6f793cf62dbb68723ae3bfbaf1d75"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}