{"path":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","commits":[{"id":"415bbbe7da8065dd3c477bdc3c703c6425622998","date":1485393793,"type":0,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  @ShardsFixed(num = 3)\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(25);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(25000);  \n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(100);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"598b5d23aa7c9732bf473c21a9cd309c44599394","date":1485530378,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  @ShardsFixed(num = 3)\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(25);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(25000);  \n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(100);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c9595c75582a7ea7efb585014102ed83f2d9c8b","date":1523581112,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 3)\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(25);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(25000);  \n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(100);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 3)\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(25);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(25000);  \n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(100);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b87d1f8719d7f05be003f3477450b74af13706a","date":1523590376,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 3)\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(25);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(25000);  \n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(100);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 3)\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(25);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(25000);  \n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(100);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 3)\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(12);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(5000);  \n    int nReadThreads = 5 + random().nextInt(12);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(50);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(30);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 3)\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(25);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(25000);  \n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(100);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(100);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","bugFix":["415bbbe7da8065dd3c477bdc3c703c6425622998"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5c929d2716fa79d443b93a82adb1da5b578ebd8","date":1550428858,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 3)\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(12);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(5000);  \n    int nReadThreads = 5 + random().nextInt(12);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(50);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(30);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 3)\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(12);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(5000);  \n    int nReadThreads = 5 + random().nextInt(12);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(50);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(30);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add1e7dd742ea533ff4318cea83ca0a1f669f662","date":1585262285,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 3)\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(12);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(5000);  \n    int nReadThreads = 5 + random().nextInt(12);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(50);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(30);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30, TimeUnit.SECONDS); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 3)\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(12);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(5000);  \n    int nReadThreads = 5 + random().nextInt(12);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(50);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(30);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestStressInPlaceUpdates#stressTest().mjava","sourceNew":"  @Test\n  @ShardsFixed(num = 3)\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(12);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(5000);  \n    int nReadThreads = 5 + random().nextInt(12);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    if (log.isInfoEnabled()) {\n      log.info(\"{}\", Arrays.asList\n          (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n    }\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(50);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(\"{}: Deleting id={}, version={}. Returned version={}\"\n                      , delType, id, info.version, returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(30);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id={}, val=[{},{}], version={}, Prev was=[{},{}].  Returned version={}\"\n                        ,id, nextVal1, nextVal2, info.version, val1, val2, returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id={}, val=[{},{}], version={}, Prev was=[{},{}].  Returned version={}\"\n                        ,id, nextVal1, nextVal2, info.version, val1, val2,  returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30, TimeUnit.SECONDS); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  @ShardsFixed(num = 3)\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 09-Apr-2018\n  public void stressTest() throws Exception {\n    waitForRecoveriesToFinish(true);\n\n    this.leaderClient = getClientForLeader();\n    assertNotNull(\"Couldn't obtain client for the leader of the shard\", this.leaderClient);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30 + random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4 + random().nextInt(25);\n    final int deleteByQueryPercent = random().nextInt(8);\n    final int ndocs = atLeast(5);\n    int nWriteThreads = 5 + random().nextInt(12);\n    int fullUpdatePercent = 5 + random().nextInt(50);\n\n    // query variables\n    final int percentRealtimeQuery = 75;\n    // number of cumulative read/write operations by all threads\n    final AtomicLong operations = new AtomicLong(5000);  \n    int nReadThreads = 5 + random().nextInt(12);\n\n\n    /** // testing\n     final int commitPercent = 5;\n     final int softCommitPercent = 100; // what percent of the commits are soft\n     final int deletePercent = 0;\n     final int deleteByQueryPercent = 50;\n     final int ndocs = 10;\n     int nWriteThreads = 10;\n\n     final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n     // query variables\n     final int percentRealtimeQuery = 101;\n     final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n     int nReadThreads = 10;\n\n     int fullUpdatePercent = 20;\n     **/\n\n    log.info(\"{}\", Arrays.asList\n             (\"commitPercent\", commitPercent, \"softCommitPercent\", softCommitPercent,\n              \"deletePercent\", deletePercent, \"deleteByQueryPercent\", deleteByQueryPercent,\n              \"ndocs\", ndocs, \"nWriteThreads\", nWriteThreads, \"percentRealtimeQuery\", percentRealtimeQuery,\n              \"operations\", operations, \"nReadThreads\", nReadThreads));\n\n    initModel(ndocs);\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i = 0; i < nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() > 0) {\n              int oper = rand.nextInt(50);\n\n              if (oper < commitPercent) {\n                Map<Integer, DocInfo> newCommittedModel;\n                long version;\n\n                synchronized (TestStressInPlaceUpdates.this) {\n                  // take a snapshot of the model\n                  // this is safe to do w/o synchronizing on the model because it's a ConcurrentHashMap\n                  newCommittedModel = new HashMap<>(model);  \n                  version = snapshotCount++;\n\n                  int chosenClientIndex = rand.nextInt(clients.size());\n\n                  if (rand.nextInt(100) < softCommitPercent) {\n                    log.info(\"softCommit start\");\n                    clients.get(chosenClientIndex).commit(true, true, true);\n                    log.info(\"softCommit end\");\n                  } else {\n                    log.info(\"hardCommit start\");\n                    clients.get(chosenClientIndex).commit();\n                    log.info(\"hardCommit end\");\n                  }\n\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      log.info(\"installing new committedModel version={}\", committedModelClock);\n                    }\n                    clientIndexUsedForCommit = chosenClientIndex;\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n                continue;\n              }\n\n              int id;\n\n              if (rand.nextBoolean()) {\n                id = rand.nextInt(ndocs);\n              } else {\n                id = lastId;  // reuse the last ID half of the time to force more race conditions\n              }\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = rand.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              DocInfo info = model.get(id);\n\n              // yield after getting the next version to increase the odds of updates happening out of order\n              if (rand.nextBoolean()) Thread.yield();\n\n              if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                final boolean dbq = (oper >= commitPercent + deletePercent);\n                final String delType = dbq ? \"DBI\": \"DBQ\";\n                log.info(\"{} id {}: {}\", delType, id, info);\n                \n                Long returnedVersion = null;\n\n                try {\n                  returnedVersion = deleteDocAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)), dbq);\n                  log.info(delType + \": Deleting id=\" + id + \", version=\" + info.version \n                           + \".  Returned version=\" + returnedVersion);\n                } catch (RuntimeException e) {\n                  if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                      || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                    // Its okay for a leader to reject a concurrent request\n                    log.warn(\"Conflict during {}, rejected id={}, {}\", delType, id, e);\n                    returnedVersion = null;\n                  } else {\n                    throw e;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), 0, 0));\n                  }\n                }\n                \n              } else {\n                int val1 = info.intFieldValue;\n                long val2 = info.longFieldValue;\n                int nextVal1 = val1;\n                long nextVal2 = val2;\n\n                int addOper = rand.nextInt(30);\n                Long returnedVersion;\n                if (addOper < fullUpdatePercent || info.version <= 0) { // if document was never indexed or was deleted\n                  // FULL UPDATE\n                  nextVal1 = Primes.nextPrime(val1 + 1);\n                  nextVal2 = nextVal1 * 1000000000l;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"title_s\", \"title\" + id, \"val1_i_dvo\", nextVal1, \"val2_l_dvo\", nextVal2, \"_version_\", info.version);\n                    log.info(\"FULL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during full update, rejected id={}, {}\", id, e);\n                      returnedVersion = null;\n                    } else {\n                      throw e;\n                    }\n                  }\n                } else {\n                  // PARTIAL\n                  nextVal2 = val2 + val1;\n                  try {\n                    returnedVersion = addDocAndGetVersion(\"id\", id, \"val2_l_dvo\", map(\"inc\", String.valueOf(val1)), \"_version_\", info.version);\n                    log.info(\"PARTIAL: Writing id=\" + id + \", val=[\" + nextVal1 + \",\" + nextVal2 + \"], version=\" + info.version + \", Prev was=[\" + val1 + \",\" + val2 + \"].  Returned version=\" + returnedVersion);\n                  } catch (RuntimeException e) {\n                    if (e.getMessage() != null && e.getMessage().contains(\"version conflict\")\n                        || e.getMessage() != null && e.getMessage().contains(\"Conflict\")) {\n                      // Its okay for a leader to reject a concurrent request\n                      log.warn(\"Conflict during partial update, rejected id={}, {}\", id, e);\n                    } else if (e.getMessage() != null && e.getMessage().contains(\"Document not found for update.\") \n                               && e.getMessage().contains(\"id=\"+id)) {\n                      log.warn(\"Attempted a partial update for a recently deleted document, rejected id={}, {}\", id, e);\n                    } else {\n                      throw e;\n                    }\n                    returnedVersion = null;\n                  }\n                }\n\n                // only update model if update had no conflict & the version is newer\n                synchronized (model) {\n                  DocInfo currInfo = model.get(id);\n                  if (null != returnedVersion &&\n                      (Math.abs(returnedVersion.longValue()) > Math.abs(currInfo.version))) {\n                    model.put(id, new DocInfo(returnedVersion.longValue(), nextVal1, nextVal2));\n                  }\n\n                }\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n\n    }\n\n    // Read threads\n    for (int i = 0; i < nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\" + i) {\n        Random rand = new Random(random().nextInt());\n\n        @SuppressWarnings(\"unchecked\")\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo expected;\n\n              if (realTime) {\n                expected = model.get(id);\n              } else {\n                synchronized (TestStressInPlaceUpdates.this) {\n                  expected = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                log.info(\"querying id {}\", id);\n              }\n              ModifiableSolrParams params = new ModifiableSolrParams();\n              if (realTime) {\n                params.set(\"wt\", \"json\");\n                params.set(\"qt\", \"/get\");\n                params.set(\"ids\", Integer.toString(id));\n              } else {\n                params.set(\"wt\", \"json\");\n                params.set(\"q\", \"id:\" + Integer.toString(id));\n                params.set(\"omitHeader\", \"true\");\n              }\n\n              int clientId = rand.nextInt(clients.size());\n              if (!realTime) clientId = clientIndexUsedForCommit;\n\n              QueryResponse response = clients.get(clientId).query(params);\n              if (response.getResults().size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else if (response.getResults().size() == 1) {\n                final SolrDocument actual = response.getResults().get(0);\n                final String msg = \"Realtime=\" + realTime + \", expected=\" + expected + \", actual=\" + actual;\n                assertNotNull(msg, actual);\n\n                final Long foundVersion = (Long) actual.getFieldValue(\"_version_\");\n                assertNotNull(msg, foundVersion);\n                assertTrue(msg + \"... solr doc has non-positive version???\",\n                           0 < foundVersion.longValue());\n                final Integer intVal = (Integer) actual.getFieldValue(\"val1_i_dvo\");\n                assertNotNull(msg, intVal);\n                \n                final Long longVal = (Long) actual.getFieldValue(\"val2_l_dvo\");\n                assertNotNull(msg, longVal);\n\n                assertTrue(msg + \" ...solr returned older version then model. \" +\n                           \"should not be possible given the order of operations in writer threads\",\n                           Math.abs(expected.version) <= foundVersion.longValue());\n\n                if (foundVersion.longValue() == expected.version) {\n                  assertEquals(msg, expected.intFieldValue, intVal.intValue());\n                  assertEquals(msg, expected.longFieldValue, longVal.longValue());\n                }\n\n                // Some things we can assert about any Doc returned from solr,\n                // even if it's newer then our (expected) model information...\n\n                assertTrue(msg + \" ...how did a doc in solr get a non positive intVal?\",\n                           0 < intVal);\n                assertTrue(msg + \" ...how did a doc in solr get a non positive longVal?\",\n                           0 < longVal);\n                assertEquals(msg + \" ...intVal and longVal in solr doc are internally (modulo) inconsistent w/eachother\",\n                             0, (longVal % intVal));\n\n                // NOTE: when foundVersion is greater then the version read from the model,\n                // it's not possible to make any assertions about the field values in solr relative to the\n                // field values in the model -- ie: we can *NOT* assert expected.longFieldVal <= doc.longVal\n                //\n                // it's tempting to think that this would be possible if we changed our model to preserve the\n                // \"old\" valuess when doing a delete, but that's still no garuntee because of how oportunistic\n                // concurrency works with negative versions:  When adding a doc, we can assert that it must not\n                // exist with version<0, but we can't assert that the *reason* it doesn't exist was because of\n                // a delete with the specific version of \"-42\".\n                // So a wrtier thread might (1) prep to add a doc for the first time with \"intValue=1,_version_=-1\",\n                // and that add may succeed and (2) return some version X which is put in the model.  but\n                // inbetween #1 and #2 other threads may have added & deleted the doc repeatedly, updating\n                // the model with intValue=7,_version_=-42, and a reader thread might meanwhile read from the\n                // model before #2 and expect intValue=5, but get intValue=1 from solr (with a greater version)\n                \n              } else {\n                fail(String.format(Locale.ENGLISH, \"There were more than one result: {}\", response));\n              }\n            }\n          } catch (Throwable e) {\n            operations.set(-1L);\n            log.error(\"\", e);\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n    // Start all threads\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    { // final pass over uncommitted model with RTG\n\n      for (SolrClient client : clients) {\n        for (Map.Entry<Integer,DocInfo> entry : model.entrySet()) {\n          final Integer id = entry.getKey();\n          final DocInfo expected = entry.getValue();\n          final SolrDocument actual = client.getById(id.toString());\n\n          String msg = \"RTG: \" + id + \"=\" + expected;\n          if (null == actual) {\n            // a deleted or non-existent document\n            // sanity check of the model agrees...\n            assertTrue(msg + \" is deleted/non-existent in Solr, but model has non-neg version\",\n                       expected.version < 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.intFieldValue, 0);\n            assertEquals(msg + \" is deleted/non-existent in Solr\", expected.longFieldValue, 0);\n          } else {\n            msg = msg + \" <==VS==> \" + actual;\n            assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n            assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n            assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n            assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                       0 < expected.version);\n          }\n        }\n      }\n    }\n    \n    { // do a final search and compare every result with the model\n\n      // because commits don't provide any sort of concrete versioning (or optimistic concurrency constraints)\n      // there's no way to garuntee that our committedModel matches what was in Solr at the time of the last commit.\n      // It's possible other threads made additional writes to solr before the commit was processed, but after\n      // the committedModel variable was assigned it's new value.\n      //\n      // what we can do however, is commit all completed updates, and *then* compare solr search results\n      // against the (new) committed model....\n      \n      waitForThingsToLevelOut(30, TimeUnit.SECONDS); // NOTE: this does an automatic commit for us & ensures replicas are up to date\n      committedModel = new HashMap<>(model);\n\n      // first, prune the model of any docs that have negative versions\n      // ie: were never actually added, or were ultimately deleted.\n      for (int i = 0; i < ndocs; i++) {\n        DocInfo info = committedModel.get(i);\n        if (info.version < 0) {\n          // first, a quick sanity check of the model itself...\n          assertEquals(\"Inconsistent int value in model for deleted doc\" + i + \"=\" + info,\n                       0, info.intFieldValue);\n          assertEquals(\"Inconsistent long value in model for deleted doc\" + i + \"=\" + info,\n                       0L, info.longFieldValue);\n\n          committedModel.remove(i);\n        }\n      }\n\n      for (SolrClient client : clients) {\n        QueryResponse rsp = client.query(params(\"q\",\"*:*\", \"sort\", \"id asc\", \"rows\", ndocs+\"\"));\n        for (SolrDocument actual : rsp.getResults()) {\n          final Integer id = Integer.parseInt(actual.getFieldValue(\"id\").toString());\n          final DocInfo expected = committedModel.get(id); \n          \n          assertNotNull(\"Doc found but missing/deleted from model: \" + actual, expected);\n          \n          final String msg = \"Search: \" + id + \"=\" + expected + \" <==VS==> \" + actual;\n          assertEquals(msg, expected.intFieldValue, actual.getFieldValue(\"val1_i_dvo\"));\n          assertEquals(msg, expected.longFieldValue, actual.getFieldValue(\"val2_l_dvo\"));\n          assertEquals(msg, expected.version, actual.getFieldValue(\"_version_\"));\n          assertTrue(msg + \" doc exists in solr, but version is negative???\",\n                     0 < expected.version);\n\n          // also sanity check the model (which we already know matches the doc)\n          assertEquals(\"Inconsistent (modulo) values in model for id \" + id + \"=\" + expected,\n                       0, (expected.longFieldValue % expected.intFieldValue));\n        }\n        assertEquals(committedModel.size(), rsp.getResults().getNumFound());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"415bbbe7da8065dd3c477bdc3c703c6425622998":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"598b5d23aa7c9732bf473c21a9cd309c44599394":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","415bbbe7da8065dd3c477bdc3c703c6425622998"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["6b87d1f8719d7f05be003f3477450b74af13706a"],"3c9595c75582a7ea7efb585014102ed83f2d9c8b":["415bbbe7da8065dd3c477bdc3c703c6425622998"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6b87d1f8719d7f05be003f3477450b74af13706a":["415bbbe7da8065dd3c477bdc3c703c6425622998","3c9595c75582a7ea7efb585014102ed83f2d9c8b"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["b5c929d2716fa79d443b93a82adb1da5b578ebd8"],"b5c929d2716fa79d443b93a82adb1da5b578ebd8":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a966532d92cf9ba2856f15a8140151bb6b518e4b"]},"commit2Childs":{"415bbbe7da8065dd3c477bdc3c703c6425622998":["598b5d23aa7c9732bf473c21a9cd309c44599394","3c9595c75582a7ea7efb585014102ed83f2d9c8b","6b87d1f8719d7f05be003f3477450b74af13706a"],"598b5d23aa7c9732bf473c21a9cd309c44599394":[],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["b5c929d2716fa79d443b93a82adb1da5b578ebd8"],"3c9595c75582a7ea7efb585014102ed83f2d9c8b":["6b87d1f8719d7f05be003f3477450b74af13706a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["415bbbe7da8065dd3c477bdc3c703c6425622998","598b5d23aa7c9732bf473c21a9cd309c44599394"],"6b87d1f8719d7f05be003f3477450b74af13706a":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"b5c929d2716fa79d443b93a82adb1da5b578ebd8":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["598b5d23aa7c9732bf473c21a9cd309c44599394","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}