{"path":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":2,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"backwards/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Term is correctly encoded\", NumericUtils.longToPrefixCoded(lvalue, shift), termAtt.term());\n      assertEquals(\"Type correct\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"No more tokens available\", stream.incrementToken());\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Term is correctly encoded\", NumericUtils.longToPrefixCoded(lvalue, shift), termAtt.term());\n      assertEquals(\"Type correct\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"No more tokens available\", stream.incrementToken());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = new BytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    assertEquals(lvalue, numericAtt.getRawValue());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.toBytesRef(bytes);\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermAttribute termAtt = stream.getAttribute(TermAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Term is correctly encoded\", NumericUtils.longToPrefixCoded(lvalue, shift), termAtt.term());\n      assertEquals(\"Type correct\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"No more tokens available\", stream.incrementToken());\n  }\n\n","bugFix":null,"bugIntro":["d37d9627738304db0500dec1c44453fcbb3f5f91"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d37d9627738304db0500dec1c44453fcbb3f5f91","date":1295479243,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = new BytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.toBytesRef(bytes);\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = new BytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    assertEquals(lvalue, numericAtt.getRawValue());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.toBytesRef(bytes);\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e79a6d080bdd5b2a8f56342cf571b5476de04180","date":1295638686,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = new BytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.toBytesRef(bytes);\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = new BytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    assertEquals(lvalue, numericAtt.getRawValue());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.toBytesRef(bytes);\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = new BytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.toBytesRef(bytes);\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = new BytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    assertEquals(lvalue, numericAtt.getRawValue());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.toBytesRef(bytes);\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3d07f1ae3b58102f36f3393c397d78ba4e547a4","date":1300715535,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.fillBytesRef();\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = new BytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.toBytesRef(bytes);\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.fillBytesRef();\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = new BytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.toBytesRef(bytes);\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.fillBytesRef();\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = new BytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.toBytesRef(bytes);\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.fillBytesRef();\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.fillBytesRef();\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["e79a6d080bdd5b2a8f56342cf571b5476de04180","b3d07f1ae3b58102f36f3393c397d78ba4e547a4"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["29ef99d61cda9641b6250bf9567329a6e65f901d","b3d07f1ae3b58102f36f3393c397d78ba4e547a4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["b3d07f1ae3b58102f36f3393c397d78ba4e547a4"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["955c32f886db6f6356c9fcdea6b1f1cb4effda24","d37d9627738304db0500dec1c44453fcbb3f5f91"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"b3d07f1ae3b58102f36f3393c397d78ba4e547a4":["d37d9627738304db0500dec1c44453fcbb3f5f91"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["955c32f886db6f6356c9fcdea6b1f1cb4effda24","d37d9627738304db0500dec1c44453fcbb3f5f91"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d37d9627738304db0500dec1c44453fcbb3f5f91":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":[],"d619839baa8ce5503e496b94a9e42ad6f079293f":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["29ef99d61cda9641b6250bf9567329a6e65f901d","e79a6d080bdd5b2a8f56342cf571b5476de04180","d37d9627738304db0500dec1c44453fcbb3f5f91"],"b3d07f1ae3b58102f36f3393c397d78ba4e547a4":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","d619839baa8ce5503e496b94a9e42ad6f079293f","3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"d37d9627738304db0500dec1c44453fcbb3f5f91":["29ef99d61cda9641b6250bf9567329a6e65f901d","b3d07f1ae3b58102f36f3393c397d78ba4e547a4","e79a6d080bdd5b2a8f56342cf571b5476de04180"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","d619839baa8ce5503e496b94a9e42ad6f079293f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}