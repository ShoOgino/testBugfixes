{"path":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","commits":[{"id":"0c3e228bf650e96f3002a8fb73dd0c13d55af077","date":1138253849,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"/dev/null","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)Config.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n    Node tokNode = (Node)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODE);\n    NodeList nList = (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET);\n\n    if (tokNode==null){\n      throw new SolrException(1,\"analyzer without class or tokenizer & filter list\");\n    }\n    TokenizerFactory tfac = readTokenizerFactory(tokNode);\n\n    /******\n    // oops, getChildNodes() includes text (newlines, etc) in addition\n    // to the actual child elements\n    NodeList nList = node.getChildNodes();\n    TokenizerFactory tfac = readTokenizerFactory(nList.item(0));\n     if (tfac==null) {\n       throw new SolrException(1,\"TokenizerFactory must be specified first in analyzer\");\n     }\n    ******/\n\n    ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    for (int i=0; i<nList.getLength(); i++) {\n      TokenFilterFactory filt = readTokenFilterFactory(nList.item(i));\n      if (filt != null) filters.add(filt);\n    }\n\n    return new TokenizerChain(tfac, filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ffa55a3112f6a9ed19ca7e20579dff40c1f493b2","date":1180428723,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)Config.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n    Node tokNode = (Node)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODE);\n    NodeList nList = (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET);\n\n    if (tokNode==null){\n      throw new SolrException(500,\"analyzer without class or tokenizer & filter list\");\n    }\n    TokenizerFactory tfac = readTokenizerFactory(tokNode);\n\n    /******\n    // oops, getChildNodes() includes text (newlines, etc) in addition\n    // to the actual child elements\n    NodeList nList = node.getChildNodes();\n    TokenizerFactory tfac = readTokenizerFactory(nList.item(0));\n     if (tfac==null) {\n       throw new SolrException(500,\"TokenizerFactory must be specified first in analyzer\");\n     }\n    ******/\n\n    ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    for (int i=0; i<nList.getLength(); i++) {\n      TokenFilterFactory filt = readTokenFilterFactory(nList.item(i));\n      if (filt != null) filters.add(filt);\n    }\n\n    return new TokenizerChain(tfac, filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)Config.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n    Node tokNode = (Node)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODE);\n    NodeList nList = (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET);\n\n    if (tokNode==null){\n      throw new SolrException(1,\"analyzer without class or tokenizer & filter list\");\n    }\n    TokenizerFactory tfac = readTokenizerFactory(tokNode);\n\n    /******\n    // oops, getChildNodes() includes text (newlines, etc) in addition\n    // to the actual child elements\n    NodeList nList = node.getChildNodes();\n    TokenizerFactory tfac = readTokenizerFactory(nList.item(0));\n     if (tfac==null) {\n       throw new SolrException(1,\"TokenizerFactory must be specified first in analyzer\");\n     }\n    ******/\n\n    ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    for (int i=0; i<nList.getLength(); i++) {\n      TokenFilterFactory filt = readTokenFilterFactory(nList.item(i));\n      if (filt != null) filters.add(filt);\n    }\n\n    return new TokenizerChain(tfac, filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4abe53aaee39b5f2f41dd9a0b905c1ddf880996","date":1180477701,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)Config.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n    Node tokNode = (Node)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODE);\n    NodeList nList = (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET);\n\n    if (tokNode==null){\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    TokenizerFactory tfac = readTokenizerFactory(tokNode);\n\n    /******\n    // oops, getChildNodes() includes text (newlines, etc) in addition\n    // to the actual child elements\n    NodeList nList = node.getChildNodes();\n    TokenizerFactory tfac = readTokenizerFactory(nList.item(0));\n     if (tfac==null) {\n       throw new SolrException( SolrException.StatusCode.SERVER_ERROR,\"TokenizerFactory must be specified first in analyzer\");\n     }\n    ******/\n\n    ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    for (int i=0; i<nList.getLength(); i++) {\n      TokenFilterFactory filt = readTokenFilterFactory(nList.item(i));\n      if (filt != null) filters.add(filt);\n    }\n\n    return new TokenizerChain(tfac, filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)Config.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n    Node tokNode = (Node)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODE);\n    NodeList nList = (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET);\n\n    if (tokNode==null){\n      throw new SolrException(500,\"analyzer without class or tokenizer & filter list\");\n    }\n    TokenizerFactory tfac = readTokenizerFactory(tokNode);\n\n    /******\n    // oops, getChildNodes() includes text (newlines, etc) in addition\n    // to the actual child elements\n    NodeList nList = node.getChildNodes();\n    TokenizerFactory tfac = readTokenizerFactory(nList.item(0));\n     if (tfac==null) {\n       throw new SolrException(500,\"TokenizerFactory must be specified first in analyzer\");\n     }\n    ******/\n\n    ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    for (int i=0; i<nList.getLength(); i++) {\n      TokenFilterFactory filt = readTokenFilterFactory(nList.item(i));\n      if (filt != null) filters.add(filt);\n    }\n\n    return new TokenizerChain(tfac, filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6d6338c87060be5f66757a94945975f3bbd377a9","date":1189278234,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)solrConfig.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n    Node tokNode = (Node)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODE);\n    NodeList nList = (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET);\n\n    if (tokNode==null){\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    TokenizerFactory tfac = readTokenizerFactory(solrConfig, tokNode);\n\n    /******\n    // oops, getChildNodes() includes text (newlines, etc) in addition\n    // to the actual child elements\n    NodeList nList = node.getChildNodes();\n    TokenizerFactory tfac = readTokenizerFactory(nList.item(0));\n     if (tfac==null) {\n       throw new SolrException( SolrException.StatusCode.SERVER_ERROR,\"TokenizerFactory must be specified first in analyzer\");\n     }\n    ******/\n\n    ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    for (int i=0; i<nList.getLength(); i++) {\n      TokenFilterFactory filt = readTokenFilterFactory(solrConfig, nList.item(i));\n      if (filt != null) filters.add(filt);\n    }\n\n    return new TokenizerChain(tfac, filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)Config.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n    Node tokNode = (Node)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODE);\n    NodeList nList = (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET);\n\n    if (tokNode==null){\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    TokenizerFactory tfac = readTokenizerFactory(tokNode);\n\n    /******\n    // oops, getChildNodes() includes text (newlines, etc) in addition\n    // to the actual child elements\n    NodeList nList = node.getChildNodes();\n    TokenizerFactory tfac = readTokenizerFactory(nList.item(0));\n     if (tfac==null) {\n       throw new SolrException( SolrException.StatusCode.SERVER_ERROR,\"TokenizerFactory must be specified first in analyzer\");\n     }\n    ******/\n\n    ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    for (int i=0; i<nList.getLength(); i++) {\n      TokenFilterFactory filt = readTokenFilterFactory(nList.item(i));\n      if (filt != null) filters.add(filt);\n    }\n\n    return new TokenizerChain(tfac, filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fcf52a7da226d8d3756cc8bf9f3ae1f39952b014","date":1195912306,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)solrConfig.getResourceLoader().newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure \n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader = \n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return plugin; // does not need to do anything\n      }\n    };\n    tokenizerLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure somethign was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return plugin; // does not need to do anything\n      }\n    };\n    filterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)solrConfig.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n    Node tokNode = (Node)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODE);\n    NodeList nList = (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET);\n\n    if (tokNode==null){\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    TokenizerFactory tfac = readTokenizerFactory(solrConfig, tokNode);\n\n    /******\n    // oops, getChildNodes() includes text (newlines, etc) in addition\n    // to the actual child elements\n    NodeList nList = node.getChildNodes();\n    TokenizerFactory tfac = readTokenizerFactory(nList.item(0));\n     if (tfac==null) {\n       throw new SolrException( SolrException.StatusCode.SERVER_ERROR,\"TokenizerFactory must be specified first in analyzer\");\n     }\n    ******/\n\n    ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    for (int i=0; i<nList.getLength(); i++) {\n      TokenFilterFactory filt = readTokenFilterFactory(solrConfig, nList.item(i));\n      if (filt != null) filters.add(filt);\n    }\n\n    return new TokenizerChain(tfac, filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ddfdefa0e75d3bf3596b2309f6465f81273b9c9","date":1196616952,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)solrConfig.getResourceLoader().newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure \n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader = \n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)solrConfig.getResourceLoader().newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure \n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader = \n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return plugin; // does not need to do anything\n      }\n    };\n    tokenizerLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure somethign was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return plugin; // does not need to do anything\n      }\n    };\n    filterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"72cd269b00ce636078acda21f4b6f920b75dba13","date":1225131045,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)loader.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure \n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader = \n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)solrConfig.getResourceLoader().newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure \n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader = \n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"00c1e7284eb0e728903446dd05972acc9905dd53","date":1226627781,"type":3,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)loader.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)loader.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure \n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader = \n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n    \n    return new TokenizerChain(tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bf0e17cfd70114fa265a0ac990861cc37685024e","date":1268618829,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // nocommit: add support for CoreAware & Co here?\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)loader.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":["88f4b27679f86131b71575c0c68cae9ff261ac35"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8b712a9305796bf68e7e2515c4937771deeb5351","date":1268640574,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // nocommit: add support for CoreAware & Co here?\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // nocommit: add support for CoreAware & Co here?\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":["88f4b27679f86131b71575c0c68cae9ff261ac35"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4880f7e65af3c0bb359e5507a036acd44614bdcf","date":1268704387,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // No need to be core-aware as Analyzers are not in the core-aware list\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // nocommit: add support for CoreAware & Co here?\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":["88f4b27679f86131b71575c0c68cae9ff261ac35"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // No need to be core-aware as Analyzers are not in the core-aware list\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // No need to be core-aware as Analyzers are not in the core-aware list\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"6d6338c87060be5f66757a94945975f3bbd377a9":["c4abe53aaee39b5f2f41dd9a0b905c1ddf880996"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"c4abe53aaee39b5f2f41dd9a0b905c1ddf880996":["ffa55a3112f6a9ed19ca7e20579dff40c1f493b2"],"9ddfdefa0e75d3bf3596b2309f6465f81273b9c9":["fcf52a7da226d8d3756cc8bf9f3ae1f39952b014"],"72cd269b00ce636078acda21f4b6f920b75dba13":["9ddfdefa0e75d3bf3596b2309f6465f81273b9c9"],"0c3e228bf650e96f3002a8fb73dd0c13d55af077":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bf0e17cfd70114fa265a0ac990861cc37685024e":["00c1e7284eb0e728903446dd05972acc9905dd53"],"4880f7e65af3c0bb359e5507a036acd44614bdcf":["8b712a9305796bf68e7e2515c4937771deeb5351"],"00c1e7284eb0e728903446dd05972acc9905dd53":["72cd269b00ce636078acda21f4b6f920b75dba13"],"8b712a9305796bf68e7e2515c4937771deeb5351":["bf0e17cfd70114fa265a0ac990861cc37685024e"],"ad94625fb8d088209f46650c8097196fec67f00c":["4880f7e65af3c0bb359e5507a036acd44614bdcf"],"fcf52a7da226d8d3756cc8bf9f3ae1f39952b014":["6d6338c87060be5f66757a94945975f3bbd377a9"],"ffa55a3112f6a9ed19ca7e20579dff40c1f493b2":["0c3e228bf650e96f3002a8fb73dd0c13d55af077"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"6d6338c87060be5f66757a94945975f3bbd377a9":["fcf52a7da226d8d3756cc8bf9f3ae1f39952b014"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["0c3e228bf650e96f3002a8fb73dd0c13d55af077"],"c4abe53aaee39b5f2f41dd9a0b905c1ddf880996":["6d6338c87060be5f66757a94945975f3bbd377a9"],"9ddfdefa0e75d3bf3596b2309f6465f81273b9c9":["72cd269b00ce636078acda21f4b6f920b75dba13"],"72cd269b00ce636078acda21f4b6f920b75dba13":["00c1e7284eb0e728903446dd05972acc9905dd53"],"0c3e228bf650e96f3002a8fb73dd0c13d55af077":["ffa55a3112f6a9ed19ca7e20579dff40c1f493b2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"bf0e17cfd70114fa265a0ac990861cc37685024e":["8b712a9305796bf68e7e2515c4937771deeb5351"],"00c1e7284eb0e728903446dd05972acc9905dd53":["bf0e17cfd70114fa265a0ac990861cc37685024e"],"4880f7e65af3c0bb359e5507a036acd44614bdcf":["ad94625fb8d088209f46650c8097196fec67f00c"],"8b712a9305796bf68e7e2515c4937771deeb5351":["4880f7e65af3c0bb359e5507a036acd44614bdcf"],"fcf52a7da226d8d3756cc8bf9f3ae1f39952b014":["9ddfdefa0e75d3bf3596b2309f6465f81273b9c9"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"ffa55a3112f6a9ed19ca7e20579dff40c1f493b2":["c4abe53aaee39b5f2f41dd9a0b905c1ddf880996"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}