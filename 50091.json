{"path":"contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getLoggingAnalyzer(Analyzer,PrintStream,String).mjava","commits":[{"id":"d68e5c46e6a5ebdf4dafec4a123344092b915cc0","date":1256752193,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getLoggingAnalyzer(Analyzer,PrintStream,String).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil#getLoggingAnalyzer(Analyzer,PrintStream,String).mjava","sourceNew":"  /**\n   * Returns a simple analyzer wrapper that logs all tokens produced by the\n   * underlying child analyzer to the given log stream (typically System.err);\n   * Otherwise behaves exactly like the child analyzer, delivering the very\n   * same tokens; useful for debugging purposes on custom indexing and/or\n   * querying.\n   * \n   * @param child\n   *            the underlying child analyzer\n   * @param log\n   *            the print stream to log to (typically System.err)\n   * @param logName\n   *            a name for this logger (typically \"log\" or similar)\n   * @return a logging analyzer\n   */\n  public static Analyzer getLoggingAnalyzer(final Analyzer child, \n      final PrintStream log, final String logName) {\n    \n    if (child == null) \n      throw new IllegalArgumentException(\"child analyzer must not be null\");\n    if (log == null) \n      throw new IllegalArgumentException(\"logStream must not be null\");\n\n    return new Analyzer() {\n      public TokenStream tokenStream(final String fieldName, Reader reader) {\n        return new TokenFilter(child.tokenStream(fieldName, reader)) {\n          private int position = -1;\n          private TermAttribute termAtt = addAttribute(TermAttribute.class);\n          private PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          private TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n         \n          public boolean incrementToken() throws IOException {\n            boolean hasNext = input.incrementToken();\n            log.println(toString(hasNext));\n            return hasNext;\n          }\n          \n          private String toString(boolean hasNext) {\n            if (!hasNext) return \"[\" + logName + \":EOS:\" + fieldName + \"]\\n\";\n            \n            position += posIncrAtt.getPositionIncrement();\n            return \"[\" + logName + \":\" + position + \":\" + fieldName + \":\"\n                + termAtt.term() + \":\" + offsetAtt.startOffset()\n                + \"-\" + offsetAtt.endOffset() + \":\" + typeAtt.type()\n                + \"]\";\n          }         \n        };\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a simple analyzer wrapper that logs all tokens produced by the\n   * underlying child analyzer to the given log stream (typically System.err);\n   * Otherwise behaves exactly like the child analyzer, delivering the very\n   * same tokens; useful for debugging purposes on custom indexing and/or\n   * querying.\n   * \n   * @param child\n   *            the underlying child analyzer\n   * @param log\n   *            the print stream to log to (typically System.err)\n   * @param logName\n   *            a name for this logger (typically \"log\" or similar)\n   * @return a logging analyzer\n   */\n  public static Analyzer getLoggingAnalyzer(final Analyzer child, \n      final PrintStream log, final String logName) {\n    \n    if (child == null) \n      throw new IllegalArgumentException(\"child analyzer must not be null\");\n    if (log == null) \n      throw new IllegalArgumentException(\"logStream must not be null\");\n\n    return new Analyzer() {\n      public TokenStream tokenStream(final String fieldName, Reader reader) {\n        return new TokenFilter(child.tokenStream(fieldName, reader)) {\n          private int position = -1;\n          private TermAttribute termAtt = addAttribute(TermAttribute.class);\n          private PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          private TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n         \n          public boolean incrementToken() throws IOException {\n            boolean hasNext = input.incrementToken();\n            log.println(toString(hasNext));\n            return hasNext;\n          }\n          \n          private String toString(boolean hasNext) {\n            if (!hasNext) return \"[\" + logName + \":EOS:\" + fieldName + \"]\\n\";\n            \n            position += posIncrAtt.getPositionIncrement();\n            return \"[\" + logName + \":\" + position + \":\" + fieldName + \":\"\n                + termAtt.term() + \":\" + offsetAtt.startOffset()\n                + \"-\" + offsetAtt.endOffset() + \":\" + typeAtt.type()\n                + \"]\";\n          }         \n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d57eb7c98c08c03af6e4cd83509df31c81ac16af","date":1257684312,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getLoggingAnalyzer(Analyzer,PrintStream,String).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getLoggingAnalyzer(Analyzer,PrintStream,String).mjava","sourceNew":"  /**\n   * Returns a simple analyzer wrapper that logs all tokens produced by the\n   * underlying child analyzer to the given log stream (typically System.err);\n   * Otherwise behaves exactly like the child analyzer, delivering the very\n   * same tokens; useful for debugging purposes on custom indexing and/or\n   * querying.\n   * \n   * @param child\n   *            the underlying child analyzer\n   * @param log\n   *            the print stream to log to (typically System.err)\n   * @param logName\n   *            a name for this logger (typically \"log\" or similar)\n   * @return a logging analyzer\n   */\n  public static Analyzer getLoggingAnalyzer(final Analyzer child, \n      final PrintStream log, final String logName) {\n    \n    if (child == null) \n      throw new IllegalArgumentException(\"child analyzer must not be null\");\n    if (log == null) \n      throw new IllegalArgumentException(\"logStream must not be null\");\n\n    return new Analyzer() {\n      @Override\n      public TokenStream tokenStream(final String fieldName, Reader reader) {\n        return new TokenFilter(child.tokenStream(fieldName, reader)) {\n          private int position = -1;\n          private TermAttribute termAtt = addAttribute(TermAttribute.class);\n          private PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          private TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n         \n          @Override\n          public boolean incrementToken() throws IOException {\n            boolean hasNext = input.incrementToken();\n            log.println(toString(hasNext));\n            return hasNext;\n          }\n          \n          private String toString(boolean hasNext) {\n            if (!hasNext) return \"[\" + logName + \":EOS:\" + fieldName + \"]\\n\";\n            \n            position += posIncrAtt.getPositionIncrement();\n            return \"[\" + logName + \":\" + position + \":\" + fieldName + \":\"\n                + termAtt.term() + \":\" + offsetAtt.startOffset()\n                + \"-\" + offsetAtt.endOffset() + \":\" + typeAtt.type()\n                + \"]\";\n          }         \n        };\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a simple analyzer wrapper that logs all tokens produced by the\n   * underlying child analyzer to the given log stream (typically System.err);\n   * Otherwise behaves exactly like the child analyzer, delivering the very\n   * same tokens; useful for debugging purposes on custom indexing and/or\n   * querying.\n   * \n   * @param child\n   *            the underlying child analyzer\n   * @param log\n   *            the print stream to log to (typically System.err)\n   * @param logName\n   *            a name for this logger (typically \"log\" or similar)\n   * @return a logging analyzer\n   */\n  public static Analyzer getLoggingAnalyzer(final Analyzer child, \n      final PrintStream log, final String logName) {\n    \n    if (child == null) \n      throw new IllegalArgumentException(\"child analyzer must not be null\");\n    if (log == null) \n      throw new IllegalArgumentException(\"logStream must not be null\");\n\n    return new Analyzer() {\n      public TokenStream tokenStream(final String fieldName, Reader reader) {\n        return new TokenFilter(child.tokenStream(fieldName, reader)) {\n          private int position = -1;\n          private TermAttribute termAtt = addAttribute(TermAttribute.class);\n          private PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          private TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n         \n          public boolean incrementToken() throws IOException {\n            boolean hasNext = input.incrementToken();\n            log.println(toString(hasNext));\n            return hasNext;\n          }\n          \n          private String toString(boolean hasNext) {\n            if (!hasNext) return \"[\" + logName + \":EOS:\" + fieldName + \"]\\n\";\n            \n            position += posIncrAtt.getPositionIncrement();\n            return \"[\" + logName + \":\" + position + \":\" + fieldName + \":\"\n                + termAtt.term() + \":\" + offsetAtt.startOffset()\n                + \"-\" + offsetAtt.endOffset() + \":\" + typeAtt.type()\n                + \"]\";\n          }         \n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getLoggingAnalyzer(Analyzer,PrintStream,String).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getLoggingAnalyzer(Analyzer,PrintStream,String).mjava","sourceNew":"  /**\n   * Returns a simple analyzer wrapper that logs all tokens produced by the\n   * underlying child analyzer to the given log stream (typically System.err);\n   * Otherwise behaves exactly like the child analyzer, delivering the very\n   * same tokens; useful for debugging purposes on custom indexing and/or\n   * querying.\n   * \n   * @param child\n   *            the underlying child analyzer\n   * @param log\n   *            the print stream to log to (typically System.err)\n   * @param logName\n   *            a name for this logger (typically \"log\" or similar)\n   * @return a logging analyzer\n   */\n  public static Analyzer getLoggingAnalyzer(final Analyzer child, \n      final PrintStream log, final String logName) {\n    \n    if (child == null) \n      throw new IllegalArgumentException(\"child analyzer must not be null\");\n    if (log == null) \n      throw new IllegalArgumentException(\"logStream must not be null\");\n\n    return new Analyzer() {\n      @Override\n      public TokenStream tokenStream(final String fieldName, Reader reader) {\n        return new TokenFilter(child.tokenStream(fieldName, reader)) {\n          private int position = -1;\n          private TermAttribute termAtt = addAttribute(TermAttribute.class);\n          private PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          private TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n         \n          @Override\n          public boolean incrementToken() throws IOException {\n            boolean hasNext = input.incrementToken();\n            log.println(toString(hasNext));\n            return hasNext;\n          }\n          \n          private String toString(boolean hasNext) {\n            if (!hasNext) return \"[\" + logName + \":EOS:\" + fieldName + \"]\\n\";\n            \n            position += posIncrAtt.getPositionIncrement();\n            return \"[\" + logName + \":\" + position + \":\" + fieldName + \":\"\n                + termAtt.term() + \":\" + offsetAtt.startOffset()\n                + \"-\" + offsetAtt.endOffset() + \":\" + typeAtt.type()\n                + \"]\";\n          }         \n        };\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a simple analyzer wrapper that logs all tokens produced by the\n   * underlying child analyzer to the given log stream (typically System.err);\n   * Otherwise behaves exactly like the child analyzer, delivering the very\n   * same tokens; useful for debugging purposes on custom indexing and/or\n   * querying.\n   * \n   * @param child\n   *            the underlying child analyzer\n   * @param log\n   *            the print stream to log to (typically System.err)\n   * @param logName\n   *            a name for this logger (typically \"log\" or similar)\n   * @return a logging analyzer\n   */\n  public static Analyzer getLoggingAnalyzer(final Analyzer child, \n      final PrintStream log, final String logName) {\n    \n    if (child == null) \n      throw new IllegalArgumentException(\"child analyzer must not be null\");\n    if (log == null) \n      throw new IllegalArgumentException(\"logStream must not be null\");\n\n    return new Analyzer() {\n      @Override\n      public TokenStream tokenStream(final String fieldName, Reader reader) {\n        return new TokenFilter(child.tokenStream(fieldName, reader)) {\n          private int position = -1;\n          private TermAttribute termAtt = addAttribute(TermAttribute.class);\n          private PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          private TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n         \n          @Override\n          public boolean incrementToken() throws IOException {\n            boolean hasNext = input.incrementToken();\n            log.println(toString(hasNext));\n            return hasNext;\n          }\n          \n          private String toString(boolean hasNext) {\n            if (!hasNext) return \"[\" + logName + \":EOS:\" + fieldName + \"]\\n\";\n            \n            position += posIncrAtt.getPositionIncrement();\n            return \"[\" + logName + \":\" + position + \":\" + fieldName + \":\"\n                + termAtt.term() + \":\" + offsetAtt.startOffset()\n                + \"-\" + offsetAtt.endOffset() + \":\" + typeAtt.type()\n                + \"]\";\n          }         \n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d57eb7c98c08c03af6e4cd83509df31c81ac16af":["d68e5c46e6a5ebdf4dafec4a123344092b915cc0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["d57eb7c98c08c03af6e4cd83509df31c81ac16af"],"d68e5c46e6a5ebdf4dafec4a123344092b915cc0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d68e5c46e6a5ebdf4dafec4a123344092b915cc0"],"d57eb7c98c08c03af6e4cd83509df31c81ac16af":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"d68e5c46e6a5ebdf4dafec4a123344092b915cc0":["d57eb7c98c08c03af6e4cd83509df31c81ac16af"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}