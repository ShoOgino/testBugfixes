{"path":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","commits":[{"id":"0c066f7f6446f2d91513e81976f4b070a38763c7","date":1395242366,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","pathOld":"/dev/null","sourceNew":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"test\"));\n    pq.add(new Term(\"field\", \"http\"));\n    pq.add(new Term(\"field\", \"www\"));\n    pq.add(new Term(\"field\", \"facebook\"));\n    pq.add(new Term(\"field\", \"com\"));\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery();\n    pq2.add(new Term(\"field\", \"test\"));\n    pq2.add(new Term(\"field\", \"httpwwwfacebookcom\"));\n    pq2.add(new Term(\"field\", \"www\"));\n    pq2.add(new Term(\"field\", \"facebook\"));\n    pq2.add(new Term(\"field\", \"com\"));\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","sourceNew":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"test\"));\n    pq.add(new Term(\"field\", \"http\"));\n    pq.add(new Term(\"field\", \"www\"));\n    pq.add(new Term(\"field\", \"facebook\"));\n    pq.add(new Term(\"field\", \"com\"));\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery();\n    pq2.add(new Term(\"field\", \"test\"));\n    pq2.add(new Term(\"field\", \"httpwwwfacebookcom\"));\n    pq2.add(new Term(\"field\", \"www\"));\n    pq2.add(new Term(\"field\", \"facebook\"));\n    pq2.add(new Term(\"field\", \"com\"));\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"test\"));\n    pq.add(new Term(\"field\", \"http\"));\n    pq.add(new Term(\"field\", \"www\"));\n    pq.add(new Term(\"field\", \"facebook\"));\n    pq.add(new Term(\"field\", \"com\"));\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery();\n    pq2.add(new Term(\"field\", \"test\"));\n    pq2.add(new Term(\"field\", \"httpwwwfacebookcom\"));\n    pq2.add(new Term(\"field\", \"www\"));\n    pq2.add(new Term(\"field\", \"facebook\"));\n    pq2.add(new Term(\"field\", \"com\"));\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","sourceNew":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"test\"));\n    pq.add(new Term(\"field\", \"http\"));\n    pq.add(new Term(\"field\", \"www\"));\n    pq.add(new Term(\"field\", \"facebook\"));\n    pq.add(new Term(\"field\", \"com\"));\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery();\n    pq2.add(new Term(\"field\", \"test\"));\n    pq2.add(new Term(\"field\", \"httpwwwfacebookcom\"));\n    pq2.add(new Term(\"field\", \"www\"));\n    pq2.add(new Term(\"field\", \"facebook\"));\n    pq2.add(new Term(\"field\", \"com\"));\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"test\"));\n    pq.add(new Term(\"field\", \"http\"));\n    pq.add(new Term(\"field\", \"www\"));\n    pq.add(new Term(\"field\", \"facebook\"));\n    pq.add(new Term(\"field\", \"com\"));\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery();\n    pq2.add(new Term(\"field\", \"test\"));\n    pq2.add(new Term(\"field\", \"httpwwwfacebookcom\"));\n    pq2.add(new Term(\"field\", \"www\"));\n    pq2.add(new Term(\"field\", \"facebook\"));\n    pq2.add(new Term(\"field\", \"com\"));\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","sourceNew":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"test\"));\n    pq.add(new Term(\"field\", \"http\"));\n    pq.add(new Term(\"field\", \"www\"));\n    pq.add(new Term(\"field\", \"facebook\"));\n    pq.add(new Term(\"field\", \"com\"));\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery();\n    pq2.add(new Term(\"field\", \"test\"));\n    pq2.add(new Term(\"field\", \"httpwwwfacebookcom\"));\n    pq2.add(new Term(\"field\", \"www\"));\n    pq2.add(new Term(\"field\", \"facebook\"));\n    pq2.add(new Term(\"field\", \"com\"));\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"test\"));\n    pq.add(new Term(\"field\", \"http\"));\n    pq.add(new Term(\"field\", \"www\"));\n    pq.add(new Term(\"field\", \"facebook\"));\n    pq.add(new Term(\"field\", \"com\"));\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery();\n    pq2.add(new Term(\"field\", \"test\"));\n    pq2.add(new Term(\"field\", \"httpwwwfacebookcom\"));\n    pq2.add(new Term(\"field\", \"www\"));\n    pq2.add(new Term(\"field\", \"facebook\"));\n    pq2.add(new Term(\"field\", \"com\"));\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9e1499c5d26c936238506df90a3c02c76707722","date":1434449920,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","sourceNew":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery(\"field\", \"test\", \"http\", \"www\", \"facebook\", \"com\");\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery(\"field\", \"test\", \"httpwwwfacebookcom\", \"www\", \"facebook\", \"com\");\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"test\"));\n    pq.add(new Term(\"field\", \"http\"));\n    pq.add(new Term(\"field\", \"www\"));\n    pq.add(new Term(\"field\", \"facebook\"));\n    pq.add(new Term(\"field\", \"com\"));\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery();\n    pq2.add(new Term(\"field\", \"test\"));\n    pq2.add(new Term(\"field\", \"httpwwwfacebookcom\"));\n    pq2.add(new Term(\"field\", \"www\"));\n    pq2.add(new Term(\"field\", \"facebook\"));\n    pq2.add(new Term(\"field\", \"com\"));\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f68d01cf19df971dcdcb05e30247f4ad7ec9747","date":1434611645,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","sourceNew":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery(\"field\", \"test\", \"http\", \"www\", \"facebook\", \"com\");\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery(\"field\", \"test\", \"httpwwwfacebookcom\", \"www\", \"facebook\", \"com\");\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery.Builder bq = new BooleanQuery.Builder();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq.build(), reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery(\"field\", \"test\", \"http\", \"www\", \"facebook\", \"com\");\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery(\"field\", \"test\", \"httpwwwfacebookcom\", \"www\", \"facebook\", \"com\");\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a1862266772deb28cdcb7d996b64d2177022687","date":1453077824,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FastVectorHighlighterTest#testBooleanPhraseWithSynonym().mjava","sourceNew":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery(\"field\", \"test\", \"http\", \"www\", \"facebook\", \"com\");\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery(\"field\", \"test\", \"httpwwwfacebookcom\", \"www\", \"facebook\", \"com\");\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery.Builder bq = new BooleanQuery.Builder();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq.build(), reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBooleanPhraseWithSynonym() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    FieldType type = new FieldType(TextField.TYPE_NOT_STORED);\n    type.setStoreTermVectorOffsets(true);\n    type.setStoreTermVectorPositions(true);\n    type.setStoreTermVectors(true);\n    type.freeze();\n    Token syn = new Token(\"httpwwwfacebookcom\", 6, 29);\n    syn.setPositionIncrement(0);\n    CannedTokenStream ts = new CannedTokenStream(\n        new Token(\"test\", 0, 4),\n        new Token(\"http\", 6, 10),\n        syn,\n        new Token(\"www\", 13, 16),\n        new Token(\"facebook\", 17, 25),\n        new Token(\"com\", 26, 29)\n    );\n    Field field = new Field(\"field\", ts, type);\n    doc.add(field);\n    doc.add(new StoredField(\"field\", \"Test: http://www.facebook.com\"));\n    writer.addDocument(doc);\n    FastVectorHighlighter highlighter = new FastVectorHighlighter();\n    \n    IndexReader reader = DirectoryReader.open(writer, true);\n    int docId = 0;\n    \n    // query1: match\n    PhraseQuery pq = new PhraseQuery(\"field\", \"test\", \"http\", \"www\", \"facebook\", \"com\");\n    FieldQuery fieldQuery  = highlighter.getFieldQuery(pq, reader);\n    String[] bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query2: match\n    PhraseQuery pq2 = new PhraseQuery(\"field\", \"test\", \"httpwwwfacebookcom\", \"www\", \"facebook\", \"com\");\n    fieldQuery  = highlighter.getFieldQuery(pq2, reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    // query3: OR query1 and query2 together\n    BooleanQuery.Builder bq = new BooleanQuery.Builder();\n    bq.add(pq, BooleanClause.Occur.SHOULD);\n    bq.add(pq2, BooleanClause.Occur.SHOULD);\n    fieldQuery  = highlighter.getFieldQuery(bq.build(), reader);\n    bestFragments = highlighter.getBestFragments(fieldQuery, reader, docId, \"field\", 54, 1);\n    assertEquals(\"<b>Test: http://www.facebook.com</b>\", bestFragments[0]);\n    \n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["e9e1499c5d26c936238506df90a3c02c76707722"],"2a1862266772deb28cdcb7d996b64d2177022687":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"e9e1499c5d26c936238506df90a3c02c76707722":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["0c066f7f6446f2d91513e81976f4b070a38763c7"],"0c066f7f6446f2d91513e81976f4b070a38763c7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2a1862266772deb28cdcb7d996b64d2177022687"]},"commit2Childs":{"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["2a1862266772deb28cdcb7d996b64d2177022687"],"2a1862266772deb28cdcb7d996b64d2177022687":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"e9e1499c5d26c936238506df90a3c02c76707722":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0c066f7f6446f2d91513e81976f4b070a38763c7"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["e9e1499c5d26c936238506df90a3c02c76707722"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"0c066f7f6446f2d91513e81976f4b070a38763c7":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}