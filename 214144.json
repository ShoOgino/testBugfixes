{"path":"solr/core/src/java/org/apache/solr/rest/schema/FieldTypeXmlAdapter#createAnalyzerElement(Document,String,Map[String,#]).mjava","commits":[{"id":"bdf16ebe435fc9daea90a73b8683ff001c6d3523","date":1409931231,"type":0,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/rest/schema/FieldTypeXmlAdapter#createAnalyzerElement(Document,String,Map[String,#]).mjava","pathOld":"/dev/null","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  protected static Element createAnalyzerElement(Document doc, String type, Map<String,?> json) {\n    Element analyzer = doc.createElement(\"analyzer\");\n    if (type != null)\n      analyzer.setAttribute(\"type\", type);\n    \n    // charFilter(s)\n    List<Map<String,?>> charFilters = (List<Map<String,?>>)json.get(\"charFilters\");\n    if (charFilters != null)\n      appendFilterElements(doc, analyzer, \"charFilter\", charFilters);\n    \n    // tokenizer\n    Map<String,?> tokenizerJson = (Map<String,?>)json.get(\"tokenizer\");\n    if (tokenizerJson == null)\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Analyzer must define a tokenizer!\");\n    \n    String tokClass = (String)tokenizerJson.get(\"class\");\n    if (tokClass == null)\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Every tokenizer must define a class property!\");\n    \n    analyzer.appendChild(appendAttrs(doc.createElement(\"tokenizer\"), tokenizerJson));\n    \n    // filter(s)\n    List<Map<String,?>> filters = (List<Map<String,?>>)json.get(\"filters\");\n    if (filters != null)\n      appendFilterElements(doc, analyzer, \"filter\", filters);\n    \n    return analyzer;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["3c3d2444349054ee067813f2bec7610c0933009b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3c3d2444349054ee067813f2bec7610c0933009b","date":1434665250,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/rest/schema/FieldTypeXmlAdapter#createAnalyzerElement(Document,String,Map[String,#]).mjava","pathOld":"solr/core/src/java/org/apache/solr/rest/schema/FieldTypeXmlAdapter#createAnalyzerElement(Document,String,Map[String,#]).mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  protected static Element createAnalyzerElement(Document doc, String type, Map<String,?> analyzer) {\n    Element analyzerElem = appendAttrs(doc.createElement(\"analyzer\"), analyzer);\n    if (type != null)\n      analyzerElem.setAttribute(\"type\", type);\n\n    List<Map<String,?>> charFilters = (List<Map<String,?>>)analyzer.get(\"charFilters\");\n    Map<String,?> tokenizer = (Map<String,?>)analyzer.get(\"tokenizer\");\n    List<Map<String,?>> filters = (List<Map<String,?>>)analyzer.get(\"filters\");\n\n    if (analyzer.get(\"class\") == null) {\n      if (charFilters != null)\n        appendFilterElements(doc, analyzerElem, \"charFilter\", charFilters);\n\n      if (tokenizer == null)\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Analyzer must define a tokenizer!\");\n\n      if (tokenizer.get(\"class\") == null)\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Every tokenizer must define a class property!\");\n\n      analyzerElem.appendChild(appendAttrs(doc.createElement(\"tokenizer\"), tokenizer));\n\n      if (filters != null)\n        appendFilterElements(doc, analyzerElem, \"filter\", filters);\n\n    } else { // When analyzer class is specified: char filters, tokenizers, and filters are disallowed\n      if (charFilters != null)\n        throw new SolrException\n            (ErrorCode.BAD_REQUEST, \"An analyzer with a class property may not define any char filters!\");\n\n      if (tokenizer != null)\n        throw new SolrException\n            (ErrorCode.BAD_REQUEST, \"An analyzer with a class property may not define a tokenizer!\");\n\n      if (filters != null)\n        throw new SolrException\n            (ErrorCode.BAD_REQUEST, \"An analyzer with a class property may not define any filters!\");\n    }\n    \n    return analyzerElem;\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  protected static Element createAnalyzerElement(Document doc, String type, Map<String,?> json) {\n    Element analyzer = doc.createElement(\"analyzer\");\n    if (type != null)\n      analyzer.setAttribute(\"type\", type);\n    \n    // charFilter(s)\n    List<Map<String,?>> charFilters = (List<Map<String,?>>)json.get(\"charFilters\");\n    if (charFilters != null)\n      appendFilterElements(doc, analyzer, \"charFilter\", charFilters);\n    \n    // tokenizer\n    Map<String,?> tokenizerJson = (Map<String,?>)json.get(\"tokenizer\");\n    if (tokenizerJson == null)\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Analyzer must define a tokenizer!\");\n    \n    String tokClass = (String)tokenizerJson.get(\"class\");\n    if (tokClass == null)\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Every tokenizer must define a class property!\");\n    \n    analyzer.appendChild(appendAttrs(doc.createElement(\"tokenizer\"), tokenizerJson));\n    \n    // filter(s)\n    List<Map<String,?>> filters = (List<Map<String,?>>)json.get(\"filters\");\n    if (filters != null)\n      appendFilterElements(doc, analyzer, \"filter\", filters);\n    \n    return analyzer;\n  }\n\n","bugFix":["bdf16ebe435fc9daea90a73b8683ff001c6d3523"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c24804758d67429e3055070a9fe970d4f159954","date":1565508925,"type":3,"author":"Tomoko Uchida","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/rest/schema/FieldTypeXmlAdapter#createAnalyzerElement(Document,String,Map[String,#]).mjava","pathOld":"solr/core/src/java/org/apache/solr/rest/schema/FieldTypeXmlAdapter#createAnalyzerElement(Document,String,Map[String,#]).mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  protected static Element createAnalyzerElement(Document doc, String type, Map<String,?> analyzer) {\n    Element analyzerElem = appendAttrs(doc.createElement(\"analyzer\"), analyzer);\n    if (type != null)\n      analyzerElem.setAttribute(\"type\", type);\n\n    List<Map<String,?>> charFilters = (List<Map<String,?>>)analyzer.get(\"charFilters\");\n    Map<String,?> tokenizer = (Map<String,?>)analyzer.get(\"tokenizer\");\n    List<Map<String,?>> filters = (List<Map<String,?>>)analyzer.get(\"filters\");\n\n    if (analyzer.get(\"class\") == null) {\n      if (charFilters != null)\n        appendFilterElements(doc, analyzerElem, \"charFilter\", charFilters);\n\n      if (tokenizer == null)\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Analyzer must define a tokenizer!\");\n\n      if (tokenizer.get(\"class\") == null && tokenizer.get(\"name\") == null)\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Every tokenizer must define a class or name property!\");\n\n      analyzerElem.appendChild(appendAttrs(doc.createElement(\"tokenizer\"), tokenizer));\n\n      if (filters != null)\n        appendFilterElements(doc, analyzerElem, \"filter\", filters);\n\n    } else { // When analyzer class is specified: char filters, tokenizers, and filters are disallowed\n      if (charFilters != null)\n        throw new SolrException\n            (ErrorCode.BAD_REQUEST, \"An analyzer with a class property may not define any char filters!\");\n\n      if (tokenizer != null)\n        throw new SolrException\n            (ErrorCode.BAD_REQUEST, \"An analyzer with a class property may not define a tokenizer!\");\n\n      if (filters != null)\n        throw new SolrException\n            (ErrorCode.BAD_REQUEST, \"An analyzer with a class property may not define any filters!\");\n    }\n    \n    return analyzerElem;\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  protected static Element createAnalyzerElement(Document doc, String type, Map<String,?> analyzer) {\n    Element analyzerElem = appendAttrs(doc.createElement(\"analyzer\"), analyzer);\n    if (type != null)\n      analyzerElem.setAttribute(\"type\", type);\n\n    List<Map<String,?>> charFilters = (List<Map<String,?>>)analyzer.get(\"charFilters\");\n    Map<String,?> tokenizer = (Map<String,?>)analyzer.get(\"tokenizer\");\n    List<Map<String,?>> filters = (List<Map<String,?>>)analyzer.get(\"filters\");\n\n    if (analyzer.get(\"class\") == null) {\n      if (charFilters != null)\n        appendFilterElements(doc, analyzerElem, \"charFilter\", charFilters);\n\n      if (tokenizer == null)\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Analyzer must define a tokenizer!\");\n\n      if (tokenizer.get(\"class\") == null)\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Every tokenizer must define a class property!\");\n\n      analyzerElem.appendChild(appendAttrs(doc.createElement(\"tokenizer\"), tokenizer));\n\n      if (filters != null)\n        appendFilterElements(doc, analyzerElem, \"filter\", filters);\n\n    } else { // When analyzer class is specified: char filters, tokenizers, and filters are disallowed\n      if (charFilters != null)\n        throw new SolrException\n            (ErrorCode.BAD_REQUEST, \"An analyzer with a class property may not define any char filters!\");\n\n      if (tokenizer != null)\n        throw new SolrException\n            (ErrorCode.BAD_REQUEST, \"An analyzer with a class property may not define a tokenizer!\");\n\n      if (filters != null)\n        throw new SolrException\n            (ErrorCode.BAD_REQUEST, \"An analyzer with a class property may not define any filters!\");\n    }\n    \n    return analyzerElem;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2c24804758d67429e3055070a9fe970d4f159954":["3c3d2444349054ee067813f2bec7610c0933009b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3c3d2444349054ee067813f2bec7610c0933009b":["bdf16ebe435fc9daea90a73b8683ff001c6d3523"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2c24804758d67429e3055070a9fe970d4f159954"],"bdf16ebe435fc9daea90a73b8683ff001c6d3523":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"2c24804758d67429e3055070a9fe970d4f159954":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["bdf16ebe435fc9daea90a73b8683ff001c6d3523"],"3c3d2444349054ee067813f2bec7610c0933009b":["2c24804758d67429e3055070a9fe970d4f159954"],"bdf16ebe435fc9daea90a73b8683ff001c6d3523":["3c3d2444349054ee067813f2bec7610c0933009b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}