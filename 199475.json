{"path":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = IndexReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.getSequentialSubReaders().length);\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = IndexReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.getSequentialSubReaders().length);\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.getSequentialSubReaders().length);\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = IndexReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.getSequentialSubReaders().length);\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.getSequentialSubReaders().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.getSequentialSubReaders().length);\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":["ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ced66195b26fdb1f77ee00e2a77ec6918dedd766","date":1344948886,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.getSequentialSubReaders().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","bugFix":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.getSequentialSubReaders().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.getSequentialSubReaders().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.getSequentialSubReaders().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.getSequentialSubReaders().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.shutdown();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.shutdown();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.shutdown();\n      writer = new IndexWriter(directory, newIndexWriterConfig(ANALYZER)\n          .setOpenMode(OpenMode.APPEND)\n          .setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.shutdown();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.shutdown();\n      writer = new IndexWriter(directory, newIndexWriterConfig(\n          TEST_VERSION_CURRENT, ANALYZER).setOpenMode(\n          OpenMode.APPEND).setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.shutdown();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(ANALYZER)\n          .setOpenMode(OpenMode.APPEND)\n          .setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.shutdown();\n      writer = new IndexWriter(directory, newIndexWriterConfig(ANALYZER)\n          .setOpenMode(OpenMode.APPEND)\n          .setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.shutdown();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"feb4029567b43f074ed7b6eb8fb126d355075dfd","date":1544812585,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestThreadedForceMerge#runTest(Random,Directory).mjava","sourceNew":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.getDocStats().numDocs + \" maxDoc=\" + writer.getDocStats().maxDoc + \" config=\" + writer.getConfig(), expectedDocCount, writer.getDocStats().numDocs);\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.getDocStats().numDocs + \" maxDoc=\" + writer.getDocStats().maxDoc + \" config=\" + writer.getConfig(), expectedDocCount, writer.getDocStats().maxDoc);\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(ANALYZER)\n          .setOpenMode(OpenMode.APPEND)\n          .setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","sourceOld":"  public void runTest(Random random, Directory directory) throws Exception {\n\n    IndexWriter writer = new IndexWriter(\n        directory,\n        newIndexWriterConfig(ANALYZER).\n            setOpenMode(OpenMode.CREATE).\n            setMaxBufferedDocs(2).\n            setMergePolicy(newLogMergePolicy())\n    );\n\n    for(int iter=0;iter<NUM_ITER;iter++) {\n      final int iterFinal = iter;\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);\n\n      final FieldType customType = new FieldType(StringField.TYPE_STORED);\n      customType.setOmitNorms(true);\n      \n      for(int i=0;i<200;i++) {\n        Document d = new Document();\n        d.add(newField(\"id\", Integer.toString(i), customType));\n        d.add(newField(\"contents\", English.intToEnglish(i), customType));\n        writer.addDocument(d);\n      }\n\n      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);\n\n      Thread[] threads = new Thread[NUM_THREADS];\n      \n      for(int i=0;i<NUM_THREADS;i++) {\n        final int iFinal = i;\n        final IndexWriter writerFinal = writer;\n        threads[i] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              for(int j=0;j<NUM_ITER2;j++) {\n                writerFinal.forceMerge(1, false);\n                for(int k=0;k<17*(1+iFinal);k++) {\n                  Document d = new Document();\n                  d.add(newField(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k, customType));\n                  d.add(newField(\"contents\", English.intToEnglish(iFinal+k), customType));\n                  writerFinal.addDocument(d);\n                }\n                for(int k=0;k<9*(1+iFinal);k++)\n                  writerFinal.deleteDocuments(new Term(\"id\", iterFinal + \"_\" + iFinal + \"_\" + j + \"_\" + k));\n                writerFinal.forceMerge(1);\n              }\n            } catch (Throwable t) {\n              setFailed();\n              System.out.println(Thread.currentThread().getName() + \": hit exception\");\n              t.printStackTrace(System.out);\n            }\n          }\n        };\n      }\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].start();\n\n      for(int i=0;i<NUM_THREADS;i++)\n        threads[i].join();\n\n      assertTrue(!failed);\n\n      final int expectedDocCount = (int) ((1+iter)*(200+8*NUM_ITER2*(NUM_THREADS/2.0)*(1+NUM_THREADS)));\n\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.numDocs());\n      assertEquals(\"index=\" + writer.segString() + \" numDocs=\" + writer.numDocs() + \" maxDoc=\" + writer.maxDoc() + \" config=\" + writer.getConfig(), expectedDocCount, writer.maxDoc());\n\n      writer.close();\n      writer = new IndexWriter(directory, newIndexWriterConfig(ANALYZER)\n          .setOpenMode(OpenMode.APPEND)\n          .setMaxBufferedDocs(2));\n      \n      DirectoryReader reader = DirectoryReader.open(directory);\n      assertEquals(\"reader=\" + reader, 1, reader.leaves().size());\n      assertEquals(expectedDocCount, reader.numDocs());\n      reader.close();\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"feb4029567b43f074ed7b6eb8fb126d355075dfd":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"ced66195b26fdb1f77ee00e2a77ec6918dedd766":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["feb4029567b43f074ed7b6eb8fb126d355075dfd"]},"commit2Childs":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["3c188105a9aae04f56c24996f98f8333fc825d2e","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","ced66195b26fdb1f77ee00e2a77ec6918dedd766"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"feb4029567b43f074ed7b6eb8fb126d355075dfd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["feb4029567b43f074ed7b6eb8fb126d355075dfd"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ced66195b26fdb1f77ee00e2a77ec6918dedd766":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}