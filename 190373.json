{"path":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","commits":[{"id":"c8dc32eb86895b9e6625afad8d7071931ee0f0b2","date":1244184369,"type":1,"author":"Noble Paul","isMerge":false,"pathNew":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    resolver.context = context1;\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.pk).equals(row.get(entity.pk))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity,\n                                               DataConfig.Entity parentEntity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, entity, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entities\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    resolver.addNamespace(null, (Map) entity.allAttributes);\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    resolver.context = context1;\n    entityProcessor.init(context1);\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.pk).equals(row.get(entity.pk))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //so propogate up the changes in the chain\n    if (parentEntity != null && parentEntity.isDocRoot) {\n      EntityProcessor parentEntityProcessor = getEntityProcessor(parentEntity);\n      ContextImpl context2 = new ContextImpl(parentEntity, resolver, null, Context.FIND_DELTA, session, null, this);\n      resolver.context = context2;\n      parentEntityProcessor.init(context2);\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, parentEntityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, parentEntityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"210e60bfae7c0585fc04cfe0f50c2b14a841e4e2","date":1245919165,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.pk).equals(row.get(entity.pk))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    resolver.context = context1;\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.pk).equals(row.get(entity.pk))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"782154d790b2066a4483cdc8f835e4d8c4ad66d8","date":1251194066,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.getPk()).equals(row.get(entity.getPk()))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.pk).equals(row.get(entity.pk))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","bugFix":["5a2fb92cb166ab36a1320f8bf3cb157063177c45"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","pathOld":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/DocBuilder#collectDelta(DataConfig.Entity,VariableResolverImpl,Set[Map[String,Object]]).mjava","sourceNew":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.getPk()).equals(row.get(entity.getPk()))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","sourceOld":"  /**\n   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last\n   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level\n   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>\n   *\n   * @return an iterator to the list of keys for which Solr documents should be updated.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity, VariableResolverImpl resolver,\n                                               Set<Map<String, Object>> deletedRows) {\n    //someone called abort\n    if (stop.get())\n      return new HashSet();\n\n    EntityProcessor entityProcessor = getEntityProcessor(entity);\n    ContextImpl context1 = new ContextImpl(entity, resolver, null, Context.FIND_DELTA, session, null, this);\n    entityProcessor.init(context1);\n\n    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();\n\n    if (entity.entities != null) {\n\n      for (DataConfig.Entity entity1 : entity.entities) {\n        //this ensures that we start from the leaf nodes\n        myModifiedPks.addAll(collectDelta(entity1, resolver, deletedRows));\n        //someone called abort\n        if (stop.get())\n          return new HashSet();\n      }\n\n    }\n    // identifying the modified rows for this entity\n\n    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();\n    LOG.info(\"Running ModifiedRowKey() for Entity: \" + entity.name);\n    //get the modified rows in this entity\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextModifiedRowKey();\n\n      if (row == null)\n        break;\n\n      deltaSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n    //get the deleted rows for this entity\n    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();\n    Set<Map<String, Object>> deltaRemoveSet = new HashSet<Map<String, Object>>();\n    while (true) {\n      Map<String, Object> row = entityProcessor.nextDeletedRowKey();\n      if (row == null)\n        break;\n\n      //Check to see if this delete is in the current delta set\n      for (Map<String, Object> modifiedRow : deltaSet) {\n        if (modifiedRow.get(entity.getPk()).equals(row.get(entity.getPk()))) {\n          deltaRemoveSet.add(modifiedRow);\n        }\n      }\n\n      deletedSet.add(row);\n      importStatistics.rowsCount.incrementAndGet();\n      // check for abort\n      if (stop.get())\n        return new HashSet();\n    }\n\n    //asymmetric Set difference\n    deltaSet.removeAll(deltaRemoveSet);\n\n    LOG.info(\"Completed ModifiedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deltaSet.size());\n    LOG.info(\"Completed DeletedRowKey for Entity: \" + entity.name + \" rows obtained : \" + deletedSet.size());\n\n    myModifiedPks.addAll(deltaSet);\n    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();\n    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these\n    //propogate up the changes in the chain\n    if (entity.parentEntity != null) {\n      // identifying deleted rows with deltas\n\n      for (Map<String, Object> row : myModifiedPks) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n      // running the same for deletedrows\n      for (Map<String, Object> row : deletedSet) {\n        getModifiedParentRows(resolver.addNamespace(entity.name, row), entity.name, entityProcessor, parentKeyList);\n        // check for abort\n        if (stop.get())\n          return new HashSet();\n      }\n    }\n    LOG.info(\"Completed parentDeltaQuery for Entity: \" + entity.name);\n    if (entity.isDocRoot)\n      deletedRows.addAll(deletedSet);\n\n    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(\n            parentKeyList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"782154d790b2066a4483cdc8f835e4d8c4ad66d8":["210e60bfae7c0585fc04cfe0f50c2b14a841e4e2"],"c8dc32eb86895b9e6625afad8d7071931ee0f0b2":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ad94625fb8d088209f46650c8097196fec67f00c":["782154d790b2066a4483cdc8f835e4d8c4ad66d8"],"210e60bfae7c0585fc04cfe0f50c2b14a841e4e2":["c8dc32eb86895b9e6625afad8d7071931ee0f0b2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"782154d790b2066a4483cdc8f835e4d8c4ad66d8":["ad94625fb8d088209f46650c8097196fec67f00c"],"c8dc32eb86895b9e6625afad8d7071931ee0f0b2":["210e60bfae7c0585fc04cfe0f50c2b14a841e4e2"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["c8dc32eb86895b9e6625afad8d7071931ee0f0b2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"210e60bfae7c0585fc04cfe0f50c2b14a841e4e2":["782154d790b2066a4483cdc8f835e4d8c4ad66d8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}