{"path":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","commits":[{"id":"ebcb21d043bc7d0dba7d6a2999514e4f4af22ab0","date":1424186100,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","pathOld":"/dev/null","sourceNew":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertSame(postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for docs only: ok\n    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);\n    assertEquals(-1, docsOnly.docID());\n    assertEquals(0, docsOnly.nextDoc());\n    assertEquals(1, docsOnly.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());\n    // reuse that too\n    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);\n    assertNotNull(docsOnly2);\n    assertSame(docsOnly, docsOnly2);\n    // and it had better work\n    assertEquals(-1, docsOnly2.docID());\n    assertEquals(0, docsOnly2.nextDoc());\n    assertEquals(1, docsOnly2.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());\n    \n    // we did not index positions\n    PostingsEnum docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.POSITIONS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.PAYLOADS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.OFFSETS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n    assertNull(docsAndPositionsEnum);\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cb5311f0bff57ce15a23909f4cfb953773630534","date":1424827033,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","sourceNew":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertSame(postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for docs only: ok\n    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);\n    assertEquals(-1, docsOnly.docID());\n    assertEquals(0, docsOnly.nextDoc());\n    assertEquals(1, docsOnly.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());\n    // reuse that too\n    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);\n    assertNotNull(docsOnly2);\n    assertSame(docsOnly, docsOnly2);\n    // and it had better work\n    assertEquals(-1, docsOnly2.docID());\n    assertEquals(0, docsOnly2.nextDoc());\n    assertEquals(1, docsOnly2.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());\n    \n    // we did not index positions\n    PostingsEnum docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.POSITIONS);\n    // nocommit: check\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.PAYLOADS);\n    // nocommit: check\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.OFFSETS);\n    // nocommit: check\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n    // nocommit: check\n    assertNull(docsAndPositionsEnum);\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertSame(postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for docs only: ok\n    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);\n    assertEquals(-1, docsOnly.docID());\n    assertEquals(0, docsOnly.nextDoc());\n    assertEquals(1, docsOnly.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());\n    // reuse that too\n    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);\n    assertNotNull(docsOnly2);\n    assertSame(docsOnly, docsOnly2);\n    // and it had better work\n    assertEquals(-1, docsOnly2.docID());\n    assertEquals(0, docsOnly2.nextDoc());\n    assertEquals(1, docsOnly2.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());\n    \n    // we did not index positions\n    PostingsEnum docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.POSITIONS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.PAYLOADS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.OFFSETS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n    assertNull(docsAndPositionsEnum);\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cb77aeaebb451427f825381042f68a6916417d1d","date":1427819930,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","sourceNew":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertSame(postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for docs only: ok\n    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);\n    assertEquals(-1, docsOnly.docID());\n    assertEquals(0, docsOnly.nextDoc());\n    assertEquals(1, docsOnly.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());\n    // reuse that too\n    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);\n    assertNotNull(docsOnly2);\n    assertSame(docsOnly, docsOnly2);\n    // and it had better work\n    assertEquals(-1, docsOnly2.docID());\n    assertEquals(0, docsOnly2.nextDoc());\n    assertEquals(1, docsOnly2.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());\n    \n    // we did not index positions\n    PostingsEnum docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.POSITIONS);\n    assertNotNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.PAYLOADS);\n    assertNotNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.OFFSETS);\n    assertNotNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n    assertNotNull(docsAndPositionsEnum);\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertSame(postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for docs only: ok\n    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);\n    assertEquals(-1, docsOnly.docID());\n    assertEquals(0, docsOnly.nextDoc());\n    assertEquals(1, docsOnly.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());\n    // reuse that too\n    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);\n    assertNotNull(docsOnly2);\n    assertSame(docsOnly, docsOnly2);\n    // and it had better work\n    assertEquals(-1, docsOnly2.docID());\n    assertEquals(0, docsOnly2.nextDoc());\n    assertEquals(1, docsOnly2.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());\n    \n    // we did not index positions\n    PostingsEnum docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.POSITIONS);\n    // nocommit: check\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.PAYLOADS);\n    // nocommit: check\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.OFFSETS);\n    // nocommit: check\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n    // nocommit: check\n    assertNull(docsAndPositionsEnum);\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8c2189c92e27c6a628b665c0482041efecaf7cb4","date":1427904014,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","sourceNew":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertSame(postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for any flags: ok\n    for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {\n      postings = termsEnum.postings(null, null, flag);\n      assertEquals(-1, postings.docID());\n      assertEquals(0, postings.nextDoc());\n      assertEquals(1, postings.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n      // reuse that too\n      postings2 = termsEnum.postings(null, postings, flag);\n      assertNotNull(postings2);\n      assertSame(postings, postings2);\n      // and it had better work\n      assertEquals(-1, postings2.docID());\n      assertEquals(0, postings2.nextDoc());\n      assertEquals(1, postings2.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());\n    }\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertSame(postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for docs only: ok\n    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);\n    assertEquals(-1, docsOnly.docID());\n    assertEquals(0, docsOnly.nextDoc());\n    assertEquals(1, docsOnly.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());\n    // reuse that too\n    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);\n    assertNotNull(docsOnly2);\n    assertSame(docsOnly, docsOnly2);\n    // and it had better work\n    assertEquals(-1, docsOnly2.docID());\n    assertEquals(0, docsOnly2.nextDoc());\n    assertEquals(1, docsOnly2.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());\n    \n    // we did not index positions\n    PostingsEnum docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.POSITIONS);\n    assertNotNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.PAYLOADS);\n    assertNotNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.OFFSETS);\n    assertNotNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n    assertNotNull(docsAndPositionsEnum);\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6404b8725cd3df3fda5f1c19a46cac85e49f070c","date":1427911851,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","sourceNew":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertReused(\"foo\", postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for any flags: ok\n    for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {\n      postings = termsEnum.postings(null, null, flag);\n      assertEquals(-1, postings.docID());\n      assertEquals(0, postings.nextDoc());\n      assertEquals(1, postings.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n      // reuse that too\n      postings2 = termsEnum.postings(null, postings, flag);\n      assertNotNull(postings2);\n      assertReused(\"foo\", postings, postings2);\n      // and it had better work\n      assertEquals(-1, postings2.docID());\n      assertEquals(0, postings2.nextDoc());\n      assertEquals(1, postings2.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());\n    }\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertSame(postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for any flags: ok\n    for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {\n      postings = termsEnum.postings(null, null, flag);\n      assertEquals(-1, postings.docID());\n      assertEquals(0, postings.nextDoc());\n      assertEquals(1, postings.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n      // reuse that too\n      postings2 = termsEnum.postings(null, postings, flag);\n      assertNotNull(postings2);\n      assertSame(postings, postings2);\n      // and it had better work\n      assertEquals(-1, postings2.docID());\n      assertEquals(0, postings2.nextDoc());\n      assertEquals(1, postings2.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());\n    }\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"db32fd0015139a1e3e1703a5d5e6b560c5adb1ca","date":1427913177,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase#testPostingsEnumDocsOnly().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","sourceNew":"  public void testPostingsEnumDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertReused(\"foo\", postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for any flags: ok\n    for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {\n      postings = termsEnum.postings(null, null, flag);\n      assertEquals(-1, postings.docID());\n      assertEquals(0, postings.nextDoc());\n      assertEquals(1, postings.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n      // reuse that too\n      postings2 = termsEnum.postings(null, postings, flag);\n      assertNotNull(postings2);\n      assertReused(\"foo\", postings, postings2);\n      // and it had better work\n      assertEquals(-1, postings2.docID());\n      assertEquals(0, postings2.nextDoc());\n      assertEquals(1, postings2.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());\n    }\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertReused(\"foo\", postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for any flags: ok\n    for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {\n      postings = termsEnum.postings(null, null, flag);\n      assertEquals(-1, postings.docID());\n      assertEquals(0, postings.nextDoc());\n      assertEquals(1, postings.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n      // reuse that too\n      postings2 = termsEnum.postings(null, postings, flag);\n      assertNotNull(postings2);\n      assertReused(\"foo\", postings, postings2);\n      // and it had better work\n      assertEquals(-1, postings2.docID());\n      assertEquals(0, postings2.nextDoc());\n      assertEquals(1, postings2.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());\n    }\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b4e3cd382d0d075a0f1725649c084bb6510c483","date":1428096423,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BasePostingsFormatTestCase#testPostingsEnumDocsOnly().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","sourceNew":"  public void testPostingsEnumDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertReused(\"foo\", postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for any flags: ok\n    for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {\n      postings = termsEnum.postings(null, null, flag);\n      assertEquals(-1, postings.docID());\n      assertEquals(0, postings.nextDoc());\n      assertEquals(1, postings.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n      // reuse that too\n      postings2 = termsEnum.postings(null, postings, flag);\n      assertNotNull(postings2);\n      assertReused(\"foo\", postings, postings2);\n      // and it had better work\n      assertEquals(-1, postings2.docID());\n      assertEquals(0, postings2.nextDoc());\n      assertEquals(1, postings2.freq());\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());\n    }\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertSame(postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for docs only: ok\n    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);\n    assertEquals(-1, docsOnly.docID());\n    assertEquals(0, docsOnly.nextDoc());\n    assertEquals(1, docsOnly.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());\n    // reuse that too\n    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);\n    assertNotNull(docsOnly2);\n    assertSame(docsOnly, docsOnly2);\n    // and it had better work\n    assertEquals(-1, docsOnly2.docID());\n    assertEquals(0, docsOnly2.nextDoc());\n    assertEquals(1, docsOnly2.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());\n    \n    // we did not index positions\n    PostingsEnum docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.POSITIONS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.PAYLOADS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.OFFSETS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n    assertNull(docsAndPositionsEnum);\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b4e3cd382d0d075a0f1725649c084bb6510c483","date":1428096423,"type":6,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseTermVectorsFormatTestCase#testPostingsEnumFreqs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsEnum#testDocsOnly().mjava","sourceNew":"  public void testPostingsEnumFreqs() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        return new TokenStreamComponents(new MockTokenizer());\n      }\n    });\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setStoreTermVectors(true);\n    doc.add(new Field(\"foo\", \"bar bar\", ft));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    Terms terms = getOnlySegmentReader(reader).getTermVector(0, \"foo\");\n    TermsEnum termsEnum = terms.iterator(null);\n    assertNotNull(termsEnum);\n    assertEquals(new BytesRef(\"bar\"), termsEnum.next());\n    \n    // simple use (FREQS)\n    PostingsEnum postings = termsEnum.postings(null, null);\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(2, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    // and it had better work\n    assertEquals(-1, postings2.docID());\n    assertEquals(0, postings2.nextDoc());\n    assertEquals(2, postings2.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());\n    \n    // asking for docs only: ok\n    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);\n    assertEquals(-1, docsOnly.docID());\n    assertEquals(0, docsOnly.nextDoc());\n    // we don't define what it is, but if its something else, we should look into it?\n    assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());\n    // reuse that too\n    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);\n    assertNotNull(docsOnly2);\n    // and it had better work\n    assertEquals(-1, docsOnly2.docID());\n    assertEquals(0, docsOnly2.nextDoc());\n    // we don't define what it is, but if its something else, we should look into it?\n    assertTrue(docsOnly.freq() == 1 || docsOnly.freq() == 2);\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());\n    \n    // asking for any flags: ok\n    for (int flag : new int[] { NONE, FREQS, POSITIONS, PAYLOADS, OFFSETS, ALL }) {\n      postings = termsEnum.postings(null, null, flag);\n      assertEquals(-1, postings.docID());\n      assertEquals(0, postings.nextDoc());\n      if (flag != NONE) {\n        assertEquals(2, postings.freq());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n      // reuse that too\n      postings2 = termsEnum.postings(null, postings, flag);\n      assertNotNull(postings2);\n      // and it had better work\n      assertEquals(-1, postings2.docID());\n      assertEquals(0, postings2.nextDoc());\n      if (flag != NONE) {\n        assertEquals(2, postings2.freq());\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings2.nextDoc());\n    }\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsOnly() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(null);\n    IndexWriter iw = new IndexWriter(dir, iwc);\n    Document doc = new Document();\n    doc.add(new StringField(\"foo\", \"bar\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader reader = DirectoryReader.open(iw, false);\n    \n    // sugar method (FREQS)\n    PostingsEnum postings = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"));\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // termsenum reuse (FREQS)\n    TermsEnum termsEnum = getOnlySegmentReader(reader).terms(\"foo\").iterator(null);\n    termsEnum.seekExact(new BytesRef(\"bar\"));\n    PostingsEnum postings2 = termsEnum.postings(null, postings);\n    assertNotNull(postings2);\n    assertSame(postings, postings2);\n    // and it had better work\n    assertEquals(-1, postings.docID());\n    assertEquals(0, postings.nextDoc());\n    assertEquals(1, postings.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, postings.nextDoc());\n    \n    // asking for docs only: ok\n    PostingsEnum docsOnly = termsEnum.postings(null, null, PostingsEnum.NONE);\n    assertEquals(-1, docsOnly.docID());\n    assertEquals(0, docsOnly.nextDoc());\n    assertEquals(1, docsOnly.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly.nextDoc());\n    // reuse that too\n    PostingsEnum docsOnly2 = termsEnum.postings(null, docsOnly, PostingsEnum.NONE);\n    assertNotNull(docsOnly2);\n    assertSame(docsOnly, docsOnly2);\n    // and it had better work\n    assertEquals(-1, docsOnly2.docID());\n    assertEquals(0, docsOnly2.nextDoc());\n    assertEquals(1, docsOnly2.freq());\n    assertEquals(DocIdSetIterator.NO_MORE_DOCS, docsOnly2.nextDoc());\n    \n    // we did not index positions\n    PostingsEnum docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.POSITIONS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.PAYLOADS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.OFFSETS);\n    assertNull(docsAndPositionsEnum);\n    \n    // we did not index positions\n    docsAndPositionsEnum = getOnlySegmentReader(reader).postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n    assertNull(docsAndPositionsEnum);\n    \n    iw.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"cb5311f0bff57ce15a23909f4cfb953773630534":["ebcb21d043bc7d0dba7d6a2999514e4f4af22ab0"],"db32fd0015139a1e3e1703a5d5e6b560c5adb1ca":["6404b8725cd3df3fda5f1c19a46cac85e49f070c"],"8c2189c92e27c6a628b665c0482041efecaf7cb4":["cb77aeaebb451427f825381042f68a6916417d1d"],"6404b8725cd3df3fda5f1c19a46cac85e49f070c":["8c2189c92e27c6a628b665c0482041efecaf7cb4"],"6b4e3cd382d0d075a0f1725649c084bb6510c483":["ebcb21d043bc7d0dba7d6a2999514e4f4af22ab0","db32fd0015139a1e3e1703a5d5e6b560c5adb1ca"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cb77aeaebb451427f825381042f68a6916417d1d":["cb5311f0bff57ce15a23909f4cfb953773630534"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6b4e3cd382d0d075a0f1725649c084bb6510c483"],"ebcb21d043bc7d0dba7d6a2999514e4f4af22ab0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"cb5311f0bff57ce15a23909f4cfb953773630534":["cb77aeaebb451427f825381042f68a6916417d1d"],"db32fd0015139a1e3e1703a5d5e6b560c5adb1ca":["6b4e3cd382d0d075a0f1725649c084bb6510c483"],"8c2189c92e27c6a628b665c0482041efecaf7cb4":["6404b8725cd3df3fda5f1c19a46cac85e49f070c"],"6404b8725cd3df3fda5f1c19a46cac85e49f070c":["db32fd0015139a1e3e1703a5d5e6b560c5adb1ca"],"6b4e3cd382d0d075a0f1725649c084bb6510c483":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ebcb21d043bc7d0dba7d6a2999514e4f4af22ab0"],"cb77aeaebb451427f825381042f68a6916417d1d":["8c2189c92e27c6a628b665c0482041efecaf7cb4"],"ebcb21d043bc7d0dba7d6a2999514e4f4af22ab0":["cb5311f0bff57ce15a23909f4cfb953773630534","6b4e3cd382d0d075a0f1725649c084bb6510c483"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}