{"path":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","commits":[{"id":"296b8b38a87feb478921f77834a2302dfe77641c","date":1209506838,"type":0,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","pathOld":"/dev/null","sourceNew":"  /**\r\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\r\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\r\n   * \r\n   * <p>\r\n   * \r\n   * @param query\r\n   *          that caused hit\r\n   * @param tokenStream\r\n   *          of text to be highlighted\r\n   * @param fieldName\r\n   *          restricts Term's used based on field name\r\n   * @param reader\r\n   *          to use for scoring\r\n   * @return\r\n   * @throws IOException\r\n   */\r\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\r\n      IndexReader reader) throws IOException {\r\n    this.fieldName = fieldName;\r\n    this.cachedTokenFilter = new CachingTokenFilter(tokenStream);\r\n\r\n    Map terms = new HashMap();\r\n    extract(query, terms);\r\n\r\n    int totalNumDocs = reader.numDocs();\r\n    Set weightedTerms = terms.keySet();\r\n    Iterator it = weightedTerms.iterator();\r\n\r\n    try {\r\n      while (it.hasNext()) {\r\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\r\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\r\n\r\n        // IDF algorithm taken from DefaultSimilarity class\r\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\r\n        weightedSpanTerm.weight *= idf;\r\n      }\r\n    } finally {\r\n\r\n      closeReaders();\r\n    }\r\n\r\n    return terms;\r\n  }\r\n\n","sourceOld":null,"bugFix":null,"bugIntro":["5d934099a6f0a3ae0285025a1e1b61b7b05fed8f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5d934099a6f0a3ae0285025a1e1b61b7b05fed8f","date":1211715535,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","sourceNew":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return\n   * @throws IOException\n   */\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    this.fieldName = fieldName;\n    this.cachedTokenFilter = new CachingTokenFilter(tokenStream);\n\n    Map terms = new PositionCheckingMap();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set weightedTerms = terms.keySet();\n    Iterator it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","sourceOld":"  /**\r\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\r\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\r\n   * \r\n   * <p>\r\n   * \r\n   * @param query\r\n   *          that caused hit\r\n   * @param tokenStream\r\n   *          of text to be highlighted\r\n   * @param fieldName\r\n   *          restricts Term's used based on field name\r\n   * @param reader\r\n   *          to use for scoring\r\n   * @return\r\n   * @throws IOException\r\n   */\r\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\r\n      IndexReader reader) throws IOException {\r\n    this.fieldName = fieldName;\r\n    this.cachedTokenFilter = new CachingTokenFilter(tokenStream);\r\n\r\n    Map terms = new HashMap();\r\n    extract(query, terms);\r\n\r\n    int totalNumDocs = reader.numDocs();\r\n    Set weightedTerms = terms.keySet();\r\n    Iterator it = weightedTerms.iterator();\r\n\r\n    try {\r\n      while (it.hasNext()) {\r\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\r\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\r\n\r\n        // IDF algorithm taken from DefaultSimilarity class\r\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\r\n        weightedSpanTerm.weight *= idf;\r\n      }\r\n    } finally {\r\n\r\n      closeReaders();\r\n    }\r\n\r\n    return terms;\r\n  }\r\n\n","bugFix":["296b8b38a87feb478921f77834a2302dfe77641c"],"bugIntro":["fb821cbfa5ecf725348dd3bc3878a9fadd24f725","c9bc1fe868bb126a5b8517d9d2abcf329f56d283"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9bc1fe868bb126a5b8517d9d2abcf329f56d283","date":1219151801,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","sourceNew":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return\n   * @throws IOException\n   */\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    this.fieldName = fieldName;\n    this.cachedTokenFilter = new CachingTokenFilter(tokenStream);\n\n    Map terms = new PositionCheckingMap();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set weightedTerms = terms.keySet();\n    Iterator it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // docFreq counts deletes\n        if(totalNumDocs < docFreq) {\n          docFreq = totalNumDocs;\n        }\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","sourceOld":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return\n   * @throws IOException\n   */\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    this.fieldName = fieldName;\n    this.cachedTokenFilter = new CachingTokenFilter(tokenStream);\n\n    Map terms = new PositionCheckingMap();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set weightedTerms = terms.keySet();\n    Iterator it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","bugFix":["5d934099a6f0a3ae0285025a1e1b61b7b05fed8f"],"bugIntro":["fb821cbfa5ecf725348dd3bc3878a9fadd24f725"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"943c3f9cf96b8df37f4273d66a66182e2a669467","date":1249394171,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","sourceNew":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return\n   * @throws IOException\n   */\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    this.fieldName = fieldName;\n    this.tokenStream = tokenStream;\n\n    Map terms = new PositionCheckingMap();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set weightedTerms = terms.keySet();\n    Iterator it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // docFreq counts deletes\n        if(totalNumDocs < docFreq) {\n          docFreq = totalNumDocs;\n        }\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","sourceOld":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return\n   * @throws IOException\n   */\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    this.fieldName = fieldName;\n    this.cachedTokenFilter = new CachingTokenFilter(tokenStream);\n\n    Map terms = new PositionCheckingMap();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set weightedTerms = terms.keySet();\n    Iterator it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // docFreq counts deletes\n        if(totalNumDocs < docFreq) {\n          docFreq = totalNumDocs;\n        }\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"edae6ef134f154e25cf2b430b07b84f9c831dd12","date":1250644583,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","sourceNew":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return\n   * @throws IOException\n   */\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    if (fieldName != null) {\n      this.fieldName = StringHelper.intern(fieldName);\n    } else {\n      this.fieldName = null;\n    }\n    this.tokenStream = tokenStream;\n\n    Map terms = new PositionCheckingMap();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set weightedTerms = terms.keySet();\n    Iterator it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // docFreq counts deletes\n        if(totalNumDocs < docFreq) {\n          docFreq = totalNumDocs;\n        }\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","sourceOld":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return\n   * @throws IOException\n   */\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    this.fieldName = fieldName;\n    this.tokenStream = tokenStream;\n\n    Map terms = new PositionCheckingMap();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set weightedTerms = terms.keySet();\n    Iterator it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // docFreq counts deletes\n        if(totalNumDocs < docFreq) {\n          docFreq = totalNumDocs;\n        }\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fa5818da3b8f6ad9654775d0db1c2db3b4e1d99b","date":1250649744,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","sourceNew":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return Map of WeightedSpanTerms with quasi tf/idf scores\n   * @throws IOException\n   */\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    if (fieldName != null) {\n      this.fieldName = StringHelper.intern(fieldName);\n    } else {\n      this.fieldName = null;\n    }\n    this.tokenStream = tokenStream;\n\n    Map terms = new PositionCheckingMap();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set weightedTerms = terms.keySet();\n    Iterator it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // docFreq counts deletes\n        if(totalNumDocs < docFreq) {\n          docFreq = totalNumDocs;\n        }\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","sourceOld":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return\n   * @throws IOException\n   */\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    if (fieldName != null) {\n      this.fieldName = StringHelper.intern(fieldName);\n    } else {\n      this.fieldName = null;\n    }\n    this.tokenStream = tokenStream;\n\n    Map terms = new PositionCheckingMap();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set weightedTerms = terms.keySet();\n    Iterator it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // docFreq counts deletes\n        if(totalNumDocs < docFreq) {\n          docFreq = totalNumDocs;\n        }\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ffdf794cee8d43eb612df752c592cef2dc3e75ae","date":1256465578,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","sourceNew":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return Map of WeightedSpanTerms with quasi tf/idf scores\n   * @throws IOException\n   */\n  public Map<String,WeightedSpanTerm> getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    if (fieldName != null) {\n      this.fieldName = StringHelper.intern(fieldName);\n    } else {\n      this.fieldName = null;\n    }\n    this.tokenStream = tokenStream;\n\n    Map<String,WeightedSpanTerm> terms = new PositionCheckingMap<String>();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set<String> weightedTerms = terms.keySet();\n    Iterator<String> it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // docFreq counts deletes\n        if(totalNumDocs < docFreq) {\n          docFreq = totalNumDocs;\n        }\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","sourceOld":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return Map of WeightedSpanTerms with quasi tf/idf scores\n   * @throws IOException\n   */\n  public Map getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    if (fieldName != null) {\n      this.fieldName = StringHelper.intern(fieldName);\n    } else {\n      this.fieldName = null;\n    }\n    this.tokenStream = tokenStream;\n\n    Map terms = new PositionCheckingMap();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set weightedTerms = terms.keySet();\n    Iterator it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = (WeightedSpanTerm) terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // docFreq counts deletes\n        if(totalNumDocs < docFreq) {\n          docFreq = totalNumDocs;\n        }\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getWeightedSpanTermsWithScores(Query,TokenStream,String,IndexReader).mjava","sourceNew":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return Map of WeightedSpanTerms with quasi tf/idf scores\n   * @throws IOException\n   */\n  public Map<String,WeightedSpanTerm> getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    if (fieldName != null) {\n      this.fieldName = StringHelper.intern(fieldName);\n    } else {\n      this.fieldName = null;\n    }\n    this.tokenStream = tokenStream;\n\n    Map<String,WeightedSpanTerm> terms = new PositionCheckingMap<String>();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set<String> weightedTerms = terms.keySet();\n    Iterator<String> it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // docFreq counts deletes\n        if(totalNumDocs < docFreq) {\n          docFreq = totalNumDocs;\n        }\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","sourceOld":"  /**\n   * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>TokenStream</code>. Uses a supplied\n   * <code>IndexReader</code> to properly weight terms (for gradient highlighting).\n   * \n   * <p>\n   * \n   * @param query\n   *          that caused hit\n   * @param tokenStream\n   *          of text to be highlighted\n   * @param fieldName\n   *          restricts Term's used based on field name\n   * @param reader\n   *          to use for scoring\n   * @return Map of WeightedSpanTerms with quasi tf/idf scores\n   * @throws IOException\n   */\n  public Map<String,WeightedSpanTerm> getWeightedSpanTermsWithScores(Query query, TokenStream tokenStream, String fieldName,\n      IndexReader reader) throws IOException {\n    if (fieldName != null) {\n      this.fieldName = StringHelper.intern(fieldName);\n    } else {\n      this.fieldName = null;\n    }\n    this.tokenStream = tokenStream;\n\n    Map<String,WeightedSpanTerm> terms = new PositionCheckingMap<String>();\n    extract(query, terms);\n\n    int totalNumDocs = reader.numDocs();\n    Set<String> weightedTerms = terms.keySet();\n    Iterator<String> it = weightedTerms.iterator();\n\n    try {\n      while (it.hasNext()) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(it.next());\n        int docFreq = reader.docFreq(new Term(fieldName, weightedSpanTerm.term));\n        // docFreq counts deletes\n        if(totalNumDocs < docFreq) {\n          docFreq = totalNumDocs;\n        }\n        // IDF algorithm taken from DefaultSimilarity class\n        float idf = (float) (Math.log((float) totalNumDocs / (double) (docFreq + 1)) + 1.0);\n        weightedSpanTerm.weight *= idf;\n      }\n    } finally {\n\n      closeReaders();\n    }\n\n    return terms;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"ffdf794cee8d43eb612df752c592cef2dc3e75ae":["fa5818da3b8f6ad9654775d0db1c2db3b4e1d99b"],"edae6ef134f154e25cf2b430b07b84f9c831dd12":["943c3f9cf96b8df37f4273d66a66182e2a669467"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fa5818da3b8f6ad9654775d0db1c2db3b4e1d99b":["edae6ef134f154e25cf2b430b07b84f9c831dd12"],"5d934099a6f0a3ae0285025a1e1b61b7b05fed8f":["296b8b38a87feb478921f77834a2302dfe77641c"],"943c3f9cf96b8df37f4273d66a66182e2a669467":["c9bc1fe868bb126a5b8517d9d2abcf329f56d283"],"296b8b38a87feb478921f77834a2302dfe77641c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c9bc1fe868bb126a5b8517d9d2abcf329f56d283":["5d934099a6f0a3ae0285025a1e1b61b7b05fed8f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["ffdf794cee8d43eb612df752c592cef2dc3e75ae"]},"commit2Childs":{"ffdf794cee8d43eb612df752c592cef2dc3e75ae":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"edae6ef134f154e25cf2b430b07b84f9c831dd12":["fa5818da3b8f6ad9654775d0db1c2db3b4e1d99b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["296b8b38a87feb478921f77834a2302dfe77641c"],"fa5818da3b8f6ad9654775d0db1c2db3b4e1d99b":["ffdf794cee8d43eb612df752c592cef2dc3e75ae"],"5d934099a6f0a3ae0285025a1e1b61b7b05fed8f":["c9bc1fe868bb126a5b8517d9d2abcf329f56d283"],"943c3f9cf96b8df37f4273d66a66182e2a669467":["edae6ef134f154e25cf2b430b07b84f9c831dd12"],"296b8b38a87feb478921f77834a2302dfe77641c":["5d934099a6f0a3ae0285025a1e1b61b7b05fed8f"],"c9bc1fe868bb126a5b8517d9d2abcf329f56d283":["943c3f9cf96b8df37f4273d66a66182e2a669467"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}