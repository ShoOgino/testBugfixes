{"path":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","commits":[{"id":"df5e4eb47076636341c2cfdc58472477477d7e96","date":1329187541,"type":1,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#processDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(\"dbqlevel\", 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n          // forward to all replicas\n          if (replicas != null) {\n            ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n            params.set(\"dbqlevel\", 3);\n            params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n            params.set(SEEN_LEADER, \"true\");\n            cmdDistrib.distribDelete(cmd, replicas, params);\n\n            // wait for DBQ responses before releasing the update block to eliminate the possibility\n            // of an add being reordered.\n            // TODO: this isn't strictly necessary - we could do the same thing we do for PeerSync\n            // in DUH2 and add a clause that prevents deleting older docs.\n            cmdDistrib.finish();\n          }\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  private void processDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n        }\n      }\n\n      doLocalDelete(cmd);\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    // TODO: we should consider this? Send delete query to everyone in the current collection\n\n    if (zkEnabled) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      if (!params.getBool(DELQUERY_END_POINT, false)) {\n        params.set(DELQUERY_END_POINT, true);\n\n        String nodeName = req.getCore().getCoreDescriptor().getCoreContainer()\n            .getZkController().getNodeName();\n        String shardZkNodeName = nodeName + \"_\" + req.getCore().getName();\n        List<Node> nodes = getCollectionUrls(req, req.getCore().getCoreDescriptor()\n            .getCloudDescriptor().getCollectionName(), shardZkNodeName);\n\n        if (nodes != null) {\n          cmdDistrib.distribDelete(cmd, nodes, params);\n          finish();\n        }\n      }\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26ef32891379baf5993bc211f03b682ed6f20ec","date":1329188422,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n          // forward to all replicas\n          if (replicas != null) {\n            ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n            params.set(DELETE_BY_QUERY_LEVEL, 3);\n            params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n            params.set(SEEN_LEADER, \"true\");\n            cmdDistrib.distribDelete(cmd, replicas, params);\n\n            // wait for DBQ responses before releasing the update block to eliminate the possibility\n            // of an add being reordered.\n            // TODO: this isn't strictly necessary - we could do the same thing we do for PeerSync\n            // in DUH2 and add a clause that prevents deleting older docs.\n            cmdDistrib.finish();\n          }\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(\"dbqlevel\", 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n          // forward to all replicas\n          if (replicas != null) {\n            ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n            params.set(\"dbqlevel\", 3);\n            params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n            params.set(SEEN_LEADER, \"true\");\n            cmdDistrib.distribDelete(cmd, replicas, params);\n\n            // wait for DBQ responses before releasing the update block to eliminate the possibility\n            // of an add being reordered.\n            // TODO: this isn't strictly necessary - we could do the same thing we do for PeerSync\n            // in DUH2 and add a clause that prevents deleting older docs.\n            cmdDistrib.finish();\n          }\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ff0145d36648854a08ed492ce60c9616b8296418","date":1329575183,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n          // forward to all replicas\n          if (replicas != null) {\n            ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n            params.set(DELETE_BY_QUERY_LEVEL, 3);\n            params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n            params.set(SEEN_LEADER, \"true\");\n            cmdDistrib.distribDelete(cmd, replicas, params);\n\n            // wait for DBQ responses before releasing the update block to eliminate the possibility\n            // of an add being reordered.\n            // TODO: this isn't strictly necessary - we could do the same thing we do for PeerSync\n            // in DUH2 and add a clause that prevents deleting older docs.\n            cmdDistrib.finish();\n          }\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n          // forward to all replicas\n          if (replicas != null) {\n            ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n            params.set(DELETE_BY_QUERY_LEVEL, 3);\n            params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n            params.set(SEEN_LEADER, \"true\");\n            cmdDistrib.distribDelete(cmd, replicas, params);\n\n            // wait for DBQ responses before releasing the update block to eliminate the possibility\n            // of an add being reordered.\n            // TODO: this isn't strictly necessary - we could do the same thing we do for PeerSync\n            // in DUH2 and add a clause that prevents deleting older docs.\n            cmdDistrib.finish();\n          }\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"613328143fc4e9ad6e49e951301c7733adb38083","date":1330620114,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n\n    // TODO: need to handle reorders to replicas somehow\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 3);\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(SEEN_LEADER, \"true\");\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n          // forward to all replicas\n          if (replicas != null) {\n            ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n            params.set(DELETE_BY_QUERY_LEVEL, 3);\n            params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n            params.set(SEEN_LEADER, \"true\");\n            cmdDistrib.distribDelete(cmd, replicas, params);\n\n            // wait for DBQ responses before releasing the update block to eliminate the possibility\n            // of an add being reordered.\n            // TODO: this isn't strictly necessary - we could do the same thing we do for PeerSync\n            // in DUH2 and add a clause that prevents deleting older docs.\n            cmdDistrib.finish();\n          }\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":["412d05aa585785cd44861bece79b8861a10fb179","2806236d9dfa336ac413d3724a4123e7cf4d1e93"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9652a1b09ee0e7d6533fdfedf1d7c4d9036b49d","date":1330786058,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n\n    // TODO: need to handle reorders to replicas somehow\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 3);\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(SEEN_LEADER, \"true\");\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n\n    // TODO: need to handle reorders to replicas somehow\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 3);\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(SEEN_LEADER, \"true\");\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n\n    // TODO: need to handle reorders to replicas somehow\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 3);\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(SEEN_LEADER, \"true\");\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n          // forward to all replicas\n          if (replicas != null) {\n            ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n            params.set(DELETE_BY_QUERY_LEVEL, 3);\n            params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n            params.set(SEEN_LEADER, \"true\");\n            cmdDistrib.distribDelete(cmd, replicas, params);\n\n            // wait for DBQ responses before releasing the update block to eliminate the possibility\n            // of an add being reordered.\n            // TODO: this isn't strictly necessary - we could do the same thing we do for PeerSync\n            // in DUH2 and add a clause that prevents deleting older docs.\n            cmdDistrib.finish();\n          }\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1bea3922196318026c4274f2013416acb60c691e","date":1336496433,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n\n    // TODO: need to handle reorders to replicas somehow\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 3);\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(SEEN_LEADER, \"true\");\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          // TODO: flush any adds to these replicas so they do not get reordered w.r.t. this DBQ\n\n          doLocalDelete(cmd);\n\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n\n    // TODO: need to handle reorders to replicas somehow\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 3);\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(SEEN_LEADER, \"true\");\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e2fe35ac47f8f51356d6c1724455d18f31c94fae","date":1337966698,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n      DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n\n    // TODO: need to handle reorders to replicas somehow\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = !req.getParams().getBool(SEEN_LEADER, false);\n    } else {\n      zkCheck();\n    }\n\n    // Lev1: we are the first to receive this deleteByQuery, it must be forwarded to the leader of every shard\n    // Lev2: we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // Lev3: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n\n    int dbqlevel = req.getParams().getInt(DELETE_BY_QUERY_LEVEL, 1);\n\n    if (zkEnabled && dbqlevel == 1) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 2);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the level to 2 so we look up and forward to our own replicas (if any)\n      dbqlevel = 2;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && dbqlevel == 2) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n\n    // TODO: need to handle reorders to replicas somehow\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DELETE_BY_QUERY_LEVEL, 3);\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(SEEN_LEADER, \"true\");\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb999ed3fc6e419b9104de9ebfe62ace27f31d5f","date":1341327930,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n      DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n\n    // TODO: need to handle reorders to replicas somehow\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n      DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n\n    // TODO: need to handle reorders to replicas somehow\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6948dfbf6c703c42e0d9831d5b2a1ce38e75abb6","date":1343134001,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b","date":1343203827,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      replicas = setupRequest();\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f767f8c99eaedb984df754fe61f21c5de260f94","date":1344105153,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8fd5be977c105554c6a7b68afcdbc511439723ab","date":1344115570,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getCloudState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getCloudState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6013b4c7388f1627659c8f96c44abd10a294d3a6","date":1346343796,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05a14b2611ead08655a2b2bdc61632eb31316e57","date":1346366621,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6","date":1346692465,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      if (!req.getCore().getCoreDescriptor().getCloudDescriptor().isLeader()) {\n        log.error(\"Abort sending request to replicas, we are no longer leader\");\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Abort sending request to replicas, we are no longer leader\");\n      }\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":["a6378064655e76cd7b908b1cab4ce425b384b508","d8469c0c0b45f7e3da74918efc8ede2ad2efe2b1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d8469c0c0b45f7e3da74918efc8ede2ad2efe2b1","date":1346817835,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      if (!req.getCore().getCoreDescriptor().getCloudDescriptor().isLeader()) {\n        log.error(\"Abort sending request to replicas, we are no longer leader\");\n        throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Abort sending request to replicas, we are no longer leader\");\n      }\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      if (!req.getCore().getCoreDescriptor().getCloudDescriptor().isLeader()) {\n        log.error(\"Abort sending request to replicas, we are no longer leader\");\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Abort sending request to replicas, we are no longer leader\");\n      }\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":["7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6"],"bugIntro":["a6378064655e76cd7b908b1cab4ce425b384b508"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a6378064655e76cd7b908b1cab4ce425b384b508","date":1347656715,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      if (!req.getCore().getCoreDescriptor().getCloudDescriptor().isLeader()) {\n        log.error(\"Abort sending request to replicas, we are no longer leader\");\n        throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Abort sending request to replicas, we are no longer leader\");\n      }\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":["7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6","df5e4eb47076636341c2cfdc58472477477d7e96","d8469c0c0b45f7e3da74918efc8ede2ad2efe2b1"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2806236d9dfa336ac413d3724a4123e7cf4d1e93","date":1348631501,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":["df5e4eb47076636341c2cfdc58472477477d7e96","613328143fc4e9ad6e49e951301c7733adb38083"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c5a558d54519c651068ddb202f03befefb1514a7","date":1354382006,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlicesMap(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eec5368fa415ebab044b7ae01de50d5b49519b7e","date":1355029764,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlicesMap(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      Map<String,Slice> slices = zkController.getClusterState().getSlices(collection);\n      if (slices == null) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Cannot find collection:\" + collection + \" in \"\n                + zkController.getClusterState().getCollections());\n      }\n\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Map.Entry<String,Slice> sliceEntry : slices.entrySet()) {\n        String sliceName = sliceEntry.getKey();\n        ZkNodeProps leaderProps;\n        try {\n          leaderProps = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leaderProps);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      params.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, params);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"56a558aa5aadd60ae850d1ab090098bc63bdfaf9","date":1355245333,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3d7c0c8a97beb56d2e168604f9928de17981eabe","date":1357257676,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.REPLAY)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":["df5e4eb47076636341c2cfdc58472477477d7e96"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.REPLAY)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderProps(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplay = (cmd.getFlags() & UpdateCommand.REPLAY) != 0;\n    boolean leaderLogic = isLeader && !isReplay;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb4a195b8dc1808cd01748bd2e0fba26ca915d4d","date":1361851792,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = zkController.getCoreNodeName(req.getCore().getCoreDescriptor());\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.REPLAY)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderNodeName = coreLeaderProps.getCoreNodeName();\n        String coreName = req.getCore().getName();\n        String coreNodeName = zkController.getNodeName() + \"_\" + coreName;\n        isLeader = coreNodeName.equals(leaderNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.REPLAY)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8a2f1187198fd8201881b815eea2fa3ba7b8ec5f","date":1369845628,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = zkController.getCoreNodeName(req.getCore().getCoreDescriptor());\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = zkController.getCoreNodeName(req.getCore().getCoreDescriptor());\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.REPLAY)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8f1ea787bab5bdb5e72685e55424898da05509b6","date":1370289750,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkController.getClusterState().getCollection(collection);\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = zkController.getCoreNodeName(req.getCore().getCoreDescriptor());\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n\n    // forward to all replicas\n    if (leaderLogic) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      if (subShardLeaders != null)  {\n        cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n      }\n      if (replicas != null) {\n        cmdDistrib.distribDelete(cmd, replicas, params);\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      DocCollection coll = zkController.getClusterState().getCollection(collection);\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = zkController.getCoreNodeName(req.getCore().getCoreDescriptor());\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n\n    // forward to all replicas\n    if (leaderLogic && replicas != null) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      cmdDistrib.distribDelete(cmd, replicas, params);\n      cmdDistrib.finish();\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":["2c6fae58725738008effbd9d848abc49122913fe","412d05aa585785cd44861bece79b8861a10fb179"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"412d05aa585785cd44861bece79b8861a10fb179","date":1370300480,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = zkController.getCoreNodeName(req.getCore().getCoreDescriptor());\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    // forward to all replicas\n    if (leaderLogic && zkEnabled) {\n      List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      if (subShardLeaders != null)  {\n        cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n      }\n      if (replicas != null) {\n        cmdDistrib.distribDelete(cmd, replicas, params);\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkController.getClusterState().getCollection(collection);\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = zkController.getCoreNodeName(req.getCore().getCoreDescriptor());\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n\n    // forward to all replicas\n    if (leaderLogic) {\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      if (subShardLeaders != null)  {\n        cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n      }\n      if (replicas != null) {\n        cmdDistrib.distribDelete(cmd, replicas, params);\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":["8f1ea787bab5bdb5e72685e55424898da05509b6","613328143fc4e9ad6e49e951301c7733adb38083"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    // forward to all replicas\n    if (leaderLogic && zkEnabled) {\n      List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      if (subShardLeaders != null)  {\n        cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n      }\n      if (replicas != null) {\n        cmdDistrib.distribDelete(cmd, replicas, params);\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = zkController.getCoreNodeName(req.getCore().getCoreDescriptor());\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    // forward to all replicas\n    if (leaderLogic && zkEnabled) {\n      List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      if (subShardLeaders != null)  {\n        cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n      }\n      if (replicas != null) {\n        cmdDistrib.distribDelete(cmd, replicas, params);\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"96adbab674ae121f8b6b3e10474070b4bd97a219","date":1373614333,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    // forward to all replicas\n    if (leaderLogic && zkEnabled) {\n      List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      if (subShardLeaders != null)  {\n        cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n      }\n      if (replicas != null) {\n        cmdDistrib.distribDelete(cmd, replicas, params);\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":["91e069c492cf4895697ef7b81df0ffb9a8bd4b48"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = zkController.getCoreNodeName(req.getCore().getCoreDescriptor());\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    // forward to all replicas\n    if (leaderLogic && zkEnabled) {\n      List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n      if (subShardLeaders != null)  {\n        cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n      }\n      if (replicas != null) {\n        cmdDistrib.distribDelete(cmd, replicas, params);\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1eeda7e62e149f90eee8895af874c74efa7d4852","date":1375293182,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","date":1376375609,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(params.get(ShardParams.SHARD_KEYS), params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"91e069c492cf4895697ef7b81df0ffb9a8bd4b48","date":1382134253,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.syncDelete(cmd, subShardLeaders, params);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":["96adbab674ae121f8b6b3e10474070b4bd97a219"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"da888af1ab894358122a22229051215f58cf4d54","date":1384408702,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(\"distrib.from\", ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(\"distrib.from.collection\", req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(\"distrib.from.shard\", req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3333dd7044501b4f20231ea55ab64e688285d153","date":1384785078,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(\"distrib.from\", ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(\"distrib.from.collection\", req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(\"distrib.from.shard\", req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a9d97c95155f9d108d71e447e2f3fdc15d0d1f0","date":1385584801,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      if (log.isDebugEnabled()) {\n        outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n            zkController.getBaseUrl(), req.getCore().getName()));\n      }\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a51acc2e27bfb18091f9395494aebe82266f7ce7","date":1385611742,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      if (log.isDebugEnabled()) {\n        outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n            zkController.getBaseUrl(), req.getCore().getName()));\n      }\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(\"update.from\", ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(\"distrib.from\", ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(\"distrib.from.collection\", req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(\"distrib.from.shard\", req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<Node>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<Node>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"14d5815ecbef89580f5c48990bcd433f04f8563a","date":1399564106,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":["845e792cacdb2bb8da8fb051c0afc60db568233f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"be2d2facad861c539d42173b0e4538d64b7fda80","date":1405194900,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(),\n                  req.getCore().getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2fc9f4a33c8fefeb1260aea04273a36b0d32378e","date":1421852764,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      if(route == null) route = params.get(ShardParams.SHARD_KEYS);// deprecated . kept for backcompat\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a219f1dcad1700e84807666bdbd2b573e8de7021","date":1428130940,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, ZkStateReader.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"86290366cefc1b9d4eced13b430858c4a4c0421d","date":1432321109,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    // Find the version\n    long versionOnUpdate = cmd.getVersion();\n    if (versionOnUpdate == 0) {\n      String versionOnUpdateS = req.getParams().get(VERSION_FIELD);\n      versionOnUpdate = versionOnUpdateS == null ? 0 : Long.parseLong(versionOnUpdateS);\n    }\n    versionOnUpdate = Math.abs(versionOnUpdate);  // normalize to positive version\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    if (!leaderLogic && versionOnUpdate==0) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"missing _version_ on update from leader\");\n    }\n\n    vinfo.blockUpdates();\n    try {\n\n      if (versionsStored) {\n        if (leaderLogic) {\n          long version = vinfo.getNewClock();\n          cmd.setVersion(-version);\n          // TODO update versions in all buckets\n\n          doLocalDelete(cmd);\n\n        } else {\n          cmd.setVersion(-versionOnUpdate);\n\n          if (ulog.getState() != UpdateLog.State.ACTIVE && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {\n            // we're not in an active state, and this update isn't from a replay, so buffer it.\n            cmd.setFlags(cmd.getFlags() | UpdateCommand.BUFFERING);\n            ulog.deleteByQuery(cmd);\n            return;\n          }\n\n          doLocalDelete(cmd);\n        }\n      }\n\n      // since we don't know which documents were deleted, the easiest thing to do is to invalidate\n      // all real-time caches (i.e. UpdateLog) which involves also getting a new version of the IndexReader\n      // (so cache misses will see up-to-date data)\n\n    } finally {\n      vinfo.unblockUpdates();\n    }\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7350fba633b826986454e97668c5ad03b46bcaca","date":1446484423,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            List<Node> myReplicas = new ArrayList<>();\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>();\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2c6fae58725738008effbd9d848abc49122913fe","date":1455911986,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.finish();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":["8f1ea787bab5bdb5e72685e55424898da05509b6"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"845e792cacdb2bb8da8fb051c0afc60db568233f","date":1456851727,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":["14d5815ecbef89580f5c48990bcd433f04f8563a"],"bugIntro":["c0cf9c2ec975506bab465b6b2be92cb9bffc84d3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cf1a614098b46c9c22afebd7b898ae4d1d2fc273","date":1457088850,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new StdNode(coreLeaderProps, collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6d2dadc1f5ca8703d8659f4964961f9967935d75","date":1490231750,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e5fa6615014cd2288fe930f8c8bb726f9504961d","date":1490280013,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"61c45e99cf6676da48f19d7511c73712ad39402b","date":1495508331,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequest();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN);\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"601f914e4448cab7640fecfb5d15f8f2e2af0bf6","date":1508947828,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = cloudDesc.getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = cloudDesc.getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, cloudDesc.getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, cloudDesc.getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = req.getCore().getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, req.getCore().getCoreDescriptor().getCloudDescriptor().getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, req.getCore().getCoreDescriptor().getCloudDescriptor().getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<String>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615bf5b56d95ed8c9bf06a402db6c817d6bff21a","date":1509492118,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled\n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null && rollupReplicationTracker == null) {\n        rollupReplicationTracker = new RollupRequestReplicationTracker(req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = cloudDesc.getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n\n\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null) {\n        // If we've determined that there are no docs on this shard that need to be deleted, then we don't send\n        // sub-requests to any other replicas for this shard. In this case, min_rf is meaningless for this shard\n        // so flag that in replicationTracker\n        outParams.add(UpdateRequest.MIN_REPFACT, req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      cmdDistrib.distribDelete(cmd, leaders, outParams, false, rollupReplicationTracker, null);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    // check if client has requested minimum replication factor information. will set replicationTracker to null if\n    // we aren't the leader or subShardLeader\n    checkReplicationTracker(cmd);\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n    versionDeleteByQuery(cmd);\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = cloudDesc.getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, cloudDesc.getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, cloudDesc.getShardId());\n\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = \n    DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled \n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = cloudDesc.getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n      cmdDistrib.distribDelete(cmd, leaders, outParams);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n\n    versionDeleteByQuery(cmd);\n\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = cloudDesc.getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, cloudDesc.getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, cloudDesc.getShardId());\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad55ff45b3a5483090d87a63019d0e6a8d4b5a65","date":1509551229,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled\n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null && rollupReplicationTracker == null) {\n        rollupReplicationTracker = new RollupRequestReplicationTracker(req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = cloudDesc.getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n\n\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null) {\n        // If we've determined that there are no docs on this shard that need to be deleted, then we don't send\n        // sub-requests to any other replicas for this shard. In this case, min_rf is meaningless for this shard\n        // so flag that in replicationTracker\n        outParams.add(UpdateRequest.MIN_REPFACT, req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      cmdDistrib.distribDelete(cmd, leaders, outParams, false, rollupReplicationTracker, null);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    // check if client has requested minimum replication factor information. will set replicationTracker to null if\n    // we aren't the leader or subShardLeader\n    checkReplicationTracker(cmd);\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n    versionDeleteByQuery(cmd);\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = cloudDesc.getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, collection);\n          params.set(DISTRIB_FROM_SHARD, cloudDesc.getShardId());\n\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled\n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null && rollupReplicationTracker == null) {\n        rollupReplicationTracker = new RollupRequestReplicationTracker(req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = cloudDesc.getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n\n\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null) {\n        // If we've determined that there are no docs on this shard that need to be deleted, then we don't send\n        // sub-requests to any other replicas for this shard. In this case, min_rf is meaningless for this shard\n        // so flag that in replicationTracker\n        outParams.add(UpdateRequest.MIN_REPFACT, req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      cmdDistrib.distribDelete(cmd, leaders, outParams, false, rollupReplicationTracker, null);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    // check if client has requested minimum replication factor information. will set replicationTracker to null if\n    // we aren't the leader or subShardLeader\n    checkReplicationTracker(cmd);\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n    versionDeleteByQuery(cmd);\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = cloudDesc.getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, cloudDesc.getCollectionName());\n          params.set(DISTRIB_FROM_SHARD, cloudDesc.getShardId());\n\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c0cf9c2ec975506bab465b6b2be92cb9bffc84d3","date":1533596209,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled\n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null && rollupReplicationTracker == null) {\n        rollupReplicationTracker = new RollupRequestReplicationTracker(req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = cloudDesc.getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new ForwardNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName, maxRetriesOnForward));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n\n\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null) {\n        // If we've determined that there are no docs on this shard that need to be deleted, then we don't send\n        // sub-requests to any other replicas for this shard. In this case, min_rf is meaningless for this shard\n        // so flag that in replicationTracker\n        outParams.add(UpdateRequest.MIN_REPFACT, req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      cmdDistrib.distribDelete(cmd, leaders, outParams, false, rollupReplicationTracker, null);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    // check if client has requested minimum replication factor information. will set replicationTracker to null if\n    // we aren't the leader or subShardLeader\n    checkReplicationTracker(cmd);\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n    versionDeleteByQuery(cmd);\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = cloudDesc.getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, collection);\n          params.set(DISTRIB_FROM_SHARD, cloudDesc.getShardId());\n\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled\n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null && rollupReplicationTracker == null) {\n        rollupReplicationTracker = new RollupRequestReplicationTracker(req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = cloudDesc.getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new RetryNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n\n\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null) {\n        // If we've determined that there are no docs on this shard that need to be deleted, then we don't send\n        // sub-requests to any other replicas for this shard. In this case, min_rf is meaningless for this shard\n        // so flag that in replicationTracker\n        outParams.add(UpdateRequest.MIN_REPFACT, req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      cmdDistrib.distribDelete(cmd, leaders, outParams, false, rollupReplicationTracker, null);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    // check if client has requested minimum replication factor information. will set replicationTracker to null if\n    // we aren't the leader or subShardLeader\n    checkReplicationTracker(cmd);\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n    versionDeleteByQuery(cmd);\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = cloudDesc.getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, collection);\n          params.set(DISTRIB_FROM_SHARD, cloudDesc.getShardId());\n\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":["845e792cacdb2bb8da8fb051c0afc60db568233f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"43f5f8344e80b4bfb2069917069430266753d2f0","date":1538584815,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled\n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      if (rollupReplicationTracker == null) {\n        rollupReplicationTracker = new RollupRequestReplicationTracker();\n      }\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = cloudDesc.getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new ForwardNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName, maxRetriesOnForward));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n\n\n      if (params.get(UpdateRequest.MIN_REPFACT) != null) {\n        // TODO: Kept this for rolling upgrades. Remove in Solr 9\n        outParams.add(UpdateRequest.MIN_REPFACT, req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      cmdDistrib.distribDelete(cmd, leaders, outParams, false, rollupReplicationTracker, null);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n    \n\n    // check if client has requested minimum replication factor information. will set replicationTracker to null if\n    // we aren't the leader or subShardLeader\n    checkReplicationTracker(cmd);\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n    versionDeleteByQuery(cmd);\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = cloudDesc.getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, collection);\n          params.set(DISTRIB_FROM_SHARD, cloudDesc.getShardId());\n\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled\n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null && rollupReplicationTracker == null) {\n        rollupReplicationTracker = new RollupRequestReplicationTracker(req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = cloudDesc.getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new ForwardNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName, maxRetriesOnForward));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n\n\n      if (req.getParams().get(UpdateRequest.MIN_REPFACT) != null) {\n        // If we've determined that there are no docs on this shard that need to be deleted, then we don't send\n        // sub-requests to any other replicas for this shard. In this case, min_rf is meaningless for this shard\n        // so flag that in replicationTracker\n        outParams.add(UpdateRequest.MIN_REPFACT, req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      cmdDistrib.distribDelete(cmd, leaders, outParams, false, rollupReplicationTracker, null);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    // check if client has requested minimum replication factor information. will set replicationTracker to null if\n    // we aren't the leader or subShardLeader\n    checkReplicationTracker(cmd);\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n    versionDeleteByQuery(cmd);\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = cloudDesc.getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, collection);\n          params.set(DISTRIB_FROM_SHARD, cloudDesc.getShardId());\n\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d70e774cb25c8a8d2c3e5e84200f235f9168d87","date":1553016391,"type":3,"author":"Bar Rotstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor#doDeleteByQuery(DeleteUpdateCommand).mjava","sourceNew":"  /**\n   * for implementing classes to setup request data(nodes, replicas)\n   * @param cmd the delete command being processed\n   */\n  protected void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n    // even in non zk mode, tests simulate updates from a leader\n    setupRequest(cmd);\n    doDeleteByQuery(cmd, null, null);\n  }\n\n","sourceOld":"  public void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n\n    // even in non zk mode, tests simulate updates from a leader\n    if(!zkEnabled) {\n      isLeader = getNonZkLeaderAssumption(req);\n    } else {\n      zkCheck();\n    }\n\n    // NONE: we are the first to receive this deleteByQuery\n    //       - it must be forwarded to the leader of every shard\n    // TO:   we are a leader receiving a forwarded deleteByQuery... we must:\n    //       - block all updates (use VersionInfo)\n    //       - flush *all* updates going to our replicas\n    //       - forward the DBQ to our replicas and wait for the response\n    //       - log + execute the local DBQ\n    // FROM: we are a replica receiving a DBQ from our leader\n    //       - log + execute the local DBQ\n    DistribPhase phase = DistribPhase.parseParam(req.getParams().get(DISTRIB_UPDATE_PARAM));\n\n    DocCollection coll = zkEnabled\n      ? zkController.getClusterState().getCollection(collection) : null;\n\n    if (zkEnabled && DistribPhase.NONE == phase) {\n      if (rollupReplicationTracker == null) {\n        rollupReplicationTracker = new RollupRequestReplicationTracker();\n      }\n      boolean leaderForAnyShard = false;  // start off by assuming we are not a leader for any shard\n\n      ModifiableSolrParams outParams = new ModifiableSolrParams(filterParams(req.getParams()));\n      outParams.set(DISTRIB_UPDATE_PARAM, DistribPhase.TOLEADER.toString());\n      outParams.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      SolrParams params = req.getParams();\n      String route = params.get(ShardParams._ROUTE_);\n      Collection<Slice> slices = coll.getRouter().getSearchSlices(route, params, coll);\n\n      List<Node> leaders =  new ArrayList<>(slices.size());\n      for (Slice slice : slices) {\n        String sliceName = slice.getName();\n        Replica leader;\n        try {\n          leader = zkController.getZkStateReader().getLeaderRetry(collection, sliceName);\n        } catch (InterruptedException e) {\n          throw new SolrException(ErrorCode.SERVICE_UNAVAILABLE, \"Exception finding leader for shard \" + sliceName, e);\n        }\n\n        // TODO: What if leaders changed in the meantime?\n        // should we send out slice-at-a-time and if a node returns \"hey, I'm not a leader\" (or we get an error because it went down) then look up the new leader?\n\n        // Am I the leader for this slice?\n        ZkCoreNodeProps coreLeaderProps = new ZkCoreNodeProps(leader);\n        String leaderCoreNodeName = leader.getName();\n        String coreNodeName = cloudDesc.getCoreNodeName();\n        isLeader = coreNodeName.equals(leaderCoreNodeName);\n\n        if (isLeader) {\n          // don't forward to ourself\n          leaderForAnyShard = true;\n        } else {\n          leaders.add(new ForwardNode(coreLeaderProps, zkController.getZkStateReader(), collection, sliceName, maxRetriesOnForward));\n        }\n      }\n\n      outParams.remove(\"commit\"); // this will be distributed from the local commit\n\n\n      if (params.get(UpdateRequest.MIN_REPFACT) != null) {\n        // TODO: Kept this for rolling upgrades. Remove in Solr 9\n        outParams.add(UpdateRequest.MIN_REPFACT, req.getParams().get(UpdateRequest.MIN_REPFACT));\n      }\n      cmdDistrib.distribDelete(cmd, leaders, outParams, false, rollupReplicationTracker, null);\n\n      if (!leaderForAnyShard) {\n        return;\n      }\n\n      // change the phase to TOLEADER so we look up and forward to our own replicas (if any)\n      phase = DistribPhase.TOLEADER;\n    }\n\n    List<Node> replicas = null;\n\n    if (zkEnabled && DistribPhase.TOLEADER == phase) {\n      // This core should be a leader\n      isLeader = true;\n      replicas = setupRequestForDBQ();\n    } else if (DistribPhase.FROMLEADER == phase) {\n      isLeader = false;\n    }\n    \n\n    // check if client has requested minimum replication factor information. will set replicationTracker to null if\n    // we aren't the leader or subShardLeader\n    checkReplicationTracker(cmd);\n\n    if (vinfo == null) {\n      super.processDelete(cmd);\n      return;\n    }\n\n    // at this point, there is an update we need to try and apply.\n    // we may or may not be the leader.\n\n    boolean isReplayOrPeersync = (cmd.getFlags() & (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0;\n    boolean leaderLogic = isLeader && !isReplayOrPeersync;\n    versionDeleteByQuery(cmd);\n    if (zkEnabled)  {\n      // forward to all replicas\n      ModifiableSolrParams params = new ModifiableSolrParams(filterParams(req.getParams()));\n      params.set(CommonParams.VERSION_FIELD, Long.toString(cmd.getVersion()));\n      params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n      params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n          zkController.getBaseUrl(), req.getCore().getName()));\n\n      boolean someReplicas = false;\n      boolean subShardLeader = false;\n      try {\n        subShardLeader = amISubShardLeader(coll, null, null, null);\n        if (subShardLeader)  {\n          String myShardId = cloudDesc.getShardId();\n          Replica leaderReplica = zkController.getZkStateReader().getLeaderRetry(\n              collection, myShardId);\n          // DBQ forwarded to NRT and TLOG replicas\n          List<ZkCoreNodeProps> replicaProps = zkController.getZkStateReader()\n              .getReplicaProps(collection, myShardId, leaderReplica.getName(), null, Replica.State.DOWN, EnumSet.of(Replica.Type.NRT, Replica.Type.TLOG));\n          if (replicaProps != null) {\n            final List<Node> myReplicas = new ArrayList<>(replicaProps.size());\n            for (ZkCoreNodeProps replicaProp : replicaProps) {\n              myReplicas.add(new StdNode(replicaProp, collection, myShardId));\n            }\n            cmdDistrib.distribDelete(cmd, myReplicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n            someReplicas = true;\n          }\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new ZooKeeperException(ErrorCode.SERVER_ERROR, \"\", e);\n      }\n      if (leaderLogic) {\n        List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);\n        if (subShardLeaders != null)  {\n          cmdDistrib.distribDelete(cmd, subShardLeaders, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        final List<Node> nodesByRoutingRules = getNodesByRoutingRules(zkController.getClusterState(), coll, null, null);\n        if (nodesByRoutingRules != null && !nodesByRoutingRules.isEmpty())  {\n          params = new ModifiableSolrParams(filterParams(req.getParams()));\n          params.set(DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n          params.set(DISTRIB_FROM, ZkCoreNodeProps.getCoreUrl(\n              zkController.getBaseUrl(), req.getCore().getName()));\n          params.set(DISTRIB_FROM_COLLECTION, collection);\n          params.set(DISTRIB_FROM_SHARD, cloudDesc.getShardId());\n\n          cmdDistrib.distribDelete(cmd, nodesByRoutingRules, params, true, rollupReplicationTracker, leaderReplicationTracker);\n        }\n        if (replicas != null) {\n          cmdDistrib.distribDelete(cmd, replicas, params, false, rollupReplicationTracker, leaderReplicationTracker);\n          someReplicas = true;\n        }\n      }\n\n      if (someReplicas)  {\n        cmdDistrib.blockAndDoRetries();\n      }\n    }\n\n\n    if (returnVersions && rsp != null) {\n      if (deleteByQueryResponse == null) {\n        deleteByQueryResponse = new NamedList<>(1);\n        rsp.add(\"deleteByQuery\",deleteByQueryResponse);\n      }\n      deleteByQueryResponse.add(cmd.getQuery(), cmd.getVersion());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"37a0f60745e53927c4c876cfe5b5a58170f0646c":["412d05aa585785cd44861bece79b8861a10fb179","96adbab674ae121f8b6b3e10474070b4bd97a219"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["ff0145d36648854a08ed492ce60c9616b8296418","d9652a1b09ee0e7d6533fdfedf1d7c4d9036b49d"],"ad55ff45b3a5483090d87a63019d0e6a8d4b5a65":["615bf5b56d95ed8c9bf06a402db6c817d6bff21a"],"d8469c0c0b45f7e3da74918efc8ede2ad2efe2b1":["7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6"],"1eeda7e62e149f90eee8895af874c74efa7d4852":["96adbab674ae121f8b6b3e10474070b4bd97a219"],"a219f1dcad1700e84807666bdbd2b573e8de7021":["2fc9f4a33c8fefeb1260aea04273a36b0d32378e"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["e5fa6615014cd2288fe930f8c8bb726f9504961d","61c45e99cf6676da48f19d7511c73712ad39402b"],"2fc9f4a33c8fefeb1260aea04273a36b0d32378e":["be2d2facad861c539d42173b0e4538d64b7fda80"],"aba371508186796cc6151d8223a5b4e16d02e26e":["fb999ed3fc6e419b9104de9ebfe62ace27f31d5f","6948dfbf6c703c42e0d9831d5b2a1ce38e75abb6"],"c26ef32891379baf5993bc211f03b682ed6f20ec":["df5e4eb47076636341c2cfdc58472477477d7e96"],"96adbab674ae121f8b6b3e10474070b4bd97a219":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"7350fba633b826986454e97668c5ad03b46bcaca":["86290366cefc1b9d4eced13b430858c4a4c0421d"],"14d5815ecbef89580f5c48990bcd433f04f8563a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"845e792cacdb2bb8da8fb051c0afc60db568233f":["2c6fae58725738008effbd9d848abc49122913fe"],"05a14b2611ead08655a2b2bdc61632eb31316e57":["d6f074e73200c07d54f242d3880a8da5a35ff97b","6013b4c7388f1627659c8f96c44abd10a294d3a6"],"da888af1ab894358122a22229051215f58cf4d54":["91e069c492cf4895697ef7b81df0ffb9a8bd4b48"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["412d05aa585785cd44861bece79b8861a10fb179"],"8a2f1187198fd8201881b815eea2fa3ba7b8ec5f":["cb4a195b8dc1808cd01748bd2e0fba26ca915d4d"],"613328143fc4e9ad6e49e951301c7733adb38083":["ff0145d36648854a08ed492ce60c9616b8296418"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["e2fe35ac47f8f51356d6c1724455d18f31c94fae","fb999ed3fc6e419b9104de9ebfe62ace27f31d5f"],"c5a558d54519c651068ddb202f03befefb1514a7":["2806236d9dfa336ac413d3724a4123e7cf4d1e93"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["aba371508186796cc6151d8223a5b4e16d02e26e","3f767f8c99eaedb984df754fe61f21c5de260f94"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["da888af1ab894358122a22229051215f58cf4d54","a51acc2e27bfb18091f9395494aebe82266f7ce7"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["2c6fae58725738008effbd9d848abc49122913fe","845e792cacdb2bb8da8fb051c0afc60db568233f"],"2c6fae58725738008effbd9d848abc49122913fe":["7350fba633b826986454e97668c5ad03b46bcaca"],"df5e4eb47076636341c2cfdc58472477477d7e96":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cb4a195b8dc1808cd01748bd2e0fba26ca915d4d":["3d7c0c8a97beb56d2e168604f9928de17981eabe"],"9d70e774cb25c8a8d2c3e5e84200f235f9168d87":["43f5f8344e80b4bfb2069917069430266753d2f0"],"3333dd7044501b4f20231ea55ab64e688285d153":["da888af1ab894358122a22229051215f58cf4d54"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["407687e67faf6e1f02a211ca078d8e3eed631027","3d7c0c8a97beb56d2e168604f9928de17981eabe"],"fb999ed3fc6e419b9104de9ebfe62ace27f31d5f":["e2fe35ac47f8f51356d6c1724455d18f31c94fae"],"43f5f8344e80b4bfb2069917069430266753d2f0":["c0cf9c2ec975506bab465b6b2be92cb9bffc84d3"],"8f1ea787bab5bdb5e72685e55424898da05509b6":["8a2f1187198fd8201881b815eea2fa3ba7b8ec5f"],"91e069c492cf4895697ef7b81df0ffb9a8bd4b48":["1eeda7e62e149f90eee8895af874c74efa7d4852"],"fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b":["fb999ed3fc6e419b9104de9ebfe62ace27f31d5f","6948dfbf6c703c42e0d9831d5b2a1ce38e75abb6"],"3d7c0c8a97beb56d2e168604f9928de17981eabe":["56a558aa5aadd60ae850d1ab090098bc63bdfaf9"],"6948dfbf6c703c42e0d9831d5b2a1ce38e75abb6":["fb999ed3fc6e419b9104de9ebfe62ace27f31d5f"],"1bea3922196318026c4274f2013416acb60c691e":["d9652a1b09ee0e7d6533fdfedf1d7c4d9036b49d"],"c0cf9c2ec975506bab465b6b2be92cb9bffc84d3":["ad55ff45b3a5483090d87a63019d0e6a8d4b5a65"],"6013b4c7388f1627659c8f96c44abd10a294d3a6":["3f767f8c99eaedb984df754fe61f21c5de260f94"],"601f914e4448cab7640fecfb5d15f8f2e2af0bf6":["61c45e99cf6676da48f19d7511c73712ad39402b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"56a558aa5aadd60ae850d1ab090098bc63bdfaf9":["eec5368fa415ebab044b7ae01de50d5b49519b7e"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["a51acc2e27bfb18091f9395494aebe82266f7ce7"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":["37a0f60745e53927c4c876cfe5b5a58170f0646c","1eeda7e62e149f90eee8895af874c74efa7d4852"],"61c45e99cf6676da48f19d7511c73712ad39402b":["6d2dadc1f5ca8703d8659f4964961f9967935d75"],"eec5368fa415ebab044b7ae01de50d5b49519b7e":["c5a558d54519c651068ddb202f03befefb1514a7"],"7a9d97c95155f9d108d71e447e2f3fdc15d0d1f0":["3333dd7044501b4f20231ea55ab64e688285d153"],"7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6":["6013b4c7388f1627659c8f96c44abd10a294d3a6"],"be2d2facad861c539d42173b0e4538d64b7fda80":["14d5815ecbef89580f5c48990bcd433f04f8563a"],"d9652a1b09ee0e7d6533fdfedf1d7c4d9036b49d":["613328143fc4e9ad6e49e951301c7733adb38083"],"6d2dadc1f5ca8703d8659f4964961f9967935d75":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"407687e67faf6e1f02a211ca078d8e3eed631027":["2806236d9dfa336ac413d3724a4123e7cf4d1e93","eec5368fa415ebab044b7ae01de50d5b49519b7e"],"8fd5be977c105554c6a7b68afcdbc511439723ab":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","3f767f8c99eaedb984df754fe61f21c5de260f94"],"412d05aa585785cd44861bece79b8861a10fb179":["8f1ea787bab5bdb5e72685e55424898da05509b6"],"2806236d9dfa336ac413d3724a4123e7cf4d1e93":["a6378064655e76cd7b908b1cab4ce425b384b508"],"3f767f8c99eaedb984df754fe61f21c5de260f94":["6948dfbf6c703c42e0d9831d5b2a1ce38e75abb6"],"ff0145d36648854a08ed492ce60c9616b8296418":["c26ef32891379baf5993bc211f03b682ed6f20ec"],"e5fa6615014cd2288fe930f8c8bb726f9504961d":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"86290366cefc1b9d4eced13b430858c4a4c0421d":["a219f1dcad1700e84807666bdbd2b573e8de7021"],"a6378064655e76cd7b908b1cab4ce425b384b508":["d8469c0c0b45f7e3da74918efc8ede2ad2efe2b1"],"a51acc2e27bfb18091f9395494aebe82266f7ce7":["7a9d97c95155f9d108d71e447e2f3fdc15d0d1f0"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["fe33227f6805edab2036cbb80645cc4e2d1fa424","6948dfbf6c703c42e0d9831d5b2a1ce38e75abb6"],"615bf5b56d95ed8c9bf06a402db6c817d6bff21a":["601f914e4448cab7640fecfb5d15f8f2e2af0bf6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9d70e774cb25c8a8d2c3e5e84200f235f9168d87"],"e2fe35ac47f8f51356d6c1724455d18f31c94fae":["1bea3922196318026c4274f2013416acb60c691e"]},"commit2Childs":{"37a0f60745e53927c4c876cfe5b5a58170f0646c":["716d18f3a9b0993bc679d7fa7abdc9bfb03411ec"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"ad55ff45b3a5483090d87a63019d0e6a8d4b5a65":["c0cf9c2ec975506bab465b6b2be92cb9bffc84d3"],"d8469c0c0b45f7e3da74918efc8ede2ad2efe2b1":["a6378064655e76cd7b908b1cab4ce425b384b508"],"1eeda7e62e149f90eee8895af874c74efa7d4852":["91e069c492cf4895697ef7b81df0ffb9a8bd4b48","716d18f3a9b0993bc679d7fa7abdc9bfb03411ec"],"a219f1dcad1700e84807666bdbd2b573e8de7021":["86290366cefc1b9d4eced13b430858c4a4c0421d"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"2fc9f4a33c8fefeb1260aea04273a36b0d32378e":["a219f1dcad1700e84807666bdbd2b573e8de7021"],"aba371508186796cc6151d8223a5b4e16d02e26e":["d6f074e73200c07d54f242d3880a8da5a35ff97b"],"c26ef32891379baf5993bc211f03b682ed6f20ec":["ff0145d36648854a08ed492ce60c9616b8296418"],"96adbab674ae121f8b6b3e10474070b4bd97a219":["37a0f60745e53927c4c876cfe5b5a58170f0646c","1eeda7e62e149f90eee8895af874c74efa7d4852"],"7350fba633b826986454e97668c5ad03b46bcaca":["2c6fae58725738008effbd9d848abc49122913fe"],"14d5815ecbef89580f5c48990bcd433f04f8563a":["be2d2facad861c539d42173b0e4538d64b7fda80"],"845e792cacdb2bb8da8fb051c0afc60db568233f":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"05a14b2611ead08655a2b2bdc61632eb31316e57":[],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["96adbab674ae121f8b6b3e10474070b4bd97a219"],"da888af1ab894358122a22229051215f58cf4d54":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","3333dd7044501b4f20231ea55ab64e688285d153"],"8a2f1187198fd8201881b815eea2fa3ba7b8ec5f":["8f1ea787bab5bdb5e72685e55424898da05509b6"],"613328143fc4e9ad6e49e951301c7733adb38083":["d9652a1b09ee0e7d6533fdfedf1d7c4d9036b49d"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"c5a558d54519c651068ddb202f03befefb1514a7":["eec5368fa415ebab044b7ae01de50d5b49519b7e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["05a14b2611ead08655a2b2bdc61632eb31316e57"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["6d2dadc1f5ca8703d8659f4964961f9967935d75","e5fa6615014cd2288fe930f8c8bb726f9504961d"],"df5e4eb47076636341c2cfdc58472477477d7e96":["c26ef32891379baf5993bc211f03b682ed6f20ec"],"2c6fae58725738008effbd9d848abc49122913fe":["845e792cacdb2bb8da8fb051c0afc60db568233f","cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"cb4a195b8dc1808cd01748bd2e0fba26ca915d4d":["8a2f1187198fd8201881b815eea2fa3ba7b8ec5f"],"9d70e774cb25c8a8d2c3e5e84200f235f9168d87":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3333dd7044501b4f20231ea55ab64e688285d153":["7a9d97c95155f9d108d71e447e2f3fdc15d0d1f0"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"fb999ed3fc6e419b9104de9ebfe62ace27f31d5f":["aba371508186796cc6151d8223a5b4e16d02e26e","fe33227f6805edab2036cbb80645cc4e2d1fa424","fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b","6948dfbf6c703c42e0d9831d5b2a1ce38e75abb6"],"43f5f8344e80b4bfb2069917069430266753d2f0":["9d70e774cb25c8a8d2c3e5e84200f235f9168d87"],"8f1ea787bab5bdb5e72685e55424898da05509b6":["412d05aa585785cd44861bece79b8861a10fb179"],"91e069c492cf4895697ef7b81df0ffb9a8bd4b48":["da888af1ab894358122a22229051215f58cf4d54"],"fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b":[],"3d7c0c8a97beb56d2e168604f9928de17981eabe":["cb4a195b8dc1808cd01748bd2e0fba26ca915d4d","d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"6948dfbf6c703c42e0d9831d5b2a1ce38e75abb6":["aba371508186796cc6151d8223a5b4e16d02e26e","fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b","3f767f8c99eaedb984df754fe61f21c5de260f94","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"1bea3922196318026c4274f2013416acb60c691e":["e2fe35ac47f8f51356d6c1724455d18f31c94fae"],"6013b4c7388f1627659c8f96c44abd10a294d3a6":["05a14b2611ead08655a2b2bdc61632eb31316e57","7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6"],"c0cf9c2ec975506bab465b6b2be92cb9bffc84d3":["43f5f8344e80b4bfb2069917069430266753d2f0"],"601f914e4448cab7640fecfb5d15f8f2e2af0bf6":["615bf5b56d95ed8c9bf06a402db6c817d6bff21a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["df5e4eb47076636341c2cfdc58472477477d7e96"],"56a558aa5aadd60ae850d1ab090098bc63bdfaf9":["3d7c0c8a97beb56d2e168604f9928de17981eabe"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["14d5815ecbef89580f5c48990bcd433f04f8563a"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":[],"61c45e99cf6676da48f19d7511c73712ad39402b":["e9017cf144952056066919f1ebc7897ff9bd71b1","601f914e4448cab7640fecfb5d15f8f2e2af0bf6"],"eec5368fa415ebab044b7ae01de50d5b49519b7e":["56a558aa5aadd60ae850d1ab090098bc63bdfaf9","407687e67faf6e1f02a211ca078d8e3eed631027"],"7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6":["d8469c0c0b45f7e3da74918efc8ede2ad2efe2b1"],"7a9d97c95155f9d108d71e447e2f3fdc15d0d1f0":["a51acc2e27bfb18091f9395494aebe82266f7ce7"],"be2d2facad861c539d42173b0e4538d64b7fda80":["2fc9f4a33c8fefeb1260aea04273a36b0d32378e"],"d9652a1b09ee0e7d6533fdfedf1d7c4d9036b49d":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","1bea3922196318026c4274f2013416acb60c691e"],"407687e67faf6e1f02a211ca078d8e3eed631027":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"6d2dadc1f5ca8703d8659f4964961f9967935d75":["61c45e99cf6676da48f19d7511c73712ad39402b"],"8fd5be977c105554c6a7b68afcdbc511439723ab":[],"412d05aa585785cd44861bece79b8861a10fb179":["37a0f60745e53927c4c876cfe5b5a58170f0646c","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"2806236d9dfa336ac413d3724a4123e7cf4d1e93":["c5a558d54519c651068ddb202f03befefb1514a7","407687e67faf6e1f02a211ca078d8e3eed631027"],"ff0145d36648854a08ed492ce60c9616b8296418":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","613328143fc4e9ad6e49e951301c7733adb38083"],"e5fa6615014cd2288fe930f8c8bb726f9504961d":["e9017cf144952056066919f1ebc7897ff9bd71b1"],"3f767f8c99eaedb984df754fe61f21c5de260f94":["d6f074e73200c07d54f242d3880a8da5a35ff97b","6013b4c7388f1627659c8f96c44abd10a294d3a6","8fd5be977c105554c6a7b68afcdbc511439723ab"],"86290366cefc1b9d4eced13b430858c4a4c0421d":["7350fba633b826986454e97668c5ad03b46bcaca"],"a6378064655e76cd7b908b1cab4ce425b384b508":["2806236d9dfa336ac413d3724a4123e7cf4d1e93"],"a51acc2e27bfb18091f9395494aebe82266f7ce7":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["8fd5be977c105554c6a7b68afcdbc511439723ab"],"615bf5b56d95ed8c9bf06a402db6c817d6bff21a":["ad55ff45b3a5483090d87a63019d0e6a8d4b5a65"],"e2fe35ac47f8f51356d6c1724455d18f31c94fae":["fe33227f6805edab2036cbb80645cc4e2d1fa424","fb999ed3fc6e419b9104de9ebfe62ace27f31d5f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","e9017cf144952056066919f1ebc7897ff9bd71b1","05a14b2611ead08655a2b2bdc61632eb31316e57","74f45af4339b0daf7a95c820ab88c1aea74fbce0","d3fcb70cf561547c7bb1506e0cf32ca7b1287064","fe9077a1ed75bdcdcc7dfff6525f73941c8cf30b","716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","8fd5be977c105554c6a7b68afcdbc511439723ab","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}