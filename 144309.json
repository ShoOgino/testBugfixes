{"path":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockSynonymFilter#test().mjava","commits":[{"id":"138a352a6d4e54824d0275bc7aa1b784e78c81fe","date":1467756222,"type":0,"author":"Steve Rowe","isMerge":false,"pathNew":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockSynonymFilter#test().mjava","pathOld":"/dev/null","sourceNew":"  /** test the mock synonym filter */\n  public void test() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer();\n        return new TokenStreamComponents(tokenizer, new MockSynonymFilter(tokenizer));\n      }\n    };\n\n    assertAnalyzesTo(analyzer, \"dogs\",\n        new String[]{\"dogs\", \"dog\"},\n        new int[]{0, 0}, // start offset\n        new int[]{4, 4}, // end offset\n        null,\n        new int[]{1, 0}, // position increment\n        new int[]{1, 1}, // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"small dogs\",\n        new String[]{\"small\", \"dogs\", \"dog\"},\n        new int[]{0, 6, 6},   // start offset\n        new int[]{5, 10, 10}, // end offset\n        null,\n        new int[]{1, 1, 0},   // position increment\n        new int[]{1, 1, 1},   // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"dogs running\",\n        new String[]{\"dogs\", \"dog\", \"running\"},\n        new int[]{0, 0, 5},  // start offset\n        new int[]{4, 4, 12}, // end offset\n        null,\n        new int[]{1, 0, 1},  // position increment\n        new int[]{1, 1, 1},  // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"small dogs running\",\n        new String[]{\"small\", \"dogs\", \"dog\", \"running\"},\n        new int[]{0, 6, 6, 11},   // start offset\n        new int[]{5, 10, 10, 18}, // end offset\n        null,\n        new int[]{1, 1, 0, 1},    // position increment\n        new int[]{1, 1, 1, 1},    // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"guinea\",\n        new String[]{\"guinea\"},\n        new int[]{0}, // start offset\n        new int[]{6}, // end offset\n        null,\n        new int[]{1}, // position increment\n        new int[]{1}, // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"pig\",\n        new String[]{\"pig\"},\n        new int[]{0}, // start offset\n        new int[]{3}, // end offset\n        null,\n        new int[]{1}, // position increment\n        new int[]{1}, // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"guinea pig\",\n        new String[]{\"guinea\", \"cavy\", \"pig\"},\n        new int[]{0, 0, 7},   // start offset\n        new int[]{6, 10, 10}, // end offset\n        null,\n        new int[]{1, 0, 1},   // position increment\n        new int[]{1, 2, 1},   // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"guinea dogs\",\n        new String[]{\"guinea\", \"dogs\", \"dog\"},\n        new int[]{0, 7, 7},   // start offset\n        new int[]{6, 11, 11}, // end offset\n        null,\n        new int[]{1, 1, 0},   // position increment\n        new int[]{1, 1, 1},   // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"dogs guinea\",\n        new String[]{\"dogs\", \"dog\", \"guinea\"},\n        new int[]{0, 0, 5},  // start offset\n        new int[]{4, 4, 11}, // end offset\n        null,\n        new int[]{1, 0, 1},  // position increment\n        new int[]{1, 1, 1},  // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"dogs guinea pig\",\n        new String[]{\"dogs\", \"dog\", \"guinea\", \"cavy\", \"pig\"},\n        new int[]{0, 0, 5, 5, 12},   // start offset\n        new int[]{4, 4, 11, 15, 15}, // end offset\n        null,\n        new int[]{1, 0, 1, 0, 1},    // position increment\n        new int[]{1, 1, 1, 2, 1},    // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"guinea pig dogs\",\n        new String[]{\"guinea\", \"cavy\", \"pig\", \"dogs\", \"dog\"},\n        new int[]{0, 0, 7, 11, 11},   // start offset\n        new int[]{6, 10, 10, 15, 15}, // end offset\n        null,\n        new int[]{1, 0, 1, 1, 0},     // position increment\n        new int[]{1, 2, 1, 1, 1},     // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"small dogs and guinea pig running\",\n        new String[]{\"small\", \"dogs\", \"dog\", \"and\", \"guinea\", \"cavy\", \"pig\", \"running\"},\n        new int[]{0, 6, 6, 11, 15, 15, 22, 26},   // start offset\n        new int[]{5, 10, 10, 14, 21, 25, 25, 33}, // end offset\n        null,\n        new int[]{1, 1, 0, 1, 1, 0, 1, 1},        // position increment\n        new int[]{1, 1, 1, 1, 1, 2, 1, 1},        // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"small guinea pig and dogs running\",\n        new String[]{\"small\", \"guinea\", \"cavy\", \"pig\", \"and\", \"dogs\", \"dog\", \"running\"},\n        new int[]{0, 6, 6, 13, 17, 21, 21, 26},   // start offset\n        new int[]{5, 12, 16, 16, 20, 25, 25, 33}, // end offset\n        null,\n        new int[]{1, 1, 0, 1, 1, 1, 0, 1},        // position increment\n        new int[]{1, 1, 2, 1, 1, 1, 1, 1},        // position length\n        true); // check that offsets are correct\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockSynonymFilter#test().mjava","pathOld":"/dev/null","sourceNew":"  /** test the mock synonym filter */\n  public void test() throws IOException {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer();\n        return new TokenStreamComponents(tokenizer, new MockSynonymFilter(tokenizer));\n      }\n    };\n\n    assertAnalyzesTo(analyzer, \"dogs\",\n        new String[]{\"dogs\", \"dog\"},\n        new int[]{0, 0}, // start offset\n        new int[]{4, 4}, // end offset\n        null,\n        new int[]{1, 0}, // position increment\n        new int[]{1, 1}, // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"small dogs\",\n        new String[]{\"small\", \"dogs\", \"dog\"},\n        new int[]{0, 6, 6},   // start offset\n        new int[]{5, 10, 10}, // end offset\n        null,\n        new int[]{1, 1, 0},   // position increment\n        new int[]{1, 1, 1},   // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"dogs running\",\n        new String[]{\"dogs\", \"dog\", \"running\"},\n        new int[]{0, 0, 5},  // start offset\n        new int[]{4, 4, 12}, // end offset\n        null,\n        new int[]{1, 0, 1},  // position increment\n        new int[]{1, 1, 1},  // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"small dogs running\",\n        new String[]{\"small\", \"dogs\", \"dog\", \"running\"},\n        new int[]{0, 6, 6, 11},   // start offset\n        new int[]{5, 10, 10, 18}, // end offset\n        null,\n        new int[]{1, 1, 0, 1},    // position increment\n        new int[]{1, 1, 1, 1},    // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"guinea\",\n        new String[]{\"guinea\"},\n        new int[]{0}, // start offset\n        new int[]{6}, // end offset\n        null,\n        new int[]{1}, // position increment\n        new int[]{1}, // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"pig\",\n        new String[]{\"pig\"},\n        new int[]{0}, // start offset\n        new int[]{3}, // end offset\n        null,\n        new int[]{1}, // position increment\n        new int[]{1}, // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"guinea pig\",\n        new String[]{\"guinea\", \"cavy\", \"pig\"},\n        new int[]{0, 0, 7},   // start offset\n        new int[]{6, 10, 10}, // end offset\n        null,\n        new int[]{1, 0, 1},   // position increment\n        new int[]{1, 2, 1},   // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"guinea dogs\",\n        new String[]{\"guinea\", \"dogs\", \"dog\"},\n        new int[]{0, 7, 7},   // start offset\n        new int[]{6, 11, 11}, // end offset\n        null,\n        new int[]{1, 1, 0},   // position increment\n        new int[]{1, 1, 1},   // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"dogs guinea\",\n        new String[]{\"dogs\", \"dog\", \"guinea\"},\n        new int[]{0, 0, 5},  // start offset\n        new int[]{4, 4, 11}, // end offset\n        null,\n        new int[]{1, 0, 1},  // position increment\n        new int[]{1, 1, 1},  // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"dogs guinea pig\",\n        new String[]{\"dogs\", \"dog\", \"guinea\", \"cavy\", \"pig\"},\n        new int[]{0, 0, 5, 5, 12},   // start offset\n        new int[]{4, 4, 11, 15, 15}, // end offset\n        null,\n        new int[]{1, 0, 1, 0, 1},    // position increment\n        new int[]{1, 1, 1, 2, 1},    // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"guinea pig dogs\",\n        new String[]{\"guinea\", \"cavy\", \"pig\", \"dogs\", \"dog\"},\n        new int[]{0, 0, 7, 11, 11},   // start offset\n        new int[]{6, 10, 10, 15, 15}, // end offset\n        null,\n        new int[]{1, 0, 1, 1, 0},     // position increment\n        new int[]{1, 2, 1, 1, 1},     // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"small dogs and guinea pig running\",\n        new String[]{\"small\", \"dogs\", \"dog\", \"and\", \"guinea\", \"cavy\", \"pig\", \"running\"},\n        new int[]{0, 6, 6, 11, 15, 15, 22, 26},   // start offset\n        new int[]{5, 10, 10, 14, 21, 25, 25, 33}, // end offset\n        null,\n        new int[]{1, 1, 0, 1, 1, 0, 1, 1},        // position increment\n        new int[]{1, 1, 1, 1, 1, 2, 1, 1},        // position length\n        true); // check that offsets are correct\n\n    assertAnalyzesTo(analyzer, \"small guinea pig and dogs running\",\n        new String[]{\"small\", \"guinea\", \"cavy\", \"pig\", \"and\", \"dogs\", \"dog\", \"running\"},\n        new int[]{0, 6, 6, 13, 17, 21, 21, 26},   // start offset\n        new int[]{5, 12, 16, 16, 20, 25, 25, 33}, // end offset\n        null,\n        new int[]{1, 1, 0, 1, 1, 1, 0, 1},        // position increment\n        new int[]{1, 1, 2, 1, 1, 1, 1, 1},        // position length\n        true); // check that offsets are correct\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"138a352a6d4e54824d0275bc7aa1b784e78c81fe":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","138a352a6d4e54824d0275bc7aa1b784e78c81fe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["138a352a6d4e54824d0275bc7aa1b784e78c81fe"]},"commit2Childs":{"138a352a6d4e54824d0275bc7aa1b784e78c81fe":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["138a352a6d4e54824d0275bc7aa1b784e78c81fe","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}