{"path":"src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","commits":[{"id":"ed0158ac307bee4b81f4c26ebe88cddc950f46db","date":1211204318,"type":0,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"/dev/null","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      for( Token token = ts.next(); token != null; token = ts.next() ){\n        String text = token.termText();\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c90f01e1c0f11ee52212ab38c6d4393b3be8a646","date":1223059437,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      for( Token token = ts.next(); token != null; token = ts.next() ){\n        String text = new String(token.termBuffer(), 0, token.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      for( Token token = ts.next(); token != null; token = ts.next() ){\n        String text = token.termText();\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ef28ac95f5f85bbf872801277448c0924b0a6827","date":1268600312,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n      while (ts.incrementToken()){\n        String text = new String(termAtt.termBuffer(), 0, termAtt.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      for( Token token = ts.next(); token != null; token = ts.next() ){\n        String text = new String(token.termBuffer(), 0, token.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","pathOld":"src/java/org/apache/solr/analysis/SynonymFilterFactory#splitByTokenizer(String,TokenizerFactory).mjava","sourceNew":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n      while (ts.incrementToken()){\n        String text = new String(termAtt.termBuffer(), 0, termAtt.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","sourceOld":"  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){\n    StringReader reader = new StringReader( source );\n    TokenStream ts = loadTokenizer(tokFactory, reader);\n    List<String> tokList = new ArrayList<String>();\n    try {\n      TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n      while (ts.incrementToken()){\n        String text = new String(termAtt.termBuffer(), 0, termAtt.termLength());\n        if( text.length() > 0 )\n          tokList.add( text );\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    finally{\n      reader.close();\n    }\n    return tokList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c90f01e1c0f11ee52212ab38c6d4393b3be8a646":["ed0158ac307bee4b81f4c26ebe88cddc950f46db"],"ed0158ac307bee4b81f4c26ebe88cddc950f46db":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ef28ac95f5f85bbf872801277448c0924b0a6827":["c90f01e1c0f11ee52212ab38c6d4393b3be8a646"],"ad94625fb8d088209f46650c8097196fec67f00c":["ef28ac95f5f85bbf872801277448c0924b0a6827"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"c90f01e1c0f11ee52212ab38c6d4393b3be8a646":["ef28ac95f5f85bbf872801277448c0924b0a6827"],"ed0158ac307bee4b81f4c26ebe88cddc950f46db":["c90f01e1c0f11ee52212ab38c6d4393b3be8a646"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ed0158ac307bee4b81f4c26ebe88cddc950f46db"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ef28ac95f5f85bbf872801277448c0924b0a6827":["ad94625fb8d088209f46650c8097196fec67f00c"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}