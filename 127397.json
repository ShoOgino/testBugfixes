{"path":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","commits":[{"id":"6eecfe8d494cb2e3ead94e9cdb9381bfe4993dcd","date":1438089844,"type":0,"author":"Mikhail Khludnev","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s_dv\",\"small2_s_dv\",\"small2_ss_dv\",\"small3_ss_dv\"},\n        {\"small_i_dv\",\"small2_i_dv\",\"small2_is_dv\",\"small3_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"score_f_dv\",ONE_ONE, new FVal(1,100)));  // field used to score\n      **/\n      types.add(new FldType(\"small_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss_dv\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss_dv\",new IRange(0,25), new SVal('A','z',1,1)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is_dv\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is_dv\",new IRange(0,25), new IRange(0,100)));\n      **/\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                +\" \"+ (random().nextBoolean() ? \"fromIndex=collection1\" : \"\")\n                +\" \"+ (random().nextBoolean() ? \"TESTenforceSameCoreAsAnotherOne=true\" : \"\")\n                +\" \"+whateverScore()+\"}*:*\"\n                , \"sort\", \"_docid_ asc\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          final String m = \"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n          ;// + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model);\n          log.error(m);\n          {\n            SolrQueryRequest f = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n              \"q\",\"*:*\", \"facet\",\"true\",\n              \"facet.field\", fromField \n                  , \"sort\", \"_docid_ asc\"\n                  ,\"rows\",\"0\"\n                );\n            log.error(\"faceting on from field: \"+h.query(f));\n          }\n          {\n            final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n            final String q = ps.get(\"q\");\n            ps.put(\"q\", q.replaceAll(\"join score=none\", \"join\"));\n            log.error(\"plain join: \"+h.query(req));\n            ps.put(\"q\", q);\n            \n          }\n          {\n          // re-execute the request... good for putting a breakpoint here for debugging\n          final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n          final String q = ps.get(\"q\");\n          ps.put(\"q\", q.replaceAll(\"\\\\}\", \" cache=false\\\\}\"));\n          String rsp = h.query(req);\n          }\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3714bcf66a68a1600e9dd11442fc1b33b62ef088","date":1556832005,"type":3,"author":"noble","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s_dv\",\"small2_s_dv\",\"small2_ss_dv\",\"small3_ss_dv\"},\n        {\"small_i_dv\",\"small2_i_dv\",\"small2_is_dv\",\"small3_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"score_f_dv\",ONE_ONE, new FVal(1,100)));  // field used to score\n      **/\n      types.add(new FldType(\"small_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss_dv\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss_dv\",new IRange(0,25), new SVal('A','z',1,1)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is_dv\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is_dv\",new IRange(0,25), new IRange(0,100)));\n      **/\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                +\" \"+ (random().nextBoolean() ? \"fromIndex=collection1\" : \"\")\n                +\" \"+ (random().nextBoolean() ? \"TESTenforceSameCoreAsAnotherOne=true\" : \"\")\n                +\" \"+whateverScore()+\"}*:*\"\n                , \"sort\", \"_docid_ asc\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          final String m = \"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ toJSONString(resultSet)\n          ;// + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model);\n          log.error(m);\n          {\n            SolrQueryRequest f = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n              \"q\",\"*:*\", \"facet\",\"true\",\n              \"facet.field\", fromField \n                  , \"sort\", \"_docid_ asc\"\n                  ,\"rows\",\"0\"\n                );\n            log.error(\"faceting on from field: \"+h.query(f));\n          }\n          {\n            final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n            final String q = ps.get(\"q\");\n            ps.put(\"q\", q.replaceAll(\"join score=none\", \"join\"));\n            log.error(\"plain join: \"+h.query(req));\n            ps.put(\"q\", q);\n            \n          }\n          {\n          // re-execute the request... good for putting a breakpoint here for debugging\n          final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n          final String q = ps.get(\"q\");\n          ps.put(\"q\", q.replaceAll(\"\\\\}\", \" cache=false\\\\}\"));\n          String rsp = h.query(req);\n          }\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s_dv\",\"small2_s_dv\",\"small2_ss_dv\",\"small3_ss_dv\"},\n        {\"small_i_dv\",\"small2_i_dv\",\"small2_is_dv\",\"small3_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"score_f_dv\",ONE_ONE, new FVal(1,100)));  // field used to score\n      **/\n      types.add(new FldType(\"small_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss_dv\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss_dv\",new IRange(0,25), new SVal('A','z',1,1)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is_dv\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is_dv\",new IRange(0,25), new IRange(0,100)));\n      **/\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                +\" \"+ (random().nextBoolean() ? \"fromIndex=collection1\" : \"\")\n                +\" \"+ (random().nextBoolean() ? \"TESTenforceSameCoreAsAnotherOne=true\" : \"\")\n                +\" \"+whateverScore()+\"}*:*\"\n                , \"sort\", \"_docid_ asc\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          final String m = \"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n          ;// + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model);\n          log.error(m);\n          {\n            SolrQueryRequest f = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n              \"q\",\"*:*\", \"facet\",\"true\",\n              \"facet.field\", fromField \n                  , \"sort\", \"_docid_ asc\"\n                  ,\"rows\",\"0\"\n                );\n            log.error(\"faceting on from field: \"+h.query(f));\n          }\n          {\n            final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n            final String q = ps.get(\"q\");\n            ps.put(\"q\", q.replaceAll(\"join score=none\", \"join\"));\n            log.error(\"plain join: \"+h.query(req));\n            ps.put(\"q\", q);\n            \n          }\n          {\n          // re-execute the request... good for putting a breakpoint here for debugging\n          final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n          final String q = ps.get(\"q\");\n          ps.put(\"q\", q.replaceAll(\"\\\\}\", \" cache=false\\\\}\"));\n          String rsp = h.query(req);\n          }\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"00a778ad8ad6c2c04607538d2f36fee001239eef","date":1576657013,"type":3,"author":"Mikhail Khludnev","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","sourceNew":"  @SuppressWarnings({\"rawtypes\", \"unchecked\"})\n  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s_dv\",\"small2_s_dv\",\"small2_ss_dv\",\"small3_ss_dv\"},\n        {\"small_i_dv\",\"small2_i_dv\",\"small2_is_dv\",\"small3_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"score_f_dv\",ONE_ONE, new FVal(1,100)));  // field used to score\n      **/\n      types.add(new FldType(\"small_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss_dv\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss_dv\",new IRange(0,25), new SVal('A','z',1,1)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is_dv\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is_dv\",new IRange(0,25), new IRange(0,100)));\n      **/\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                +\" \"+ (random().nextBoolean() ? \"fromIndex=collection1\" : \"\")\n                +\" \"+ (random().nextBoolean() ? \"TESTenforceSameCoreAsAnotherOne=true\" : \"\")\n                +\" \"+whateverScore()+\"}*:*\"\n                , \"sort\", \"_docid_ asc\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          final String m = \"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ toJSONString(resultSet)\n          ;// + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model);\n          log.error(m);\n          {\n            SolrQueryRequest f = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n              \"q\",\"*:*\", \"facet\",\"true\",\n              \"facet.field\", fromField \n                  , \"sort\", \"_docid_ asc\"\n                  ,\"rows\",\"0\"\n                );\n            log.error(\"faceting on from field: \"+h.query(f));\n          }\n          {\n            final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n            final String q = ps.get(\"q\");\n            ps.put(\"q\", q.replaceAll(\"join score=none\", \"join\"));\n            log.error(\"plain join: \"+h.query(req));\n            ps.put(\"q\", q);\n            \n          }\n          {\n          // re-execute the request... good for putting a breakpoint here for debugging\n          final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n          final String q = ps.get(\"q\");\n          ps.put(\"q\", q.replaceAll(\"\\\\}\", \" cache=false\\\\}\"));\n          h.query(req);\n          }\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s_dv\",\"small2_s_dv\",\"small2_ss_dv\",\"small3_ss_dv\"},\n        {\"small_i_dv\",\"small2_i_dv\",\"small2_is_dv\",\"small3_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"score_f_dv\",ONE_ONE, new FVal(1,100)));  // field used to score\n      **/\n      types.add(new FldType(\"small_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss_dv\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss_dv\",new IRange(0,25), new SVal('A','z',1,1)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is_dv\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is_dv\",new IRange(0,25), new IRange(0,100)));\n      **/\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                +\" \"+ (random().nextBoolean() ? \"fromIndex=collection1\" : \"\")\n                +\" \"+ (random().nextBoolean() ? \"TESTenforceSameCoreAsAnotherOne=true\" : \"\")\n                +\" \"+whateverScore()+\"}*:*\"\n                , \"sort\", \"_docid_ asc\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          final String m = \"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ toJSONString(resultSet)\n          ;// + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model);\n          log.error(m);\n          {\n            SolrQueryRequest f = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n              \"q\",\"*:*\", \"facet\",\"true\",\n              \"facet.field\", fromField \n                  , \"sort\", \"_docid_ asc\"\n                  ,\"rows\",\"0\"\n                );\n            log.error(\"faceting on from field: \"+h.query(f));\n          }\n          {\n            final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n            final String q = ps.get(\"q\");\n            ps.put(\"q\", q.replaceAll(\"join score=none\", \"join\"));\n            log.error(\"plain join: \"+h.query(req));\n            ps.put(\"q\", q);\n            \n          }\n          {\n          // re-execute the request... good for putting a breakpoint here for debugging\n          final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n          final String q = ps.get(\"q\");\n          ps.put(\"q\", q.replaceAll(\"\\\\}\", \" cache=false\\\\}\"));\n          String rsp = h.query(req);\n          }\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"246314af59d76a47fccc31e9494eefee01ec9c00","date":1576657955,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","sourceNew":"  @SuppressWarnings({\"rawtypes\", \"unchecked\"})\n  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s_dv\",\"small2_s_dv\",\"small2_ss_dv\",\"small3_ss_dv\"},\n        {\"small_i_dv\",\"small2_i_dv\",\"small2_is_dv\",\"small3_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"score_f_dv\",ONE_ONE, new FVal(1,100)));  // field used to score\n      **/\n      types.add(new FldType(\"small_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss_dv\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss_dv\",new IRange(0,25), new SVal('A','z',1,1)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is_dv\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is_dv\",new IRange(0,25), new IRange(0,100)));\n      **/\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                +\" \"+ (random().nextBoolean() ? \"fromIndex=collection1\" : \"\")\n                +\" \"+ (random().nextBoolean() ? \"TESTenforceSameCoreAsAnotherOne=true\" : \"\")\n                +\" \"+whateverScore()+\"}*:*\"\n                , \"sort\", \"_docid_ asc\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          final String m = \"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ toJSONString(resultSet)\n          ;// + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model);\n          log.error(m);\n          {\n            SolrQueryRequest f = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n              \"q\",\"*:*\", \"facet\",\"true\",\n              \"facet.field\", fromField \n                  , \"sort\", \"_docid_ asc\"\n                  ,\"rows\",\"0\"\n                );\n            log.error(\"faceting on from field: \"+h.query(f));\n          }\n          {\n            final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n            final String q = ps.get(\"q\");\n            ps.put(\"q\", q.replaceAll(\"join score=none\", \"join\"));\n            log.error(\"plain join: \"+h.query(req));\n            ps.put(\"q\", q);\n            \n          }\n          {\n          // re-execute the request... good for putting a breakpoint here for debugging\n          final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n          final String q = ps.get(\"q\");\n          ps.put(\"q\", q.replaceAll(\"\\\\}\", \" cache=false\\\\}\"));\n          h.query(req);\n          }\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s_dv\",\"small2_s_dv\",\"small2_ss_dv\",\"small3_ss_dv\"},\n        {\"small_i_dv\",\"small2_i_dv\",\"small2_is_dv\",\"small3_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"score_f_dv\",ONE_ONE, new FVal(1,100)));  // field used to score\n      **/\n      types.add(new FldType(\"small_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss_dv\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss_dv\",new IRange(0,25), new SVal('A','z',1,1)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is_dv\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is_dv\",new IRange(0,25), new IRange(0,100)));\n      **/\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                +\" \"+ (random().nextBoolean() ? \"fromIndex=collection1\" : \"\")\n                +\" \"+ (random().nextBoolean() ? \"TESTenforceSameCoreAsAnotherOne=true\" : \"\")\n                +\" \"+whateverScore()+\"}*:*\"\n                , \"sort\", \"_docid_ asc\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          final String m = \"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ toJSONString(resultSet)\n          ;// + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model);\n          log.error(m);\n          {\n            SolrQueryRequest f = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n              \"q\",\"*:*\", \"facet\",\"true\",\n              \"facet.field\", fromField \n                  , \"sort\", \"_docid_ asc\"\n                  ,\"rows\",\"0\"\n                );\n            log.error(\"faceting on from field: \"+h.query(f));\n          }\n          {\n            final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n            final String q = ps.get(\"q\");\n            ps.put(\"q\", q.replaceAll(\"join score=none\", \"join\"));\n            log.error(\"plain join: \"+h.query(req));\n            ps.put(\"q\", q);\n            \n          }\n          {\n          // re-execute the request... good for putting a breakpoint here for debugging\n          final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n          final String q = ps.get(\"q\");\n          ps.put(\"q\", q.replaceAll(\"\\\\}\", \" cache=false\\\\}\"));\n          String rsp = h.query(req);\n          }\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","sourceNew":"  @SuppressWarnings({\"rawtypes\", \"unchecked\"})\n  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s_dv\",\"small2_s_dv\",\"small2_ss_dv\",\"small3_ss_dv\"},\n        {\"small_i_dv\",\"small2_i_dv\",\"small2_is_dv\",\"small3_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"score_f_dv\",ONE_ONE, new FVal(1,100)));  // field used to score\n      **/\n      types.add(new FldType(\"small_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss_dv\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss_dv\",new IRange(0,25), new SVal('A','z',1,1)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is_dv\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is_dv\",new IRange(0,25), new IRange(0,100)));\n      **/\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                +\" \"+ (random().nextBoolean() ? \"fromIndex=collection1\" : \"\")\n                +\" \"+ (random().nextBoolean() ? \"TESTenforceSameCoreAsAnotherOne=true\" : \"\")\n                +\" \"+whateverScore()+\"}*:*\"\n                , \"sort\", \"_docid_ asc\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          final String m = \"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ toJSONString(resultSet)\n          ;// + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model);\n          log.error(m);\n          {\n            SolrQueryRequest f = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n              \"q\",\"*:*\", \"facet\",\"true\",\n              \"facet.field\", fromField \n                  , \"sort\", \"_docid_ asc\"\n                  ,\"rows\",\"0\"\n                );\n            log.error(\"faceting on from field: {}\", h.query(f));\n          }\n          {\n            final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n            final String q = ps.get(\"q\");\n            ps.put(\"q\", q.replaceAll(\"join score=none\", \"join\"));\n            log.error(\"plain join: {}\", h.query(req));\n            ps.put(\"q\", q);\n            \n          }\n          {\n          // re-execute the request... good for putting a breakpoint here for debugging\n          final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n          final String q = ps.get(\"q\");\n          ps.put(\"q\", q.replaceAll(\"\\\\}\", \" cache=false\\\\}\"));\n          h.query(req);\n          }\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @SuppressWarnings({\"rawtypes\", \"unchecked\"})\n  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s_dv\",\"small2_s_dv\",\"small2_ss_dv\",\"small3_ss_dv\"},\n        {\"small_i_dv\",\"small2_i_dv\",\"small2_is_dv\",\"small3_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"score_f_dv\",ONE_ONE, new FVal(1,100)));  // field used to score\n      **/\n      types.add(new FldType(\"small_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss_dv\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss_dv\",new IRange(0,25), new SVal('A','z',1,1)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is_dv\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is_dv\",new IRange(0,25), new IRange(0,100)));\n      **/\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                +\" \"+ (random().nextBoolean() ? \"fromIndex=collection1\" : \"\")\n                +\" \"+ (random().nextBoolean() ? \"TESTenforceSameCoreAsAnotherOne=true\" : \"\")\n                +\" \"+whateverScore()+\"}*:*\"\n                , \"sort\", \"_docid_ asc\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          final String m = \"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ toJSONString(resultSet)\n          ;// + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model);\n          log.error(m);\n          {\n            SolrQueryRequest f = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n              \"q\",\"*:*\", \"facet\",\"true\",\n              \"facet.field\", fromField \n                  , \"sort\", \"_docid_ asc\"\n                  ,\"rows\",\"0\"\n                );\n            log.error(\"faceting on from field: \"+h.query(f));\n          }\n          {\n            final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n            final String q = ps.get(\"q\");\n            ps.put(\"q\", q.replaceAll(\"join score=none\", \"join\"));\n            log.error(\"plain join: \"+h.query(req));\n            ps.put(\"q\", q);\n            \n          }\n          {\n          // re-execute the request... good for putting a breakpoint here for debugging\n          final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n          final String q = ps.get(\"q\");\n          ps.put(\"q\", q.replaceAll(\"\\\\}\", \" cache=false\\\\}\"));\n          h.query(req);\n          }\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"640ded7811e1b7d29236a5e2934ec3cd266a8199","date":1588973147,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/join/TestScoreJoinQPNoScore#testRandomJoin().mjava","sourceNew":"  @SuppressWarnings({\"rawtypes\", \"unchecked\"})\n  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s_dv\",\"small2_s_dv\",\"small2_ss_dv\",\"small3_ss_dv\"},\n        {\"small_i_dv\",\"small2_i_dv\",\"small2_is_dv\",\"small3_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"score_f_dv\",ONE_ONE, new FVal(1,100)));  // field used to score\n      **/\n      types.add(new FldType(\"small_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss_dv\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss_dv\",new IRange(0,25), new SVal('A','z',1,1)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is_dv\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is_dv\",new IRange(0,25), new IRange(0,100)));\n      **/\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"numFoundExact\", true);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                +\" \"+ (random().nextBoolean() ? \"fromIndex=collection1\" : \"\")\n                +\" \"+ (random().nextBoolean() ? \"TESTenforceSameCoreAsAnotherOne=true\" : \"\")\n                +\" \"+whateverScore()+\"}*:*\"\n                , \"sort\", \"_docid_ asc\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          final String m = \"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ toJSONString(resultSet)\n          ;// + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model);\n          log.error(m);\n          {\n            SolrQueryRequest f = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n              \"q\",\"*:*\", \"facet\",\"true\",\n              \"facet.field\", fromField \n                  , \"sort\", \"_docid_ asc\"\n                  ,\"rows\",\"0\"\n                );\n            log.error(\"faceting on from field: {}\", h.query(f));\n          }\n          {\n            final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n            final String q = ps.get(\"q\");\n            ps.put(\"q\", q.replaceAll(\"join score=none\", \"join\"));\n            log.error(\"plain join: {}\", h.query(req));\n            ps.put(\"q\", q);\n            \n          }\n          {\n          // re-execute the request... good for putting a breakpoint here for debugging\n          final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n          final String q = ps.get(\"q\");\n          ps.put(\"q\", q.replaceAll(\"\\\\}\", \" cache=false\\\\}\"));\n          h.query(req);\n          }\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @SuppressWarnings({\"rawtypes\", \"unchecked\"})\n  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s_dv\",\"small2_s_dv\",\"small2_ss_dv\",\"small3_ss_dv\"},\n        {\"small_i_dv\",\"small2_i_dv\",\"small2_is_dv\",\"small3_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"score_f_dv\",ONE_ONE, new FVal(1,100)));  // field used to score\n      **/\n      types.add(new FldType(\"small_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s_dv\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss_dv\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss_dv\",new IRange(0,25), new SVal('A','z',1,1)));\n      /** no numeric fields so far LUCENE-5868\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is_dv\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is_dv\",new IRange(0,25), new IRange(0,100)));\n      **/\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                +\" \"+ (random().nextBoolean() ? \"fromIndex=collection1\" : \"\")\n                +\" \"+ (random().nextBoolean() ? \"TESTenforceSameCoreAsAnotherOne=true\" : \"\")\n                +\" \"+whateverScore()+\"}*:*\"\n                , \"sort\", \"_docid_ asc\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          final String m = \"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ toJSONString(resultSet)\n          ;// + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model);\n          log.error(m);\n          {\n            SolrQueryRequest f = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n              \"q\",\"*:*\", \"facet\",\"true\",\n              \"facet.field\", fromField \n                  , \"sort\", \"_docid_ asc\"\n                  ,\"rows\",\"0\"\n                );\n            log.error(\"faceting on from field: {}\", h.query(f));\n          }\n          {\n            final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n            final String q = ps.get(\"q\");\n            ps.put(\"q\", q.replaceAll(\"join score=none\", \"join\"));\n            log.error(\"plain join: {}\", h.query(req));\n            ps.put(\"q\", q);\n            \n          }\n          {\n          // re-execute the request... good for putting a breakpoint here for debugging\n          final Map<String,String> ps = ((MapSolrParams)req.getParams()).getMap();\n          final String q = ps.get(\"q\");\n          ps.put(\"q\", q.replaceAll(\"\\\\}\", \" cache=false\\\\}\"));\n          h.query(req);\n          }\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"246314af59d76a47fccc31e9494eefee01ec9c00":["3714bcf66a68a1600e9dd11442fc1b33b62ef088","00a778ad8ad6c2c04607538d2f36fee001239eef"],"640ded7811e1b7d29236a5e2934ec3cd266a8199":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"6eecfe8d494cb2e3ead94e9cdb9381bfe4993dcd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3714bcf66a68a1600e9dd11442fc1b33b62ef088":["6eecfe8d494cb2e3ead94e9cdb9381bfe4993dcd"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["00a778ad8ad6c2c04607538d2f36fee001239eef"],"00a778ad8ad6c2c04607538d2f36fee001239eef":["3714bcf66a68a1600e9dd11442fc1b33b62ef088"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["640ded7811e1b7d29236a5e2934ec3cd266a8199"]},"commit2Childs":{"246314af59d76a47fccc31e9494eefee01ec9c00":[],"640ded7811e1b7d29236a5e2934ec3cd266a8199":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6eecfe8d494cb2e3ead94e9cdb9381bfe4993dcd":["3714bcf66a68a1600e9dd11442fc1b33b62ef088"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6eecfe8d494cb2e3ead94e9cdb9381bfe4993dcd"],"3714bcf66a68a1600e9dd11442fc1b33b62ef088":["246314af59d76a47fccc31e9494eefee01ec9c00","00a778ad8ad6c2c04607538d2f36fee001239eef"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["640ded7811e1b7d29236a5e2934ec3cd266a8199"],"00a778ad8ad6c2c04607538d2f36fee001239eef":["246314af59d76a47fccc31e9494eefee01ec9c00","a966532d92cf9ba2856f15a8140151bb6b518e4b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["246314af59d76a47fccc31e9494eefee01ec9c00","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}