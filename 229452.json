{"path":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","commits":[{"id":"232d48b2fd10ac5189a0ac4480ace7421be9de93","date":1334848212,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<String,String>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init((IndexSchema)null, args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init((IndexSchema)null, args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n      fail(\"Should fail JSON parsing: '\" + valid[0]);\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid, 1.0f);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["90092e3ad74adf68ec9507e7046fe5a39039964c","6c7ac188e4a03a976c95993dc3cd292df966faa4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6c7ac188e4a03a976c95993dc3cd292df966faa4","date":1365151572,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","sourceNew":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<String,String>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n      fail(\"Should fail JSON parsing: '\" + valid[0]);\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid, 1.0f);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<String,String>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init((IndexSchema)null, args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init((IndexSchema)null, args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n      fail(\"Should fail JSON parsing: '\" + valid[0]);\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid, 1.0f);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","bugFix":["232d48b2fd10ac5189a0ac4480ace7421be9de93"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"08970e5b8411182a29412c177eff67ec1110095b","date":1366640815,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","sourceNew":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<String,String>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n      fail(\"Should fail JSON parsing: '\" + valid[0]);\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid, 1.0f);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<String,String>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n      fail(\"Should fail JSON parsing: '\" + valid[0]);\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid, 1.0f);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","sourceNew":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n      fail(\"Should fail JSON parsing: '\" + valid[0]);\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid, 1.0f);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<String,String>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n      fail(\"Should fail JSON parsing: '\" + valid[0]);\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid, 1.0f);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"90092e3ad74adf68ec9507e7046fe5a39039964c","date":1453355496,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","sourceNew":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n      fail(\"Should fail JSON parsing: '\" + valid[0] + \"'\");\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid, 1.0f);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n      fail(\"Should fail JSON parsing: '\" + valid[0]);\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid, 1.0f);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","bugFix":["232d48b2fd10ac5189a0ac4480ace7421be9de93"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"acd9883560fd89e6448b2b447302fe543040cd4f","date":1488478696,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","sourceNew":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0]);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0]);\n      fail(\"Should fail JSON parsing: '\" + valid[0] + \"'\");\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0], 1.0f);\n      fail(\"Should fail JSON parsing: '\" + valid[0] + \"'\");\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid, 1.0f);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d1a307447328c95a00248512b40d7a5ff12ecd6a","date":1564817449,"type":3,"author":"Munendra S N","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","sourceNew":"  @Test\n  public void testParsers() throws Exception {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    {\n      Field f = (Field)paf.fromString(field, valid[0]);\n    }\n\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    expectThrows(Exception.class, () -> paf.fromString(field, valid[0]));\n\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n\n    {\n      Field f = (Field)paf.fromString(field, jsonValid);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0]);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0]);\n      fail(\"Should fail JSON parsing: '\" + valid[0] + \"'\");\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8061ddd97f3352007d927dae445884a6f3d857b","date":1564988276,"type":3,"author":"Atri Sharma","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","sourceNew":"  @Test\n  public void testParsers() throws Exception {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    {\n      Field f = (Field)paf.fromString(field, valid[0]);\n    }\n\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    expectThrows(Exception.class, () -> paf.fromString(field, valid[0]));\n\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n\n    {\n      Field f = (Field)paf.fromString(field, jsonValid);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0]);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0]);\n      fail(\"Should fail JSON parsing: '\" + valid[0] + \"'\");\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d8daa7a1d5d0c033d73962d5ca3bf3f9c9687693","date":1565097295,"type":3,"author":"Jan HÃ¸ydahl","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldTest#testParsers().mjava","sourceNew":"  @Test\n  public void testParsers() throws Exception {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    {\n      Field f = (Field)paf.fromString(field, valid[0]);\n    }\n\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    expectThrows(Exception.class, () -> paf.fromString(field, valid[0]));\n\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n\n    {\n      Field f = (Field)paf.fromString(field, jsonValid);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParsers() {\n    PreAnalyzedField paf = new PreAnalyzedField();\n    // use Simple format\n    HashMap<String,String> args = new HashMap<>();\n    args.put(PreAnalyzedField.PARSER_IMPL, SimplePreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0]);\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + valid[0] + \"', exception: \" + e);\n    }\n    // use JSON format\n    args.put(PreAnalyzedField.PARSER_IMPL, JsonPreAnalyzedParser.class.getName());\n    paf.init(h.getCore().getLatestSchema(), args);\n    try {\n      Field f = (Field)paf.fromString(field, valid[0]);\n      fail(\"Should fail JSON parsing: '\" + valid[0] + \"'\");\n    } catch (Exception e) {\n    }\n    byte[] deadbeef = new byte[]{(byte)0xd, (byte)0xe, (byte)0xa, (byte)0xd, (byte)0xb, (byte)0xe, (byte)0xe, (byte)0xf};\n    PreAnalyzedParser parser = new JsonPreAnalyzedParser();\n    try {\n      Field f = (Field)paf.fromString(field, jsonValid);\n      assertEquals(jsonValid, parser.toFormattedString(f));\n    } catch (Exception e) {\n      fail(\"Should pass: '\" + jsonValid + \"', exception: \" + e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["08970e5b8411182a29412c177eff67ec1110095b"],"90092e3ad74adf68ec9507e7046fe5a39039964c":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d1a307447328c95a00248512b40d7a5ff12ecd6a":["acd9883560fd89e6448b2b447302fe543040cd4f"],"232d48b2fd10ac5189a0ac4480ace7421be9de93":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d8daa7a1d5d0c033d73962d5ca3bf3f9c9687693":["acd9883560fd89e6448b2b447302fe543040cd4f","d1a307447328c95a00248512b40d7a5ff12ecd6a"],"acd9883560fd89e6448b2b447302fe543040cd4f":["90092e3ad74adf68ec9507e7046fe5a39039964c"],"6c7ac188e4a03a976c95993dc3cd292df966faa4":["232d48b2fd10ac5189a0ac4480ace7421be9de93"],"f8061ddd97f3352007d927dae445884a6f3d857b":["acd9883560fd89e6448b2b447302fe543040cd4f","d1a307447328c95a00248512b40d7a5ff12ecd6a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d1a307447328c95a00248512b40d7a5ff12ecd6a"],"08970e5b8411182a29412c177eff67ec1110095b":["6c7ac188e4a03a976c95993dc3cd292df966faa4"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["90092e3ad74adf68ec9507e7046fe5a39039964c"],"90092e3ad74adf68ec9507e7046fe5a39039964c":["acd9883560fd89e6448b2b447302fe543040cd4f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["232d48b2fd10ac5189a0ac4480ace7421be9de93"],"d1a307447328c95a00248512b40d7a5ff12ecd6a":["d8daa7a1d5d0c033d73962d5ca3bf3f9c9687693","f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"232d48b2fd10ac5189a0ac4480ace7421be9de93":["6c7ac188e4a03a976c95993dc3cd292df966faa4"],"d8daa7a1d5d0c033d73962d5ca3bf3f9c9687693":[],"acd9883560fd89e6448b2b447302fe543040cd4f":["d1a307447328c95a00248512b40d7a5ff12ecd6a","d8daa7a1d5d0c033d73962d5ca3bf3f9c9687693","f8061ddd97f3352007d927dae445884a6f3d857b"],"6c7ac188e4a03a976c95993dc3cd292df966faa4":["08970e5b8411182a29412c177eff67ec1110095b"],"f8061ddd97f3352007d927dae445884a6f3d857b":[],"08970e5b8411182a29412c177eff67ec1110095b":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d8daa7a1d5d0c033d73962d5ca3bf3f9c9687693","f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}