{"path":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","commits":[{"id":"0935c850ea562932997b72c69d93e345f21d7f45","date":1344711506,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,FieldInfos).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    final FieldsEnum fieldsEnum = vectors.iterator();\n    String fieldName;\n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    while((fieldName = fieldsEnum.next()) != null) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = fieldsEnum.terms();\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.hasPayload() ? \n                docsAndPositionsEnum.getPayload() : null;\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, FieldInfos fieldInfos) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    final FieldsEnum fieldsEnum = vectors.iterator();\n    String fieldName;\n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n\n    while((fieldName = fieldsEnum.next()) != null) {\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = fieldsEnum.terms();\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b4c7e630332c5e9e7d7a70f4ace4b3ffd3fc552","date":1344797146,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    final FieldsEnum fieldsEnum = vectors.iterator();\n    String fieldName;\n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    while((fieldName = fieldsEnum.next()) != null) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = fieldsEnum.terms();\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.getPayload();\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    final FieldsEnum fieldsEnum = vectors.iterator();\n    String fieldName;\n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    while((fieldName = fieldsEnum.next()) != null) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = fieldsEnum.terms();\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.hasPayload() ? \n                docsAndPositionsEnum.getPayload() : null;\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb07ab105350b80ed9d63ca64b117084ed7391bc","date":1344824719,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.getPayload();\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    final FieldsEnum fieldsEnum = vectors.iterator();\n    String fieldName;\n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    while((fieldName = fieldsEnum.next()) != null) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = fieldsEnum.terms();\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.getPayload();\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":1,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,FieldInfos).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.getPayload();\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, FieldInfos fieldInfos) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    final FieldsEnum fieldsEnum = vectors.iterator();\n    String fieldName;\n    String lastFieldName = null;\n\n    while((fieldName = fieldsEnum.next()) != null) {\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = fieldsEnum.terms();\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      DocsAndPositionsEnum docsAndPositionsEnum = null;\n\n      boolean startedField = false;\n\n      // NOTE: this is tricky, because TermVectors allow\n      // indexing offsets but NOT positions.  So we must\n      // lazily init the field by checking whether first\n      // position we see is -1 or not.\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n\n        if (startedField) {\n          startTerm(termsEnum.term(), freq);\n        }\n\n        // TODO: we need a \"query\" API where we can ask (via\n        // flex API) what this term was indexed with...\n        // Both positions & offsets:\n        docsAndPositionsEnum = termsEnum.docsAndPositions(null, null);\n        boolean hasOffsets = false;\n        boolean hasPositions = false;\n\n        if (docsAndPositionsEnum != null) {\n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            if (!startedField) {\n              assert numTerms > 0;\n              hasPositions = pos != -1;\n              hasOffsets = startOffset != -1;\n              startField(fieldInfo, numTerms, hasPositions, hasOffsets);\n              startTerm(termsEnum.term(), freq);\n              startedField = true;\n            }\n            if (hasOffsets) {\n              assert startOffset != -1;\n              assert endOffset != -1;\n            }\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset);\n          }\n        } else {\n          if (!startedField) {\n            assert numTerms > 0;\n            startField(fieldInfo, numTerms, hasPositions, hasOffsets);\n            startTerm(termsEnum.term(), freq);\n            startedField = true;\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","date":1344867506,"type":1,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,FieldInfos).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.getPayload();\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, FieldInfos fieldInfos) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    final FieldsEnum fieldsEnum = vectors.iterator();\n    String fieldName;\n    String lastFieldName = null;\n\n    while((fieldName = fieldsEnum.next()) != null) {\n      final FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = fieldsEnum.terms();\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      final TermsEnum termsEnum = terms.iterator(null);\n\n      DocsAndPositionsEnum docsAndPositionsEnum = null;\n\n      boolean startedField = false;\n\n      // NOTE: this is tricky, because TermVectors allow\n      // indexing offsets but NOT positions.  So we must\n      // lazily init the field by checking whether first\n      // position we see is -1 or not.\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n\n        if (startedField) {\n          startTerm(termsEnum.term(), freq);\n        }\n\n        // TODO: we need a \"query\" API where we can ask (via\n        // flex API) what this term was indexed with...\n        // Both positions & offsets:\n        docsAndPositionsEnum = termsEnum.docsAndPositions(null, null);\n        boolean hasOffsets = false;\n        boolean hasPositions = false;\n\n        if (docsAndPositionsEnum != null) {\n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            if (!startedField) {\n              assert numTerms > 0;\n              hasPositions = pos != -1;\n              hasOffsets = startOffset != -1;\n              startField(fieldInfo, numTerms, hasPositions, hasOffsets);\n              startTerm(termsEnum.term(), freq);\n              startedField = true;\n            }\n            if (hasOffsets) {\n              assert startOffset != -1;\n              assert endOffset != -1;\n            }\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset);\n          }\n        } else {\n          if (!startedField) {\n            assert numTerms > 0;\n            startField(fieldInfo, numTerms, hasPositions, hasOffsets);\n            startTerm(termsEnum.term(), freq);\n            startedField = true;\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc124b3b129ef11a255212f3af482b771c5b3a6c","date":1344947616,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.getPayload();\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.getPayload();\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.getPayload();\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.getPayload();\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    final ReaderPayloadProcessor readerPayloadProcessor = mergeState.currentReaderPayloadProcessor;\n    PayloadProcessor payloadProcessor = null;\n\n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n        \n        if (hasPayloads && readerPayloadProcessor != null) {\n          payloadProcessor = readerPayloadProcessor.getProcessor(fieldName, termsEnum.term());\n        }\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            BytesRef payload = docsAndPositionsEnum.getPayload();\n                \n            if (payloadProcessor != null && payload != null) {\n              // to not violate the D&P api, we must give the processor a private copy\n              payload = BytesRef.deepCopyOf(payload);\n              payloadProcessor.processPayload(payload);\n              if (payload.length == 0) {\n                // don't let PayloadProcessors corrumpt the index\n                payload = null;\n              }\n            }\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d56999cfc1772fd594a2a43a40007a11a188bd96","date":1345554776,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n    assert fieldCount == numFields;\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"001b25b42373b22a52f399dbf072f1224632e8e6","date":1345889167,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n    assert fieldCount == numFields;\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document.  This default\n   *  implementation requires that the vectors implement\n   *  both Fields.size and\n   *  Terms.size. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    final int numFields = vectors.size();\n    if (numFields == -1) {\n      throw new IllegalStateException(\"vectors.size() must be implemented (it returned -1)\");\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    for(String fieldName : vectors) {\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      final int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        throw new IllegalStateException(\"terms.size() must be implemented (it returned -1)\");\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc7a7bb1aa79cf53564793bb5ffa270250c679da","date":1357817084,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n    assert fieldCount == numFields;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e6354dd7c71fe122926fc53d7d29f715b1283db","date":1357915185,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n      }\n      assert termCount == numTerms;\n    }\n    assert fieldCount == numFields;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2131047ecceac64b54ba70feec3d26bbd7e483d7","date":1411862069,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.mergeFieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.mergeFieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.fieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    PostingsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.mergeFieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.FLAG_OFFSETS | PostingsEnum.FLAG_PAYLOADS);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0 ;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    DocsAndPositionsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.mergeFieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.docsAndPositions(null, docsAndPositionsEnum);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    PostingsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.mergeFieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0 ;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    PostingsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.mergeFieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.FLAG_OFFSETS | PostingsEnum.FLAG_PAYLOADS);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0 ;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    PostingsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.mergeFieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator();\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator();\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0 ;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    PostingsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.mergeFieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator(termsEnum);\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator(termsEnum);\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0 ;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermVectorsWriter#addAllDocVectors(Fields,MergeState).mjava","sourceNew":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    PostingsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.mergeFieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator();\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator();\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.postings(docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0 ;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","sourceOld":"  /** Safe (but, slowish) default method to write every\n   *  vector field in the document. */\n  protected final void addAllDocVectors(Fields vectors, MergeState mergeState) throws IOException {\n    if (vectors == null) {\n      startDocument(0);\n      finishDocument();\n      return;\n    }\n\n    int numFields = vectors.size();\n    if (numFields == -1) {\n      // count manually! TODO: Maybe enforce that Fields.size() returns something valid?\n      numFields = 0;\n      for (final Iterator<String> it = vectors.iterator(); it.hasNext(); ) {\n        it.next();\n        numFields++;\n      }\n    }\n    startDocument(numFields);\n    \n    String lastFieldName = null;\n    \n    TermsEnum termsEnum = null;\n    PostingsEnum docsAndPositionsEnum = null;\n    \n    int fieldCount = 0;\n    for(String fieldName : vectors) {\n      fieldCount++;\n      final FieldInfo fieldInfo = mergeState.mergeFieldInfos.fieldInfo(fieldName);\n\n      assert lastFieldName == null || fieldName.compareTo(lastFieldName) > 0: \"lastFieldName=\" + lastFieldName + \" fieldName=\" + fieldName;\n      lastFieldName = fieldName;\n\n      final Terms terms = vectors.terms(fieldName);\n      if (terms == null) {\n        // FieldsEnum shouldn't lie...\n        continue;\n      }\n      \n      final boolean hasPositions = terms.hasPositions();\n      final boolean hasOffsets = terms.hasOffsets();\n      final boolean hasPayloads = terms.hasPayloads();\n      assert !hasPayloads || hasPositions;\n      \n      int numTerms = (int) terms.size();\n      if (numTerms == -1) {\n        // count manually. It is stupid, but needed, as Terms.size() is not a mandatory statistics function\n        numTerms = 0;\n        termsEnum = terms.iterator();\n        while(termsEnum.next() != null) {\n          numTerms++;\n        }\n      }\n      \n      startField(fieldInfo, numTerms, hasPositions, hasOffsets, hasPayloads);\n      termsEnum = terms.iterator();\n\n      int termCount = 0;\n      while(termsEnum.next() != null) {\n        termCount++;\n\n        final int freq = (int) termsEnum.totalTermFreq();\n        \n        startTerm(termsEnum.term(), freq);\n\n        if (hasPositions || hasOffsets) {\n          docsAndPositionsEnum = termsEnum.postings(null, docsAndPositionsEnum, PostingsEnum.OFFSETS | PostingsEnum.PAYLOADS);\n          assert docsAndPositionsEnum != null;\n          \n          final int docID = docsAndPositionsEnum.nextDoc();\n          assert docID != DocIdSetIterator.NO_MORE_DOCS;\n          assert docsAndPositionsEnum.freq() == freq;\n\n          for(int posUpto=0; posUpto<freq; posUpto++) {\n            final int pos = docsAndPositionsEnum.nextPosition();\n            final int startOffset = docsAndPositionsEnum.startOffset();\n            final int endOffset = docsAndPositionsEnum.endOffset();\n            \n            final BytesRef payload = docsAndPositionsEnum.getPayload();\n\n            assert !hasPositions || pos >= 0 ;\n            addPosition(pos, startOffset, endOffset, payload);\n          }\n        }\n        finishTerm();\n      }\n      assert termCount == numTerms;\n      finishField();\n    }\n    assert fieldCount == numFields;\n    finishDocument();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"001b25b42373b22a52f399dbf072f1224632e8e6":["c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","d56999cfc1772fd594a2a43a40007a11a188bd96"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","bc124b3b129ef11a255212f3af482b771c5b3a6c"],"fb07ab105350b80ed9d63ca64b117084ed7391bc":["2b4c7e630332c5e9e7d7a70f4ace4b3ffd3fc552"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","bc124b3b129ef11a255212f3af482b771c5b3a6c"],"51f5280f31484820499077f41fcdfe92d527d9dc":["9bb9a29a5e71a90295f175df8919802993142c9a"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","fb07ab105350b80ed9d63ca64b117084ed7391bc"],"2b4c7e630332c5e9e7d7a70f4ace4b3ffd3fc552":["0935c850ea562932997b72c69d93e345f21d7f45"],"9bb9a29a5e71a90295f175df8919802993142c9a":["fc7a7bb1aa79cf53564793bb5ffa270250c679da","2131047ecceac64b54ba70feec3d26bbd7e483d7"],"fc7a7bb1aa79cf53564793bb5ffa270250c679da":["d56999cfc1772fd594a2a43a40007a11a188bd96"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2131047ecceac64b54ba70feec3d26bbd7e483d7":["fc7a7bb1aa79cf53564793bb5ffa270250c679da"],"bc124b3b129ef11a255212f3af482b771c5b3a6c":["fb07ab105350b80ed9d63ca64b117084ed7391bc"],"0935c850ea562932997b72c69d93e345f21d7f45":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d56999cfc1772fd594a2a43a40007a11a188bd96":["bc124b3b129ef11a255212f3af482b771c5b3a6c"],"4e6354dd7c71fe122926fc53d7d29f715b1283db":["d56999cfc1772fd594a2a43a40007a11a188bd96","fc7a7bb1aa79cf53564793bb5ffa270250c679da"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","fb07ab105350b80ed9d63ca64b117084ed7391bc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0f4464508ee83288c8c4585b533f9faaa93aa314"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"001b25b42373b22a52f399dbf072f1224632e8e6":[],"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"fb07ab105350b80ed9d63ca64b117084ed7391bc":["c7869f64c874ebf7f317d22c00baf2b6857797a6","bc124b3b129ef11a255212f3af482b771c5b3a6c","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["001b25b42373b22a52f399dbf072f1224632e8e6"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"2b4c7e630332c5e9e7d7a70f4ace4b3ffd3fc552":["fb07ab105350b80ed9d63ca64b117084ed7391bc"],"9bb9a29a5e71a90295f175df8919802993142c9a":["51f5280f31484820499077f41fcdfe92d527d9dc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c7869f64c874ebf7f317d22c00baf2b6857797a6","0935c850ea562932997b72c69d93e345f21d7f45","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"fc7a7bb1aa79cf53564793bb5ffa270250c679da":["9bb9a29a5e71a90295f175df8919802993142c9a","2131047ecceac64b54ba70feec3d26bbd7e483d7","4e6354dd7c71fe122926fc53d7d29f715b1283db"],"2131047ecceac64b54ba70feec3d26bbd7e483d7":["9bb9a29a5e71a90295f175df8919802993142c9a"],"bc124b3b129ef11a255212f3af482b771c5b3a6c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","d56999cfc1772fd594a2a43a40007a11a188bd96"],"0935c850ea562932997b72c69d93e345f21d7f45":["2b4c7e630332c5e9e7d7a70f4ace4b3ffd3fc552"],"d56999cfc1772fd594a2a43a40007a11a188bd96":["001b25b42373b22a52f399dbf072f1224632e8e6","fc7a7bb1aa79cf53564793bb5ffa270250c679da","4e6354dd7c71fe122926fc53d7d29f715b1283db"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"4e6354dd7c71fe122926fc53d7d29f715b1283db":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["001b25b42373b22a52f399dbf072f1224632e8e6","b05c56a41b733e02a189c48895922b5bd8c7f3d1","4e6354dd7c71fe122926fc53d7d29f715b1283db","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}