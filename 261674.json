{"path":"modules/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","commits":[{"id":"ecc11368dc265bfdad90214f8bf5da99016ab1e2","date":1294144090,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":1,"author":"Michael Busch","isMerge":true,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7ee868f5038843b2550e6e996be578b90d65378","date":1309428052,"type":4,"author":"Doron Cohen","isMerge":false,"pathNew":"/dev/null","pathOld":"modules/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":null,"sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":4,"author":"Steven Rowe","isMerge":true,"pathNew":"/dev/null","pathOld":"modules/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":null,"sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"modules/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":null,"sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e7ee868f5038843b2550e6e996be578b90d65378":["ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["ecc11368dc265bfdad90214f8bf5da99016ab1e2","e7ee868f5038843b2550e6e996be578b90d65378"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["ecc11368dc265bfdad90214f8bf5da99016ab1e2","e7ee868f5038843b2550e6e996be578b90d65378"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e7ee868f5038843b2550e6e996be578b90d65378"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":[],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["70ad682703b8585f5d0a637efec044d57ec05efb","e7ee868f5038843b2550e6e996be578b90d65378","d083e83f225b11e5fdd900e83d26ddb385b6955c","868da859b43505d9d2a023bfeae6dd0c795f5295","817d8435e9135b756f08ce6710ab0baac51bdf88"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["70ad682703b8585f5d0a637efec044d57ec05efb","ecc11368dc265bfdad90214f8bf5da99016ab1e2","868da859b43505d9d2a023bfeae6dd0c795f5295"],"e7ee868f5038843b2550e6e996be578b90d65378":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["70ad682703b8585f5d0a637efec044d57ec05efb","d083e83f225b11e5fdd900e83d26ddb385b6955c","868da859b43505d9d2a023bfeae6dd0c795f5295","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}