{"path":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(LeafReaderContext,Bits).mjava","commits":[{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":0,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(LeafReaderContext,Bits).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(LeafReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = DocValues.getSortedSet(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new DocValuesDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2713584a660051cd646423be682771e3bbd99985","date":1425046322,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(LeafReaderContext,Bits).mjava","sourceNew":null,"sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(LeafReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = DocValues.getSortedSet(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new DocValuesDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":4,"author":"Ryan Ernst","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(LeafReaderContext,Bits).mjava","sourceNew":null,"sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(LeafReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = DocValues.getSortedSet(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new DocValuesDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["c9fb5f46e264daf5ba3860defe623a89d202dd87","2713584a660051cd646423be682771e3bbd99985"],"2713584a660051cd646423be682771e3bbd99985":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2713584a660051cd646423be682771e3bbd99985"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"2713584a660051cd646423be682771e3bbd99985":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","2713584a660051cd646423be682771e3bbd99985"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}