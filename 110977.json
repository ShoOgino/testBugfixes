{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexReader#testGetFieldNames().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexReader#testGetFieldNames().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testGetFieldNames().mjava","sourceNew":"    /**\n     * Tests the IndexReader.getFieldNames implementation\n     * @throws Exception on error\n     */\n    public void testGetFieldNames() throws Exception {\n        Directory d = newDirectory();\n        // set up writer\n        IndexWriter writer = new IndexWriter(\n            d,\n            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        );\n\n        Document doc = new Document();\n\n        FieldType customType3 = new FieldType();\n        customType3.setStored(true);\n        \n        doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\"));\n        writer.addDocument(doc);\n\n        writer.close();\n        // set up reader\n        DirectoryReader reader = DirectoryReader.open(d);\n        FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n        assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n        assertNotNull(fieldInfos.fieldInfo(\"text\"));\n        assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n        assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n        reader.close();\n        // add more documents\n        writer = new IndexWriter(\n            d,\n            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                setOpenMode(OpenMode.APPEND).\n                setMergePolicy(newLogMergePolicy())\n        );\n        // want to get some more segments here\n        int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n        for (int i = 0; i < 5*mergeFactor; i++) {\n          doc = new Document();\n          doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n          doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n          doc.add(new Field(\"unindexed\", \"test1\", customType3));\n          doc.add(new TextField(\"unstored\",\"test1\"));\n          writer.addDocument(doc);\n        }\n        // new fields are in some different segments (we hope)\n        for (int i = 0; i < 5*mergeFactor; i++) {\n          doc = new Document();\n          doc.add(new Field(\"keyword2\", \"test1\", StringField.TYPE_STORED));\n          doc.add(new Field(\"text2\", \"test1\", TextField.TYPE_STORED));\n          doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n          doc.add(new TextField(\"unstored2\",\"test1\"));\n          writer.addDocument(doc);\n        }\n        // new termvector fields\n\n        FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n        customType5.setStoreTermVectors(true);\n        FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n        customType6.setStoreTermVectors(true);\n        customType6.setStoreTermVectorOffsets(true);\n        FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n        customType7.setStoreTermVectors(true);\n        customType7.setStoreTermVectorPositions(true);\n        FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n        customType8.setStoreTermVectors(true);\n        customType8.setStoreTermVectorOffsets(true);\n        customType8.setStoreTermVectorPositions(true);\n        \n        for (int i = 0; i < 5*mergeFactor; i++) {\n          doc = new Document();\n          doc.add(new Field(\"tvnot\", \"tvnot\", TextField.TYPE_STORED));\n          doc.add(new Field(\"termvector\", \"termvector\", customType5));\n          doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n          doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n          doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n          writer.addDocument(doc);\n        }\n        \n        writer.close();\n\n        // verify fields again\n        reader = DirectoryReader.open(d);\n        fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n        Collection<String> allFieldNames = new HashSet<String>();\n        Collection<String> indexedFieldNames = new HashSet<String>();\n        Collection<String> notIndexedFieldNames = new HashSet<String>();\n        Collection<String> tvFieldNames = new HashSet<String>();\n\n        for(FieldInfo fieldInfo : fieldInfos) {\n          final String name = fieldInfo.name;\n          allFieldNames.add(name);\n          if (fieldInfo.isIndexed) {\n            indexedFieldNames.add(name);\n          } else {\n            notIndexedFieldNames.add(name);\n          }\n          if (fieldInfo.storeTermVector) {\n            tvFieldNames.add(name);\n          }\n        }\n\n        assertTrue(allFieldNames.contains(\"keyword\"));\n        assertTrue(allFieldNames.contains(\"text\"));\n        assertTrue(allFieldNames.contains(\"unindexed\"));\n        assertTrue(allFieldNames.contains(\"unstored\"));\n        assertTrue(allFieldNames.contains(\"keyword2\"));\n        assertTrue(allFieldNames.contains(\"text2\"));\n        assertTrue(allFieldNames.contains(\"unindexed2\"));\n        assertTrue(allFieldNames.contains(\"unstored2\"));\n        assertTrue(allFieldNames.contains(\"tvnot\"));\n        assertTrue(allFieldNames.contains(\"termvector\"));\n        assertTrue(allFieldNames.contains(\"tvposition\"));\n        assertTrue(allFieldNames.contains(\"tvoffset\"));\n        assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n        \n        // verify that only indexed fields were returned\n        assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n        assertTrue(indexedFieldNames.contains(\"keyword\"));\n        assertTrue(indexedFieldNames.contains(\"text\"));\n        assertTrue(indexedFieldNames.contains(\"unstored\"));\n        assertTrue(indexedFieldNames.contains(\"keyword2\"));\n        assertTrue(indexedFieldNames.contains(\"text2\"));\n        assertTrue(indexedFieldNames.contains(\"unstored2\"));\n        assertTrue(indexedFieldNames.contains(\"tvnot\"));\n        assertTrue(indexedFieldNames.contains(\"termvector\"));\n        assertTrue(indexedFieldNames.contains(\"tvposition\"));\n        assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n        assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n        \n        // verify that only unindexed fields were returned\n        assertEquals(2, notIndexedFieldNames.size());    // the following fields\n        assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n        assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n                \n        // verify index term vector fields  \n        assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n        assertTrue(tvFieldNames.contains(\"termvector\"));\n\n        reader.close();\n        d.close();\n    }\n\n","sourceOld":"    /**\n     * Tests the IndexReader.getFieldNames implementation\n     * @throws Exception on error\n     */\n    public void testGetFieldNames() throws Exception {\n        Directory d = newDirectory();\n        // set up writer\n        IndexWriter writer = new IndexWriter(\n            d,\n            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        );\n\n        Document doc = new Document();\n\n        FieldType customType3 = new FieldType();\n        customType3.setStored(true);\n        \n        doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\"));\n        writer.addDocument(doc);\n\n        writer.close();\n        // set up reader\n        DirectoryReader reader = DirectoryReader.open(d);\n        FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n        assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n        assertNotNull(fieldInfos.fieldInfo(\"text\"));\n        assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n        assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n        reader.close();\n        // add more documents\n        writer = new IndexWriter(\n            d,\n            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                setOpenMode(OpenMode.APPEND).\n                setMergePolicy(newLogMergePolicy())\n        );\n        // want to get some more segments here\n        int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n        for (int i = 0; i < 5*mergeFactor; i++) {\n          doc = new Document();\n          doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n          doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n          doc.add(new Field(\"unindexed\", \"test1\", customType3));\n          doc.add(new TextField(\"unstored\",\"test1\"));\n          writer.addDocument(doc);\n        }\n        // new fields are in some different segments (we hope)\n        for (int i = 0; i < 5*mergeFactor; i++) {\n          doc = new Document();\n          doc.add(new Field(\"keyword2\", \"test1\", StringField.TYPE_STORED));\n          doc.add(new Field(\"text2\", \"test1\", TextField.TYPE_STORED));\n          doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n          doc.add(new TextField(\"unstored2\",\"test1\"));\n          writer.addDocument(doc);\n        }\n        // new termvector fields\n\n        FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n        customType5.setStoreTermVectors(true);\n        FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n        customType6.setStoreTermVectors(true);\n        customType6.setStoreTermVectorOffsets(true);\n        FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n        customType7.setStoreTermVectors(true);\n        customType7.setStoreTermVectorPositions(true);\n        FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n        customType8.setStoreTermVectors(true);\n        customType8.setStoreTermVectorOffsets(true);\n        customType8.setStoreTermVectorPositions(true);\n        \n        for (int i = 0; i < 5*mergeFactor; i++) {\n          doc = new Document();\n          doc.add(new Field(\"tvnot\", \"tvnot\", TextField.TYPE_STORED));\n          doc.add(new Field(\"termvector\", \"termvector\", customType5));\n          doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n          doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n          doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n          writer.addDocument(doc);\n        }\n        \n        writer.close();\n\n        // verify fields again\n        reader = DirectoryReader.open(d);\n        fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n        Collection<String> allFieldNames = new HashSet<String>();\n        Collection<String> indexedFieldNames = new HashSet<String>();\n        Collection<String> notIndexedFieldNames = new HashSet<String>();\n        Collection<String> tvFieldNames = new HashSet<String>();\n\n        for(FieldInfo fieldInfo : fieldInfos) {\n          final String name = fieldInfo.name;\n          allFieldNames.add(name);\n          if (fieldInfo.isIndexed) {\n            indexedFieldNames.add(name);\n          } else {\n            notIndexedFieldNames.add(name);\n          }\n          if (fieldInfo.storeTermVector) {\n            tvFieldNames.add(name);\n          }\n        }\n\n        assertTrue(allFieldNames.contains(\"keyword\"));\n        assertTrue(allFieldNames.contains(\"text\"));\n        assertTrue(allFieldNames.contains(\"unindexed\"));\n        assertTrue(allFieldNames.contains(\"unstored\"));\n        assertTrue(allFieldNames.contains(\"keyword2\"));\n        assertTrue(allFieldNames.contains(\"text2\"));\n        assertTrue(allFieldNames.contains(\"unindexed2\"));\n        assertTrue(allFieldNames.contains(\"unstored2\"));\n        assertTrue(allFieldNames.contains(\"tvnot\"));\n        assertTrue(allFieldNames.contains(\"termvector\"));\n        assertTrue(allFieldNames.contains(\"tvposition\"));\n        assertTrue(allFieldNames.contains(\"tvoffset\"));\n        assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n        \n        // verify that only indexed fields were returned\n        assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n        assertTrue(indexedFieldNames.contains(\"keyword\"));\n        assertTrue(indexedFieldNames.contains(\"text\"));\n        assertTrue(indexedFieldNames.contains(\"unstored\"));\n        assertTrue(indexedFieldNames.contains(\"keyword2\"));\n        assertTrue(indexedFieldNames.contains(\"text2\"));\n        assertTrue(indexedFieldNames.contains(\"unstored2\"));\n        assertTrue(indexedFieldNames.contains(\"tvnot\"));\n        assertTrue(indexedFieldNames.contains(\"termvector\"));\n        assertTrue(indexedFieldNames.contains(\"tvposition\"));\n        assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n        assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n        \n        // verify that only unindexed fields were returned\n        assertEquals(2, notIndexedFieldNames.size());    // the following fields\n        assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n        assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n                \n        // verify index term vector fields  \n        assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n        assertTrue(tvFieldNames.contains(\"termvector\"));\n\n        reader.close();\n        d.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87","date":1328967626,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexReader#testGetFieldNames().mjava","sourceNew":null,"sourceOld":"    /**\n     * Tests the IndexReader.getFieldNames implementation\n     * @throws Exception on error\n     */\n    public void testGetFieldNames() throws Exception {\n        Directory d = newDirectory();\n        // set up writer\n        IndexWriter writer = new IndexWriter(\n            d,\n            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        );\n\n        Document doc = new Document();\n\n        FieldType customType3 = new FieldType();\n        customType3.setStored(true);\n        \n        doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n        doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n        doc.add(new Field(\"unindexed\", \"test1\", customType3));\n        doc.add(new TextField(\"unstored\",\"test1\"));\n        writer.addDocument(doc);\n\n        writer.close();\n        // set up reader\n        DirectoryReader reader = DirectoryReader.open(d);\n        FieldInfos fieldInfos = MultiFields.getMergedFieldInfos(reader);\n        assertNotNull(fieldInfos.fieldInfo(\"keyword\"));\n        assertNotNull(fieldInfos.fieldInfo(\"text\"));\n        assertNotNull(fieldInfos.fieldInfo(\"unindexed\"));\n        assertNotNull(fieldInfos.fieldInfo(\"unstored\"));\n        reader.close();\n        // add more documents\n        writer = new IndexWriter(\n            d,\n            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n                setOpenMode(OpenMode.APPEND).\n                setMergePolicy(newLogMergePolicy())\n        );\n        // want to get some more segments here\n        int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n        for (int i = 0; i < 5*mergeFactor; i++) {\n          doc = new Document();\n          doc.add(new Field(\"keyword\", \"test1\", StringField.TYPE_STORED));\n          doc.add(new Field(\"text\", \"test1\", TextField.TYPE_STORED));\n          doc.add(new Field(\"unindexed\", \"test1\", customType3));\n          doc.add(new TextField(\"unstored\",\"test1\"));\n          writer.addDocument(doc);\n        }\n        // new fields are in some different segments (we hope)\n        for (int i = 0; i < 5*mergeFactor; i++) {\n          doc = new Document();\n          doc.add(new Field(\"keyword2\", \"test1\", StringField.TYPE_STORED));\n          doc.add(new Field(\"text2\", \"test1\", TextField.TYPE_STORED));\n          doc.add(new Field(\"unindexed2\", \"test1\", customType3));\n          doc.add(new TextField(\"unstored2\",\"test1\"));\n          writer.addDocument(doc);\n        }\n        // new termvector fields\n\n        FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n        customType5.setStoreTermVectors(true);\n        FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n        customType6.setStoreTermVectors(true);\n        customType6.setStoreTermVectorOffsets(true);\n        FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n        customType7.setStoreTermVectors(true);\n        customType7.setStoreTermVectorPositions(true);\n        FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n        customType8.setStoreTermVectors(true);\n        customType8.setStoreTermVectorOffsets(true);\n        customType8.setStoreTermVectorPositions(true);\n        \n        for (int i = 0; i < 5*mergeFactor; i++) {\n          doc = new Document();\n          doc.add(new Field(\"tvnot\", \"tvnot\", TextField.TYPE_STORED));\n          doc.add(new Field(\"termvector\", \"termvector\", customType5));\n          doc.add(new Field(\"tvoffset\", \"tvoffset\", customType6));\n          doc.add(new Field(\"tvposition\", \"tvposition\", customType7));\n          doc.add(new Field(\"tvpositionoffset\", \"tvpositionoffset\", customType8));\n          writer.addDocument(doc);\n        }\n        \n        writer.close();\n\n        // verify fields again\n        reader = DirectoryReader.open(d);\n        fieldInfos = MultiFields.getMergedFieldInfos(reader);\n\n        Collection<String> allFieldNames = new HashSet<String>();\n        Collection<String> indexedFieldNames = new HashSet<String>();\n        Collection<String> notIndexedFieldNames = new HashSet<String>();\n        Collection<String> tvFieldNames = new HashSet<String>();\n\n        for(FieldInfo fieldInfo : fieldInfos) {\n          final String name = fieldInfo.name;\n          allFieldNames.add(name);\n          if (fieldInfo.isIndexed) {\n            indexedFieldNames.add(name);\n          } else {\n            notIndexedFieldNames.add(name);\n          }\n          if (fieldInfo.storeTermVector) {\n            tvFieldNames.add(name);\n          }\n        }\n\n        assertTrue(allFieldNames.contains(\"keyword\"));\n        assertTrue(allFieldNames.contains(\"text\"));\n        assertTrue(allFieldNames.contains(\"unindexed\"));\n        assertTrue(allFieldNames.contains(\"unstored\"));\n        assertTrue(allFieldNames.contains(\"keyword2\"));\n        assertTrue(allFieldNames.contains(\"text2\"));\n        assertTrue(allFieldNames.contains(\"unindexed2\"));\n        assertTrue(allFieldNames.contains(\"unstored2\"));\n        assertTrue(allFieldNames.contains(\"tvnot\"));\n        assertTrue(allFieldNames.contains(\"termvector\"));\n        assertTrue(allFieldNames.contains(\"tvposition\"));\n        assertTrue(allFieldNames.contains(\"tvoffset\"));\n        assertTrue(allFieldNames.contains(\"tvpositionoffset\"));\n        \n        // verify that only indexed fields were returned\n        assertEquals(11, indexedFieldNames.size());    // 6 original + the 5 termvector fields \n        assertTrue(indexedFieldNames.contains(\"keyword\"));\n        assertTrue(indexedFieldNames.contains(\"text\"));\n        assertTrue(indexedFieldNames.contains(\"unstored\"));\n        assertTrue(indexedFieldNames.contains(\"keyword2\"));\n        assertTrue(indexedFieldNames.contains(\"text2\"));\n        assertTrue(indexedFieldNames.contains(\"unstored2\"));\n        assertTrue(indexedFieldNames.contains(\"tvnot\"));\n        assertTrue(indexedFieldNames.contains(\"termvector\"));\n        assertTrue(indexedFieldNames.contains(\"tvposition\"));\n        assertTrue(indexedFieldNames.contains(\"tvoffset\"));\n        assertTrue(indexedFieldNames.contains(\"tvpositionoffset\"));\n        \n        // verify that only unindexed fields were returned\n        assertEquals(2, notIndexedFieldNames.size());    // the following fields\n        assertTrue(notIndexedFieldNames.contains(\"unindexed\"));\n        assertTrue(notIndexedFieldNames.contains(\"unindexed2\"));\n                \n        // verify index term vector fields  \n        assertEquals(tvFieldNames.toString(), 4, tvFieldNames.size());    // 4 field has term vector only\n        assertTrue(tvFieldNames.contains(\"termvector\"));\n\n        reader.close();\n        d.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"]},"commit2Childs":{"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}