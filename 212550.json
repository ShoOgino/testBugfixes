{"path":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","commits":[{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+100;\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+100;\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cca56866c19997e28ef073622656669c15210540","date":1307449014,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+100;\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+100;\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with 10 more bytes of free space:\n      diskFree += 10;\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, IOContext.DEFAULT));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6f9be74ca7baaef11857ad002cad40419979516","date":1309449808,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, IOContext.DEFAULT));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f3cee3d20b0c786e6fca20539454262e29edcab","date":1310101685,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f0b9507caf22f292ac0e5e59f62db4275adf4511","date":1310107283,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1291e4568eb7d9463d751627596ef14baf4c1603","date":1310112572,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        Similarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), Field.Store.YES, Field.Index.NOT_ANALYZED));\n      d.add(newField(\"content\", \"aaa \" + i, Field.Store.NO, Field.Index.ANALYZED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n      writer.setInfoStream(System.out);\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4122a26e1fd0457a340616673a3d3aada370f713","date":1322955654,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":null,"sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":4,"author":"Uwe Schindler","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":null,"sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexReaderOnDiskFull#testDiskFull().mjava","sourceNew":null,"sourceOld":"  /**\n   * Make sure if reader tries to commit but hits disk\n   * full that reader remains consistent and usable.\n   */\n  public void testDiskFull() throws IOException {\n\n    Term searchTerm = new Term(\"content\", \"aaa\");\n    int START_COUNT = 157;\n    int END_COUNT = 144;\n    \n    // First build up a starting index:\n    MockDirectoryWrapper startDir = newDirectory();\n    IndexWriter writer = new IndexWriter(startDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    if (VERBOSE) {\n      System.out.println(\"TEST: create initial index\");\n    }\n    for(int i=0;i<157;i++) {\n      Document d = new Document();\n      d.add(newField(\"id\", Integer.toString(i), StringField.TYPE_STORED));\n      d.add(newField(\"content\", \"aaa \" + i, TextField.TYPE_UNSTORED));\n      writer.addDocument(d);\n      if (0==i%10)\n        writer.commit();\n    }\n    writer.close();\n\n    {\n      IndexReader r = IndexReader.open(startDir);\n      IndexSearcher searcher = newSearcher(r);\n      ScoreDoc[] hits = null;\n      try {\n        hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n      } catch (IOException e) {\n        e.printStackTrace();\n        fail(\"exception when init searching: \" + e);\n      }\n      searcher.close();\n      r.close();\n    }\n\n    long diskUsage = startDir.getRecomputedActualSizeInBytes();\n    long diskFree = diskUsage+_TestUtil.nextInt(random, 50, 200);\n\n    IOException err = null;\n\n    boolean done = false;\n    boolean gotExc = false;\n\n    // Iterate w/ ever increasing free disk space:\n    while(!done) {\n      MockDirectoryWrapper dir = new MockDirectoryWrapper(random, new RAMDirectory(startDir, newIOContext(random)));\n\n      // If IndexReader hits disk full, it can write to\n      // the same files again.\n      dir.setPreventDoubleWrite(false);\n\n      IndexReader reader = IndexReader.open(dir, false);\n\n      // For each disk size, first try to commit against\n      // dir that will hit random IOExceptions & disk\n      // full; after, give it infinite disk space & turn\n      // off random IOExceptions & retry w/ same reader:\n      boolean success = false;\n\n      for(int x=0;x<2;x++) {\n\n        double rate = 0.05;\n        double diskRatio = ((double) diskFree)/diskUsage;\n        long thisDiskFree;\n        String testName;\n\n        if (0 == x) {\n          thisDiskFree = diskFree;\n          if (diskRatio >= 2.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 4.0) {\n            rate /= 2;\n          }\n          if (diskRatio >= 6.0) {\n            rate = 0.0;\n          }\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: \" + diskFree + \" bytes\");\n          }\n          testName = \"disk full during reader.close() @ \" + thisDiskFree + \" bytes\";\n        } else {\n          thisDiskFree = 0;\n          rate = 0.0;\n          if (VERBOSE) {\n            System.out.println(\"\\ncycle: same writer: unlimited disk space\");\n          }\n          testName = \"reader re-use after disk full\";\n        }\n\n        dir.setMaxSizeInBytes(thisDiskFree);\n        dir.setRandomIOExceptionRate(rate);\n        DefaultSimilarity sim = new DefaultSimilarity();\n        try {\n          if (0 == x) {\n            int docId = 12;\n            for(int i=0;i<13;i++) {\n              reader.deleteDocument(docId);\n              reader.setNorm(docId, \"content\", sim.encodeNormValue(2.0f));\n              docId += 12;\n            }\n          }\n          reader.close();\n          success = true;\n          if (0 == x) {\n            done = true;\n          }\n        } catch (IOException e) {\n          if (VERBOSE) {\n            System.out.println(\"  hit IOException: \" + e);\n            e.printStackTrace(System.out);\n          }\n          err = e;\n          gotExc = true;\n          if (1 == x) {\n            e.printStackTrace();\n            fail(testName + \" hit IOException after disk space was freed up\");\n          }\n        }\n\n        // Finally, verify index is not corrupt, and, if\n        // we succeeded, we see all docs changed, and if\n        // we failed, we see either all docs or no docs\n        // changed (transactional semantics):\n        IndexReader newReader = null;\n        try {\n          newReader = IndexReader.open(dir, false);\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \":exception when creating IndexReader after disk full during close: \" + e);\n        }\n        /*\n        int result = newReader.docFreq(searchTerm);\n        if (success) {\n          if (result != END_COUNT) {\n            fail(testName + \": method did not throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result != START_COUNT && result != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but docFreq('aaa') is \" + result + \" instead of expected \" + START_COUNT + \" or \" + END_COUNT);\n          }\n        }\n        */\n\n        IndexSearcher searcher = newSearcher(newReader);\n        ScoreDoc[] hits = null;\n        try {\n          hits = searcher.search(new TermQuery(searchTerm), null, 1000).scoreDocs;\n        } catch (IOException e) {\n          e.printStackTrace();\n          fail(testName + \": exception when searching: \" + e);\n        }\n        int result2 = hits.length;\n        if (success) {\n          if (result2 != END_COUNT) {\n            fail(testName + \": method did not throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + END_COUNT);\n          }\n        } else {\n          // On hitting exception we still may have added\n          // all docs:\n          if (result2 != START_COUNT && result2 != END_COUNT) {\n            err.printStackTrace();\n            fail(testName + \": method did throw exception but hits.length for search on term 'aaa' is \" + result2 + \" instead of expected \" + START_COUNT);\n          }\n        }\n\n        searcher.close();\n        newReader.close();\n\n        if (result2 == END_COUNT) {\n          if (!gotExc)\n            fail(\"never hit disk full\");\n          break;\n        }\n      }\n\n      dir.close();\n\n      // Try again with more bytes of free space:\n      diskFree += TEST_NIGHTLY ? _TestUtil.nextInt(random, 5, 20) : _TestUtil.nextInt(random, 50, 200);\n    }\n\n    startDir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["79c2cb24929f2649a8875fb629086171f914d5ce","cca56866c19997e28ef073622656669c15210540"],"0f3cee3d20b0c786e6fca20539454262e29edcab":["cca56866c19997e28ef073622656669c15210540"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["06584e6e98d592b34e1329b384182f368d2025e8","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"06584e6e98d592b34e1329b384182f368d2025e8":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["cca56866c19997e28ef073622656669c15210540"],"1291e4568eb7d9463d751627596ef14baf4c1603":["b6f9be74ca7baaef11857ad002cad40419979516","0f3cee3d20b0c786e6fca20539454262e29edcab"],"f0b9507caf22f292ac0e5e59f62db4275adf4511":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","0f3cee3d20b0c786e6fca20539454262e29edcab"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b6f9be74ca7baaef11857ad002cad40419979516":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","cca56866c19997e28ef073622656669c15210540"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["06584e6e98d592b34e1329b384182f368d2025e8","4122a26e1fd0457a340616673a3d3aada370f713"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["f0b9507caf22f292ac0e5e59f62db4275adf4511","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["0f3cee3d20b0c786e6fca20539454262e29edcab","1291e4568eb7d9463d751627596ef14baf4c1603"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"4122a26e1fd0457a340616673a3d3aada370f713":["06584e6e98d592b34e1329b384182f368d2025e8"],"cca56866c19997e28ef073622656669c15210540":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3615ce4a1f785ae1b779244de52c6a7d99227e60"]},"commit2Childs":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["f0b9507caf22f292ac0e5e59f62db4275adf4511"],"0f3cee3d20b0c786e6fca20539454262e29edcab":["1291e4568eb7d9463d751627596ef14baf4c1603","f0b9507caf22f292ac0e5e59f62db4275adf4511","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["79c2cb24929f2649a8875fb629086171f914d5ce","cca56866c19997e28ef073622656669c15210540"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"06584e6e98d592b34e1329b384182f368d2025e8":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60","4122a26e1fd0457a340616673a3d3aada370f713"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["b6f9be74ca7baaef11857ad002cad40419979516"],"1291e4568eb7d9463d751627596ef14baf4c1603":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"f0b9507caf22f292ac0e5e59f62db4275adf4511":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","79c2cb24929f2649a8875fb629086171f914d5ce","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"b6f9be74ca7baaef11857ad002cad40419979516":["1291e4568eb7d9463d751627596ef14baf4c1603"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["5d004d0e0b3f65bb40da76d476d659d7888270e8","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["06584e6e98d592b34e1329b384182f368d2025e8"],"4122a26e1fd0457a340616673a3d3aada370f713":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"cca56866c19997e28ef073622656669c15210540":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","0f3cee3d20b0c786e6fca20539454262e29edcab","639c36565ce03aed5b0fce7c9e4448e53a1f7efd","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}