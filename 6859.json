{"path":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/blocktree/Lucene40BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","commits":[{"id":"c6d238816bcdf9bbe4ec886226d89bd93834eb7e","date":1413925889,"type":1,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/blocktree/Lucene40BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/blocktree/Lucene40BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = out.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      out.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = out.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      out.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/blocktree/Lucene40BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = out.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      out.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71387d8cb6923eb831b17a8b734608ba2e21c653","date":1414126093,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/blocktree/Lucene40BlockTreeTermsWriter.TermsWriter#writeBlock(int,boolean,int,int,int,boolean,boolean).mjava","sourceNew":null,"sourceOld":"    /** Writes the specified slice (start is inclusive, end is exclusive)\n     *  from pending stack as a new block.  If isFloor is true, there\n     *  were too many (more than maxItemsInBlock) entries sharing the\n     *  same prefix, and so we broke it into multiple floor blocks where\n     *  we record the starting label of the suffix of each floor block. */\n    private PendingBlock writeBlock(int prefixLength, boolean isFloor, int floorLeadLabel, int start, int end, boolean hasTerms, boolean hasSubBlocks) throws IOException {\n\n      assert end > start;\n\n      long startFP = out.getFilePointer();\n\n      boolean hasFloorLeadLabel = isFloor && floorLeadLabel != -1;\n\n      final BytesRef prefix = new BytesRef(prefixLength + (hasFloorLeadLabel ? 1 : 0));\n      System.arraycopy(lastTerm.get().bytes, 0, prefix.bytes, 0, prefixLength);\n      prefix.length = prefixLength;\n\n      // Write block header:\n      int numEntries = end - start;\n      int code = numEntries << 1;\n      if (end == pending.size()) {\n        // Last block:\n        code |= 1;\n      }\n      out.writeVInt(code);\n\n      /*\n      if (DEBUG) {\n        System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + brToString(prefix) + \" entCount=\" + (end-start+1) + \" startFP=\" + startFP + (isFloor ? (\" floorLeadLabel=\" + Integer.toHexString(floorLeadLabel)) : \"\"));\n      }\n      */\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      // We optimize the leaf block case (block has only terms), writing a more\n      // compact format in this case:\n      boolean isLeafBlock = hasSubBlocks == false;\n\n      final List<FST<BytesRef>> subIndices;\n\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        // Only terms:\n        subIndices = null;\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          assert ent.isTerm: \"i=\" + i;\n\n          PendingTerm term = (PendingTerm) ent;\n          assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n          BlockTermState state = term.state;\n          final int suffix = term.termBytes.length - prefixLength;\n          /*\n          if (DEBUG) {\n            BytesRef suffixBytes = new BytesRef(suffix);\n            System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            suffixBytes.length = suffix;\n            System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n          }\n          */\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n          assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n      } else {\n        // Mixed terms and sub-blocks:\n        subIndices = new ArrayList<>();\n        for (int i=start;i<end;i++) {\n          PendingEntry ent = pending.get(i);\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            assert StringHelper.startsWith(term.termBytes, prefix): \"term.term=\" + term.termBytes + \" prefix=\" + prefix;\n            BlockTermState state = term.state;\n            final int suffix = term.termBytes.length - prefixLength;\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(term.termBytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write term suffix=\" + brToString(suffixBytes));\n            }\n            */\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.termBytes, prefixLength, suffix);\n            assert floorLeadLabel == -1 || (term.termBytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            assert StringHelper.startsWith(block.prefix, prefix);\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n\n            assert floorLeadLabel == -1 || (block.prefix.bytes[prefixLength] & 0xff) >= floorLeadLabel;\n\n            assert block.fp < startFP;\n\n            /*\n            if (DEBUG) {\n              BytesRef suffixBytes = new BytesRef(suffix);\n              System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n              suffixBytes.length = suffix;\n              System.out.println(\"    write sub-block suffix=\" + brToString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            }\n            */\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      if (hasFloorLeadLabel) {\n        // We already allocated to length+1 above:\n        prefix.bytes[prefix.length++] = (byte) floorLeadLabel;\n      }\n\n      return new PendingBlock(prefix, startFP, hasTerms, isFloor, floorLeadLabel, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c6d238816bcdf9bbe4ec886226d89bd93834eb7e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c6d238816bcdf9bbe4ec886226d89bd93834eb7e"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71387d8cb6923eb831b17a8b734608ba2e21c653"]},"commit2Childs":{"c6d238816bcdf9bbe4ec886226d89bd93834eb7e":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c6d238816bcdf9bbe4ec886226d89bd93834eb7e","db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["71387d8cb6923eb831b17a8b734608ba2e21c653"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}