{"path":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore(SegmentWriteState,IndexWriter,IndexFileDeleter,SegmentInfo,MergePolicy,SegmentInfos).mjava","commits":[{"id":"44fcbde6fb2ac44ee3b45e013e54a42911e689ff","date":1292065621,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore(SegmentWriteState,IndexWriter,IndexFileDeleter,SegmentInfo,MergePolicy,SegmentInfos).mjava","pathOld":"/dev/null","sourceNew":"  /** Closes the current open doc stores an sets the\n   *  docStoreSegment and docStoreUseCFS on the provided\n   *  SegmentInfo. */\n  synchronized void closeDocStore(SegmentWriteState flushState, IndexWriter writer, IndexFileDeleter deleter, SegmentInfo newSegment, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {\n    \n    final boolean isSeparate = numDocsInRAM == 0 || !segment.equals(docStoreSegment);\n\n    assert docStoreSegment != null;\n\n    if (infoStream != null) {\n      message(\"closeDocStore: files=\" + openFiles + \"; segment=\" + docStoreSegment + \"; docStoreOffset=\" + docStoreOffset + \"; numDocsInStore=\" + numDocsInStore + \"; isSeparate=\" + isSeparate);\n    }\n\n    closedFiles.clear();\n    consumer.closeDocStore(flushState);\n    flushState.numDocsInStore = 0;\n    assert 0 == openFiles.size();\n\n    if (isSeparate) {\n      flushState.flushedFiles.clear();\n\n      if (mergePolicy.useCompoundDocStore(segmentInfos)) {\n\n        final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n        if (infoStream != null) {\n          message(\"closeDocStore: create compound file \" + compoundFileName);\n        }\n\n        boolean success = false;\n        try {\n\n          CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n          for (final String file : closedFiles) {\n            cfsWriter.addFile(file);\n          }\n      \n          // Perform the merge\n          cfsWriter.close();\n\n          success = true;\n        } finally {\n          if (!success) {\n            deleter.deleteFile(compoundFileName);\n          }\n        }\n\n        // In case the files we just merged into a CFS were\n        // not registered w/ IFD:\n        deleter.deleteNewFiles(closedFiles);\n\n        final int numSegments = segmentInfos.size();\n        for(int i=0;i<numSegments;i++) {\n          SegmentInfo si = segmentInfos.info(i);\n          if (si.getDocStoreOffset() != -1 &&\n              si.getDocStoreSegment().equals(docStoreSegment)) {\n            si.setDocStoreIsCompoundFile(true);\n          }\n        }\n\n        newSegment.setDocStoreIsCompoundFile(true);\n        if (infoStream != null) {\n          message(\"closeDocStore: after compound file index=\" + segmentInfos);\n        }\n\n        writer.checkpoint();\n      }\n    }\n\n    docStoreSegment = null;\n    docStoreOffset = 0;\n    numDocsInStore = 0;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e1cbd7e289dc1243c7a59e1a83d078163a147fe","date":1292268032,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore(SegmentWriteState,IndexWriter,IndexFileDeleter,SegmentInfo,MergePolicy,SegmentInfos).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore(SegmentWriteState,IndexWriter,IndexFileDeleter,SegmentInfo,MergePolicy,SegmentInfos).mjava","sourceNew":"  /** Closes the current open doc stores an sets the\n   *  docStoreSegment and docStoreUseCFS on the provided\n   *  SegmentInfo. */\n  synchronized void closeDocStore(SegmentWriteState flushState, IndexWriter writer, IndexFileDeleter deleter, SegmentInfo newSegment, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {\n    \n    final boolean isSeparate = numDocsInRAM == 0 || !segment.equals(docStoreSegment);\n\n    assert docStoreSegment != null;\n\n    if (infoStream != null) {\n      message(\"closeDocStore: openFiles=\" + openFiles + \"; segment=\" + docStoreSegment + \"; docStoreOffset=\" + docStoreOffset + \"; numDocsInStore=\" + numDocsInStore + \"; isSeparate=\" + isSeparate);\n    }\n\n    closedFiles.clear();\n    consumer.closeDocStore(flushState);\n    flushState.numDocsInStore = 0;\n    assert 0 == openFiles.size();\n\n    if (isSeparate) {\n      flushState.flushedFiles.clear();\n\n      if (mergePolicy.useCompoundDocStore(segmentInfos)) {\n\n        final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n        if (infoStream != null) {\n          message(\"closeDocStore: create compound file \" + compoundFileName);\n        }\n\n        boolean success = false;\n        try {\n\n          CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n          for (final String file : closedFiles) {\n            cfsWriter.addFile(file);\n          }\n      \n          // Perform the merge\n          cfsWriter.close();\n\n          success = true;\n        } finally {\n          if (!success) {\n            deleter.deleteFile(compoundFileName);\n          }\n        }\n\n        // In case the files we just merged into a CFS were\n        // not registered w/ IFD:\n        deleter.deleteNewFiles(closedFiles);\n\n        final int numSegments = segmentInfos.size();\n        for(int i=0;i<numSegments;i++) {\n          SegmentInfo si = segmentInfos.info(i);\n          if (si.getDocStoreOffset() != -1 &&\n              si.getDocStoreSegment().equals(docStoreSegment)) {\n            si.setDocStoreIsCompoundFile(true);\n          }\n        }\n\n        newSegment.setDocStoreIsCompoundFile(true);\n        if (infoStream != null) {\n          message(\"closeDocStore: after compound file index=\" + segmentInfos);\n        }\n\n        writer.checkpoint();\n      }\n    }\n\n    docStoreSegment = null;\n    docStoreOffset = 0;\n    numDocsInStore = 0;\n  }\n\n","sourceOld":"  /** Closes the current open doc stores an sets the\n   *  docStoreSegment and docStoreUseCFS on the provided\n   *  SegmentInfo. */\n  synchronized void closeDocStore(SegmentWriteState flushState, IndexWriter writer, IndexFileDeleter deleter, SegmentInfo newSegment, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {\n    \n    final boolean isSeparate = numDocsInRAM == 0 || !segment.equals(docStoreSegment);\n\n    assert docStoreSegment != null;\n\n    if (infoStream != null) {\n      message(\"closeDocStore: files=\" + openFiles + \"; segment=\" + docStoreSegment + \"; docStoreOffset=\" + docStoreOffset + \"; numDocsInStore=\" + numDocsInStore + \"; isSeparate=\" + isSeparate);\n    }\n\n    closedFiles.clear();\n    consumer.closeDocStore(flushState);\n    flushState.numDocsInStore = 0;\n    assert 0 == openFiles.size();\n\n    if (isSeparate) {\n      flushState.flushedFiles.clear();\n\n      if (mergePolicy.useCompoundDocStore(segmentInfos)) {\n\n        final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n        if (infoStream != null) {\n          message(\"closeDocStore: create compound file \" + compoundFileName);\n        }\n\n        boolean success = false;\n        try {\n\n          CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n          for (final String file : closedFiles) {\n            cfsWriter.addFile(file);\n          }\n      \n          // Perform the merge\n          cfsWriter.close();\n\n          success = true;\n        } finally {\n          if (!success) {\n            deleter.deleteFile(compoundFileName);\n          }\n        }\n\n        // In case the files we just merged into a CFS were\n        // not registered w/ IFD:\n        deleter.deleteNewFiles(closedFiles);\n\n        final int numSegments = segmentInfos.size();\n        for(int i=0;i<numSegments;i++) {\n          SegmentInfo si = segmentInfos.info(i);\n          if (si.getDocStoreOffset() != -1 &&\n              si.getDocStoreSegment().equals(docStoreSegment)) {\n            si.setDocStoreIsCompoundFile(true);\n          }\n        }\n\n        newSegment.setDocStoreIsCompoundFile(true);\n        if (infoStream != null) {\n          message(\"closeDocStore: after compound file index=\" + segmentInfos);\n        }\n\n        writer.checkpoint();\n      }\n    }\n\n    docStoreSegment = null;\n    docStoreOffset = 0;\n    numDocsInStore = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#closeDocStore(SegmentWriteState,IndexWriter,IndexFileDeleter,SegmentInfo,MergePolicy,SegmentInfos).mjava","sourceNew":null,"sourceOld":"  /** Closes the current open doc stores an sets the\n   *  docStoreSegment and docStoreUseCFS on the provided\n   *  SegmentInfo. */\n  synchronized void closeDocStore(SegmentWriteState flushState, IndexWriter writer, IndexFileDeleter deleter, SegmentInfo newSegment, MergePolicy mergePolicy, SegmentInfos segmentInfos) throws IOException {\n    \n    final boolean isSeparate = numDocsInRAM == 0 || !segment.equals(docStoreSegment);\n\n    assert docStoreSegment != null;\n\n    if (infoStream != null) {\n      message(\"closeDocStore: openFiles=\" + openFiles + \"; segment=\" + docStoreSegment + \"; docStoreOffset=\" + docStoreOffset + \"; numDocsInStore=\" + numDocsInStore + \"; isSeparate=\" + isSeparate);\n    }\n\n    closedFiles.clear();\n    consumer.closeDocStore(flushState);\n    flushState.numDocsInStore = 0;\n    assert 0 == openFiles.size();\n\n    if (isSeparate) {\n      flushState.flushedFiles.clear();\n\n      if (mergePolicy.useCompoundDocStore(segmentInfos)) {\n\n        final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n        if (infoStream != null) {\n          message(\"closeDocStore: create compound file \" + compoundFileName);\n        }\n\n        boolean success = false;\n        try {\n\n          CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n          for (final String file : closedFiles) {\n            cfsWriter.addFile(file);\n          }\n      \n          // Perform the merge\n          cfsWriter.close();\n\n          success = true;\n        } finally {\n          if (!success) {\n            deleter.deleteFile(compoundFileName);\n          }\n        }\n\n        // In case the files we just merged into a CFS were\n        // not registered w/ IFD:\n        deleter.deleteNewFiles(closedFiles);\n\n        final int numSegments = segmentInfos.size();\n        for(int i=0;i<numSegments;i++) {\n          SegmentInfo si = segmentInfos.info(i);\n          if (si.getDocStoreOffset() != -1 &&\n              si.getDocStoreSegment().equals(docStoreSegment)) {\n            si.setDocStoreIsCompoundFile(true);\n          }\n        }\n\n        newSegment.setDocStoreIsCompoundFile(true);\n        if (infoStream != null) {\n          message(\"closeDocStore: after compound file index=\" + segmentInfos);\n        }\n\n        writer.checkpoint();\n      }\n    }\n\n    docStoreSegment = null;\n    docStoreOffset = 0;\n    numDocsInStore = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"]},"commit2Childs":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}