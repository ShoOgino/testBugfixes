{"path":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(IndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","commits":[{"id":"2534504cc6a6ab3301865de897422111495e0aad","date":1499445439,"type":1,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(IndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","pathOld":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(SolrIndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","sourceNew":"  public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(new Float(hit.score));\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n          featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n            featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","sourceOld":"  public void scoreFeatures(SolrIndexSearcher solrIndexSearch, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(new Float(hit.score));\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null) {\n          featureLogger.log(hit.doc, scoringQuery, solrIndexSearch,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null) {\n            featureLogger.log(hit.doc, scoringQuery, solrIndexSearch,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f9a989a32a073c55e3aef6f807a3474184bbcf49","date":1499930209,"type":1,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(IndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","pathOld":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(SolrIndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","sourceNew":"  public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(new Float(hit.score));\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n          featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n            featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","sourceOld":"  public void scoreFeatures(SolrIndexSearcher solrIndexSearch, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(new Float(hit.score));\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null) {\n          featureLogger.log(hit.doc, scoringQuery, solrIndexSearch,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null) {\n            featureLogger.log(hit.doc, scoringQuery, solrIndexSearch,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb569fd721c41eafc2a2d788499a7df490c7f1a5","date":1499930871,"type":1,"author":"Noble Paul","isMerge":true,"pathNew":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(IndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","pathOld":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(SolrIndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","sourceNew":"  public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(new Float(hit.score));\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n          featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n            featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","sourceOld":"  public void scoreFeatures(SolrIndexSearcher solrIndexSearch, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(new Float(hit.score));\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null) {\n          featureLogger.log(hit.doc, scoringQuery, solrIndexSearch,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null) {\n            featureLogger.log(hit.doc, scoringQuery, solrIndexSearch,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a","date":1528054850,"type":3,"author":"Michael Braun","isMerge":false,"pathNew":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(IndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","pathOld":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(IndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","sourceNew":"  public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(hit.score);\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n          featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n            featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","sourceOld":"  public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(new Float(hit.score));\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n          featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n            featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"628903f37b6c442da0d390db1c6af9a0e74d41a7","date":1531736685,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(IndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","pathOld":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(IndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","sourceNew":"  public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(hit.score);\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n          featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n            featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","sourceOld":"  public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(new Float(hit.score));\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n          featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n            featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(IndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","pathOld":"solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer#scoreFeatures(IndexSearcher,TopDocs,int,LTRScoringQuery.ModelWeight,ScoreDoc[],List[LeafReaderContext],ScoreDoc[]).mjava","sourceNew":"  public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(hit.score);\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n          featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n            featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","sourceOld":"  public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n      int topN, LTRScoringQuery.ModelWeight modelWeight, ScoreDoc[] hits, List<LeafReaderContext> leaves,\n      ScoreDoc[] reranked) throws IOException {\n\n    int readerUpto = -1;\n    int endDoc = 0;\n    int docBase = 0;\n\n    LTRScoringQuery.ModelWeight.ModelScorer scorer = null;\n    int hitUpto = 0;\n    final FeatureLogger featureLogger = scoringQuery.getFeatureLogger();\n\n    while (hitUpto < hits.length) {\n      final ScoreDoc hit = hits[hitUpto];\n      final int docID = hit.doc;\n      LeafReaderContext readerContext = null;\n      while (docID >= endDoc) {\n        readerUpto++;\n        readerContext = leaves.get(readerUpto);\n        endDoc = readerContext.docBase + readerContext.reader().maxDoc();\n      }\n      // We advanced to another segment\n      if (readerContext != null) {\n        docBase = readerContext.docBase;\n        scorer = modelWeight.scorer(readerContext);\n      }\n      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n      // call score\n      // even if no feature scorers match, since a model might use that info to\n      // return a\n      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n      // past the target\n      // doc since the model algorithm still needs to compute a potentially\n      // non-zero score from blank features.\n      assert (scorer != null);\n      final int targetDoc = docID - docBase;\n      scorer.docID();\n      scorer.iterator().advance(targetDoc);\n\n      scorer.getDocInfo().setOriginalDocScore(new Float(hit.score));\n      hit.score = scorer.score();\n      if (hitUpto < topN) {\n        reranked[hitUpto] = hit;\n        // if the heap is not full, maybe I want to log the features for this\n        // document\n        if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n          featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n              modelWeight.getFeaturesInfo());\n        }\n      } else if (hitUpto == topN) {\n        // collected topN document, I create the heap\n        heapify(reranked, topN);\n      }\n      if (hitUpto >= topN) {\n        // once that heap is ready, if the score of this document is lower that\n        // the minimum\n        // i don't want to log the feature. Otherwise I replace it with the\n        // minimum and fix the\n        // heap.\n        if (hit.score > reranked[0].score) {\n          reranked[0] = hit;\n          heapAdjust(reranked, topN, 0);\n          if (featureLogger != null && indexSearcher instanceof SolrIndexSearcher) {\n            featureLogger.log(hit.doc, scoringQuery, (SolrIndexSearcher)indexSearcher,\n                modelWeight.getFeaturesInfo());\n          }\n        }\n      }\n      hitUpto++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a":["2534504cc6a6ab3301865de897422111495e0aad"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["2534504cc6a6ab3301865de897422111495e0aad","628903f37b6c442da0d390db1c6af9a0e74d41a7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fb569fd721c41eafc2a2d788499a7df490c7f1a5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f9a989a32a073c55e3aef6f807a3474184bbcf49"],"2534504cc6a6ab3301865de897422111495e0aad":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"628903f37b6c442da0d390db1c6af9a0e74d41a7":["2534504cc6a6ab3301865de897422111495e0aad","b6a269c1ddba3f8c9fa9a40572ecc538eddda41a"],"f9a989a32a073c55e3aef6f807a3474184bbcf49":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2534504cc6a6ab3301865de897422111495e0aad"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["628903f37b6c442da0d390db1c6af9a0e74d41a7"]},"commit2Childs":{"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a":["628903f37b6c442da0d390db1c6af9a0e74d41a7"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fb569fd721c41eafc2a2d788499a7df490c7f1a5","2534504cc6a6ab3301865de897422111495e0aad","f9a989a32a073c55e3aef6f807a3474184bbcf49"],"fb569fd721c41eafc2a2d788499a7df490c7f1a5":[],"2534504cc6a6ab3301865de897422111495e0aad":["b6a269c1ddba3f8c9fa9a40572ecc538eddda41a","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","628903f37b6c442da0d390db1c6af9a0e74d41a7","f9a989a32a073c55e3aef6f807a3474184bbcf49"],"628903f37b6c442da0d390db1c6af9a0e74d41a7":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f9a989a32a073c55e3aef6f807a3474184bbcf49":["fb569fd721c41eafc2a2d788499a7df490c7f1a5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","fb569fd721c41eafc2a2d788499a7df490c7f1a5","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}