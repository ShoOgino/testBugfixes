{"path":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","commits":[{"id":"6864413dbc0c12104c978c05456f3da1d45adb03","date":1186770873,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","pathOld":"/dev/null","sourceNew":"  public Token next(Token result) throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      char[] buffer = result.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = result.resizeTermBuffer(1+buffer.length);\n      }\n      result.termLength = upto;\n      return result;\n    }\n    return null;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fee44d0bd0b9443ff6068d0ba8458fd103dff4aa","date":1199000070,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","sourceNew":"  public Token next(Token result) throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      result.clear();\n      char[] buffer = result.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = result.resizeTermBuffer(1+buffer.length);\n      }\n      result.termLength = upto;\n      return result;\n    }\n    return null;\n  }\n\n","sourceOld":"  public Token next(Token result) throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      char[] buffer = result.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = result.resizeTermBuffer(1+buffer.length);\n      }\n      result.termLength = upto;\n      return result;\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","sourceNew":"  public Token next(final Token reusableToken) throws IOException {\n    assert reusableToken != null;\n    if (!done) {\n      done = true;\n      int upto = 0;\n      reusableToken.clear();\n      char[] buffer = reusableToken.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = reusableToken.resizeTermBuffer(1+buffer.length);\n      }\n      reusableToken.setTermLength(upto);\n      return reusableToken;\n    }\n    return null;\n  }\n\n","sourceOld":"  public Token next(Token result) throws IOException {\n    if (!done) {\n      done = true;\n      int upto = 0;\n      result.clear();\n      char[] buffer = result.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = result.resizeTermBuffer(1+buffer.length);\n      }\n      result.termLength = upto;\n      return result;\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7822a05f4c7c5227bbf580fb6a902918bb2d6f1","date":1226086595,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","sourceNew":"  public Token next(final Token reusableToken) throws IOException {\n    assert reusableToken != null;\n    if (!done) {\n      done = true;\n      int upto = 0;\n      reusableToken.clear();\n      char[] buffer = reusableToken.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = reusableToken.resizeTermBuffer(1+buffer.length);\n      }\n      reusableToken.setTermLength(upto);\n      reusableToken.setStartOffset(0);\n      reusableToken.setEndOffset(upto);\n      \n      return reusableToken;\n    }\n    return null;\n  }\n\n","sourceOld":"  public Token next(final Token reusableToken) throws IOException {\n    assert reusableToken != null;\n    if (!done) {\n      done = true;\n      int upto = 0;\n      reusableToken.clear();\n      char[] buffer = reusableToken.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = reusableToken.resizeTermBuffer(1+buffer.length);\n      }\n      reusableToken.setTermLength(upto);\n      return reusableToken;\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223","date":1227051709,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","sourceNew":"  /** @deprecated */\n  public Token next(final Token reusableToken) throws IOException {\n    assert reusableToken != null;\n    if (!done) {\n      done = true;\n      int upto = 0;\n      reusableToken.clear();\n      char[] buffer = reusableToken.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = reusableToken.resizeTermBuffer(1+buffer.length);\n      }\n      reusableToken.setTermLength(upto);\n      reusableToken.setStartOffset(0);\n      reusableToken.setEndOffset(upto);\n      \n      return reusableToken;\n    }\n    return null;\n  }\n\n","sourceOld":"  public Token next(final Token reusableToken) throws IOException {\n    assert reusableToken != null;\n    if (!done) {\n      done = true;\n      int upto = 0;\n      reusableToken.clear();\n      char[] buffer = reusableToken.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = reusableToken.resizeTermBuffer(1+buffer.length);\n      }\n      reusableToken.setTermLength(upto);\n      reusableToken.setStartOffset(0);\n      reusableToken.setEndOffset(upto);\n      \n      return reusableToken;\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cd27af5c226d98a7c6378c388a67a3bff7c0b3a2","date":1245784531,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","sourceNew":"  /** @deprecated */\n  public Token next(final Token reusableToken) throws IOException {\n    assert reusableToken != null;\n    if (!done) {\n      done = true;\n      int upto = 0;\n      reusableToken.clear();\n      char[] buffer = reusableToken.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = reusableToken.resizeTermBuffer(1+buffer.length);\n      }\n      reusableToken.setTermLength(upto);\n      reusableToken.setStartOffset(input.correctOffset(0));\n      reusableToken.setEndOffset(input.correctOffset(upto));\n      \n      return reusableToken;\n    }\n    return null;\n  }\n\n","sourceOld":"  /** @deprecated */\n  public Token next(final Token reusableToken) throws IOException {\n    assert reusableToken != null;\n    if (!done) {\n      done = true;\n      int upto = 0;\n      reusableToken.clear();\n      char[] buffer = reusableToken.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = reusableToken.resizeTermBuffer(1+buffer.length);\n      }\n      reusableToken.setTermLength(upto);\n      reusableToken.setStartOffset(0);\n      reusableToken.setEndOffset(upto);\n      \n      return reusableToken;\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ec8b5a20a12931b8d7e616c79c5248ae06cc5568","date":1248471948,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","sourceNew":"  /** @deprecated Will be removed in Lucene 3.0. This method is final, as it should\n   * not be overridden. Delegates to the backwards compatibility layer. */\n  public final Token next(final Token reusableToken) throws IOException {\n    return super.next(reusableToken);\n  }\n\n","sourceOld":"  /** @deprecated */\n  public Token next(final Token reusableToken) throws IOException {\n    assert reusableToken != null;\n    if (!done) {\n      done = true;\n      int upto = 0;\n      reusableToken.clear();\n      char[] buffer = reusableToken.termBuffer();\n      while (true) {\n        final int length = input.read(buffer, upto, buffer.length-upto);\n        if (length == -1) break;\n        upto += length;\n        if (upto == buffer.length)\n          buffer = reusableToken.resizeTermBuffer(1+buffer.length);\n      }\n      reusableToken.setTermLength(upto);\n      reusableToken.setStartOffset(input.correctOffset(0));\n      reusableToken.setEndOffset(input.correctOffset(upto));\n      \n      return reusableToken;\n    }\n    return null;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"439b0fe2f799d1c722151e88e32bdefad8d34ebe","date":1255282509,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/analysis/KeywordTokenizer#next(Token).mjava","sourceNew":null,"sourceOld":"  /** @deprecated Will be removed in Lucene 3.0. This method is final, as it should\n   * not be overridden. Delegates to the backwards compatibility layer. */\n  public final Token next(final Token reusableToken) throws IOException {\n    return super.next(reusableToken);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["fee44d0bd0b9443ff6068d0ba8458fd103dff4aa"],"6864413dbc0c12104c978c05456f3da1d45adb03":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["c7822a05f4c7c5227bbf580fb6a902918bb2d6f1"],"fee44d0bd0b9443ff6068d0ba8458fd103dff4aa":["6864413dbc0c12104c978c05456f3da1d45adb03"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c7822a05f4c7c5227bbf580fb6a902918bb2d6f1":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"439b0fe2f799d1c722151e88e32bdefad8d34ebe":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["439b0fe2f799d1c722151e88e32bdefad8d34ebe"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["cd27af5c226d98a7c6378c388a67a3bff7c0b3a2"],"cd27af5c226d98a7c6378c388a67a3bff7c0b3a2":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["c7822a05f4c7c5227bbf580fb6a902918bb2d6f1"],"6864413dbc0c12104c978c05456f3da1d45adb03":["fee44d0bd0b9443ff6068d0ba8458fd103dff4aa"],"fee44d0bd0b9443ff6068d0ba8458fd103dff4aa":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["cd27af5c226d98a7c6378c388a67a3bff7c0b3a2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6864413dbc0c12104c978c05456f3da1d45adb03"],"c7822a05f4c7c5227bbf580fb6a902918bb2d6f1":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"],"439b0fe2f799d1c722151e88e32bdefad8d34ebe":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["439b0fe2f799d1c722151e88e32bdefad8d34ebe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"cd27af5c226d98a7c6378c388a67a3bff7c0b3a2":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}