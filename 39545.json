{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene80/Lucene80DocValuesProducer.BinaryDecoder#decode(int).mjava","commits":[{"id":"5fcfc028fca127dc2779630e53a9c2ec208ee7a0","date":1582034562,"type":0,"author":"markharwood","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene80/Lucene80DocValuesProducer.BinaryDecoder#decode(int).mjava","pathOld":"/dev/null","sourceNew":"    BytesRef decode(int docNumber) throws IOException {\n      int blockId = docNumber >> docsPerChunkShift; \n      int docInBlockId = docNumber % docsPerChunk;\n      assert docInBlockId < docsPerChunk;\n      \n      \n      // already read and uncompressed?\n      if (blockId != lastBlockId) {\n        lastBlockId = blockId;\n        long blockStartOffset = addresses.get(blockId);\n        compressedData.seek(blockStartOffset);\n        \n        uncompressedBlockLength = 0;        \n\n        int onlyLength = -1;\n        for (int i = 0; i < docsPerChunk; i++) {\n          if (i == 0) {\n            // The first length value is special. It is shifted and has a bit to denote if\n            // all other values are the same length\n            int lengthPlusSameInd = compressedData.readVInt();\n            int sameIndicator = lengthPlusSameInd & 1;\n            int firstValLength = lengthPlusSameInd >>>1;\n            if (sameIndicator == 1) {\n              onlyLength = firstValLength;\n            }\n            uncompressedBlockLength += firstValLength;            \n          } else {\n            if (onlyLength == -1) {\n              // Various lengths are stored - read each from disk\n              uncompressedBlockLength += compressedData.readVInt();            \n            } else {\n              // Only one length \n              uncompressedBlockLength += onlyLength;\n            }\n          }\n          uncompressedDocStarts[i+1] = uncompressedBlockLength;\n        }\n        \n        if (uncompressedBlockLength == 0) {\n          uncompressedBytesRef.offset = 0;\n          uncompressedBytesRef.length = 0;\n          return uncompressedBytesRef;\n        }\n        \n        assert uncompressedBlockLength <= uncompressedBlock.length;\n        LZ4.decompress(compressedData, uncompressedBlockLength, uncompressedBlock, 0);\n      }\n      \n      uncompressedBytesRef.offset = uncompressedDocStarts[docInBlockId];        \n      uncompressedBytesRef.length = uncompressedDocStarts[docInBlockId +1] - uncompressedBytesRef.offset;\n      return uncompressedBytesRef;\n    }    \n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e673a608cacc7de01f6ad30a0fc89a889a2cca86","date":1582885616,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene80/Lucene80DocValuesProducer.BinaryDecoder#decode(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene80/Lucene80DocValuesProducer.BinaryDecoder#decode(int).mjava","sourceNew":"    BytesRef decode(int docNumber) throws IOException {\n      int blockId = docNumber >> docsPerChunkShift; \n      int docInBlockId = docNumber % docsPerChunk;\n      assert docInBlockId < docsPerChunk;\n      \n      \n      // already read and uncompressed?\n      if (blockId != lastBlockId) {\n        lastBlockId = blockId;\n        long blockStartOffset = addresses.get(blockId);\n        compressedData.seek(blockStartOffset);\n        \n        uncompressedBlockLength = 0;        \n\n        int onlyLength = -1;\n        for (int i = 0; i < docsPerChunk; i++) {\n          if (i == 0) {\n            // The first length value is special. It is shifted and has a bit to denote if\n            // all other values are the same length\n            int lengthPlusSameInd = compressedData.readVInt();\n            int sameIndicator = lengthPlusSameInd & 1;\n            int firstValLength = lengthPlusSameInd >>>1;\n            if (sameIndicator == 1) {\n              onlyLength = firstValLength;\n            }\n            uncompressedBlockLength += firstValLength;            \n          } else {\n            if (onlyLength == -1) {\n              // Various lengths are stored - read each from disk\n              uncompressedBlockLength += compressedData.readVInt();            \n            } else {\n              // Only one length \n              uncompressedBlockLength += onlyLength;\n            }\n          }\n          uncompressedDocStarts[i+1] = uncompressedBlockLength;\n        }\n        \n        if (uncompressedBlockLength == 0) {\n          uncompressedBytesRef.offset = 0;\n          uncompressedBytesRef.length = 0;\n          return uncompressedBytesRef;\n        }\n        \n        assert uncompressedBlockLength <= uncompressedBlock.length;\n        LZ4.decompress(compressedData, uncompressedBlockLength, uncompressedBlock);\n      }\n      \n      uncompressedBytesRef.offset = uncompressedDocStarts[docInBlockId];        \n      uncompressedBytesRef.length = uncompressedDocStarts[docInBlockId +1] - uncompressedBytesRef.offset;\n      return uncompressedBytesRef;\n    }    \n\n","sourceOld":"    BytesRef decode(int docNumber) throws IOException {\n      int blockId = docNumber >> docsPerChunkShift; \n      int docInBlockId = docNumber % docsPerChunk;\n      assert docInBlockId < docsPerChunk;\n      \n      \n      // already read and uncompressed?\n      if (blockId != lastBlockId) {\n        lastBlockId = blockId;\n        long blockStartOffset = addresses.get(blockId);\n        compressedData.seek(blockStartOffset);\n        \n        uncompressedBlockLength = 0;        \n\n        int onlyLength = -1;\n        for (int i = 0; i < docsPerChunk; i++) {\n          if (i == 0) {\n            // The first length value is special. It is shifted and has a bit to denote if\n            // all other values are the same length\n            int lengthPlusSameInd = compressedData.readVInt();\n            int sameIndicator = lengthPlusSameInd & 1;\n            int firstValLength = lengthPlusSameInd >>>1;\n            if (sameIndicator == 1) {\n              onlyLength = firstValLength;\n            }\n            uncompressedBlockLength += firstValLength;            \n          } else {\n            if (onlyLength == -1) {\n              // Various lengths are stored - read each from disk\n              uncompressedBlockLength += compressedData.readVInt();            \n            } else {\n              // Only one length \n              uncompressedBlockLength += onlyLength;\n            }\n          }\n          uncompressedDocStarts[i+1] = uncompressedBlockLength;\n        }\n        \n        if (uncompressedBlockLength == 0) {\n          uncompressedBytesRef.offset = 0;\n          uncompressedBytesRef.length = 0;\n          return uncompressedBytesRef;\n        }\n        \n        assert uncompressedBlockLength <= uncompressedBlock.length;\n        LZ4.decompress(compressedData, uncompressedBlockLength, uncompressedBlock, 0);\n      }\n      \n      uncompressedBytesRef.offset = uncompressedDocStarts[docInBlockId];        \n      uncompressedBytesRef.length = uncompressedDocStarts[docInBlockId +1] - uncompressedBytesRef.offset;\n      return uncompressedBytesRef;\n    }    \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9aefce86de8b17eed91ab011fb54d704d91102ef","date":1599128224,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene80/Lucene80DocValuesProducer.BinaryDecoder#decode(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene80/Lucene80DocValuesProducer.BinaryDecoder#decode(int).mjava","sourceNew":"    BytesRef decode(int docNumber) throws IOException {\n      int blockId = docNumber >> docsPerChunkShift; \n      int docInBlockId = docNumber % docsPerChunk;\n      assert docInBlockId < docsPerChunk;\n      \n      \n      // already read and uncompressed?\n      if (blockId != lastBlockId) {\n        lastBlockId = blockId;\n        long blockStartOffset = addresses.get(blockId);\n        compressedData.seek(blockStartOffset);\n        \n        uncompressedBlockLength = 0;        \n\n        int onlyLength = -1;\n        for (int i = 0; i < docsPerChunk; i++) {\n          if (i == 0) {\n            // The first length value is special. It is shifted and has a bit to denote if\n            // all other values are the same length\n            int lengthPlusSameInd = compressedData.readVInt();\n            int sameIndicator = lengthPlusSameInd & 1;\n            int firstValLength = lengthPlusSameInd >>>1;\n            if (sameIndicator == 1) {\n              onlyLength = firstValLength;\n            }\n            uncompressedBlockLength += firstValLength;            \n          } else {\n            if (onlyLength == -1) {\n              // Various lengths are stored - read each from disk\n              uncompressedBlockLength += compressedData.readVInt();            \n            } else {\n              // Only one length \n              uncompressedBlockLength += onlyLength;\n            }\n          }\n          uncompressedDocStarts[i+1] = uncompressedBlockLength;\n        }\n        \n        if (uncompressedBlockLength == 0) {\n          uncompressedBytesRef.offset = 0;\n          uncompressedBytesRef.length = 0;\n          return uncompressedBytesRef;\n        }\n        \n        assert uncompressedBlockLength <= uncompressedBlock.length;\n        LZ4.decompress(compressedData, uncompressedBlockLength, uncompressedBlock, 0);\n      }\n      \n      uncompressedBytesRef.offset = uncompressedDocStarts[docInBlockId];        \n      uncompressedBytesRef.length = uncompressedDocStarts[docInBlockId +1] - uncompressedBytesRef.offset;\n      return uncompressedBytesRef;\n    }    \n\n","sourceOld":"    BytesRef decode(int docNumber) throws IOException {\n      int blockId = docNumber >> docsPerChunkShift; \n      int docInBlockId = docNumber % docsPerChunk;\n      assert docInBlockId < docsPerChunk;\n      \n      \n      // already read and uncompressed?\n      if (blockId != lastBlockId) {\n        lastBlockId = blockId;\n        long blockStartOffset = addresses.get(blockId);\n        compressedData.seek(blockStartOffset);\n        \n        uncompressedBlockLength = 0;        \n\n        int onlyLength = -1;\n        for (int i = 0; i < docsPerChunk; i++) {\n          if (i == 0) {\n            // The first length value is special. It is shifted and has a bit to denote if\n            // all other values are the same length\n            int lengthPlusSameInd = compressedData.readVInt();\n            int sameIndicator = lengthPlusSameInd & 1;\n            int firstValLength = lengthPlusSameInd >>>1;\n            if (sameIndicator == 1) {\n              onlyLength = firstValLength;\n            }\n            uncompressedBlockLength += firstValLength;            \n          } else {\n            if (onlyLength == -1) {\n              // Various lengths are stored - read each from disk\n              uncompressedBlockLength += compressedData.readVInt();            \n            } else {\n              // Only one length \n              uncompressedBlockLength += onlyLength;\n            }\n          }\n          uncompressedDocStarts[i+1] = uncompressedBlockLength;\n        }\n        \n        if (uncompressedBlockLength == 0) {\n          uncompressedBytesRef.offset = 0;\n          uncompressedBytesRef.length = 0;\n          return uncompressedBytesRef;\n        }\n        \n        assert uncompressedBlockLength <= uncompressedBlock.length;\n        LZ4.decompress(compressedData, uncompressedBlockLength, uncompressedBlock);\n      }\n      \n      uncompressedBytesRef.offset = uncompressedDocStarts[docInBlockId];        \n      uncompressedBytesRef.length = uncompressedDocStarts[docInBlockId +1] - uncompressedBytesRef.offset;\n      return uncompressedBytesRef;\n    }    \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e673a608cacc7de01f6ad30a0fc89a889a2cca86":["5fcfc028fca127dc2779630e53a9c2ec208ee7a0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9aefce86de8b17eed91ab011fb54d704d91102ef":["e673a608cacc7de01f6ad30a0fc89a889a2cca86"],"5fcfc028fca127dc2779630e53a9c2ec208ee7a0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9aefce86de8b17eed91ab011fb54d704d91102ef"]},"commit2Childs":{"e673a608cacc7de01f6ad30a0fc89a889a2cca86":["9aefce86de8b17eed91ab011fb54d704d91102ef"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5fcfc028fca127dc2779630e53a9c2ec208ee7a0"],"9aefce86de8b17eed91ab011fb54d704d91102ef":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5fcfc028fca127dc2779630e53a9c2ec208ee7a0":["e673a608cacc7de01f6ad30a0fc89a889a2cca86"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}