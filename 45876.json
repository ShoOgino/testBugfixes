{"path":"lucene/core/src/java/org/apache/lucene/search/SloppyPhraseMatcher#gatherRptGroups(LinkedHashMap[Term,Integer]).mjava","commits":[{"id":"3b11b9d5eaf9707760ca5151530830a825197023","date":1525941319,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/SloppyPhraseMatcher#gatherRptGroups(LinkedHashMap[Term,Integer]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/SloppyPhraseScorer#gatherRptGroups(LinkedHashMap[Term,Integer]).mjava","sourceNew":"  /** Detect repetition groups. Done once - for first doc */\n  private ArrayList<ArrayList<PhrasePositions>> gatherRptGroups(LinkedHashMap<Term,Integer> rptTerms) throws IOException {\n    PhrasePositions[] rpp = repeatingPPs(rptTerms); \n    ArrayList<ArrayList<PhrasePositions>> res = new ArrayList<>();\n    if (!hasMultiTermRpts) {\n      // simpler - no multi-terms - can base on positions in first doc\n      for (int i=0; i<rpp.length; i++) {\n        PhrasePositions pp = rpp[i];\n        if (pp.rptGroup >=0) continue; // already marked as a repetition\n        int tpPos = tpPos(pp);\n        for (int j=i+1; j<rpp.length; j++) {\n          PhrasePositions pp2 = rpp[j];\n          if (\n              pp2.rptGroup >=0        // already marked as a repetition\n              || pp2.offset == pp.offset // not a repetition: two PPs are originally in same offset in the query! \n              || tpPos(pp2) != tpPos) {  // not a repetition\n            continue; \n          }\n          // a repetition\n          int g = pp.rptGroup;\n          if (g < 0) {\n            g = res.size();\n            pp.rptGroup = g;  \n            ArrayList<PhrasePositions> rl = new ArrayList<>(2);\n            rl.add(pp);\n            res.add(rl); \n          }\n          pp2.rptGroup = g;\n          res.get(g).add(pp2);\n        }\n      }\n    } else {\n      // more involved - has multi-terms\n      ArrayList<HashSet<PhrasePositions>> tmp = new ArrayList<>();\n      ArrayList<FixedBitSet> bb = ppTermsBitSets(rpp, rptTerms);\n      unionTermGroups(bb);\n      HashMap<Term,Integer> tg = termGroups(rptTerms, bb);\n      HashSet<Integer> distinctGroupIDs = new HashSet<>(tg.values());\n      for (int i=0; i<distinctGroupIDs.size(); i++) {\n        tmp.add(new HashSet<PhrasePositions>());\n      }\n      for (PhrasePositions pp : rpp) {\n        for (Term t: pp.terms) {\n          if (rptTerms.containsKey(t)) {\n            int g = tg.get(t);\n            tmp.get(g).add(pp);\n            assert pp.rptGroup==-1 || pp.rptGroup==g;  \n            pp.rptGroup = g;\n          }\n        }\n      }\n      for (HashSet<PhrasePositions> hs : tmp) {\n        res.add(new ArrayList<>(hs));\n      }\n    }\n    return res;\n  }\n\n","sourceOld":"  /** Detect repetition groups. Done once - for first doc */\n  private ArrayList<ArrayList<PhrasePositions>> gatherRptGroups(LinkedHashMap<Term,Integer> rptTerms) throws IOException {\n    PhrasePositions[] rpp = repeatingPPs(rptTerms); \n    ArrayList<ArrayList<PhrasePositions>> res = new ArrayList<>();\n    if (!hasMultiTermRpts) {\n      // simpler - no multi-terms - can base on positions in first doc\n      for (int i=0; i<rpp.length; i++) {\n        PhrasePositions pp = rpp[i];\n        if (pp.rptGroup >=0) continue; // already marked as a repetition\n        int tpPos = tpPos(pp);\n        for (int j=i+1; j<rpp.length; j++) {\n          PhrasePositions pp2 = rpp[j];\n          if (\n              pp2.rptGroup >=0        // already marked as a repetition\n              || pp2.offset == pp.offset // not a repetition: two PPs are originally in same offset in the query! \n              || tpPos(pp2) != tpPos) {  // not a repetition\n            continue; \n          }\n          // a repetition\n          int g = pp.rptGroup;\n          if (g < 0) {\n            g = res.size();\n            pp.rptGroup = g;  \n            ArrayList<PhrasePositions> rl = new ArrayList<>(2);\n            rl.add(pp);\n            res.add(rl); \n          }\n          pp2.rptGroup = g;\n          res.get(g).add(pp2);\n        }\n      }\n    } else {\n      // more involved - has multi-terms\n      ArrayList<HashSet<PhrasePositions>> tmp = new ArrayList<>();\n      ArrayList<FixedBitSet> bb = ppTermsBitSets(rpp, rptTerms);\n      unionTermGroups(bb);\n      HashMap<Term,Integer> tg = termGroups(rptTerms, bb);\n      HashSet<Integer> distinctGroupIDs = new HashSet<>(tg.values());\n      for (int i=0; i<distinctGroupIDs.size(); i++) {\n        tmp.add(new HashSet<PhrasePositions>());\n      }\n      for (PhrasePositions pp : rpp) {\n        for (Term t: pp.terms) {\n          if (rptTerms.containsKey(t)) {\n            int g = tg.get(t);\n            tmp.get(g).add(pp);\n            assert pp.rptGroup==-1 || pp.rptGroup==g;  \n            pp.rptGroup = g;\n          }\n        }\n      }\n      for (HashSet<PhrasePositions> hs : tmp) {\n        res.add(new ArrayList<>(hs));\n      }\n    }\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3b11b9d5eaf9707760ca5151530830a825197023":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3b11b9d5eaf9707760ca5151530830a825197023"]},"commit2Childs":{"3b11b9d5eaf9707760ca5151530830a825197023":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3b11b9d5eaf9707760ca5151530830a825197023"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}