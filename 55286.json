{"path":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","commits":[{"id":"01e5948db9a07144112d2f08f28ca2e3cd880348","date":1301759232,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","pathOld":"/dev/null","sourceNew":"  public void testPartialOptimize() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"45669a651c970812a680841b97a77cce06af559f","date":1301922222,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","pathOld":"/dev/null","sourceNew":"  public void testPartialOptimize() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","sourceNew":"  public void testPartialOptimize() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testPartialOptimize() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","sourceNew":"  public void testPartialOptimize() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testPartialOptimize() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","pathOld":"/dev/null","sourceNew":"  public void testPartialOptimize() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","pathOld":"/dev/null","sourceNew":"  public void testPartialOptimize() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f83af14a2a8131b14d7aee6274c740334e0363d3","date":1307579822,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","sourceNew":"  public void testPartialOptimize() throws Exception {\n    int num = atLeast(10);\n    for(int iter=0;iter<num;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testPartialOptimize() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","sourceNew":"  public void testPartialOptimize() throws Exception {\n    int num = atLeast(10);\n    for(int iter=0;iter<num;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testPartialOptimize() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","sourceNew":"  public void testPartialOptimize() throws Exception {\n    int num = atLeast(10);\n    for(int iter=0;iter<num;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testPartialOptimize() throws Exception {\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","sourceNew":"  public void testPartialOptimize() throws Exception {\n    int num = atLeast(10);\n    for(int iter=0;iter<num;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), TextField.TYPE_UNSTORED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testPartialOptimize() throws Exception {\n    int num = atLeast(10);\n    for(int iter=0;iter<num;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), Field.Store.NO, Field.Index.ANALYZED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","sourceNew":"  public void testPartialOptimize() throws Exception {\n    int num = atLeast(10);\n    for(int iter=0;iter<num;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), TextField.TYPE_UNSTORED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testPartialOptimize() throws Exception {\n    int num = atLeast(10);\n    for(int iter=0;iter<num;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      w.setInfoStream(VERBOSE ? System.out : null);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), TextField.TYPE_UNSTORED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTieredMergePolicy#testPartialOptimize().mjava","sourceNew":"  public void testPartialMerge() throws Exception {\n    int num = atLeast(10);\n    for(int iter=0;iter<num;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), TextField.TYPE_UNSTORED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: merge to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.forceMerge(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testPartialOptimize() throws Exception {\n    int num = atLeast(10);\n    for(int iter=0;iter<num;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n      conf.setMergeScheduler(new SerialMergeScheduler());\n      TieredMergePolicy tmp = newTieredMergePolicy();\n      conf.setMergePolicy(tmp);\n      conf.setMaxBufferedDocs(2);\n      tmp.setMaxMergeAtOnce(3);\n      tmp.setSegmentsPerTier(6);\n\n      IndexWriter w = new IndexWriter(dir, conf);\n      int maxCount = 0;\n      final int numDocs = _TestUtil.nextInt(random, 20, 100);\n      for(int i=0;i<numDocs;i++) {\n        Document doc = new Document();\n        doc.add(newField(\"content\", \"aaa \" + (i%4), TextField.TYPE_UNSTORED));\n        w.addDocument(doc);\n        int count = w.getSegmentCount();\n        maxCount = Math.max(count, maxCount);\n        assertTrue(\"count=\" + count + \" maxCount=\" + maxCount, count >= maxCount-3);\n      }\n\n      w.flush(true, true);\n\n      int segmentCount = w.getSegmentCount();\n      int targetCount = _TestUtil.nextInt(random, 1, segmentCount);\n      if (VERBOSE) {\n        System.out.println(\"TEST: optimize to \" + targetCount + \" segs (current count=\" + segmentCount + \")\");\n      }\n      w.optimize(targetCount);\n      assertEquals(targetCount, w.getSegmentCount());\n\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["a3776dccca01c11e7046323cfad46a3b4a471233","f83af14a2a8131b14d7aee6274c740334e0363d3"],"f83af14a2a8131b14d7aee6274c740334e0363d3":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"06584e6e98d592b34e1329b384182f368d2025e8":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["06584e6e98d592b34e1329b384182f368d2025e8"],"962d04139994fce5193143ef35615499a9a96d78":["45669a651c970812a680841b97a77cce06af559f","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"01e5948db9a07144112d2f08f28ca2e3cd880348":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["01e5948db9a07144112d2f08f28ca2e3cd880348"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","f83af14a2a8131b14d7aee6274c740334e0363d3"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["f83af14a2a8131b14d7aee6274c740334e0363d3"],"45669a651c970812a680841b97a77cce06af559f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","01e5948db9a07144112d2f08f28ca2e3cd880348"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"]},"commit2Childs":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":[],"f83af14a2a8131b14d7aee6274c740334e0363d3":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"06584e6e98d592b34e1329b384182f368d2025e8":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"962d04139994fce5193143ef35615499a9a96d78":[],"01e5948db9a07144112d2f08f28ca2e3cd880348":["f2c5f0cb44df114db4228c8f77861714b5cabaea","45669a651c970812a680841b97a77cce06af559f"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["f83af14a2a8131b14d7aee6274c740334e0363d3","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["135621f3a0670a9394eb563224a3b76cc4dddc0f","01e5948db9a07144112d2f08f28ca2e3cd880348","a3776dccca01c11e7046323cfad46a3b4a471233","45669a651c970812a680841b97a77cce06af559f"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["06584e6e98d592b34e1329b384182f368d2025e8"],"45669a651c970812a680841b97a77cce06af559f":["962d04139994fce5193143ef35615499a9a96d78"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","962d04139994fce5193143ef35615499a9a96d78","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}