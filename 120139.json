{"path":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40CompoundReader#readEntries(Directory,String).mjava","commits":[{"id":"989d940c4bf402188f4f0ae13736836885227383","date":1412263633,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40CompoundReader#readEntries(Directory,String).mjava","pathOld":"/dev/null","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, Lucene40CompoundWriter.ENTRY_CODEC, Lucene40CompoundWriter.VERSION_START, Lucene40CompoundWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= Lucene40CompoundWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9c34e07420c03a037d73169b35f349c2ad6fd8c7","date":1412304383,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40CompoundReader#readEntries(Directory,String).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40CompoundReader#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             Lucene40CompoundFormat.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, Lucene40CompoundWriter.ENTRY_CODEC, Lucene40CompoundWriter.VERSION_START, Lucene40CompoundWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= Lucene40CompoundWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, Lucene40CompoundWriter.ENTRY_CODEC, Lucene40CompoundWriter.VERSION_START, Lucene40CompoundWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= Lucene40CompoundWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40CompoundReader#readEntries(Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             Lucene40CompoundFormat.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, Lucene40CompoundWriter.ENTRY_CODEC, Lucene40CompoundWriter.VERSION_START, Lucene40CompoundWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= Lucene40CompoundWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71387d8cb6923eb831b17a8b734608ba2e21c653","date":1414126093,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40CompoundReader#readEntries(Directory,String).mjava","sourceNew":null,"sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             Lucene40CompoundFormat.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, Lucene40CompoundWriter.ENTRY_CODEC, Lucene40CompoundWriter.VERSION_START, Lucene40CompoundWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= Lucene40CompoundWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"989d940c4bf402188f4f0ae13736836885227383":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9bb9a29a5e71a90295f175df8919802993142c9a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9c34e07420c03a037d73169b35f349c2ad6fd8c7"],"9c34e07420c03a037d73169b35f349c2ad6fd8c7":["989d940c4bf402188f4f0ae13736836885227383"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"71387d8cb6923eb831b17a8b734608ba2e21c653":["9bb9a29a5e71a90295f175df8919802993142c9a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71387d8cb6923eb831b17a8b734608ba2e21c653"]},"commit2Childs":{"989d940c4bf402188f4f0ae13736836885227383":["9c34e07420c03a037d73169b35f349c2ad6fd8c7"],"9bb9a29a5e71a90295f175df8919802993142c9a":["71387d8cb6923eb831b17a8b734608ba2e21c653"],"9c34e07420c03a037d73169b35f349c2ad6fd8c7":["9bb9a29a5e71a90295f175df8919802993142c9a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["989d940c4bf402188f4f0ae13736836885227383","9bb9a29a5e71a90295f175df8919802993142c9a"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}