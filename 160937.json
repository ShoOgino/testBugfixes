{"path":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#getCollationKey(String,String).mjava","commits":[{"id":"14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64","date":1385598663,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#getCollationKey(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the text with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef getCollationKey(String field, String text) {\n    try (TokenStream source = analyzer.tokenStream(field, text)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      // we control the analyzer here: most errors are impossible\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for text: \" + text);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n      \n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to analyze text: \" + text, e);\n    }\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    try (TokenStream source = analyzer.tokenStream(field, part)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      // we control the analyzer here: most errors are impossible\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n      \n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable analyze range part: \" + part, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#getCollationKey(String,String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * analyze the text with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef getCollationKey(String field, String text) {\n    try (TokenStream source = analyzer.tokenStream(field, text)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      // we control the analyzer here: most errors are impossible\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for text: \" + text);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n      \n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to analyze text: \" + text, e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"804b857d1066ab5185b3b9101bde41b0b71426ec","date":1435846169,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#getCollationKey(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#getCollationKey(String,String).mjava","sourceNew":"  /**\n   * analyze the text with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef getCollationKey(String field, String text) {\n    try (TokenStream source = analyzer.tokenStream(field, text)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      \n\n      // we control the analyzer here: most errors are impossible\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for text: \" + text);\n      BytesRef bytes = BytesRef.deepCopyOf(termAtt.getBytesRef());\n      assert !source.incrementToken();\n      \n      source.end();\n      return bytes;\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to analyze text: \" + text, e);\n    }\n  }\n\n","sourceOld":"  /**\n   * analyze the text with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef getCollationKey(String field, String text) {\n    try (TokenStream source = analyzer.tokenStream(field, text)) {\n      source.reset();\n      \n      TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n      BytesRef bytes = termAtt.getBytesRef();\n\n      // we control the analyzer here: most errors are impossible\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for text: \" + text);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n      \n      source.end();\n      return BytesRef.deepCopyOf(bytes);\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to analyze text: \" + text, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["804b857d1066ab5185b3b9101bde41b0b71426ec"]},"commit2Childs":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"14b8979f99ff6ba77ce7fd57b57c86ace7a1ef64":["804b857d1066ab5185b3b9101bde41b0b71426ec","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}