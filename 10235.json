{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testCheckPendingFlushPostUpdate().mjava","commits":[{"id":"f1ea5763a93795952100d48e19c48f19777c552c","date":1512660172,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testCheckPendingFlushPostUpdate().mjava","pathOld":"/dev/null","sourceNew":"  public void testCheckPendingFlushPostUpdate() throws IOException, InterruptedException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    Set<String> flushingThreads = Collections.synchronizedSet(new HashSet<>());\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        StackTraceElement[] trace = new Exception().getStackTrace();\n        for (int i = 0; i < trace.length; i++) {\n          if (\"flush\".equals(trace[i].getMethodName())\n              && \"org.apache.lucene.index.DocumentsWriterPerThread\".equals(trace[i].getClassName())) {\n            flushingThreads.add(Thread.currentThread().getName());\n            break;\n          }\n        }\n      }\n    });\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig()\n        .setCheckPendingFlushUpdate(false)\n        .setMaxBufferedDocs(Integer.MAX_VALUE)\n        .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));\n    AtomicBoolean done = new AtomicBoolean(false);\n    int numThreads = 1 + random().nextInt(3);\n    CountDownLatch latch = new CountDownLatch(numThreads);\n    Set<String> indexingThreads = new HashSet<>();\n    Thread[] threads = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      threads[i] = new Thread(() -> {\n        latch.countDown();\n        int numDocs = 0;\n        while (done.get() == false) {\n\n          Document doc = new Document();\n          doc.add(new StringField(\"id\", \"foo\", Field.Store.YES));\n          try {\n            w.addDocument(doc);\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          }\n          if (numDocs++ % 10 == 0) {\n            Thread.yield();\n          }\n        }\n      });\n      indexingThreads.add(threads[i].getName());\n      threads[i].start();\n    }\n    latch.await();\n    try {\n      int numIters = rarely() ? 1 + random().nextInt(5) : 1;\n      for (int i = 0; i < numIters; i++) {\n        waitForDocs(w);\n        w.commit();\n        assertTrue(flushingThreads.toString(), flushingThreads.contains(Thread.currentThread().getName()));\n        flushingThreads.retainAll(indexingThreads);\n        assertTrue(flushingThreads.toString(), flushingThreads.isEmpty());\n      }\n      w.getConfig().setCheckPendingFlushUpdate(true);\n      numIters = 0;\n      while (true) {\n        assertFalse(\"should finish in less than 100 iterations\", numIters++ >= 100);\n        waitForDocs(w);\n        w.flush();\n        flushingThreads.retainAll(indexingThreads);\n        if (flushingThreads.isEmpty() == false) {\n          break;\n        }\n      }\n    } finally {\n      done.set(true);\n      for (int i = 0; i < numThreads; i++) {\n        threads[i].join();\n      }\n      IOUtils.close(w, dir);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testCheckPendingFlushPostUpdate().mjava","pathOld":"/dev/null","sourceNew":"  public void testCheckPendingFlushPostUpdate() throws IOException, InterruptedException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    Set<String> flushingThreads = Collections.synchronizedSet(new HashSet<>());\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        StackTraceElement[] trace = new Exception().getStackTrace();\n        for (int i = 0; i < trace.length; i++) {\n          if (\"flush\".equals(trace[i].getMethodName())\n              && \"org.apache.lucene.index.DocumentsWriterPerThread\".equals(trace[i].getClassName())) {\n            flushingThreads.add(Thread.currentThread().getName());\n            break;\n          }\n        }\n      }\n    });\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig()\n        .setCheckPendingFlushUpdate(false)\n        .setMaxBufferedDocs(Integer.MAX_VALUE)\n        .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));\n    AtomicBoolean done = new AtomicBoolean(false);\n    int numThreads = 1 + random().nextInt(3);\n    CountDownLatch latch = new CountDownLatch(numThreads);\n    Set<String> indexingThreads = new HashSet<>();\n    Thread[] threads = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      threads[i] = new Thread(() -> {\n        latch.countDown();\n        int numDocs = 0;\n        while (done.get() == false) {\n\n          Document doc = new Document();\n          doc.add(new StringField(\"id\", \"foo\", Field.Store.YES));\n          try {\n            w.addDocument(doc);\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          }\n          if (numDocs++ % 10 == 0) {\n            Thread.yield();\n          }\n        }\n      });\n      indexingThreads.add(threads[i].getName());\n      threads[i].start();\n    }\n    latch.await();\n    try {\n      int numIters = rarely() ? 1 + random().nextInt(5) : 1;\n      for (int i = 0; i < numIters; i++) {\n        waitForDocs(w);\n        w.commit();\n        assertTrue(flushingThreads.toString(), flushingThreads.contains(Thread.currentThread().getName()));\n        flushingThreads.retainAll(indexingThreads);\n        assertTrue(flushingThreads.toString(), flushingThreads.isEmpty());\n      }\n      w.getConfig().setCheckPendingFlushUpdate(true);\n      numIters = 0;\n      while (true) {\n        assertFalse(\"should finish in less than 100 iterations\", numIters++ >= 100);\n        waitForDocs(w);\n        w.flush();\n        flushingThreads.retainAll(indexingThreads);\n        if (flushingThreads.isEmpty() == false) {\n          break;\n        }\n      }\n    } finally {\n      done.set(true);\n      for (int i = 0; i < numThreads; i++) {\n        threads[i].join();\n      }\n      IOUtils.close(w, dir);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ca74ff59eae86a0bcce9cd5c062498fbd2242e","date":1512738648,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testCheckPendingFlushPostUpdate().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testCheckPendingFlushPostUpdate().mjava","sourceNew":"  public void testCheckPendingFlushPostUpdate() throws IOException, InterruptedException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    Set<String> flushingThreads = Collections.synchronizedSet(new HashSet<>());\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        StackTraceElement[] trace = new Exception().getStackTrace();\n        for (int i = 0; i < trace.length; i++) {\n          if (\"flush\".equals(trace[i].getMethodName())\n              && \"org.apache.lucene.index.DocumentsWriterPerThread\".equals(trace[i].getClassName())) {\n            flushingThreads.add(Thread.currentThread().getName());\n            break;\n          }\n        }\n      }\n    });\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig()\n        .setCheckPendingFlushUpdate(false)\n        .setMaxBufferedDocs(Integer.MAX_VALUE)\n        .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));\n    AtomicBoolean done = new AtomicBoolean(false);\n    int numThreads = 2 + random().nextInt(3);\n    CountDownLatch latch = new CountDownLatch(numThreads);\n    Set<String> indexingThreads = new HashSet<>();\n    Thread[] threads = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      threads[i] = new Thread(() -> {\n        latch.countDown();\n        int numDocs = 0;\n        while (done.get() == false) {\n\n          Document doc = new Document();\n          doc.add(new StringField(\"id\", \"foo\", Field.Store.YES));\n          try {\n            w.addDocument(doc);\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          }\n          if (numDocs++ % 10 == 0) {\n            Thread.yield();\n          }\n        }\n      });\n      indexingThreads.add(threads[i].getName());\n      threads[i].start();\n    }\n    latch.await();\n    try {\n      int numIters = rarely() ? 1 + random().nextInt(5) : 1;\n      for (int i = 0; i < numIters; i++) {\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.commit();\n        assertTrue(flushingThreads.toString(), flushingThreads.contains(Thread.currentThread().getName()));\n        flushingThreads.retainAll(indexingThreads);\n        assertTrue(flushingThreads.toString(), flushingThreads.isEmpty());\n      }\n      w.getConfig().setCheckPendingFlushUpdate(true);\n      numIters = 0;\n      while (true) {\n        assertFalse(\"should finish in less than 100 iterations\", numIters++ >= 100);\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.flush();\n        flushingThreads.retainAll(indexingThreads);\n        if (flushingThreads.isEmpty() == false) {\n          break;\n        }\n      }\n    } finally {\n      done.set(true);\n      for (int i = 0; i < numThreads; i++) {\n        threads[i].join();\n      }\n      IOUtils.close(w, dir);\n    }\n  }\n\n","sourceOld":"  public void testCheckPendingFlushPostUpdate() throws IOException, InterruptedException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    Set<String> flushingThreads = Collections.synchronizedSet(new HashSet<>());\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        StackTraceElement[] trace = new Exception().getStackTrace();\n        for (int i = 0; i < trace.length; i++) {\n          if (\"flush\".equals(trace[i].getMethodName())\n              && \"org.apache.lucene.index.DocumentsWriterPerThread\".equals(trace[i].getClassName())) {\n            flushingThreads.add(Thread.currentThread().getName());\n            break;\n          }\n        }\n      }\n    });\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig()\n        .setCheckPendingFlushUpdate(false)\n        .setMaxBufferedDocs(Integer.MAX_VALUE)\n        .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));\n    AtomicBoolean done = new AtomicBoolean(false);\n    int numThreads = 1 + random().nextInt(3);\n    CountDownLatch latch = new CountDownLatch(numThreads);\n    Set<String> indexingThreads = new HashSet<>();\n    Thread[] threads = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      threads[i] = new Thread(() -> {\n        latch.countDown();\n        int numDocs = 0;\n        while (done.get() == false) {\n\n          Document doc = new Document();\n          doc.add(new StringField(\"id\", \"foo\", Field.Store.YES));\n          try {\n            w.addDocument(doc);\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          }\n          if (numDocs++ % 10 == 0) {\n            Thread.yield();\n          }\n        }\n      });\n      indexingThreads.add(threads[i].getName());\n      threads[i].start();\n    }\n    latch.await();\n    try {\n      int numIters = rarely() ? 1 + random().nextInt(5) : 1;\n      for (int i = 0; i < numIters; i++) {\n        waitForDocs(w);\n        w.commit();\n        assertTrue(flushingThreads.toString(), flushingThreads.contains(Thread.currentThread().getName()));\n        flushingThreads.retainAll(indexingThreads);\n        assertTrue(flushingThreads.toString(), flushingThreads.isEmpty());\n      }\n      w.getConfig().setCheckPendingFlushUpdate(true);\n      numIters = 0;\n      while (true) {\n        assertFalse(\"should finish in less than 100 iterations\", numIters++ >= 100);\n        waitForDocs(w);\n        w.flush();\n        flushingThreads.retainAll(indexingThreads);\n        if (flushingThreads.isEmpty() == false) {\n          break;\n        }\n      }\n    } finally {\n      done.set(true);\n      for (int i = 0; i < numThreads; i++) {\n        threads[i].join();\n      }\n      IOUtils.close(w, dir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"20b20de317c33f1d6e07d9280783d860035c5b80","date":1512905863,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testCheckPendingFlushPostUpdate().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testCheckPendingFlushPostUpdate().mjava","sourceNew":"  public void testCheckPendingFlushPostUpdate() throws IOException, InterruptedException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    Set<String> flushingThreads = Collections.synchronizedSet(new HashSet<>());\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        StackTraceElement[] trace = new Exception().getStackTrace();\n        for (int i = 0; i < trace.length; i++) {\n          if (\"flush\".equals(trace[i].getMethodName())\n              && \"org.apache.lucene.index.DocumentsWriterPerThread\".equals(trace[i].getClassName())) {\n            flushingThreads.add(Thread.currentThread().getName());\n            break;\n          }\n        }\n      }\n    });\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig()\n        .setCheckPendingFlushUpdate(false)\n        .setMaxBufferedDocs(Integer.MAX_VALUE)\n        .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));\n    AtomicBoolean done = new AtomicBoolean(false);\n    int numThreads = 2 + random().nextInt(3);\n    CountDownLatch latch = new CountDownLatch(numThreads);\n    Set<String> indexingThreads = new HashSet<>();\n    Thread[] threads = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      threads[i] = new Thread(() -> {\n        latch.countDown();\n        int numDocs = 0;\n        while (done.get() == false) {\n\n          Document doc = new Document();\n          doc.add(new StringField(\"id\", \"foo\", Field.Store.YES));\n          try {\n            w.addDocument(doc);\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          }\n          if (numDocs++ % 10 == 0) {\n            Thread.yield();\n          }\n        }\n      });\n      indexingThreads.add(threads[i].getName());\n      threads[i].start();\n    }\n    latch.await();\n    try {\n      int numIters = rarely() ? 1 + random().nextInt(5) : 1;\n      for (int i = 0; i < numIters; i++) {\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.commit();\n        assertTrue(flushingThreads.toString(), flushingThreads.contains(Thread.currentThread().getName()));\n        flushingThreads.retainAll(indexingThreads);\n        assertTrue(flushingThreads.toString(), flushingThreads.isEmpty());\n      }\n      w.getConfig().setCheckPendingFlushUpdate(true);\n      numIters = 0;\n      while (true) {\n        assertFalse(\"should finish in less than 100 iterations\", numIters++ >= 100);\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.flush();\n        flushingThreads.retainAll(indexingThreads);\n        if (flushingThreads.isEmpty() == false) {\n          break;\n        }\n      }\n    } finally {\n      done.set(true);\n      for (int i = 0; i < numThreads; i++) {\n        threads[i].join();\n      }\n      IOUtils.close(w, dir);\n    }\n  }\n\n","sourceOld":"  public void testCheckPendingFlushPostUpdate() throws IOException, InterruptedException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    Set<String> flushingThreads = Collections.synchronizedSet(new HashSet<>());\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        StackTraceElement[] trace = new Exception().getStackTrace();\n        for (int i = 0; i < trace.length; i++) {\n          if (\"flush\".equals(trace[i].getMethodName())\n              && \"org.apache.lucene.index.DocumentsWriterPerThread\".equals(trace[i].getClassName())) {\n            flushingThreads.add(Thread.currentThread().getName());\n            break;\n          }\n        }\n      }\n    });\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig()\n        .setCheckPendingFlushUpdate(false)\n        .setMaxBufferedDocs(Integer.MAX_VALUE)\n        .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));\n    AtomicBoolean done = new AtomicBoolean(false);\n    int numThreads = 1 + random().nextInt(3);\n    CountDownLatch latch = new CountDownLatch(numThreads);\n    Set<String> indexingThreads = new HashSet<>();\n    Thread[] threads = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      threads[i] = new Thread(() -> {\n        latch.countDown();\n        int numDocs = 0;\n        while (done.get() == false) {\n\n          Document doc = new Document();\n          doc.add(new StringField(\"id\", \"foo\", Field.Store.YES));\n          try {\n            w.addDocument(doc);\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          }\n          if (numDocs++ % 10 == 0) {\n            Thread.yield();\n          }\n        }\n      });\n      indexingThreads.add(threads[i].getName());\n      threads[i].start();\n    }\n    latch.await();\n    try {\n      int numIters = rarely() ? 1 + random().nextInt(5) : 1;\n      for (int i = 0; i < numIters; i++) {\n        waitForDocs(w);\n        w.commit();\n        assertTrue(flushingThreads.toString(), flushingThreads.contains(Thread.currentThread().getName()));\n        flushingThreads.retainAll(indexingThreads);\n        assertTrue(flushingThreads.toString(), flushingThreads.isEmpty());\n      }\n      w.getConfig().setCheckPendingFlushUpdate(true);\n      numIters = 0;\n      while (true) {\n        assertFalse(\"should finish in less than 100 iterations\", numIters++ >= 100);\n        waitForDocs(w);\n        w.flush();\n        flushingThreads.retainAll(indexingThreads);\n        if (flushingThreads.isEmpty() == false) {\n          break;\n        }\n      }\n    } finally {\n      done.set(true);\n      for (int i = 0; i < numThreads; i++) {\n        threads[i].join();\n      }\n      IOUtils.close(w, dir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2916966cc9815e973c01452a0d76c98c5e0d0926","date":1577444040,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testCheckPendingFlushPostUpdate().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testCheckPendingFlushPostUpdate().mjava","sourceNew":"  public void testCheckPendingFlushPostUpdate() throws IOException, InterruptedException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    Set<String> flushingThreads = Collections.synchronizedSet(new HashSet<>());\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        if (callStackContains(DocumentsWriterPerThread.class, \"flush\")) {\n          flushingThreads.add(Thread.currentThread().getName());\n        }\n      }\n    });\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig()\n        .setCheckPendingFlushUpdate(false)\n        .setMaxBufferedDocs(Integer.MAX_VALUE)\n        .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));\n    AtomicBoolean done = new AtomicBoolean(false);\n    int numThreads = 2 + random().nextInt(3);\n    CountDownLatch latch = new CountDownLatch(numThreads);\n    Set<String> indexingThreads = new HashSet<>();\n    Thread[] threads = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      threads[i] = new Thread(() -> {\n        latch.countDown();\n        int numDocs = 0;\n        while (done.get() == false) {\n\n          Document doc = new Document();\n          doc.add(new StringField(\"id\", \"foo\", Field.Store.YES));\n          try {\n            w.addDocument(doc);\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          }\n          if (numDocs++ % 10 == 0) {\n            Thread.yield();\n          }\n        }\n      });\n      indexingThreads.add(threads[i].getName());\n      threads[i].start();\n    }\n    latch.await();\n    try {\n      int numIters = rarely() ? 1 + random().nextInt(5) : 1;\n      for (int i = 0; i < numIters; i++) {\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.commit();\n        assertTrue(flushingThreads.toString(), flushingThreads.contains(Thread.currentThread().getName()));\n        flushingThreads.retainAll(indexingThreads);\n        assertTrue(flushingThreads.toString(), flushingThreads.isEmpty());\n      }\n      w.getConfig().setCheckPendingFlushUpdate(true);\n      numIters = 0;\n      while (true) {\n        assertFalse(\"should finish in less than 100 iterations\", numIters++ >= 100);\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.flush();\n        flushingThreads.retainAll(indexingThreads);\n        if (flushingThreads.isEmpty() == false) {\n          break;\n        }\n      }\n    } finally {\n      done.set(true);\n      for (int i = 0; i < numThreads; i++) {\n        threads[i].join();\n      }\n      IOUtils.close(w, dir);\n    }\n  }\n\n","sourceOld":"  public void testCheckPendingFlushPostUpdate() throws IOException, InterruptedException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    Set<String> flushingThreads = Collections.synchronizedSet(new HashSet<>());\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        StackTraceElement[] trace = new Exception().getStackTrace();\n        for (int i = 0; i < trace.length; i++) {\n          if (\"flush\".equals(trace[i].getMethodName())\n              && \"org.apache.lucene.index.DocumentsWriterPerThread\".equals(trace[i].getClassName())) {\n            flushingThreads.add(Thread.currentThread().getName());\n            break;\n          }\n        }\n      }\n    });\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig()\n        .setCheckPendingFlushUpdate(false)\n        .setMaxBufferedDocs(Integer.MAX_VALUE)\n        .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));\n    AtomicBoolean done = new AtomicBoolean(false);\n    int numThreads = 2 + random().nextInt(3);\n    CountDownLatch latch = new CountDownLatch(numThreads);\n    Set<String> indexingThreads = new HashSet<>();\n    Thread[] threads = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      threads[i] = new Thread(() -> {\n        latch.countDown();\n        int numDocs = 0;\n        while (done.get() == false) {\n\n          Document doc = new Document();\n          doc.add(new StringField(\"id\", \"foo\", Field.Store.YES));\n          try {\n            w.addDocument(doc);\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          }\n          if (numDocs++ % 10 == 0) {\n            Thread.yield();\n          }\n        }\n      });\n      indexingThreads.add(threads[i].getName());\n      threads[i].start();\n    }\n    latch.await();\n    try {\n      int numIters = rarely() ? 1 + random().nextInt(5) : 1;\n      for (int i = 0; i < numIters; i++) {\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.commit();\n        assertTrue(flushingThreads.toString(), flushingThreads.contains(Thread.currentThread().getName()));\n        flushingThreads.retainAll(indexingThreads);\n        assertTrue(flushingThreads.toString(), flushingThreads.isEmpty());\n      }\n      w.getConfig().setCheckPendingFlushUpdate(true);\n      numIters = 0;\n      while (true) {\n        assertFalse(\"should finish in less than 100 iterations\", numIters++ >= 100);\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.flush();\n        flushingThreads.retainAll(indexingThreads);\n        if (flushingThreads.isEmpty() == false) {\n          break;\n        }\n      }\n    } finally {\n      done.set(true);\n      for (int i = 0; i < numThreads; i++) {\n        threads[i].join();\n      }\n      IOUtils.close(w, dir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"94ec73c5617c177b1d81ddfe04bbff1d08fccecc","date":1577456244,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testCheckPendingFlushPostUpdate().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testCheckPendingFlushPostUpdate().mjava","sourceNew":"  public void testCheckPendingFlushPostUpdate() throws IOException, InterruptedException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    Set<String> flushingThreads = Collections.synchronizedSet(new HashSet<>());\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        if (callStackContains(DocumentsWriterPerThread.class, \"flush\")) {\n          flushingThreads.add(Thread.currentThread().getName());\n        }\n      }\n    });\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig()\n        .setCheckPendingFlushUpdate(false)\n        .setMaxBufferedDocs(Integer.MAX_VALUE)\n        .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));\n    AtomicBoolean done = new AtomicBoolean(false);\n    int numThreads = 2 + random().nextInt(3);\n    CountDownLatch latch = new CountDownLatch(numThreads);\n    Set<String> indexingThreads = new HashSet<>();\n    Thread[] threads = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      threads[i] = new Thread(() -> {\n        latch.countDown();\n        int numDocs = 0;\n        while (done.get() == false) {\n\n          Document doc = new Document();\n          doc.add(new StringField(\"id\", \"foo\", Field.Store.YES));\n          try {\n            w.addDocument(doc);\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          }\n          if (numDocs++ % 10 == 0) {\n            Thread.yield();\n          }\n        }\n      });\n      indexingThreads.add(threads[i].getName());\n      threads[i].start();\n    }\n    latch.await();\n    try {\n      int numIters = rarely() ? 1 + random().nextInt(5) : 1;\n      for (int i = 0; i < numIters; i++) {\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.commit();\n        assertTrue(flushingThreads.toString(), flushingThreads.contains(Thread.currentThread().getName()));\n        flushingThreads.retainAll(indexingThreads);\n        assertTrue(flushingThreads.toString(), flushingThreads.isEmpty());\n      }\n      w.getConfig().setCheckPendingFlushUpdate(true);\n      numIters = 0;\n      while (true) {\n        assertFalse(\"should finish in less than 100 iterations\", numIters++ >= 100);\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.flush();\n        flushingThreads.retainAll(indexingThreads);\n        if (flushingThreads.isEmpty() == false) {\n          break;\n        }\n      }\n    } finally {\n      done.set(true);\n      for (int i = 0; i < numThreads; i++) {\n        threads[i].join();\n      }\n      IOUtils.close(w, dir);\n    }\n  }\n\n","sourceOld":"  public void testCheckPendingFlushPostUpdate() throws IOException, InterruptedException {\n    MockDirectoryWrapper dir = newMockDirectory();\n    Set<String> flushingThreads = Collections.synchronizedSet(new HashSet<>());\n    dir.failOn(new MockDirectoryWrapper.Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        StackTraceElement[] trace = new Exception().getStackTrace();\n        for (int i = 0; i < trace.length; i++) {\n          if (\"flush\".equals(trace[i].getMethodName())\n              && \"org.apache.lucene.index.DocumentsWriterPerThread\".equals(trace[i].getClassName())) {\n            flushingThreads.add(Thread.currentThread().getName());\n            break;\n          }\n        }\n      }\n    });\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig()\n        .setCheckPendingFlushUpdate(false)\n        .setMaxBufferedDocs(Integer.MAX_VALUE)\n        .setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));\n    AtomicBoolean done = new AtomicBoolean(false);\n    int numThreads = 2 + random().nextInt(3);\n    CountDownLatch latch = new CountDownLatch(numThreads);\n    Set<String> indexingThreads = new HashSet<>();\n    Thread[] threads = new Thread[numThreads];\n    for (int i = 0; i < numThreads; i++) {\n      threads[i] = new Thread(() -> {\n        latch.countDown();\n        int numDocs = 0;\n        while (done.get() == false) {\n\n          Document doc = new Document();\n          doc.add(new StringField(\"id\", \"foo\", Field.Store.YES));\n          try {\n            w.addDocument(doc);\n          } catch (Exception e) {\n            throw new AssertionError(e);\n          }\n          if (numDocs++ % 10 == 0) {\n            Thread.yield();\n          }\n        }\n      });\n      indexingThreads.add(threads[i].getName());\n      threads[i].start();\n    }\n    latch.await();\n    try {\n      int numIters = rarely() ? 1 + random().nextInt(5) : 1;\n      for (int i = 0; i < numIters; i++) {\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.commit();\n        assertTrue(flushingThreads.toString(), flushingThreads.contains(Thread.currentThread().getName()));\n        flushingThreads.retainAll(indexingThreads);\n        assertTrue(flushingThreads.toString(), flushingThreads.isEmpty());\n      }\n      w.getConfig().setCheckPendingFlushUpdate(true);\n      numIters = 0;\n      while (true) {\n        assertFalse(\"should finish in less than 100 iterations\", numIters++ >= 100);\n        waitForDocsInBuffers(w, Math.min(2, threads.length));\n        w.flush();\n        flushingThreads.retainAll(indexingThreads);\n        if (flushingThreads.isEmpty() == false) {\n          break;\n        }\n      }\n    } finally {\n      done.set(true);\n      for (int i = 0; i < numThreads; i++) {\n        threads[i].join();\n      }\n      IOUtils.close(w, dir);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f1ea5763a93795952100d48e19c48f19777c552c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"20b20de317c33f1d6e07d9280783d860035c5b80":["417142ff08fda9cf0b72d5133e63097a166c6458","29ca74ff59eae86a0bcce9cd5c062498fbd2242e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"29ca74ff59eae86a0bcce9cd5c062498fbd2242e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"2916966cc9815e973c01452a0d76c98c5e0d0926":["20b20de317c33f1d6e07d9280783d860035c5b80"],"94ec73c5617c177b1d81ddfe04bbff1d08fccecc":["20b20de317c33f1d6e07d9280783d860035c5b80","2916966cc9815e973c01452a0d76c98c5e0d0926"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2916966cc9815e973c01452a0d76c98c5e0d0926"],"417142ff08fda9cf0b72d5133e63097a166c6458":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f1ea5763a93795952100d48e19c48f19777c552c"]},"commit2Childs":{"f1ea5763a93795952100d48e19c48f19777c552c":["417142ff08fda9cf0b72d5133e63097a166c6458"],"20b20de317c33f1d6e07d9280783d860035c5b80":["2916966cc9815e973c01452a0d76c98c5e0d0926","94ec73c5617c177b1d81ddfe04bbff1d08fccecc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f1ea5763a93795952100d48e19c48f19777c552c","417142ff08fda9cf0b72d5133e63097a166c6458"],"29ca74ff59eae86a0bcce9cd5c062498fbd2242e":["20b20de317c33f1d6e07d9280783d860035c5b80"],"2916966cc9815e973c01452a0d76c98c5e0d0926":["94ec73c5617c177b1d81ddfe04bbff1d08fccecc","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"94ec73c5617c177b1d81ddfe04bbff1d08fccecc":[],"417142ff08fda9cf0b72d5133e63097a166c6458":["20b20de317c33f1d6e07d9280783d860035c5b80","29ca74ff59eae86a0bcce9cd5c062498fbd2242e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["94ec73c5617c177b1d81ddfe04bbff1d08fccecc","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}