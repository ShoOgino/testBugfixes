{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers#testDefinitionUsingMethodReference1().mjava","commits":[{"id":"d87468ba199460e43121d57563bbc0560d509c29","date":1446677057,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharTokenizers#testDefinitionUsingMethodReference1().mjava","pathOld":"/dev/null","sourceNew":"  public void testDefinitionUsingMethodReference1() throws Exception {\n    final StringReader reader = new StringReader(\"Tokenizer Test\");\n    final Tokenizer tokenizer = CharTokenizer.fromSeparatorCharPredicate(Character::isWhitespace);\n    tokenizer.setReader(reader);\n    assertTokenStreamContents(tokenizer, new String[] { \"Tokenizer\", \"Test\" });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d87468ba199460e43121d57563bbc0560d509c29"],"d87468ba199460e43121d57563bbc0560d509c29":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d87468ba199460e43121d57563bbc0560d509c29"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"d87468ba199460e43121d57563bbc0560d509c29":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}