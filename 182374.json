{"path":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointsReader).mjava","commits":[{"id":"d561885e9bb6238af1ff8afe8630dcfe49b66ac7","date":1469780634,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointsReader).mjava","pathOld":"/dev/null","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointsReader reader) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = reader.size(fieldName);\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      reader.getValue(i, scratch1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratch1, offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratch1, offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratch1, offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratch1, offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(reader.getDocID(i));\n    }\n\n    build(1, numLeaves, reader, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a20457919db052812998f60294d17daa883ff972","date":1470227748,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointsReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointsReader).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointsReader reader) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = reader.size(fieldName);\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      reader.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(reader.getDocID(i));\n    }\n\n    build(1, numLeaves, reader, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointsReader reader) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = reader.size(fieldName);\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      reader.getValue(i, scratch1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratch1, offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratch1, offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratch1, offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratch1, offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(reader.getDocID(i));\n    }\n\n    build(1, numLeaves, reader, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointsReader).mjava","pathOld":"/dev/null","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointsReader reader) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = reader.size(fieldName);\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      reader.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(reader.getDocID(i));\n    }\n\n    build(1, numLeaves, reader, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"367f57e2ee85b7f7e28cfe73370a22cf67624f65","date":1476778467,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#writeFieldNDims(IndexOutput,String,MutablePointsReader).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointsReader reader) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = reader.size(fieldName);\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      reader.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(reader.getDocID(i));\n    }\n\n    build(1, numLeaves, reader, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a20457919db052812998f60294d17daa883ff972":["d561885e9bb6238af1ff8afe8630dcfe49b66ac7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"367f57e2ee85b7f7e28cfe73370a22cf67624f65":["a20457919db052812998f60294d17daa883ff972"],"d561885e9bb6238af1ff8afe8630dcfe49b66ac7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a20457919db052812998f60294d17daa883ff972"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["367f57e2ee85b7f7e28cfe73370a22cf67624f65"]},"commit2Childs":{"a20457919db052812998f60294d17daa883ff972":["367f57e2ee85b7f7e28cfe73370a22cf67624f65","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d561885e9bb6238af1ff8afe8630dcfe49b66ac7","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"367f57e2ee85b7f7e28cfe73370a22cf67624f65":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d561885e9bb6238af1ff8afe8630dcfe49b66ac7":["a20457919db052812998f60294d17daa883ff972"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}