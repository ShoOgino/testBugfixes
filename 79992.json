{"path":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int,IndexWriter).mjava","commits":[{"id":"027bee21e09164c9ee230395405076d1e0034b30","date":1401521821,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int,IndexWriter).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int).mjava","sourceNew":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last, IndexWriter writer) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentCommitInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos, infos.info(0), writer)) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i), writer);\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1), writer) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","sourceOld":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentCommitInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos, infos.info(0))) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i));\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1)) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d28f215464f76024caf026606f8ea51a5319c53","date":1527226629,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int,MergeContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/LogMergePolicy#findForcedMergesMaxNumSegments(SegmentInfos,int,int,IndexWriter).mjava","sourceNew":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last, MergeContext mergeContext) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentCommitInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos, infos.info(0), mergeContext)) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i), mergeContext);\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1), mergeContext) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","sourceOld":"  /**\n   * Returns the merges necessary to forceMerge the index. This method constraints\n   * the returned merges only by the {@code maxNumSegments} parameter, and\n   * guaranteed that exactly that number of segments will remain in the index.\n   */\n  private MergeSpecification findForcedMergesMaxNumSegments(SegmentInfos infos, int maxNumSegments, int last, IndexWriter writer) throws IOException {\n    MergeSpecification spec = new MergeSpecification();\n    final List<SegmentCommitInfo> segments = infos.asList();\n\n    // First, enroll all \"full\" merges (size\n    // mergeFactor) to potentially be run concurrently:\n    while (last - maxNumSegments + 1 >= mergeFactor) {\n      spec.add(new OneMerge(segments.subList(last - mergeFactor, last)));\n      last -= mergeFactor;\n    }\n\n    // Only if there are no full merges pending do we\n    // add a final partial (< mergeFactor segments) merge:\n    if (0 == spec.merges.size()) {\n      if (maxNumSegments == 1) {\n\n        // Since we must merge down to 1 segment, the\n        // choice is simple:\n        if (last > 1 || !isMerged(infos, infos.info(0), writer)) {\n          spec.add(new OneMerge(segments.subList(0, last)));\n        }\n      } else if (last > maxNumSegments) {\n\n        // Take care to pick a partial merge that is\n        // least cost, but does not make the index too\n        // lopsided.  If we always just picked the\n        // partial tail then we could produce a highly\n        // lopsided index over time:\n\n        // We must merge this many segments to leave\n        // maxNumSegments in the index (from when\n        // forceMerge was first kicked off):\n        final int finalMergeSize = last - maxNumSegments + 1;\n\n        // Consider all possible starting points:\n        long bestSize = 0;\n        int bestStart = 0;\n\n        for(int i=0;i<last-finalMergeSize+1;i++) {\n          long sumSize = 0;\n          for(int j=0;j<finalMergeSize;j++) {\n            sumSize += size(infos.info(j+i), writer);\n          }\n          if (i == 0 || (sumSize < 2*size(infos.info(i-1), writer) && sumSize < bestSize)) {\n            bestStart = i;\n            bestSize = sumSize;\n          }\n        }\n\n        spec.add(new OneMerge(segments.subList(bestStart, bestStart + finalMergeSize)));\n      }\n    }\n    return spec.merges.size() == 0 ? null : spec;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1d28f215464f76024caf026606f8ea51a5319c53":["027bee21e09164c9ee230395405076d1e0034b30"],"027bee21e09164c9ee230395405076d1e0034b30":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1d28f215464f76024caf026606f8ea51a5319c53"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["027bee21e09164c9ee230395405076d1e0034b30"],"1d28f215464f76024caf026606f8ea51a5319c53":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"027bee21e09164c9ee230395405076d1e0034b30":["1d28f215464f76024caf026606f8ea51a5319c53"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}