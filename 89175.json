{"path":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter#addCategoryDocument(CategoryPath,int,int).mjava","commits":[{"id":"ea469eab8fd0f3032f4fcde1c644a721e8309d3b","date":1320301582,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter#addCategoryDocument(CategoryPath,int,int).mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/lucene/LuceneTaxonomyWriter#addCategoryDocument(CategoryPath,int,int).mjava","sourceNew":"  // Note that the methods calling addCategoryDocument() are synchornized,\n  // so this method is effectively synchronized as well, but we'll add\n  // synchronized to be on the safe side, and we can reuse class-local objects\n  // instead of allocating them every time\n  protected synchronized int addCategoryDocument(CategoryPath categoryPath,\n                                                  int length, int parent)\n      throws CorruptIndexException, IOException {\n    // Before Lucene 2.9, position increments >=0 were supported, so we\n    // added 1 to parent to allow the parent -1 (the parent of the root).\n    // Unfortunately, starting with Lucene 2.9, after LUCENE-1542, this is\n    // no longer enough, since 0 is not encoded consistently either (see\n    // comment in SinglePositionTokenStream). But because we must be\n    // backward-compatible with existing indexes, we can't just fix what\n    // we write here (e.g., to write parent+2), and need to do a workaround\n    // in the reader (which knows that anyway only category 0 has a parent\n    // -1).    \n    parentStream.set(parent+1);\n    Document d = new Document();\n    d.add(parentStreamField);\n\n    fullPathField.setValue(categoryPath.toString(delimiter, length));\n    d.add(fullPathField);\n\n    // Note that we do no pass an Analyzer here because the fields that are\n    // added to the Document are untokenized or contains their own TokenStream.\n    // Therefore the IndexWriter's Analyzer has no effect.\n    indexWriter.addDocument(d);\n    int id = nextID++;\n\n    addToCache(categoryPath, length, id);\n\n    // also add to the parent array\n    getParentArray().add(id, parent);\n\n    return id;\n  }\n\n","sourceOld":"  // Note that the methods calling addCategoryDocument() are synchornized,\n  // so this method is effectively synchronized as well, but we'll add\n  // synchronized to be on the safe side, and we can reuse class-local objects\n  // instead of allocating them every time\n  protected synchronized int addCategoryDocument(CategoryPath categoryPath,\n                                                  int length, int parent)\n      throws CorruptIndexException, IOException {\n    // Before Lucene 2.9, position increments >=0 were supported, so we\n    // added 1 to parent to allow the parent -1 (the parent of the root).\n    // Unfortunately, starting with Lucene 2.9, after LUCENE-1542, this is\n    // no longer enough, since 0 is not encoded consistently either (see\n    // comment in SinglePositionTokenStream). But because we must be\n    // backward-compatible with existing indexes, we can't just fix what\n    // we write here (e.g., to write parent+2), and need to do a workaround\n    // in the reader (which knows that anyway only category 0 has a parent\n    // -1).    \n    parentStream.set(parent+1);\n    Document d = new Document();\n    d.add(parentStreamField);\n\n    fullPathField.setValue(categoryPath.toString(delimiter, length));\n    d.add(fullPathField);\n\n    // Note that we do no pass an Analyzer here because the fields that are\n    // added to the Document are untokenized or contains their own TokenStream.\n    // Therefore the IndexWriter's Analyzer has no effect.\n    indexWriter.addDocument(d);\n    int id = nextID++;\n\n    addToCache(categoryPath, length, id);\n\n    // also add to the parent array\n    getParentArray().add(id, parent);\n\n    return id;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a78a90fc9701e511308346ea29f4f5e548bb39fe","date":1329489995,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter#addCategoryDocument(CategoryPath,int,int).mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter#addCategoryDocument(CategoryPath,int,int).mjava","sourceNew":"  // Note that the methods calling addCategoryDocument() are synchornized,\n  // so this method is effectively synchronized as well, but we'll add\n  // synchronized to be on the safe side, and we can reuse class-local objects\n  // instead of allocating them every time\n  protected synchronized int addCategoryDocument(CategoryPath categoryPath,\n                                                  int length, int parent)\n      throws CorruptIndexException, IOException {\n    // Before Lucene 2.9, position increments >=0 were supported, so we\n    // added 1 to parent to allow the parent -1 (the parent of the root).\n    // Unfortunately, starting with Lucene 2.9, after LUCENE-1542, this is\n    // no longer enough, since 0 is not encoded consistently either (see\n    // comment in SinglePositionTokenStream). But because we must be\n    // backward-compatible with existing indexes, we can't just fix what\n    // we write here (e.g., to write parent+2), and need to do a workaround\n    // in the reader (which knows that anyway only category 0 has a parent\n    // -1).    \n    parentStream.set(parent+1);\n    Document d = new Document();\n    d.add(parentStreamField);\n\n    fullPathField.setStringValue(categoryPath.toString(delimiter, length));\n    d.add(fullPathField);\n\n    // Note that we do no pass an Analyzer here because the fields that are\n    // added to the Document are untokenized or contains their own TokenStream.\n    // Therefore the IndexWriter's Analyzer has no effect.\n    indexWriter.addDocument(d);\n    int id = nextID++;\n\n    addToCache(categoryPath, length, id);\n\n    // also add to the parent array\n    getParentArray().add(id, parent);\n\n    return id;\n  }\n\n","sourceOld":"  // Note that the methods calling addCategoryDocument() are synchornized,\n  // so this method is effectively synchronized as well, but we'll add\n  // synchronized to be on the safe side, and we can reuse class-local objects\n  // instead of allocating them every time\n  protected synchronized int addCategoryDocument(CategoryPath categoryPath,\n                                                  int length, int parent)\n      throws CorruptIndexException, IOException {\n    // Before Lucene 2.9, position increments >=0 were supported, so we\n    // added 1 to parent to allow the parent -1 (the parent of the root).\n    // Unfortunately, starting with Lucene 2.9, after LUCENE-1542, this is\n    // no longer enough, since 0 is not encoded consistently either (see\n    // comment in SinglePositionTokenStream). But because we must be\n    // backward-compatible with existing indexes, we can't just fix what\n    // we write here (e.g., to write parent+2), and need to do a workaround\n    // in the reader (which knows that anyway only category 0 has a parent\n    // -1).    \n    parentStream.set(parent+1);\n    Document d = new Document();\n    d.add(parentStreamField);\n\n    fullPathField.setValue(categoryPath.toString(delimiter, length));\n    d.add(fullPathField);\n\n    // Note that we do no pass an Analyzer here because the fields that are\n    // added to the Document are untokenized or contains their own TokenStream.\n    // Therefore the IndexWriter's Analyzer has no effect.\n    indexWriter.addDocument(d);\n    int id = nextID++;\n\n    addToCache(categoryPath, length, id);\n\n    // also add to the parent array\n    getParentArray().add(id, parent);\n\n    return id;\n  }\n\n","bugFix":["89f15687f60bd49cd3d9de427e85c17fd9397d61"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter#addCategoryDocument(CategoryPath,int,int).mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter#addCategoryDocument(CategoryPath,int,int).mjava","sourceNew":"  // Note that the methods calling addCategoryDocument() are synchornized,\n  // so this method is effectively synchronized as well, but we'll add\n  // synchronized to be on the safe side, and we can reuse class-local objects\n  // instead of allocating them every time\n  protected synchronized int addCategoryDocument(CategoryPath categoryPath,\n                                                  int length, int parent)\n      throws CorruptIndexException, IOException {\n    // Before Lucene 2.9, position increments >=0 were supported, so we\n    // added 1 to parent to allow the parent -1 (the parent of the root).\n    // Unfortunately, starting with Lucene 2.9, after LUCENE-1542, this is\n    // no longer enough, since 0 is not encoded consistently either (see\n    // comment in SinglePositionTokenStream). But because we must be\n    // backward-compatible with existing indexes, we can't just fix what\n    // we write here (e.g., to write parent+2), and need to do a workaround\n    // in the reader (which knows that anyway only category 0 has a parent\n    // -1).    \n    parentStream.set(parent+1);\n    Document d = new Document();\n    d.add(parentStreamField);\n\n    fullPathField.setStringValue(categoryPath.toString(delimiter, length));\n    d.add(fullPathField);\n\n    // Note that we do no pass an Analyzer here because the fields that are\n    // added to the Document are untokenized or contains their own TokenStream.\n    // Therefore the IndexWriter's Analyzer has no effect.\n    indexWriter.addDocument(d);\n    int id = nextID++;\n\n    addToCache(categoryPath, length, id);\n\n    // also add to the parent array\n    getParentArray().add(id, parent);\n\n    return id;\n  }\n\n","sourceOld":"  // Note that the methods calling addCategoryDocument() are synchornized,\n  // so this method is effectively synchronized as well, but we'll add\n  // synchronized to be on the safe side, and we can reuse class-local objects\n  // instead of allocating them every time\n  protected synchronized int addCategoryDocument(CategoryPath categoryPath,\n                                                  int length, int parent)\n      throws CorruptIndexException, IOException {\n    // Before Lucene 2.9, position increments >=0 were supported, so we\n    // added 1 to parent to allow the parent -1 (the parent of the root).\n    // Unfortunately, starting with Lucene 2.9, after LUCENE-1542, this is\n    // no longer enough, since 0 is not encoded consistently either (see\n    // comment in SinglePositionTokenStream). But because we must be\n    // backward-compatible with existing indexes, we can't just fix what\n    // we write here (e.g., to write parent+2), and need to do a workaround\n    // in the reader (which knows that anyway only category 0 has a parent\n    // -1).    \n    parentStream.set(parent+1);\n    Document d = new Document();\n    d.add(parentStreamField);\n\n    fullPathField.setStringValue(categoryPath.toString(delimiter, length));\n    d.add(fullPathField);\n\n    // Note that we do no pass an Analyzer here because the fields that are\n    // added to the Document are untokenized or contains their own TokenStream.\n    // Therefore the IndexWriter's Analyzer has no effect.\n    indexWriter.addDocument(d);\n    int id = nextID++;\n\n    addToCache(categoryPath, length, id);\n\n    // also add to the parent array\n    getParentArray().add(id, parent);\n\n    return id;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a78a90fc9701e511308346ea29f4f5e548bb39fe":["ea469eab8fd0f3032f4fcde1c644a721e8309d3b"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"ea469eab8fd0f3032f4fcde1c644a721e8309d3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"a78a90fc9701e511308346ea29f4f5e548bb39fe":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"ea469eab8fd0f3032f4fcde1c644a721e8309d3b":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ea469eab8fd0f3032f4fcde1c644a721e8309d3b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}