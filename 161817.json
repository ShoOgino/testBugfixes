{"path":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","commits":[{"id":"307cff5af2b00f126fdf9d3435b75d5ed4d0f402","date":1305370109,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"/dev/null","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final FirstPassGroupingCollector c1 = new FirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final SecondPassGroupingCollector c2 = new SecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n    \n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c5f61d6a2927b52517a31a8bf022549d33b1dfec","date":1305652854,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final FirstPassGroupingCollector c1 = new FirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final SecondPassGroupingCollector c2 = new SecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final FirstPassGroupingCollector c1 = new FirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final SecondPassGroupingCollector c2 = new SecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n    \n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"/dev/null","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final FirstPassGroupingCollector c1 = new FirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final SecondPassGroupingCollector c2 = new SecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"/dev/null","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final FirstPassGroupingCollector c1 = new FirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final SecondPassGroupingCollector c2 = new SecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1fa60a501961bce2ff07ee1cde7c78699025547e","date":1307054117,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final TermFirstPassGroupingCollector c1 = new TermFirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final TermSecondPassGroupingCollector c2 = new TermSecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final FirstPassGroupingCollector c1 = new FirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final SecondPassGroupingCollector c2 = new SecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c715a0f99152be7566591f323c6c5a25725a1bcb","date":1307118449,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final TermFirstPassGroupingCollector c1 = new TermFirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final TermSecondPassGroupingCollector c2 = new TermSecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final FirstPassGroupingCollector c1 = new FirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final SecondPassGroupingCollector c2 = new SecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e7c99bd45fa88a3d93a03fdd773053bef72268e","date":1307218088,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final TermFirstPassGroupingCollector c1 = new TermFirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final TermSecondPassGroupingCollector c2 = new TermSecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final FirstPassGroupingCollector c1 = new FirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final SecondPassGroupingCollector c2 = new SecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"random text\"));\n    doc.add(new Field(\"id\", customType, \"1\"));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random text\"));\n    doc.add(new Field(\"id\", customType, \"2\"));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random textual data\"));\n    doc.add(new Field(\"id\", customType, \"3\"));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author2\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some random text\"));\n    doc.add(new Field(\"id\", customType, \"4\"));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author3\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random text\"));\n    doc.add(new Field(\"id\", customType, \"5\"));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author3\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"random\"));\n    doc.add(new Field(\"id\", customType, \"6\"));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", TextField.TYPE_STORED,  \"random word stuck in alot of other text\"));\n    doc.add(new Field(\"id\", customType, \"6\"));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final TermFirstPassGroupingCollector c1 = new TermFirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final TermSecondPassGroupingCollector c2 = new TermSecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"1\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"2\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random textual data\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"3\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"4\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"some more random text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"5\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"content\", \"random\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(new Field(\"id\", \"6\", Field.Store.YES, Field.Index.NO));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final TermFirstPassGroupingCollector c1 = new TermFirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final TermSecondPassGroupingCollector c2 = new TermSecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd","date":1317197236,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final TermFirstPassGroupingCollector c1 = new TermFirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final TermSecondPassGroupingCollector c2 = new TermSecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"random text\"));\n    doc.add(new Field(\"id\", customType, \"1\"));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random text\"));\n    doc.add(new Field(\"id\", customType, \"2\"));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author1\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random textual data\"));\n    doc.add(new Field(\"id\", customType, \"3\"));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author2\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some random text\"));\n    doc.add(new Field(\"id\", customType, \"4\"));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author3\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"some more random text\"));\n    doc.add(new Field(\"id\", customType, \"5\"));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, TextField.TYPE_STORED, \"author3\"));\n    doc.add(new Field(\"content\", TextField.TYPE_STORED, \"random\"));\n    doc.add(new Field(\"id\", customType, \"6\"));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", TextField.TYPE_STORED,  \"random word stuck in alot of other text\"));\n    doc.add(new Field(\"id\", customType, \"6\"));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final TermFirstPassGroupingCollector c1 = new TermFirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final TermSecondPassGroupingCollector c2 = new TermSecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00","date":1317931776,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final AbstractFirstPassGroupingCollector c1 = createRandomFirstPassCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final AbstractSecondPassGroupingCollector c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    compareGroupValue(\"author3\", group);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    compareGroupValue(\"author1\", group);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    compareGroupValue(\"author2\", group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    compareGroupValue(null, group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final TermFirstPassGroupingCollector c1 = new TermFirstPassGroupingCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final TermSecondPassGroupingCollector c2 = new TermSecondPassGroupingCollector(groupField, c1.getTopGroups(0, true), groupSort, null, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    assertEquals(new BytesRef(\"author3\"), group.groupValue);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    assertEquals(new BytesRef(\"author1\"), group.groupValue);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    assertEquals(new BytesRef(\"author2\"), group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    assertNull(group.groupValue);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4739c84c362b9673ab5ed3e038ff760c718c30c8","date":1322161679,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final AbstractFirstPassGroupingCollector c1 = createRandomFirstPassCollector(groupField, groupSort, 10, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final AbstractSecondPassGroupingCollector c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    compareGroupValue(\"author3\", group);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    compareGroupValue(\"author1\", group);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    compareGroupValue(\"author2\", group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    compareGroupValue(null, group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n    \n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    // 0\n    Document doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    doc.add(new Field(groupField, \"author1\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    doc.add(new Field(groupField, \"author2\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    doc.add(new Field(groupField, \"author3\", TextField.TYPE_STORED));\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final AbstractFirstPassGroupingCollector c1 = createRandomFirstPassCollector(groupField, groupSort, 10);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final AbstractSecondPassGroupingCollector c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    compareGroupValue(\"author3\", group);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    compareGroupValue(\"author1\", group);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    compareGroupValue(\"author2\", group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    compareGroupValue(null, group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b588d7000deacb0a01f30746b91644112b94326","date":1331201456,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final AbstractFirstPassGroupingCollector<?> c1 = createRandomFirstPassCollector(groupField, groupSort, 10, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final AbstractSecondPassGroupingCollector<?> c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups<?> groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs<?> group = groups.groups[0];\n    compareGroupValue(\"author3\", group);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    compareGroupValue(\"author1\", group);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    compareGroupValue(\"author2\", group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    compareGroupValue(null, group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final AbstractFirstPassGroupingCollector c1 = createRandomFirstPassCollector(groupField, groupSort, 10, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final AbstractSecondPassGroupingCollector c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    compareGroupValue(\"author3\", group);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    compareGroupValue(\"author1\", group);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    compareGroupValue(\"author2\", group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    compareGroupValue(null, group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["85d41890f2bad879e6a04c6dd7d2cf276f973994","d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"38e3b736c7ca086d61b7dbb841c905ee115490da","date":1331657018,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final AbstractFirstPassGroupingCollector<?> c1 = createRandomFirstPassCollector(groupField, groupSort, 10, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final AbstractSecondPassGroupingCollector<?> c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups<?> groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs<?> group = groups.groups[0];\n    compareGroupValue(\"author3\", group);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    compareGroupValue(\"author1\", group);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    compareGroupValue(\"author2\", group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    compareGroupValue(null, group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final AbstractFirstPassGroupingCollector c1 = createRandomFirstPassCollector(groupField, groupSort, 10, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final AbstractSecondPassGroupingCollector c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs group = groups.groups[0];\n    compareGroupValue(\"author3\", group);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    compareGroupValue(\"author1\", group);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    compareGroupValue(\"author2\", group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    compareGroupValue(null, group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random(),\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final AbstractFirstPassGroupingCollector<?> c1 = createRandomFirstPassCollector(groupField, groupSort, 10, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final AbstractSecondPassGroupingCollector<?> c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups<?> groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs<?> group = groups.groups[0];\n    compareGroupValue(\"author3\", group);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    compareGroupValue(\"author1\", group);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    compareGroupValue(\"author2\", group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    compareGroupValue(null, group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random,\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final AbstractFirstPassGroupingCollector<?> c1 = createRandomFirstPassCollector(groupField, groupSort, 10, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final AbstractSecondPassGroupingCollector<?> c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups<?> groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs<?> group = groups.groups[0];\n    compareGroupValue(\"author3\", group);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    compareGroupValue(\"author1\", group);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    compareGroupValue(\"author2\", group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    compareGroupValue(null, group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","pathOld":"modules/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#testBasic().mjava","sourceNew":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random(),\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final AbstractFirstPassGroupingCollector<?> c1 = createRandomFirstPassCollector(groupField, groupSort, 10, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final AbstractSecondPassGroupingCollector<?> c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups<?> groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs<?> group = groups.groups[0];\n    compareGroupValue(\"author3\", group);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    compareGroupValue(\"author1\", group);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    compareGroupValue(\"author2\", group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    compareGroupValue(null, group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testBasic() throws Exception {\n\n    final String groupField = \"author\";\n\n    FieldType customType = new FieldType();\n    customType.setStored(true);\n\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(\n                               random(),\n                               dir,\n                               newIndexWriterConfig(TEST_VERSION_CURRENT,\n                                                    new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    boolean canUseIDV = !\"Lucene3x\".equals(w.w.getConfig().getCodec().getName());\n    // 0\n    Document doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"1\", customType));\n    w.addDocument(doc);\n\n    // 1\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"2\", customType));\n    w.addDocument(doc);\n\n    // 2\n    doc = new Document();\n    addGroupField(doc, groupField, \"author1\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random textual data\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"3\", customType));\n    w.addDocument(doc);\n\n    // 3\n    doc = new Document();\n    addGroupField(doc, groupField, \"author2\", canUseIDV);\n    doc.add(new Field(\"content\", \"some random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"4\", customType));\n    w.addDocument(doc);\n\n    // 4\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"some more random text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"5\", customType));\n    w.addDocument(doc);\n\n    // 5\n    doc = new Document();\n    addGroupField(doc, groupField, \"author3\", canUseIDV);\n    doc.add(new Field(\"content\", \"random\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    // 6 -- no author field\n    doc = new Document();\n    doc.add(new Field(\"content\", \"random word stuck in alot of other text\", TextField.TYPE_STORED));\n    doc.add(new Field(\"id\", \"6\", customType));\n    w.addDocument(doc);\n\n    IndexSearcher indexSearcher = new IndexSearcher(w.getReader());\n    w.close();\n\n    final Sort groupSort = Sort.RELEVANCE;\n    final AbstractFirstPassGroupingCollector<?> c1 = createRandomFirstPassCollector(groupField, groupSort, 10, canUseIDV);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c1);\n\n    final AbstractSecondPassGroupingCollector<?> c2 = createSecondPassCollector(c1, groupField, groupSort, null, 0, 5, true, false, true);\n    indexSearcher.search(new TermQuery(new Term(\"content\", \"random\")), c2);\n\n    final TopGroups<?> groups = c2.getTopGroups(0);\n\n    assertEquals(7, groups.totalHitCount);\n    assertEquals(7, groups.totalGroupedHitCount);\n    assertEquals(4, groups.groups.length);\n\n    // relevance order: 5, 0, 3, 4, 1, 2, 6\n\n    // the later a document is added the higher this docId\n    // value\n    GroupDocs<?> group = groups.groups[0];\n    compareGroupValue(\"author3\", group);\n    assertEquals(2, group.scoreDocs.length);\n    assertEquals(5, group.scoreDocs[0].doc);\n    assertEquals(4, group.scoreDocs[1].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n\n    group = groups.groups[1];\n    compareGroupValue(\"author1\", group);\n    assertEquals(3, group.scoreDocs.length);\n    assertEquals(0, group.scoreDocs[0].doc);\n    assertEquals(1, group.scoreDocs[1].doc);\n    assertEquals(2, group.scoreDocs[2].doc);\n    assertTrue(group.scoreDocs[0].score > group.scoreDocs[1].score);\n    assertTrue(group.scoreDocs[1].score > group.scoreDocs[2].score);\n\n    group = groups.groups[2];\n    compareGroupValue(\"author2\", group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(3, group.scoreDocs[0].doc);\n\n    group = groups.groups[3];\n    compareGroupValue(null, group);\n    assertEquals(1, group.scoreDocs.length);\n    assertEquals(6, group.scoreDocs[0].doc);\n\n    indexSearcher.getIndexReader().close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"c5f61d6a2927b52517a31a8bf022549d33b1dfec":["307cff5af2b00f126fdf9d3435b75d5ed4d0f402"],"38e3b736c7ca086d61b7dbb841c905ee115490da":["4739c84c362b9673ab5ed3e038ff760c718c30c8","6b588d7000deacb0a01f30746b91644112b94326"],"4739c84c362b9673ab5ed3e038ff760c718c30c8":["8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00"],"c715a0f99152be7566591f323c6c5a25725a1bcb":["c3a8a449466c1ff7ce2274fe73dab487256964b4","1fa60a501961bce2ff07ee1cde7c78699025547e"],"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"1fa60a501961bce2ff07ee1cde7c78699025547e":["c5f61d6a2927b52517a31a8bf022549d33b1dfec"],"1e7c99bd45fa88a3d93a03fdd773053bef72268e":["a3776dccca01c11e7046323cfad46a3b4a471233","1fa60a501961bce2ff07ee1cde7c78699025547e"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c5f61d6a2927b52517a31a8bf022549d33b1dfec"],"307cff5af2b00f126fdf9d3435b75d5ed4d0f402":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c5f61d6a2927b52517a31a8bf022549d33b1dfec"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["6b588d7000deacb0a01f30746b91644112b94326"],"6b588d7000deacb0a01f30746b91644112b94326":["4739c84c362b9673ab5ed3e038ff760c718c30c8"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["1fa60a501961bce2ff07ee1cde7c78699025547e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["1509f151d7692d84fae414b2b799ac06ba60fcb4"]},"commit2Childs":{"c5f61d6a2927b52517a31a8bf022549d33b1dfec":["1fa60a501961bce2ff07ee1cde7c78699025547e","c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233"],"38e3b736c7ca086d61b7dbb841c905ee115490da":[],"4739c84c362b9673ab5ed3e038ff760c718c30c8":["38e3b736c7ca086d61b7dbb841c905ee115490da","6b588d7000deacb0a01f30746b91644112b94326"],"c715a0f99152be7566591f323c6c5a25725a1bcb":[],"8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00":["4739c84c362b9673ab5ed3e038ff760c718c30c8"],"1fa60a501961bce2ff07ee1cde7c78699025547e":["c715a0f99152be7566591f323c6c5a25725a1bcb","1e7c99bd45fa88a3d93a03fdd773053bef72268e","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"1e7c99bd45fa88a3d93a03fdd773053bef72268e":[],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["c715a0f99152be7566591f323c6c5a25725a1bcb"],"307cff5af2b00f126fdf9d3435b75d5ed4d0f402":["c5f61d6a2927b52517a31a8bf022549d33b1dfec"],"a3776dccca01c11e7046323cfad46a3b4a471233":["1e7c99bd45fa88a3d93a03fdd773053bef72268e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c3a8a449466c1ff7ce2274fe73dab487256964b4","307cff5af2b00f126fdf9d3435b75d5ed4d0f402","a3776dccca01c11e7046323cfad46a3b4a471233"],"6b588d7000deacb0a01f30746b91644112b94326":["38e3b736c7ca086d61b7dbb841c905ee115490da","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["8b48c85d1bf438ef65fbc1abe44f4e2c04a43e00"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["38e3b736c7ca086d61b7dbb841c905ee115490da","c715a0f99152be7566591f323c6c5a25725a1bcb","1e7c99bd45fa88a3d93a03fdd773053bef72268e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}