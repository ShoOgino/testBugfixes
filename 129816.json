{"path":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","commits":[{"id":"81d695ea56e846db8af5ac4e15826d341ef894e1","date":1361067281,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"/dev/null","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(_TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      BytesRef actual = new BytesRef();\n      BytesRef expected = new BytesRef();\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        single.lookupOrd(i, expected);\n        multi.lookupOrd(i, actual);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<Long>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["14b133bc4d7193efff507eb88f86fcc07c4e8b50","402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ddbb72a33557d2b5bc22ee95daf3281c43560502","date":1361334582,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"/dev/null","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(_TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      BytesRef actual = new BytesRef();\n      BytesRef expected = new BytesRef();\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        single.lookupOrd(i, expected);\n        multi.lookupOrd(i, actual);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<Long>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      BytesRef actual = new BytesRef();\n      BytesRef expected = new BytesRef();\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        single.lookupOrd(i, expected);\n        multi.lookupOrd(i, actual);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<Long>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(_TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      BytesRef actual = new BytesRef();\n      BytesRef expected = new BytesRef();\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        single.lookupOrd(i, expected);\n        multi.lookupOrd(i, actual);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<Long>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      BytesRef actual = new BytesRef();\n      BytesRef expected = new BytesRef();\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        single.lookupOrd(i, expected);\n        multi.lookupOrd(i, actual);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      BytesRef actual = new BytesRef();\n      BytesRef expected = new BytesRef();\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        single.lookupOrd(i, expected);\n        multi.lookupOrd(i, actual);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<Long>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.shutdown();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      BytesRef actual = new BytesRef();\n      BytesRef expected = new BytesRef();\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        single.lookupOrd(i, expected);\n        multi.lookupOrd(i, actual);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      BytesRef actual = new BytesRef();\n      BytesRef expected = new BytesRef();\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        single.lookupOrd(i, expected);\n        multi.lookupOrd(i, actual);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf","date":1401983689,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.shutdown();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.shutdown();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      BytesRef actual = new BytesRef();\n      BytesRef expected = new BytesRef();\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        single.lookupOrd(i, expected);\n        multi.lookupOrd(i, actual);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.shutdown();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad2a673349939e48652bf304cccf673c3412198f","date":1409585169,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    assumeTrue(\"codec does not support SORTED_SET\", defaultCodecSupportsSortedSet());\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":["81d695ea56e846db8af5ac4e15826d341ef894e1"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    AtomicReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6e4b7ec2c9e255a912a3c37dbd8300f77ba2f046","date":1417033646,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = atLeast(500);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlyLeafReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlySegmentReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlyLeafReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      while (true) {\n        int docID = single.nextDoc();\n        assertEquals(docID, multi.nextDoc());\n        if (docID == NO_MORE_DOCS) {\n          break;\n        }\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    testRandomAdvance(merged.getSortedSetDocValues(\"bytes\"), MultiDocValues.getSortedSetValues(ir, \"bytes\"));\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlyLeafReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlyLeafReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      while (true) {\n        int docID = single.nextDoc();\n        assertEquals(docID, multi.nextDoc());\n        if (docID == NO_MORE_DOCS) {\n          break;\n        }\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    testRandomAdvance(merged.getSortedSetDocValues(\"bytes\"), MultiDocValues.getSortedSetValues(ir, \"bytes\"));\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlyLeafReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlyLeafReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      while (true) {\n        int docID = single.nextDoc();\n        assertEquals(docID, multi.nextDoc());\n        if (docID == NO_MORE_DOCS) {\n          break;\n        }\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    testRandomAdvance(merged.getSortedSetDocValues(\"bytes\"), MultiDocValues.getSortedSetValues(ir, \"bytes\"));\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlyLeafReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      for (int i = 0; i < numDocs; i++) {\n        single.setDocument(i);\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        multi.setDocument(i);\n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"14b133bc4d7193efff507eb88f86fcc07c4e8b50","date":1477907694,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlyLeafReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      while (true) {\n        int docID = single.nextDoc();\n        assertEquals(docID, multi.nextDoc());\n        if (docID == NO_MORE_DOCS) {\n          break;\n        }\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    testRandomAdvance(merged.getSortedSetDocValues(\"bytes\"), MultiDocValues.getSortedSetValues(ir, \"bytes\"));\n    testRandomAdvanceExact(merged.getSortedSetDocValues(\"bytes\"), MultiDocValues.getSortedSetValues(ir, \"bytes\"), merged.maxDoc());\n\n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlyLeafReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      while (true) {\n        int docID = single.nextDoc();\n        assertEquals(docID, multi.nextDoc());\n        if (docID == NO_MORE_DOCS) {\n          break;\n        }\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    testRandomAdvance(merged.getSortedSetDocValues(\"bytes\"), MultiDocValues.getSortedSetValues(ir, \"bytes\"));\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":["81d695ea56e846db8af5ac4e15826d341ef894e1"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"320888923ec13b91f53082558f01f4c9960dd226","date":1477926871,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestMultiDocValues#testSortedSetWithDups().mjava","sourceNew":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlyLeafReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      while (true) {\n        int docID = single.nextDoc();\n        assertEquals(docID, multi.nextDoc());\n        if (docID == NO_MORE_DOCS) {\n          break;\n        }\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    testRandomAdvance(merged.getSortedSetDocValues(\"bytes\"), MultiDocValues.getSortedSetValues(ir, \"bytes\"));\n    testRandomAdvanceExact(merged.getSortedSetDocValues(\"bytes\"), MultiDocValues.getSortedSetValues(ir, \"bytes\"), merged.maxDoc());\n\n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","sourceOld":"  // tries to make more dups than testSortedSet\n  public void testSortedSetWithDups() throws Exception {\n    Directory dir = newDirectory();\n    \n    IndexWriterConfig iwc = newIndexWriterConfig(random(), null);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int numDocs = TEST_NIGHTLY ? atLeast(500) : atLeast(50);\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      int numValues = random().nextInt(5);\n      for (int j = 0; j < numValues; j++) {\n        doc.add(new SortedSetDocValuesField(\"bytes\", new BytesRef(TestUtil.randomSimpleString(random(), 2))));\n      }\n      iw.addDocument(doc);\n      if (random().nextInt(17) == 0) {\n        iw.commit();\n      }\n    }\n    DirectoryReader ir = iw.getReader();\n    iw.forceMerge(1);\n    DirectoryReader ir2 = iw.getReader();\n    LeafReader merged = getOnlyLeafReader(ir2);\n    iw.close();\n    \n    SortedSetDocValues multi = MultiDocValues.getSortedSetValues(ir, \"bytes\");\n    SortedSetDocValues single = merged.getSortedSetDocValues(\"bytes\");\n    if (multi == null) {\n      assertNull(single);\n    } else {\n      assertEquals(single.getValueCount(), multi.getValueCount());\n      // check values\n      for (long i = 0; i < single.getValueCount(); i++) {\n        final BytesRef expected = BytesRef.deepCopyOf(single.lookupOrd(i));\n        final BytesRef actual = multi.lookupOrd(i);\n        assertEquals(expected, actual);\n      }\n      // check ord list\n      while (true) {\n        int docID = single.nextDoc();\n        assertEquals(docID, multi.nextDoc());\n        if (docID == NO_MORE_DOCS) {\n          break;\n        }\n        ArrayList<Long> expectedList = new ArrayList<>();\n        long ord;\n        while ((ord = single.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          expectedList.add(ord);\n        }\n        \n        int upto = 0;\n        while ((ord = multi.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n          assertEquals(expectedList.get(upto).longValue(), ord);\n          upto++;\n        }\n        assertEquals(expectedList.size(), upto);\n      }\n    }\n    testRandomAdvance(merged.getSortedSetDocValues(\"bytes\"), MultiDocValues.getSortedSetValues(ir, \"bytes\"));\n    \n    ir.close();\n    ir2.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"6613659748fe4411a7dcf85266e55db1f95f7315":["ddbb72a33557d2b5bc22ee95daf3281c43560502"],"ddbb72a33557d2b5bc22ee95daf3281c43560502":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","81d695ea56e846db8af5ac4e15826d341ef894e1"],"320888923ec13b91f53082558f01f4c9960dd226":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","14b133bc4d7193efff507eb88f86fcc07c4e8b50"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["d0ef034a4f10871667ae75181537775ddcf8ade4","ad2a673349939e48652bf304cccf673c3412198f"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["6e4b7ec2c9e255a912a3c37dbd8300f77ba2f046"],"81d695ea56e846db8af5ac4e15826d341ef894e1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"6e4b7ec2c9e255a912a3c37dbd8300f77ba2f046":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"14b133bc4d7193efff507eb88f86fcc07c4e8b50":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"ad2a673349939e48652bf304cccf673c3412198f":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["14b133bc4d7193efff507eb88f86fcc07c4e8b50"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"ddbb72a33557d2b5bc22ee95daf3281c43560502":["6613659748fe4411a7dcf85266e55db1f95f7315"],"320888923ec13b91f53082558f01f4c9960dd226":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["320888923ec13b91f53082558f01f4c9960dd226"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["6e4b7ec2c9e255a912a3c37dbd8300f77ba2f046"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"81d695ea56e846db8af5ac4e15826d341ef894e1":["ddbb72a33557d2b5bc22ee95daf3281c43560502"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ddbb72a33557d2b5bc22ee95daf3281c43560502","81d695ea56e846db8af5ac4e15826d341ef894e1"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","14b133bc4d7193efff507eb88f86fcc07c4e8b50"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["402ad3ddc9da7b70da1b167667a60ece6a1381fb","ad2a673349939e48652bf304cccf673c3412198f"],"6e4b7ec2c9e255a912a3c37dbd8300f77ba2f046":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"14b133bc4d7193efff507eb88f86fcc07c4e8b50":["320888923ec13b91f53082558f01f4c9960dd226","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ad2a673349939e48652bf304cccf673c3412198f":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["320888923ec13b91f53082558f01f4c9960dd226","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}