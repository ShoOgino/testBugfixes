{"path":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,CloudConfig,ZkNodeProps,NamedList).mjava","commits":[{"id":"c526352db87264a72a7a9ad68c1b769b81e54305","date":1598780188,"type":1,"author":"Ilan Ginzburg","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,CloudConfig,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, CloudConfig cloudConfig, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), cloudConfig, new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, cloudConfig, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, cloudConfig, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(cloudConfig, restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), cloudConfig, new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7b17e79a71117668ecbf8d3417c876e41396565","date":1598973672,"type":5,"author":"Ilan Ginzburg","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,CloudConfig,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, CloudConfig cloudConfig, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), cloudConfig, new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, cloudConfig, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, cloudConfig, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(cloudConfig, restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), cloudConfig, new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e7b17e79a71117668ecbf8d3417c876e41396565":["c526352db87264a72a7a9ad68c1b769b81e54305"],"c526352db87264a72a7a9ad68c1b769b81e54305":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e7b17e79a71117668ecbf8d3417c876e41396565"]},"commit2Childs":{"e7b17e79a71117668ecbf8d3417c876e41396565":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c526352db87264a72a7a9ad68c1b769b81e54305":["e7b17e79a71117668ecbf8d3417c876e41396565"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c526352db87264a72a7a9ad68c1b769b81e54305"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}