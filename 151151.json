{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","commits":[{"id":"9fc0d60683b47b5d922124c31f57c8b34734f9e6","date":1480846684,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","pathOld":"/dev/null","sourceNew":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    if (offlinePointWriter != null) {\n      offlinePointWriter.close();\n    }\n\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    LongBitSet ordBitSet;\n    if (numDims > 1) {\n      if (singleValuePerDoc) {\n        ordBitSet = new LongBitSet(maxDoc);\n      } else {\n        ordBitSet = new LongBitSet(pointCount);\n      }\n    } else {\n      ordBitSet = null;\n    }\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    // Sort all docs once by each dimension:\n    PathSlice[] sortedPointWriters = new PathSlice[numDims];\n\n    // This is only used on exception; on normal code paths we close all files we opened:\n    List<Closeable> toCloseHeroically = new ArrayList<>();\n\n    boolean success = false;\n    try {\n      //long t0 = System.nanoTime();\n      for(int dim=0;dim<numDims;dim++) {\n        sortedPointWriters[dim] = new PathSlice(sort(dim), 0, pointCount);\n      }\n      //long t1 = System.nanoTime();\n      //System.out.println(\"sort time: \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      if (tempInput != null) {\n        tempDir.deleteFile(tempInput.getName());\n        tempInput = null;\n      } else {\n        assert heapPointWriter != null;\n        heapPointWriter = null;\n      }\n\n      build(1, numLeaves, sortedPointWriters,\n            ordBitSet, out,\n            minPackedValue, maxPackedValue,\n            splitPackedValues,\n            leafBlockFPs,\n            toCloseHeroically);\n\n      for(PathSlice slice : sortedPointWriters) {\n        slice.writer.destroy();\n      }\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n        IOUtils.closeWhileHandlingException(toCloseHeroically);\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9856095f7afb5a607bf5e65077615ed91273508c","date":1481837697,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","pathOld":"/dev/null","sourceNew":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    if (offlinePointWriter != null) {\n      offlinePointWriter.close();\n    }\n\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    LongBitSet ordBitSet;\n    if (numDims > 1) {\n      if (singleValuePerDoc) {\n        ordBitSet = new LongBitSet(maxDoc);\n      } else {\n        ordBitSet = new LongBitSet(pointCount);\n      }\n    } else {\n      ordBitSet = null;\n    }\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    // Sort all docs once by each dimension:\n    PathSlice[] sortedPointWriters = new PathSlice[numDims];\n\n    // This is only used on exception; on normal code paths we close all files we opened:\n    List<Closeable> toCloseHeroically = new ArrayList<>();\n\n    boolean success = false;\n    try {\n      //long t0 = System.nanoTime();\n      for(int dim=0;dim<numDims;dim++) {\n        sortedPointWriters[dim] = new PathSlice(sort(dim), 0, pointCount);\n      }\n      //long t1 = System.nanoTime();\n      //System.out.println(\"sort time: \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      if (tempInput != null) {\n        tempDir.deleteFile(tempInput.getName());\n        tempInput = null;\n      } else {\n        assert heapPointWriter != null;\n        heapPointWriter = null;\n      }\n\n      build(1, numLeaves, sortedPointWriters,\n            ordBitSet, out,\n            minPackedValue, maxPackedValue,\n            splitPackedValues,\n            leafBlockFPs,\n            toCloseHeroically);\n\n      for(PathSlice slice : sortedPointWriters) {\n        slice.writer.destroy();\n      }\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n        IOUtils.closeWhileHandlingException(toCloseHeroically);\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6652c943595e92c187ee904c382863013eae28f","date":1539042663,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","sourceNew":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    if (offlinePointWriter != null) {\n      offlinePointWriter.close();\n    }\n\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    LongBitSet ordBitSet;\n    if (numDataDims > 1) {\n      if (singleValuePerDoc) {\n        ordBitSet = new LongBitSet(maxDoc);\n      } else {\n        ordBitSet = new LongBitSet(pointCount);\n      }\n    } else {\n      ordBitSet = null;\n    }\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    // Sort all docs once by each dimension:\n    PathSlice[] sortedPointWriters = new PathSlice[numDataDims];\n\n    // This is only used on exception; on normal code paths we close all files we opened:\n    List<Closeable> toCloseHeroically = new ArrayList<>();\n\n    boolean success = false;\n    try {\n      //long t0 = System.nanoTime();\n      for(int dim=0;dim<numDataDims;dim++) {\n        sortedPointWriters[dim] = new PathSlice(sort(dim), 0, pointCount);\n      }\n      //long t1 = System.nanoTime();\n      //System.out.println(\"sort time: \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      if (tempInput != null) {\n        tempDir.deleteFile(tempInput.getName());\n        tempInput = null;\n      } else {\n        assert heapPointWriter != null;\n        heapPointWriter = null;\n      }\n\n      build(1, numLeaves, sortedPointWriters,\n            ordBitSet, out,\n            minPackedValue, maxPackedValue,\n            splitPackedValues,\n            leafBlockFPs,\n            toCloseHeroically);\n\n      for(PathSlice slice : sortedPointWriters) {\n        slice.writer.destroy();\n      }\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n        IOUtils.closeWhileHandlingException(toCloseHeroically);\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    if (offlinePointWriter != null) {\n      offlinePointWriter.close();\n    }\n\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    LongBitSet ordBitSet;\n    if (numDims > 1) {\n      if (singleValuePerDoc) {\n        ordBitSet = new LongBitSet(maxDoc);\n      } else {\n        ordBitSet = new LongBitSet(pointCount);\n      }\n    } else {\n      ordBitSet = null;\n    }\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    // Sort all docs once by each dimension:\n    PathSlice[] sortedPointWriters = new PathSlice[numDims];\n\n    // This is only used on exception; on normal code paths we close all files we opened:\n    List<Closeable> toCloseHeroically = new ArrayList<>();\n\n    boolean success = false;\n    try {\n      //long t0 = System.nanoTime();\n      for(int dim=0;dim<numDims;dim++) {\n        sortedPointWriters[dim] = new PathSlice(sort(dim), 0, pointCount);\n      }\n      //long t1 = System.nanoTime();\n      //System.out.println(\"sort time: \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      if (tempInput != null) {\n        tempDir.deleteFile(tempInput.getName());\n        tempInput = null;\n      } else {\n        assert heapPointWriter != null;\n        heapPointWriter = null;\n      }\n\n      build(1, numLeaves, sortedPointWriters,\n            ordBitSet, out,\n            minPackedValue, maxPackedValue,\n            splitPackedValues,\n            leafBlockFPs,\n            toCloseHeroically);\n\n      for(PathSlice slice : sortedPointWriters) {\n        slice.writer.destroy();\n      }\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n        IOUtils.closeWhileHandlingException(toCloseHeroically);\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"78bdc7d6906146edb12a1a6c1f765ba680ed5124","date":1549523533,"type":3,"author":"iverase","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","sourceNew":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    PointWriter data;\n\n    if (offlinePointWriter != null) {\n      offlinePointWriter.close();\n      data = offlinePointWriter;\n      tempInput = null;\n    } else {\n      data = heapPointWriter;\n      heapPointWriter = null;\n    }\n\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(numDataDims, bytesPerDim, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    boolean success = false;\n    try {\n\n\n      build(1, numLeaves, data, out,\n          radixSelector, minPackedValue, maxPackedValue,\n            splitPackedValues, leafBlockFPs);\n\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    if (offlinePointWriter != null) {\n      offlinePointWriter.close();\n    }\n\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    LongBitSet ordBitSet;\n    if (numDataDims > 1) {\n      if (singleValuePerDoc) {\n        ordBitSet = new LongBitSet(maxDoc);\n      } else {\n        ordBitSet = new LongBitSet(pointCount);\n      }\n    } else {\n      ordBitSet = null;\n    }\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    // Sort all docs once by each dimension:\n    PathSlice[] sortedPointWriters = new PathSlice[numDataDims];\n\n    // This is only used on exception; on normal code paths we close all files we opened:\n    List<Closeable> toCloseHeroically = new ArrayList<>();\n\n    boolean success = false;\n    try {\n      //long t0 = System.nanoTime();\n      for(int dim=0;dim<numDataDims;dim++) {\n        sortedPointWriters[dim] = new PathSlice(sort(dim), 0, pointCount);\n      }\n      //long t1 = System.nanoTime();\n      //System.out.println(\"sort time: \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      if (tempInput != null) {\n        tempDir.deleteFile(tempInput.getName());\n        tempInput = null;\n      } else {\n        assert heapPointWriter != null;\n        heapPointWriter = null;\n      }\n\n      build(1, numLeaves, sortedPointWriters,\n            ordBitSet, out,\n            minPackedValue, maxPackedValue,\n            splitPackedValues,\n            leafBlockFPs,\n            toCloseHeroically);\n\n      for(PathSlice slice : sortedPointWriters) {\n        slice.writer.destroy();\n      }\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n        IOUtils.closeWhileHandlingException(toCloseHeroically);\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a69ebf290ab26d026cc224e517e0d93d931ac87b","date":1549869083,"type":3,"author":"iverase","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","sourceNew":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    BKDRadixSelector.PathSlice writer;\n    if (offlinePointWriter != null) {\n      offlinePointWriter.close();\n      writer = new BKDRadixSelector.PathSlice(offlinePointWriter, 0, pointCount);\n      tempInput = null;\n    } else {\n      writer =  new BKDRadixSelector.PathSlice(heapPointWriter, 0, pointCount);\n      heapPointWriter = null;\n    }\n\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(numDataDims, bytesPerDim, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    boolean success = false;\n    try {\n\n\n      build(1, numLeaves, writer, out,\n          radixSelector, minPackedValue, maxPackedValue,\n            splitPackedValues, leafBlockFPs);\n\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    PointWriter data;\n\n    if (offlinePointWriter != null) {\n      offlinePointWriter.close();\n      data = offlinePointWriter;\n      tempInput = null;\n    } else {\n      data = heapPointWriter;\n      heapPointWriter = null;\n    }\n\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(numDataDims, bytesPerDim, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    boolean success = false;\n    try {\n\n\n      build(1, numLeaves, data, out,\n          radixSelector, minPackedValue, maxPackedValue,\n            splitPackedValues, leafBlockFPs);\n\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"76a51551f05a6c96a115b5a656837ecc8fd0b1ff","date":1551422476,"type":3,"author":"iverase","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","sourceNew":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    //mark as finished\n    finished = true;\n\n    pointWriter.close();\n    BKDRadixSelector.PathSlice points = new BKDRadixSelector.PathSlice(pointWriter, 0, pointCount);\n    //clean up pointers\n    tempInput = null;\n    pointWriter = null;\n\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(numDataDims, bytesPerDim, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    boolean success = false;\n    try {\n\n\n      build(1, numLeaves, points, out,\n          radixSelector, minPackedValue, maxPackedValue,\n            splitPackedValues, leafBlockFPs);\n\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    BKDRadixSelector.PathSlice writer;\n    if (offlinePointWriter != null) {\n      offlinePointWriter.close();\n      writer = new BKDRadixSelector.PathSlice(offlinePointWriter, 0, pointCount);\n      tempInput = null;\n    } else {\n      writer =  new BKDRadixSelector.PathSlice(heapPointWriter, 0, pointCount);\n      heapPointWriter = null;\n    }\n\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(numDataDims, bytesPerDim, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    boolean success = false;\n    try {\n\n\n      build(1, numLeaves, writer, out,\n          radixSelector, minPackedValue, maxPackedValue,\n            splitPackedValues, leafBlockFPs);\n\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7f06758793500ca773d0df1037290e6e404fb33","date":1562230223,"type":3,"author":"Ignacio Vera","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","sourceNew":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    //mark as finished\n    finished = true;\n\n    pointWriter.close();\n    BKDRadixSelector.PathSlice points = new BKDRadixSelector.PathSlice(pointWriter, 0, pointCount);\n    //clean up pointers\n    tempInput = null;\n    pointWriter = null;\n\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(numDataDims, numIndexDims, bytesPerDim, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    boolean success = false;\n    try {\n\n\n      build(1, numLeaves, points, out,\n          radixSelector, minPackedValue, maxPackedValue,\n            splitPackedValues, leafBlockFPs, new int[maxPointsInLeafNode]);\n\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    //mark as finished\n    finished = true;\n\n    pointWriter.close();\n    BKDRadixSelector.PathSlice points = new BKDRadixSelector.PathSlice(pointWriter, 0, pointCount);\n    //clean up pointers\n    tempInput = null;\n    pointWriter = null;\n\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(numDataDims, bytesPerDim, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    boolean success = false;\n    try {\n\n\n      build(1, numLeaves, points, out,\n          radixSelector, minPackedValue, maxPackedValue,\n            splitPackedValues, leafBlockFPs);\n\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb94bf667d51f9c390c99d97afb36b7caab6b6e9","date":1599548621,"type":3,"author":"Ignacio Vera","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#finish(IndexOutput).mjava","sourceNew":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    //mark as finished\n    finished = true;\n\n    pointWriter.close();\n    BKDRadixSelector.PathSlice points = new BKDRadixSelector.PathSlice(pointWriter, 0, pointCount);\n    //clean up pointers\n    tempInput = null;\n    pointWriter = null;\n\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > config.maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+config.bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= config.maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" config.maxPointsInLeafNode=\" + config.maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(config, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    boolean success = false;\n    try {\n\n\n      build(1, numLeaves, points, out,\n          radixSelector, minPackedValue, maxPackedValue,\n            splitPackedValues, leafBlockFPs, new int[config.maxPointsInLeafNode]);\n\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /** Writes the BKD tree to the provided {@link IndexOutput} and returns the file offset where index was written. */\n  public long finish(IndexOutput out) throws IOException {\n    // System.out.println(\"\\nBKDTreeWriter.finish pointCount=\" + pointCount + \" out=\" + out + \" heapWriter=\" + heapPointWriter);\n\n    // TODO: specialize the 1D case?  it's much faster at indexing time (no partitioning on recurse...)\n\n    // Catch user silliness:\n    if (pointCount == 0) {\n      throw new IllegalStateException(\"must index at least one point\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    //mark as finished\n    finished = true;\n\n    pointWriter.close();\n    BKDRadixSelector.PathSlice points = new BKDRadixSelector.PathSlice(pointWriter, 0, pointCount);\n    //clean up pointers\n    tempInput = null;\n    pointWriter = null;\n\n\n    long countPerLeaf = pointCount;\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = (int) innerNodeCount;\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    // NOTE: we could save the 1+ here, to use a bit less heap at search time, but then we'd need a somewhat costly check at each\n    // step of the recursion to recompute the split dim:\n\n    // Indexed by nodeID, but first (root) nodeID is 1.  We do 1+ because the lead byte at each recursion says which dim we split on.\n    byte[] splitPackedValues = new byte[Math.toIntExact(numLeaves*(1+bytesPerDim))];\n\n    // +1 because leaf count is power of 2 (e.g. 8), and innerNodeCount is power of 2 minus 1 (e.g. 7)\n    long[] leafBlockFPs = new long[numLeaves];\n\n    // Make sure the math above \"worked\":\n    assert pointCount / numLeaves <= maxPointsInLeafNode: \"pointCount=\" + pointCount + \" numLeaves=\" + numLeaves + \" maxPointsInLeafNode=\" + maxPointsInLeafNode;\n\n    //We re-use the selector so we do not need to create an object every time.\n    BKDRadixSelector radixSelector = new BKDRadixSelector(numDataDims, numIndexDims, bytesPerDim, maxPointsSortInHeap, tempDir, tempFileNamePrefix);\n\n    boolean success = false;\n    try {\n\n\n      build(1, numLeaves, points, out,\n          radixSelector, minPackedValue, maxPackedValue,\n            splitPackedValues, leafBlockFPs, new int[maxPointsInLeafNode]);\n\n\n      // If no exception, we should have cleaned everything up:\n      assert tempDir.getCreatedFiles().isEmpty();\n      //long t2 = System.nanoTime();\n      //System.out.println(\"write time: \" + ((t2-t1)/1000000.0) + \" msec\");\n\n      success = true;\n    } finally {\n      if (success == false) {\n        IOUtils.deleteFilesIgnoringExceptions(tempDir, tempDir.getCreatedFiles());\n      }\n    }\n\n    //System.out.println(\"Total nodes: \" + innerNodeCount);\n\n    // Write index:\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9fc0d60683b47b5d922124c31f57c8b34734f9e6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c7f06758793500ca773d0df1037290e6e404fb33":["76a51551f05a6c96a115b5a656837ecc8fd0b1ff"],"bb94bf667d51f9c390c99d97afb36b7caab6b6e9":["c7f06758793500ca773d0df1037290e6e404fb33"],"f6652c943595e92c187ee904c382863013eae28f":["9fc0d60683b47b5d922124c31f57c8b34734f9e6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"78bdc7d6906146edb12a1a6c1f765ba680ed5124":["f6652c943595e92c187ee904c382863013eae28f"],"a69ebf290ab26d026cc224e517e0d93d931ac87b":["78bdc7d6906146edb12a1a6c1f765ba680ed5124"],"9856095f7afb5a607bf5e65077615ed91273508c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9fc0d60683b47b5d922124c31f57c8b34734f9e6"],"76a51551f05a6c96a115b5a656837ecc8fd0b1ff":["a69ebf290ab26d026cc224e517e0d93d931ac87b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bb94bf667d51f9c390c99d97afb36b7caab6b6e9"]},"commit2Childs":{"9fc0d60683b47b5d922124c31f57c8b34734f9e6":["f6652c943595e92c187ee904c382863013eae28f","9856095f7afb5a607bf5e65077615ed91273508c"],"c7f06758793500ca773d0df1037290e6e404fb33":["bb94bf667d51f9c390c99d97afb36b7caab6b6e9"],"bb94bf667d51f9c390c99d97afb36b7caab6b6e9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f6652c943595e92c187ee904c382863013eae28f":["78bdc7d6906146edb12a1a6c1f765ba680ed5124"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9fc0d60683b47b5d922124c31f57c8b34734f9e6","9856095f7afb5a607bf5e65077615ed91273508c"],"78bdc7d6906146edb12a1a6c1f765ba680ed5124":["a69ebf290ab26d026cc224e517e0d93d931ac87b"],"a69ebf290ab26d026cc224e517e0d93d931ac87b":["76a51551f05a6c96a115b5a656837ecc8fd0b1ff"],"9856095f7afb5a607bf5e65077615ed91273508c":[],"76a51551f05a6c96a115b5a656837ecc8fd0b1ff":["c7f06758793500ca773d0df1037290e6e404fb33"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9856095f7afb5a607bf5e65077615ed91273508c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}