{"path":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","commits":[{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","pathOld":"/dev/null","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      // TODO: look into forcefully taking over any lease\n      if (fs.exists(tlogFile) && openExisting) {\n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["c6d82c04c0bc088fae82f28ef47cb25a164f47fd"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","pathOld":"/dev/null","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      // TODO: look into forcefully taking over any lease\n      if (fs.exists(tlogFile) && openExisting) {\n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7ed97e9132b34af23573a6b39c34ec0574e5c67e","date":1420913354,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      // TODO: look into forcefully taking over any lease\n      if (fs.exists(tlogFile) && openExisting) {\n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      // TODO: look into forcefully taking over any lease\n      if (fs.exists(tlogFile) && openExisting) {\n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c6d82c04c0bc088fae82f28ef47cb25a164f47fd","date":1422552161,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf());\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      // TODO: look into forcefully taking over any lease\n      if (fs.exists(tlogFile) && openExisting) {\n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","bugFix":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e0bbd91feb34c5f3efb419225ce6d207e7abb052","date":1426964933,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf());\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf());\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b82485108ad24cfd45d88a7465e68000f54055c","date":1430225324,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean,Integer).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting, Integer tlogDfsReplication) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)tlogDfsReplication.intValue());\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e0bbd91feb34c5f3efb419225ce6d207e7abb052":["c6d82c04c0bc088fae82f28ef47cb25a164f47fd"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["c6d82c04c0bc088fae82f28ef47cb25a164f47fd","e0bbd91feb34c5f3efb419225ce6d207e7abb052"],"2b82485108ad24cfd45d88a7465e68000f54055c":["e0bbd91feb34c5f3efb419225ce6d207e7abb052"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c6d82c04c0bc088fae82f28ef47cb25a164f47fd":["7ed97e9132b34af23573a6b39c34ec0574e5c67e"],"7ed97e9132b34af23573a6b39c34ec0574e5c67e":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2b82485108ad24cfd45d88a7465e68000f54055c"]},"commit2Childs":{"e0bbd91feb34c5f3efb419225ce6d207e7abb052":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","2b82485108ad24cfd45d88a7465e68000f54055c"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["37a0f60745e53927c4c876cfe5b5a58170f0646c","7ed97e9132b34af23573a6b39c34ec0574e5c67e"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"2b82485108ad24cfd45d88a7465e68000f54055c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["849494cf2f3a96af5c8c84995108ddd8456fcd04","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"c6d82c04c0bc088fae82f28ef47cb25a164f47fd":["e0bbd91feb34c5f3efb419225ce6d207e7abb052","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"7ed97e9132b34af23573a6b39c34ec0574e5c67e":["c6d82c04c0bc088fae82f28ef47cb25a164f47fd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","37a0f60745e53927c4c876cfe5b5a58170f0646c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}