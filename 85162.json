{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testValidNumberOfExpansions().mjava","commits":[{"id":"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2","date":1446074047,"type":0,"author":"Areek Zillur","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testValidNumberOfExpansions().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    completionTokenStream.setPayload(new BytesRef());\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    stream.reset();\n    CompletionTokenStream.BytesRefBuilderTermAttribute attr = stream.addAttribute(CompletionTokenStream.BytesRefBuilderTermAttribute.class);\n    PositionIncrementAttribute posAttr = stream.addAttribute(PositionIncrementAttribute.class);\n    int maxPos = 0;\n    int count = 0;\n    while(stream.incrementToken()) {\n      count++;\n      assertNotNull(attr.getBytesRef());\n      assertTrue(attr.getBytesRef().length > 0);\n      maxPos += posAttr.getPositionIncrement();\n    }\n    stream.close();\n    assertEquals(count, 256);\n    assertEquals(count, maxPos);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","date":1528168051,"type":5,"author":"David Smiley","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testValidNumberOfExpansions().mjava","sourceNew":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","sourceOld":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    completionTokenStream.setPayload(new BytesRef());\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    stream.reset();\n    CompletionTokenStream.BytesRefBuilderTermAttribute attr = stream.addAttribute(CompletionTokenStream.BytesRefBuilderTermAttribute.class);\n    PositionIncrementAttribute posAttr = stream.addAttribute(PositionIncrementAttribute.class);\n    int maxPos = 0;\n    int count = 0;\n    while(stream.incrementToken()) {\n      count++;\n      assertNotNull(attr.getBytesRef());\n      assertTrue(attr.getBytesRef().length > 0);\n      maxPos += posAttr.getPositionIncrement();\n    }\n    stream.close();\n    assertEquals(count, 256);\n    assertEquals(count, maxPos);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":5,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testValidNumberOfExpansions().mjava","sourceNew":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","sourceOld":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    completionTokenStream.setPayload(new BytesRef());\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    stream.reset();\n    CompletionTokenStream.BytesRefBuilderTermAttribute attr = stream.addAttribute(CompletionTokenStream.BytesRefBuilderTermAttribute.class);\n    PositionIncrementAttribute posAttr = stream.addAttribute(PositionIncrementAttribute.class);\n    int maxPos = 0;\n    int count = 0;\n    while(stream.incrementToken()) {\n      count++;\n      assertNotNull(attr.getBytesRef());\n      assertTrue(attr.getBytesRef().length > 0);\n      maxPos += posAttr.getPositionIncrement();\n    }\n    stream.close();\n    assertEquals(count, 256);\n    assertEquals(count, maxPos);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":5,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testValidNumberOfExpansions().mjava","sourceNew":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","sourceOld":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    completionTokenStream.setPayload(new BytesRef());\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    stream.reset();\n    CompletionTokenStream.BytesRefBuilderTermAttribute attr = stream.addAttribute(CompletionTokenStream.BytesRefBuilderTermAttribute.class);\n    PositionIncrementAttribute posAttr = stream.addAttribute(PositionIncrementAttribute.class);\n    int maxPos = 0;\n    int count = 0;\n    while(stream.incrementToken()) {\n      count++;\n      assertNotNull(attr.getBytesRef());\n      assertTrue(attr.getBytesRef().length > 0);\n      maxPos += posAttr.getPositionIncrement();\n    }\n    stream.close();\n    assertEquals(count, 256);\n    assertEquals(count, maxPos);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2"],"f592209545c71895260367152601e9200399776d":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"]},"commit2Childs":{"509ddf2b18aec24f54a1cbabf7d15ed537d61ff2":["b70042a8a492f7054d480ccdd2be9796510d4327","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","f592209545c71895260367152601e9200399776d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["509ddf2b18aec24f54a1cbabf7d15ed537d61ff2"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f592209545c71895260367152601e9200399776d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}