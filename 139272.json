{"path":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","commits":[{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"/dev/null","sourceNew":"  public void testFixedPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {1};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = new MockRAMDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6267e1ce56c2eec111425690cd04e251b6f14952","date":1275222352,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {1};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = new MockRAMDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {1};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = new MockRAMDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"833a7987bc1c94455fde83e3311f72bddedcfb93","date":1279951470,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {1};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = new MockRAMDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {1};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = new MockRAMDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"03b152509ee3fa8cf52abb8a4a0cfe7287c59fc8","date":1281277545,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = new MockRAMDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {1};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = new MockRAMDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory(RANDOM);\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = new MockRAMDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory(RANDOM);\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a493e6d0c3ad86bd55c0a1360d110142e948f2bd","date":1289406991,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodecInfo().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodecInfo().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8bc084aae57b2027dcd1e8786dabc47987dce76b","date":1289596643,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodecInfo().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c498d3f8d75170b121f5eda2c6210ac5beb5d411","date":1289726298,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodecInfo().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e1cbd7e289dc1243c7a59e1a83d078163a147fe","date":1292268032,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, -1, SEGMENT, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n\n    RANDOM = this.newRandom();\n\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {1};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = new MockRAMDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, CodecProvider.getDefault().getWriter(null));\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getCodec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56da903869515527852ee21ea7ef7bfe414cd40d","date":1294224724,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0c7a8f7304b75b1528814c5820fa23a96816c27","date":1298314239,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14ec33385f6fbb6ce172882d14605790418a5d31","date":1298910796,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1224a4027481acce15495b03bce9b48b93b42722","date":1300792329,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e92442af786151ee55bc283eb472f629e3c7b52b","date":1301070252,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, SegmentCodecs.build(fieldInfos, CodecProvider.getDefault()), fieldInfos.hasVectors());\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, SegmentCodecs.build(clonedFieldInfos, CodecProvider.getDefault()), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fe2fc74577855eadfb5eae3153c2fffdaaf791","date":1305237079,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, true, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos.hasVectors(), clonedFieldInfos);\n    si.setHasProx(false);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, IOContext.READ, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6f9be74ca7baaef11857ad002cad40419979516","date":1309449808,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, IOContext.READ, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seek(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 64, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, clonedFieldInfos.buildSegmentCodecs(false), clonedFieldInfos);\n\n    final FieldsProducer reader = si.getSegmentCodecs().codec().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos();\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final TermsEnum termsEnum = fieldsEnum.terms();\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = termsEnum.docs(null,  docsEnum);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868186558eb3a854ce7e720a52bb445795d54910","date":1327853682,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), IndexReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testFixedPostings().mjava","sourceNew":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testFixedPostings() throws Throwable {\n    final int NUM_TERMS = 100;\n    final TermData[] terms = new TermData[NUM_TERMS];\n    for(int i=0;i<NUM_TERMS;i++) {\n      final int[] docs = new int[] {i};\n      final String text = Integer.toString(i, Character.MAX_RADIX);\n      terms[i] = new TermData(text, docs, null);\n    }\n\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData field = new FieldData(\"field\", fieldInfos, terms, true, false);\n    final FieldData[] fields = new FieldData[] {field};\n\n    final Directory dir = newDirectory();\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, true);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    final FieldsProducer reader = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final FieldsEnum fieldsEnum = reader.iterator();\n    assertNotNull(fieldsEnum.next());\n    final Terms terms2 = fieldsEnum.terms();\n    assertNotNull(terms2);\n\n    final TermsEnum termsEnum = terms2.iterator(null);\n\n    DocsEnum docsEnum = null;\n    for(int i=0;i<NUM_TERMS;i++) {\n      final BytesRef term = termsEnum.next();\n      assertNotNull(term);\n      assertEquals(terms[i].text2, term.utf8ToString());\n\n      // do this twice to stress test the codec's reuse, ie,\n      // make sure it properly fully resets (rewinds) its\n      // internal state:\n      for(int iter=0;iter<2;iter++) {\n        docsEnum = _TestUtil.docs(random, termsEnum, null,  docsEnum, false);\n        assertEquals(terms[i].docs[0], docsEnum.nextDoc());\n        assertEquals(DocsEnum.NO_MORE_DOCS, docsEnum.nextDoc());\n      }\n    }\n    assertNull(termsEnum.next());\n\n    for(int i=0;i<NUM_TERMS;i++) {\n      assertEquals(termsEnum.seekCeil(new BytesRef(terms[i].text2)), TermsEnum.SeekStatus.FOUND);\n    }\n\n    assertNull(fieldsEnum.next());\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fe2fc74577855eadfb5eae3153c2fffdaaf791":["e92442af786151ee55bc283eb472f629e3c7b52b"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["d3fe2fc74577855eadfb5eae3153c2fffdaaf791"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["833a7987bc1c94455fde83e3311f72bddedcfb93","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"e92442af786151ee55bc283eb472f629e3c7b52b":["1224a4027481acce15495b03bce9b48b93b42722"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["bde51b089eb7f86171eb3406e38a274743f9b7ac","e92442af786151ee55bc283eb472f629e3c7b52b"],"14ec33385f6fbb6ce172882d14605790418a5d31":["b0c7a8f7304b75b1528814c5820fa23a96816c27"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b6f9be74ca7baaef11857ad002cad40419979516":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["2553b00f699380c64959ccb27991289aae87be2e","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["d619839baa8ce5503e496b94a9e42ad6f079293f","d3fe2fc74577855eadfb5eae3153c2fffdaaf791"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["fd9cc9d77712aba3662f24632df7539ab75e3667","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["d3fe2fc74577855eadfb5eae3153c2fffdaaf791"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe"],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["8bc084aae57b2027dcd1e8786dabc47987dce76b"],"868186558eb3a854ce7e720a52bb445795d54910":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["868da859b43505d9d2a023bfeae6dd0c795f5295","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"1224a4027481acce15495b03bce9b48b93b42722":["14ec33385f6fbb6ce172882d14605790418a5d31"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["6267e1ce56c2eec111425690cd04e251b6f14952"],"03b152509ee3fa8cf52abb8a4a0cfe7287c59fc8":["6267e1ce56c2eec111425690cd04e251b6f14952"],"70ad682703b8585f5d0a637efec044d57ec05efb":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","56da903869515527852ee21ea7ef7bfe414cd40d"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["03b152509ee3fa8cf52abb8a4a0cfe7287c59fc8"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["85a883878c0af761245ab048babc63d099f835f3","8bc084aae57b2027dcd1e8786dabc47987dce76b"],"85a883878c0af761245ab048babc63d099f835f3":["1f653cfcf159baeaafe5d01682a911e95bba4012","a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"3cc749c053615f5871f3b95715fe292f34e70a53":["7b91922b55d15444d554721b352861d028eb8278"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["3cc749c053615f5871f3b95715fe292f34e70a53"],"2553b00f699380c64959ccb27991289aae87be2e":["a3776dccca01c11e7046323cfad46a3b4a471233","fd9cc9d77712aba3662f24632df7539ab75e3667"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["b6f9be74ca7baaef11857ad002cad40419979516","fd9cc9d77712aba3662f24632df7539ab75e3667"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["872cff1d3a554e0cd64014cd97f88d3002b0f491","868186558eb3a854ce7e720a52bb445795d54910"],"7b91922b55d15444d554721b352861d028eb8278":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"8bc084aae57b2027dcd1e8786dabc47987dce76b":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"6267e1ce56c2eec111425690cd04e251b6f14952":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["3cc749c053615f5871f3b95715fe292f34e70a53","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["70ad682703b8585f5d0a637efec044d57ec05efb","e92442af786151ee55bc283eb472f629e3c7b52b"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["56da903869515527852ee21ea7ef7bfe414cd40d"],"56da903869515527852ee21ea7ef7bfe414cd40d":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"a3776dccca01c11e7046323cfad46a3b4a471233":["e92442af786151ee55bc283eb472f629e3c7b52b","d3fe2fc74577855eadfb5eae3153c2fffdaaf791"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","56da903869515527852ee21ea7ef7bfe414cd40d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"d3fe2fc74577855eadfb5eae3153c2fffdaaf791":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","fd9cc9d77712aba3662f24632df7539ab75e3667","a3776dccca01c11e7046323cfad46a3b4a471233"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["85a883878c0af761245ab048babc63d099f835f3","8bc084aae57b2027dcd1e8786dabc47987dce76b"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["6267e1ce56c2eec111425690cd04e251b6f14952"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["b6f9be74ca7baaef11857ad002cad40419979516"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"e92442af786151ee55bc283eb472f629e3c7b52b":["d3fe2fc74577855eadfb5eae3153c2fffdaaf791","c0ef0193974807e4bddf5432a6b0287fe4d6c9df","d619839baa8ce5503e496b94a9e42ad6f079293f","a3776dccca01c11e7046323cfad46a3b4a471233"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":[],"14ec33385f6fbb6ce172882d14605790418a5d31":["1224a4027481acce15495b03bce9b48b93b42722"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd","85a883878c0af761245ab048babc63d099f835f3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"b6f9be74ca7baaef11857ad002cad40419979516":["d083e83f225b11e5fdd900e83d26ddb385b6955c"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["5d004d0e0b3f65bb40da76d476d659d7888270e8","7b91922b55d15444d554721b352861d028eb8278"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ab5cb6a74aefb78aa0569857970b9151dfe2e787","56da903869515527852ee21ea7ef7bfe414cd40d"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["ddc4c914be86e34b54f70023f45a60fa7f04e929","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"7e1cbd7e289dc1243c7a59e1a83d078163a147fe":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"868186558eb3a854ce7e720a52bb445795d54910":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"1224a4027481acce15495b03bce9b48b93b42722":["e92442af786151ee55bc283eb472f629e3c7b52b"],"03b152509ee3fa8cf52abb8a4a0cfe7287c59fc8":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"70ad682703b8585f5d0a637efec044d57ec05efb":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"85a883878c0af761245ab048babc63d099f835f3":["c498d3f8d75170b121f5eda2c6210ac5beb5d411"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["70ad682703b8585f5d0a637efec044d57ec05efb"],"3cc749c053615f5871f3b95715fe292f34e70a53":["872cff1d3a554e0cd64014cd97f88d3002b0f491","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["868186558eb3a854ce7e720a52bb445795d54910","5cab9a86bd67202d20b6adc463008c8e982b070a","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"2553b00f699380c64959ccb27991289aae87be2e":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"8bc084aae57b2027dcd1e8786dabc47987dce76b":["7e1cbd7e289dc1243c7a59e1a83d078163a147fe","c498d3f8d75170b121f5eda2c6210ac5beb5d411"],"6267e1ce56c2eec111425690cd04e251b6f14952":["833a7987bc1c94455fde83e3311f72bddedcfb93","03b152509ee3fa8cf52abb8a4a0cfe7287c59fc8"],"7b91922b55d15444d554721b352861d028eb8278":["3cc749c053615f5871f3b95715fe292f34e70a53"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":[],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["14ec33385f6fbb6ce172882d14605790418a5d31","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"56da903869515527852ee21ea7ef7bfe414cd40d":["70ad682703b8585f5d0a637efec044d57ec05efb","b0c7a8f7304b75b1528814c5820fa23a96816c27","868da859b43505d9d2a023bfeae6dd0c795f5295"],"a3776dccca01c11e7046323cfad46a3b4a471233":["2553b00f699380c64959ccb27991289aae87be2e"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","5d004d0e0b3f65bb40da76d476d659d7888270e8","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","b65b350ca9588f9fc76ce7d6804160d06c45ff42","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}