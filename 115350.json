{"path":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","commits":[{"id":"2c007e7c4cf8c55bc2a5884e315123afaaeec87f","date":1327520966,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 150; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(200);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["1e9ce820cd3ed9efb959c181daaafd22f0c70143"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 150; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(200);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 150; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(200);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41709fbea0bb4b2def71488206a08c65c071857d","date":1327594132,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 150; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(200);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dba4f3620c2030b477e14b828c70c3b05653707a","date":1327681907,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"78a55f24d9b493c2a1cecf79f1d78279062b545b","date":1327688152,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 150; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(200);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd92b8bcc88e969302510acf77bd6970da3994c4","date":1327839530,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 150; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(200);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a80994db3380cd78c6f65b84515e2e931b6b3da","date":1329530403,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegisterSetup(null, desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].publishAsDown(controllers[slot\n                  % nodeCount].getBaseUrl(), desc, controllers[slot\n                  % nodeCount].getNodeName()\n                  + \"_\" + coreName, coreName);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b834dd353486678973f4157b3ba402ac3a7ca88","date":1329782329,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegisterSetup(null, desc, false);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegisterSetup(null, desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c51a2dcb8b4e1820a44f35f11961110201e06cdb","date":1329994529,"type":3,"author":"Sami Siren","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegisterSetup(null, desc, false);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegisterSetup(null, desc, false);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","bugFix":null,"bugIntro":["7875fce026a0a335830cfc75abc3eb009eff9a73"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9813dd0748537c429b7c0a9b4723ea1ba496c047","date":1330304954,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegisterSetup(null, desc, false);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d05854aa6fb36cfe1a6e745776aec397719f6612","date":1330887140,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      reader = new ZkStateReader(zkClient);\n      \n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegisterSetup(null, desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n    \n    System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random.nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random.nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random.nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["77a0b04ddf690033aa642a3caf096a2ebfe1812f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a5093a9e893633cc091cf2f729d7863671c2b715","date":1339132888,"type":3,"author":"Sami Siren","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.valueOf(sliceCount).toString());\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      if (zkClient != null) {\n        zkClient.close();\n      }\n      if (reader != null) {\n        reader.close();\n      }\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"21591922fb4db3e2a6ffb2cb342b3d61c053a973","date":1340761680,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdownNow();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f767f8c99eaedb984df754fe61f21c5de260f94","date":1344105153,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8fd5be977c105554c6a7b68afcdbc511439723ab","date":1344115570,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateCloudState(true);\n        CloudState state = reader.getCloudState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c8719b2c0b382be11f5b193b6fc14bc310e906b","date":1344770591,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","date":1344867506,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1);\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"adc2388a5005de25370273411bc713d0ff722805","date":1345719157,"type":3,"author":"Sami Siren","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"001b25b42373b22a52f399dbf072f1224632e8e6","date":1345889167,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    System.setProperty(ZkStateReader.NUM_SHARDS_PROP, Integer.toString(sliceCount));\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    final ZkController[] controllers = new ZkController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n      \n      controllers[i] = new ZkController(null, server.getZkAddress(), TIMEOUT, 10000,\n          \"localhost\", \"898\" + i, \"solr\", new CurrentCoreDescriptorProvider() {\n\n            @Override\n            public List<CoreDescriptor> getCurrentDescriptors() {\n              // do nothing\n              return null;\n            }\n          });\n      }\n\n      System.setProperty(\"bootstrap_confdir\", getFile(\"solr/collection1/conf\")\n          .getAbsolutePath());\n\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n            final CloudDescriptor collection1Desc = new CloudDescriptor();\n            collection1Desc.setCollectionName(\"collection1\");\n            collection1Desc.setNumShards(sliceCount);\n\n            final String coreName = \"core\" + slot;\n            \n            final CoreDescriptor desc = new CoreDescriptor(null, coreName, \"\");\n            desc.setCloudDescriptor(collection1Desc);\n            try {\n              controllers[slot % nodeCount].preRegister(desc);\n              ids[slot] = controllers[slot % nodeCount]\n                  .register(coreName, desc);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);\n      System.clearProperty(\"bootstrap_confdir\");\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2ea5c545bc2b67aa46deae6deb429d251ba4dd87","date":1346223518,"type":3,"author":"Sami Siren","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b42a1da4332f4ae31270dd1f2598108eca63cf99","date":1346345335,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getShards().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 90; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4497a62bc4277479a03071cdcaba45e97915cab0"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05a14b2611ead08655a2b2bdc61632eb31316e57","date":1346366621,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getShards().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 90; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      for (int i = 0; i < 40; i++) {\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        int count = 0;\n        for (String name : slices.keySet()) {\n          count += slices.get(name).getShards().size();\n        }\n        if (coreCount == count) break;\n        Thread.sleep(200);\n      }\n\n      // make sure all cores have been returned a id\n      for (int i = 0; i < 90; i++) {\n        int assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1)), 15000);\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fa64435b5902ce266c23755a4a00691a3285dab8","date":1347243290,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 90; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getShards().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 90; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c5a558d54519c651068ddb202f03befefb1514a7","date":1354382006,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 90; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 90; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 90; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlices(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 90; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"43e3abc68d83ddfa6c1e94ecdc3137a1437227cd","date":1355793656,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 120; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 90; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"561cfa39557299807a181eefac95148b212bd053","date":1355847078,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 120; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 120; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 120; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        for (String name : slices.keySet()) {\n          cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n        }\n        if (coreCount == cloudStateSliceCount) break;\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 90; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 120; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 120; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 120; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 120; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b8810a3869c79294054e48a213408c3d527e9c1f","date":1392845489,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 120; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 120; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(500);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7b7c044ecca0686a7c507c67a17a019647b5044d","date":1393803940,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 120; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29f5eaf296600e1665151e7929d42a3cbe22e481","date":1393983215,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"96ea64d994d340044e0d57aeb6a5871539d10ca5","date":1394225445,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i, \"collection1\");\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<String,AtomicInteger>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb1f22cfa77230b5f05b7784feae5367f6bbb488","date":1395968145,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir().getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["1e9ce820cd3ed9efb959c181daaafd22f0c70143"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1e9ce820cd3ed9efb959c181daaafd22f0c70143","date":1396201051,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").getAbsolutePath();\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir().getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f","bb1f22cfa77230b5f05b7784feae5367f6bbb488"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a0f5bb79c600763ffe7b8141df59a3169d31e48","date":1396689440,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").getAbsolutePath();\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = dataDir.getAbsolutePath() + File.separator\n        + \"zookeeper/server1/data\";\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"77a0b04ddf690033aa642a3caf096a2ebfe1812f","date":1408972109,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").getAbsolutePath();\n\n    final int nodeCount = random().nextInt(50)+50;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(100)+100;  //how many cores to register\n    final int sliceCount = random().nextInt(20)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f4abec28b874149a7223e32cc7a01704c27790de","date":1410644789,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7875fce026a0a335830cfc75abc3eb009eff9a73","date":1425897108,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":["c51a2dcb8b4e1820a44f35f11961110201e06cdb"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      zkClient.makePath(ZkStateReader.LIVE_NODES_ZKNODE, true);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a219f1dcad1700e84807666bdbd2b573e8de7021","date":1428130940,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, ZkStateReader.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cb5af3afeddbb803fb785098176e6e177c34261b","date":1428905393,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = Executors.newFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4497a62bc4277479a03071cdcaba45e97915cab0","date":1429346577,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\", \n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":["b42a1da4332f4ae31270dd1f2598108eca63cf99"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"102da6baafc0f534a59f31729343dbab9d3b9e9a","date":1438410244,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState();\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState(true);\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d48cfd089cba66f9745d8043e8e971b60514418d","date":1449003177,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState();\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState();\n        ClusterState state = reader.getClusterState();\n        Map<String,Slice> slices = state.getSlicesMap(\"collection1\");\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(\"collection1\", \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a0c04b71951333291abc7f317109a6a5957bd28","date":1457097827,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState();\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n        Runnable coreStarter = new Runnable() {\n          @Override\n          public void run() {\n\n            final String coreName = \"core\" + slot;\n            \n            try {\n              ids[slot]=controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n            } catch (Throwable e) {\n              e.printStackTrace();\n              fail(\"register threw exception:\" + e.getClass());\n            }\n          }\n        };\n        \n        nodeExecutors[i % nodeCount].submit(coreStarter);\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState();\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f","date":1457343183,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        reader.updateClusterState();\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"82fbc9a4af34a68002cd5cf8bbac6b604aeef413","date":1474634253,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      if (DEBUG) {\n        if (controllers[0] != null) {\n          zkClient.printLayoutToStdOut();\n        }\n      }\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5de502b5478255493125e7e801411ba17a6682ec","date":1490974101,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(COLLECTION, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(COLLECTION);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(COLLECTION, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6f20fd35e3055a0c5b387df0b986a68d65d86441","date":1491045405,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(COLLECTION, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(COLLECTION);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(COLLECTION, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(collection, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(collection);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(collection, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9b4296bd51ca61b482138791478afdd0f7d3a3d","date":1498058739,"type":4,"author":"Cao Manh Dat","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(COLLECTION, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(COLLECTION);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(COLLECTION, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":4,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(COLLECTION, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(COLLECTION);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(COLLECTION, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":4,"author":"Karl Wright","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/OverseerTest#testShardAssignmentBigger().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testShardAssignmentBigger() throws Exception {\n    String zkDir = createTempDir(\"zkData\").toFile().getAbsolutePath();\n\n    final int nodeCount = random().nextInt(TEST_NIGHTLY ? 50 : 10)+(TEST_NIGHTLY ? 50 : 10)+1;   //how many simulated nodes (num of threads)\n    final int coreCount = random().nextInt(TEST_NIGHTLY ? 100 : 11)+(TEST_NIGHTLY ? 100 : 11)+1; //how many cores to register\n    final int sliceCount = random().nextInt(TEST_NIGHTLY ? 20 : 5)+1;  //how many slices\n    \n    ZkTestServer server = new ZkTestServer(zkDir);\n\n    SolrZkClient zkClient = null;\n    ZkStateReader reader = null;\n    SolrZkClient overseerClient = null;\n\n    final MockZKController[] controllers = new MockZKController[nodeCount];\n    final ExecutorService[] nodeExecutors = new ExecutorService[nodeCount];\n    try {\n      server.run();\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      zkClient = new SolrZkClient(server.getZkAddress(), TIMEOUT);\n      ZkController.createClusterZkNodes(zkClient);\n      \n      overseerClient = electNewOverseer(server.getZkAddress());\n\n      reader = new ZkStateReader(zkClient);\n      reader.createClusterStateWatchersAndUpdate();\n\n      for (int i = 0; i < nodeCount; i++) {\n        controllers[i] = new MockZKController(server.getZkAddress(), \"node\" + i);\n      }      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i] = ExecutorUtil.newMDCAwareFixedThreadPool(1, new DefaultSolrThreadFactory(\"testShardAssignment\"));\n      }\n      \n      final String[] ids = new String[coreCount];\n      //register total of coreCount cores\n      for (int i = 0; i < coreCount; i++) {\n        final int slot = i;\n\n        nodeExecutors[i % nodeCount].submit((Runnable) () -> {\n\n          final String coreName = \"core\" + slot;\n\n          try {\n            ids[slot] = controllers[slot % nodeCount].publishState(COLLECTION, coreName, \"node\" + slot, Replica.State.ACTIVE, sliceCount);\n          } catch (Throwable e) {\n            e.printStackTrace();\n            fail(\"register threw exception:\" + e.getClass());\n          }\n        });\n      }\n      \n      for (int i = 0; i < nodeCount; i++) {\n        nodeExecutors[i].shutdown();\n      }\n\n      for (int i = 0; i < nodeCount; i++) {\n        while (!nodeExecutors[i].awaitTermination(100, TimeUnit.MILLISECONDS));\n      }\n      \n      // make sure all cores have been assigned a id in cloudstate\n      int cloudStateSliceCount = 0;\n      for (int i = 0; i < 40; i++) {\n        cloudStateSliceCount = 0;\n        ClusterState state = reader.getClusterState();\n        final Map<String,Slice> slices = state.getSlicesMap(COLLECTION);\n        if (slices != null) {\n          for (String name : slices.keySet()) {\n            cloudStateSliceCount += slices.get(name).getReplicasMap().size();\n          }\n          if (coreCount == cloudStateSliceCount) break;\n        }\n\n        Thread.sleep(200);\n      }\n      assertEquals(\"Unable to verify all cores have been assigned an id in cloudstate\",\n                   coreCount, cloudStateSliceCount);\n\n      // make sure all cores have been returned an id\n      int assignedCount = 0;\n      for (int i = 0; i < 240; i++) {\n        assignedCount = 0;\n        for (int j = 0; j < coreCount; j++) {\n          if (ids[j] != null) {\n            assignedCount++;\n          }\n        }\n        if (coreCount == assignedCount) {\n          break;\n        }\n        Thread.sleep(1000);\n      }\n      assertEquals(\"Unable to verify all cores have been returned an id\", \n                   coreCount, assignedCount);\n      \n      final HashMap<String, AtomicInteger> counters = new HashMap<>();\n      for (int i = 1; i < sliceCount+1; i++) {\n        counters.put(\"shard\" + i, new AtomicInteger());\n      }\n      \n      for (int i = 0; i < coreCount; i++) {\n        final AtomicInteger ai = counters.get(ids[i]);\n        assertNotNull(\"could not find counter for shard:\" + ids[i], ai);\n        ai.incrementAndGet();\n      }\n\n      for (String counter: counters.keySet()) {\n        int count = counters.get(counter).intValue();\n        int expectedCount = coreCount / sliceCount;\n        int min = expectedCount - 1;\n        int max = expectedCount + 1;\n        if (count < min || count > max) {\n          fail(\"Unevenly assigned shard ids, \" + counter + \" had \" + count\n              + \", expected: \" + min + \"-\" + max);\n        }\n      }\n      \n      //make sure leaders are in cloud state\n      for (int i = 0; i < sliceCount; i++) {\n        assertNotNull(reader.getLeaderUrl(COLLECTION, \"shard\" + (i + 1), 15000));\n      }\n\n    } finally {\n      close(zkClient);\n      close(overseerClient);\n      close(reader);\n      for (int i = 0; i < controllers.length; i++)\n        if (controllers[i] != null) {\n          controllers[i].close();\n        }\n      server.shutdown();\n      for (int i = 0; i < nodeCount; i++) {\n        if (nodeExecutors[i] != null) {\n          nodeExecutors[i].shutdownNow();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"001b25b42373b22a52f399dbf072f1224632e8e6":["d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9","adc2388a5005de25370273411bc713d0ff722805"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":["7b7c044ecca0686a7c507c67a17a019647b5044d","29f5eaf296600e1665151e7929d42a3cbe22e481"],"5de502b5478255493125e7e801411ba17a6682ec":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"adc2388a5005de25370273411bc713d0ff722805":["1c8719b2c0b382be11f5b193b6fc14bc310e906b"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","1e9ce820cd3ed9efb959c181daaafd22f0c70143"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["561cfa39557299807a181eefac95148b212bd053","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["3a80994db3380cd78c6f65b84515e2e931b6b3da","d05854aa6fb36cfe1a6e745776aec397719f6612"],"6b834dd353486678973f4157b3ba402ac3a7ca88":["3a80994db3380cd78c6f65b84515e2e931b6b3da"],"6f20fd35e3055a0c5b387df0b986a68d65d86441":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d48cfd089cba66f9745d8043e8e971b60514418d":["102da6baafc0f534a59f31729343dbab9d3b9e9a"],"41709fbea0bb4b2def71488206a08c65c071857d":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"b8810a3869c79294054e48a213408c3d527e9c1f":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"a219f1dcad1700e84807666bdbd2b573e8de7021":["7875fce026a0a335830cfc75abc3eb009eff9a73"],"29f5eaf296600e1665151e7929d42a3cbe22e481":["7b7c044ecca0686a7c507c67a17a019647b5044d"],"77a0b04ddf690033aa642a3caf096a2ebfe1812f":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"43e3abc68d83ddfa6c1e94ecdc3137a1437227cd":["c5a558d54519c651068ddb202f03befefb1514a7"],"d05854aa6fb36cfe1a6e745776aec397719f6612":["9813dd0748537c429b7c0a9b4723ea1ba496c047"],"21591922fb4db3e2a6ffb2cb342b3d61c053a973":["a5093a9e893633cc091cf2f729d7863671c2b715"],"bb1f22cfa77230b5f05b7784feae5367f6bbb488":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"f4abec28b874149a7223e32cc7a01704c27790de":["77a0b04ddf690033aa642a3caf096a2ebfe1812f"],"05a14b2611ead08655a2b2bdc61632eb31316e57":["001b25b42373b22a52f399dbf072f1224632e8e6","b42a1da4332f4ae31270dd1f2598108eca63cf99"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["6f20fd35e3055a0c5b387df0b986a68d65d86441","a9b4296bd51ca61b482138791478afdd0f7d3a3d"],"3a0c04b71951333291abc7f317109a6a5957bd28":["d48cfd089cba66f9745d8043e8e971b60514418d"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["561cfa39557299807a181eefac95148b212bd053"],"2ea5c545bc2b67aa46deae6deb429d251ba4dd87":["adc2388a5005de25370273411bc713d0ff722805"],"561cfa39557299807a181eefac95148b212bd053":["43e3abc68d83ddfa6c1e94ecdc3137a1437227cd"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["a5093a9e893633cc091cf2f729d7863671c2b715","21591922fb4db3e2a6ffb2cb342b3d61c053a973"],"c5a558d54519c651068ddb202f03befefb1514a7":["fa64435b5902ce266c23755a4a00691a3285dab8"],"a5093a9e893633cc091cf2f729d7863671c2b715":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["21591922fb4db3e2a6ffb2cb342b3d61c053a973","3f767f8c99eaedb984df754fe61f21c5de260f94"],"cb5af3afeddbb803fb785098176e6e177c34261b":["a219f1dcad1700e84807666bdbd2b573e8de7021"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["407687e67faf6e1f02a211ca078d8e3eed631027","561cfa39557299807a181eefac95148b212bd053"],"82fbc9a4af34a68002cd5cf8bbac6b604aeef413":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"dba4f3620c2030b477e14b828c70c3b05653707a":["41709fbea0bb4b2def71488206a08c65c071857d"],"fd92b8bcc88e969302510acf77bd6970da3994c4":["0d22ac6a4146774c1bc8400160fc0b6150294e92","dba4f3620c2030b477e14b828c70c3b05653707a"],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["3a0c04b71951333291abc7f317109a6a5957bd28"],"4497a62bc4277479a03071cdcaba45e97915cab0":["cb5af3afeddbb803fb785098176e6e177c34261b"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["f4abec28b874149a7223e32cc7a01704c27790de","7875fce026a0a335830cfc75abc3eb009eff9a73"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["8fd5be977c105554c6a7b68afcdbc511439723ab","1c8719b2c0b382be11f5b193b6fc14bc310e906b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f","82fbc9a4af34a68002cd5cf8bbac6b604aeef413"],"1e9ce820cd3ed9efb959c181daaafd22f0c70143":["bb1f22cfa77230b5f05b7784feae5367f6bbb488"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["d6f074e73200c07d54f242d3880a8da5a35ff97b","1c8719b2c0b382be11f5b193b6fc14bc310e906b"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["29f5eaf296600e1665151e7929d42a3cbe22e481"],"9813dd0748537c429b7c0a9b4723ea1ba496c047":["c51a2dcb8b4e1820a44f35f11961110201e06cdb"],"78a55f24d9b493c2a1cecf79f1d78279062b545b":["a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","dba4f3620c2030b477e14b828c70c3b05653707a"],"a9b4296bd51ca61b482138791478afdd0f7d3a3d":["5de502b5478255493125e7e801411ba17a6682ec"],"102da6baafc0f534a59f31729343dbab9d3b9e9a":["4497a62bc4277479a03071cdcaba45e97915cab0"],"fa64435b5902ce266c23755a4a00691a3285dab8":["b42a1da4332f4ae31270dd1f2598108eca63cf99"],"407687e67faf6e1f02a211ca078d8e3eed631027":["fa64435b5902ce266c23755a4a00691a3285dab8","c5a558d54519c651068ddb202f03befefb1514a7"],"b42a1da4332f4ae31270dd1f2598108eca63cf99":["2ea5c545bc2b67aa46deae6deb429d251ba4dd87"],"8fd5be977c105554c6a7b68afcdbc511439723ab":["fe33227f6805edab2036cbb80645cc4e2d1fa424","3f767f8c99eaedb984df754fe61f21c5de260f94"],"28288370235ed02234a64753cdbf0c6ec096304a":["5de502b5478255493125e7e801411ba17a6682ec","a9b4296bd51ca61b482138791478afdd0f7d3a3d"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"c51a2dcb8b4e1820a44f35f11961110201e06cdb":["6b834dd353486678973f4157b3ba402ac3a7ca88"],"3f767f8c99eaedb984df754fe61f21c5de260f94":["21591922fb4db3e2a6ffb2cb342b3d61c053a973"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["d05854aa6fb36cfe1a6e745776aec397719f6612"],"7875fce026a0a335830cfc75abc3eb009eff9a73":["f4abec28b874149a7223e32cc7a01704c27790de"],"7b7c044ecca0686a7c507c67a17a019647b5044d":["b8810a3869c79294054e48a213408c3d527e9c1f"],"3a80994db3380cd78c6f65b84515e2e931b6b3da":["dba4f3620c2030b477e14b828c70c3b05653707a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["28288370235ed02234a64753cdbf0c6ec096304a"],"1c8719b2c0b382be11f5b193b6fc14bc310e906b":["3f767f8c99eaedb984df754fe61f21c5de260f94"]},"commit2Childs":{"001b25b42373b22a52f399dbf072f1224632e8e6":["05a14b2611ead08655a2b2bdc61632eb31316e57"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":[],"adc2388a5005de25370273411bc713d0ff722805":["001b25b42373b22a52f399dbf072f1224632e8e6","2ea5c545bc2b67aa46deae6deb429d251ba4dd87"],"5de502b5478255493125e7e801411ba17a6682ec":["a9b4296bd51ca61b482138791478afdd0f7d3a3d","28288370235ed02234a64753cdbf0c6ec096304a"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["77a0b04ddf690033aa642a3caf096a2ebfe1812f"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"6b834dd353486678973f4157b3ba402ac3a7ca88":["c51a2dcb8b4e1820a44f35f11961110201e06cdb"],"6f20fd35e3055a0c5b387df0b986a68d65d86441":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1"],"d48cfd089cba66f9745d8043e8e971b60514418d":["3a0c04b71951333291abc7f317109a6a5957bd28"],"41709fbea0bb4b2def71488206a08c65c071857d":["dba4f3620c2030b477e14b828c70c3b05653707a"],"b8810a3869c79294054e48a213408c3d527e9c1f":["7b7c044ecca0686a7c507c67a17a019647b5044d"],"29f5eaf296600e1665151e7929d42a3cbe22e481":["96ea64d994d340044e0d57aeb6a5871539d10ca5","634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a219f1dcad1700e84807666bdbd2b573e8de7021":["cb5af3afeddbb803fb785098176e6e177c34261b"],"77a0b04ddf690033aa642a3caf096a2ebfe1812f":["f4abec28b874149a7223e32cc7a01704c27790de"],"43e3abc68d83ddfa6c1e94ecdc3137a1437227cd":["561cfa39557299807a181eefac95148b212bd053"],"d05854aa6fb36cfe1a6e745776aec397719f6612":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"21591922fb4db3e2a6ffb2cb342b3d61c053a973":["fe33227f6805edab2036cbb80645cc4e2d1fa424","d6f074e73200c07d54f242d3880a8da5a35ff97b","3f767f8c99eaedb984df754fe61f21c5de260f94"],"bb1f22cfa77230b5f05b7784feae5367f6bbb488":["1e9ce820cd3ed9efb959c181daaafd22f0c70143"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["78a55f24d9b493c2a1cecf79f1d78279062b545b"],"f4abec28b874149a7223e32cc7a01704c27790de":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","7875fce026a0a335830cfc75abc3eb009eff9a73"],"05a14b2611ead08655a2b2bdc61632eb31316e57":[],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"3a0c04b71951333291abc7f317109a6a5957bd28":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["37a0f60745e53927c4c876cfe5b5a58170f0646c","b8810a3869c79294054e48a213408c3d527e9c1f"],"2ea5c545bc2b67aa46deae6deb429d251ba4dd87":["b42a1da4332f4ae31270dd1f2598108eca63cf99"],"561cfa39557299807a181eefac95148b212bd053":["37a0f60745e53927c4c876cfe5b5a58170f0646c","849494cf2f3a96af5c8c84995108ddd8456fcd04","d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["8fd5be977c105554c6a7b68afcdbc511439723ab"],"c5a558d54519c651068ddb202f03befefb1514a7":["43e3abc68d83ddfa6c1e94ecdc3137a1437227cd","407687e67faf6e1f02a211ca078d8e3eed631027"],"a5093a9e893633cc091cf2f729d7863671c2b715":["21591922fb4db3e2a6ffb2cb342b3d61c053a973","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"cb5af3afeddbb803fb785098176e6e177c34261b":["4497a62bc4277479a03071cdcaba45e97915cab0"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"82fbc9a4af34a68002cd5cf8bbac6b604aeef413":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"dba4f3620c2030b477e14b828c70c3b05653707a":["fd92b8bcc88e969302510acf77bd6970da3994c4","78a55f24d9b493c2a1cecf79f1d78279062b545b","3a80994db3380cd78c6f65b84515e2e931b6b3da"],"fd92b8bcc88e969302510acf77bd6970da3994c4":[],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["82fbc9a4af34a68002cd5cf8bbac6b604aeef413","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4497a62bc4277479a03071cdcaba45e97915cab0":["102da6baafc0f534a59f31729343dbab9d3b9e9a"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"0d22ac6a4146774c1bc8400160fc0b6150294e92":["fd92b8bcc88e969302510acf77bd6970da3994c4"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["5de502b5478255493125e7e801411ba17a6682ec","6f20fd35e3055a0c5b387df0b986a68d65d86441","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"1e9ce820cd3ed9efb959c181daaafd22f0c70143":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9":["001b25b42373b22a52f399dbf072f1224632e8e6"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["2a0f5bb79c600763ffe7b8141df59a3169d31e48","bb1f22cfa77230b5f05b7784feae5367f6bbb488"],"9813dd0748537c429b7c0a9b4723ea1ba496c047":["d05854aa6fb36cfe1a6e745776aec397719f6612"],"78a55f24d9b493c2a1cecf79f1d78279062b545b":[],"a9b4296bd51ca61b482138791478afdd0f7d3a3d":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"102da6baafc0f534a59f31729343dbab9d3b9e9a":["d48cfd089cba66f9745d8043e8e971b60514418d"],"fa64435b5902ce266c23755a4a00691a3285dab8":["c5a558d54519c651068ddb202f03befefb1514a7","407687e67faf6e1f02a211ca078d8e3eed631027"],"407687e67faf6e1f02a211ca078d8e3eed631027":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"b42a1da4332f4ae31270dd1f2598108eca63cf99":["05a14b2611ead08655a2b2bdc61632eb31316e57","fa64435b5902ce266c23755a4a00691a3285dab8"],"8fd5be977c105554c6a7b68afcdbc511439723ab":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"28288370235ed02234a64753cdbf0c6ec096304a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"c51a2dcb8b4e1820a44f35f11961110201e06cdb":["9813dd0748537c429b7c0a9b4723ea1ba496c047"],"3f767f8c99eaedb984df754fe61f21c5de260f94":["d6f074e73200c07d54f242d3880a8da5a35ff97b","8fd5be977c105554c6a7b68afcdbc511439723ab","1c8719b2c0b382be11f5b193b6fc14bc310e906b"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["41709fbea0bb4b2def71488206a08c65c071857d","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["a5093a9e893633cc091cf2f729d7863671c2b715"],"7b7c044ecca0686a7c507c67a17a019647b5044d":["96ea64d994d340044e0d57aeb6a5871539d10ca5","29f5eaf296600e1665151e7929d42a3cbe22e481"],"7875fce026a0a335830cfc75abc3eb009eff9a73":["a219f1dcad1700e84807666bdbd2b573e8de7021","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"3a80994db3380cd78c6f65b84515e2e931b6b3da":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","6b834dd353486678973f4157b3ba402ac3a7ca88"],"1c8719b2c0b382be11f5b193b6fc14bc310e906b":["adc2388a5005de25370273411bc713d0ff722805","c7869f64c874ebf7f317d22c00baf2b6857797a6","d0ba34ddeec9e4ab657150c29a5614a7bfbb53c9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["96ea64d994d340044e0d57aeb6a5871539d10ca5","37a0f60745e53927c4c876cfe5b5a58170f0646c","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","05a14b2611ead08655a2b2bdc61632eb31316e57","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","d3fcb70cf561547c7bb1506e0cf32ca7b1287064","fd92b8bcc88e969302510acf77bd6970da3994c4","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","c7869f64c874ebf7f317d22c00baf2b6857797a6","78a55f24d9b493c2a1cecf79f1d78279062b545b","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}