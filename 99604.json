{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readLegacySegmentInfo(Directory,int,IndexInput).mjava","commits":[{"id":"6842f2837919389de395b2bb61824335f40e5431","date":1337865715,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readLegacySegmentInfo(Directory,int,IndexInput).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readSegmentInfo(String,Directory,int,IndexInput).mjava","sourceNew":"  /** reads from legacy 3.x segments_N */\n  private SegmentInfoPerCommit readLegacySegmentInfo(Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    assert format != Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE;\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    final String name = input.readString();\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset = input.readInt();\n    final Map<String,String> attributes = new HashMap<String,String>();\n    \n    // parse the docstore stuff and shove it into attributes\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n      attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n      attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n      attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    // Replicate logic from 3.x's SegmentInfo.files():\n    final Set<String> files = new HashSet<String>();\n    if (isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n    }\n    \n    if (docStoreOffset != -1) {\n      if (docStoreIsCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n    } else if (!isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n    }\n    \n    if (normGen != null) {\n      for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n        long gen = ent.getValue();\n        if (gen >= SegmentInfo.YES) {\n          // Definitely a separate norm file, with generation:\n          files.add(IndexFileNames.fileNameFromGeneration(name, \"s\" + ent.getKey(), gen));\n        } else if (gen == SegmentInfo.NO) {\n          // No separate norm\n        } else {\n          // We should have already hit indexformat too old exception\n          assert false;\n        }\n      }\n    }\n\n    // nocommit: convert normgen into attributes?\n    SegmentInfo info = new SegmentInfo(dir, version, name, docCount, normGen, isCompoundFile,\n                                       null, diagnostics, Collections.unmodifiableMap(attributes));\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","sourceOld":"  private SegmentInfoPerCommit readSegmentInfo(String segmentName, Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    // NOTE: we ignore this and use the incoming arg\n    // instead, if it's non-null:\n    final String name = input.readString();\n    if (segmentName == null) {\n      segmentName = name;\n    }\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset;\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    final Map<String,String> attributes;\n    \n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      // we already upgraded to 4.x si format: so shared docstore stuff is in the attributes map.\n      attributes = input.readStringStringMap();\n      String v = attributes.get(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY);\n      docStoreOffset = v == null ? -1 : Integer.parseInt(v);\n      \n      v = attributes.get(Lucene3xSegmentInfoFormat.DS_NAME_KEY);\n      docStoreSegment = v == null ? segmentName : v;\n      \n      v = attributes.get(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY);\n      docStoreIsCompoundFile = v == null ? false : Boolean.parseBoolean(v);\n    } else {\n      // for older formats, parse the docstore stuff and shove it into attributes\n      attributes = new HashMap<String,String>();\n      docStoreOffset = input.readInt();\n      if (docStoreOffset != -1) {\n        docStoreSegment = input.readString();\n        docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n        attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n        attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n        attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n      } else {\n        docStoreSegment = name;\n        docStoreIsCompoundFile = false;\n      }\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    final Set<String> files;\n    if (format == Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE) {\n      files = input.readStringSet();\n    } else {\n      // Replicate logic from 3.x's SegmentInfo.files():\n      files = new HashSet<String>();\n      if (isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n      } else {\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n      }\n\n      if (docStoreOffset != -1) {\n        if (docStoreIsCompoundFile) {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n        } else {\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n          files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n          addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n        }\n      } else if (!isCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(segmentName, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n\n      if (normGen != null) {\n        for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n          long gen = ent.getValue();\n          if (gen >= SegmentInfo.YES) {\n            // Definitely a separate norm file, with generation:\n            files.add(IndexFileNames.fileNameFromGeneration(segmentName, \"s\" + ent.getKey(), gen));\n          } else if (gen == SegmentInfo.NO) {\n            // No separate norm\n          } else {\n            // We should have already hit indexformat too old exception\n            assert false;\n          }\n        }\n      }\n    }\n\n    // nocommit: convert normgen into attributes?\n    SegmentInfo info = new SegmentInfo(dir, version, segmentName, docCount, normGen, isCompoundFile,\n                                       null, diagnostics, Collections.unmodifiableMap(attributes));\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ee3df95012e016c229172f87a6c4077957246c4a","date":1337867023,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readLegacySegmentInfo(Directory,int,IndexInput).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readLegacySegmentInfo(Directory,int,IndexInput).mjava","sourceNew":"  /** reads from legacy 3.x segments_N */\n  private SegmentInfoPerCommit readLegacySegmentInfo(Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_3_1);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_3_1);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    final String name = input.readString();\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset = input.readInt();\n    final Map<String,String> attributes = new HashMap<String,String>();\n    \n    // parse the docstore stuff and shove it into attributes\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n      attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n      attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n      attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    // Replicate logic from 3.x's SegmentInfo.files():\n    final Set<String> files = new HashSet<String>();\n    if (isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n    }\n    \n    if (docStoreOffset != -1) {\n      if (docStoreIsCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n    } else if (!isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n    }\n    \n    if (normGen != null) {\n      for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n        long gen = ent.getValue();\n        if (gen >= SegmentInfo.YES) {\n          // Definitely a separate norm file, with generation:\n          files.add(IndexFileNames.fileNameFromGeneration(name, \"s\" + ent.getKey(), gen));\n        } else if (gen == SegmentInfo.NO) {\n          // No separate norm\n        } else {\n          // We should have already hit indexformat too old exception\n          assert false;\n        }\n      }\n    }\n\n    // nocommit: convert normgen into attributes?\n    SegmentInfo info = new SegmentInfo(dir, version, name, docCount, normGen, isCompoundFile,\n                                       null, diagnostics, Collections.unmodifiableMap(attributes));\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","sourceOld":"  /** reads from legacy 3.x segments_N */\n  private SegmentInfoPerCommit readLegacySegmentInfo(Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    assert format != Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE;\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_4X_UPGRADE);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    final String name = input.readString();\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset = input.readInt();\n    final Map<String,String> attributes = new HashMap<String,String>();\n    \n    // parse the docstore stuff and shove it into attributes\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n      attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n      attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n      attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    // Replicate logic from 3.x's SegmentInfo.files():\n    final Set<String> files = new HashSet<String>();\n    if (isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n    }\n    \n    if (docStoreOffset != -1) {\n      if (docStoreIsCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n    } else if (!isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n    }\n    \n    if (normGen != null) {\n      for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n        long gen = ent.getValue();\n        if (gen >= SegmentInfo.YES) {\n          // Definitely a separate norm file, with generation:\n          files.add(IndexFileNames.fileNameFromGeneration(name, \"s\" + ent.getKey(), gen));\n        } else if (gen == SegmentInfo.NO) {\n          // No separate norm\n        } else {\n          // We should have already hit indexformat too old exception\n          assert false;\n        }\n      }\n    }\n\n    // nocommit: convert normgen into attributes?\n    SegmentInfo info = new SegmentInfo(dir, version, name, docCount, normGen, isCompoundFile,\n                                       null, diagnostics, Collections.unmodifiableMap(attributes));\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"764b942fd30efcae6e532c19771f32eeeb0037b2","date":1337868546,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readLegacySegmentInfo(Directory,int,IndexInput).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readLegacySegmentInfo(Directory,int,IndexInput).mjava","sourceNew":"  /** reads from legacy 3.x segments_N */\n  private SegmentInfoPerCommit readLegacySegmentInfo(Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_3_1);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_3_1);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    final String name = input.readString();\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset = input.readInt();\n    final Map<String,String> attributes = new HashMap<String,String>();\n    \n    // parse the docstore stuff and shove it into attributes\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n      attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n      attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n      attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    // Replicate logic from 3.x's SegmentInfo.files():\n    final Set<String> files = new HashSet<String>();\n    if (isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n    }\n    \n    if (docStoreOffset != -1) {\n      if (docStoreIsCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n    } else if (!isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n    }\n    \n    // parse the normgen stuff and shove it into attributes\n    if (normGen != null) {\n      attributes.put(Lucene3xSegmentInfoFormat.NORMGEN_KEY, Integer.toString(numNormGen));\n      for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n        long gen = ent.getValue();\n        if (gen >= SegmentInfo.YES) {\n          // Definitely a separate norm file, with generation:\n          files.add(IndexFileNames.fileNameFromGeneration(name, \"s\" + ent.getKey(), gen));\n          attributes.put(Lucene3xSegmentInfoFormat.NORMGEN_PREFIX + ent.getKey(), Long.toString(gen));\n        } else if (gen == SegmentInfo.NO) {\n          // No separate norm\n        } else {\n          // We should have already hit indexformat too old exception\n          assert false;\n        }\n      }\n    }\n\n    SegmentInfo info = new SegmentInfo(dir, version, name, docCount, isCompoundFile,\n                                       null, diagnostics, Collections.unmodifiableMap(attributes));\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","sourceOld":"  /** reads from legacy 3.x segments_N */\n  private SegmentInfoPerCommit readLegacySegmentInfo(Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_3_1);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_3_1);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    final String name = input.readString();\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset = input.readInt();\n    final Map<String,String> attributes = new HashMap<String,String>();\n    \n    // parse the docstore stuff and shove it into attributes\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n      attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n      attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n      attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    // Replicate logic from 3.x's SegmentInfo.files():\n    final Set<String> files = new HashSet<String>();\n    if (isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n    }\n    \n    if (docStoreOffset != -1) {\n      if (docStoreIsCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n    } else if (!isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n    }\n    \n    if (normGen != null) {\n      for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n        long gen = ent.getValue();\n        if (gen >= SegmentInfo.YES) {\n          // Definitely a separate norm file, with generation:\n          files.add(IndexFileNames.fileNameFromGeneration(name, \"s\" + ent.getKey(), gen));\n        } else if (gen == SegmentInfo.NO) {\n          // No separate norm\n        } else {\n          // We should have already hit indexformat too old exception\n          assert false;\n        }\n      }\n    }\n\n    // nocommit: convert normgen into attributes?\n    SegmentInfo info = new SegmentInfo(dir, version, name, docCount, normGen, isCompoundFile,\n                                       null, diagnostics, Collections.unmodifiableMap(attributes));\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readLegacySegmentInfo(Directory,int,IndexInput).mjava","pathOld":"/dev/null","sourceNew":"  /** reads from legacy 3.x segments_N */\n  private SegmentInfoPerCommit readLegacySegmentInfo(Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_3_1);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_3_1);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    final String name = input.readString();\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset = input.readInt();\n    final Map<String,String> attributes = new HashMap<String,String>();\n    \n    // parse the docstore stuff and shove it into attributes\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n      attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n      attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n      attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    // Replicate logic from 3.x's SegmentInfo.files():\n    final Set<String> files = new HashSet<String>();\n    if (isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n    }\n    \n    if (docStoreOffset != -1) {\n      if (docStoreIsCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n    } else if (!isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n    }\n    \n    // parse the normgen stuff and shove it into attributes\n    if (normGen != null) {\n      attributes.put(Lucene3xSegmentInfoFormat.NORMGEN_KEY, Integer.toString(numNormGen));\n      for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n        long gen = ent.getValue();\n        if (gen >= SegmentInfo.YES) {\n          // Definitely a separate norm file, with generation:\n          files.add(IndexFileNames.fileNameFromGeneration(name, \"s\" + ent.getKey(), gen));\n          attributes.put(Lucene3xSegmentInfoFormat.NORMGEN_PREFIX + ent.getKey(), Long.toString(gen));\n        } else if (gen == SegmentInfo.NO) {\n          // No separate norm\n        } else {\n          // We should have already hit indexformat too old exception\n          assert false;\n        }\n      }\n    }\n\n    SegmentInfo info = new SegmentInfo(dir, version, name, docCount, isCompoundFile,\n                                       null, diagnostics, Collections.unmodifiableMap(attributes));\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57ae3024996ccdb3c36c42cb890e1efb37df4ce8","date":1338343651,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xSegmentInfoReader#readLegacySegmentInfo(Directory,int,IndexInput).mjava","sourceNew":null,"sourceOld":"  /** reads from legacy 3.x segments_N */\n  private SegmentInfoPerCommit readLegacySegmentInfo(Directory dir, int format, IndexInput input) throws IOException {\n    // check that it is a format we can understand\n    if (format > Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS) {\n      throw new IndexFormatTooOldException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_3_1);\n    }\n    if (format < Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      throw new IndexFormatTooNewException(input, format,\n                                           Lucene3xSegmentInfoFormat.FORMAT_DIAGNOSTICS, Lucene3xSegmentInfoFormat.FORMAT_3_1);\n    }\n    final String version;\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n\n    final String name = input.readString();\n\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    \n    final int docStoreOffset = input.readInt();\n    final Map<String,String> attributes = new HashMap<String,String>();\n    \n    // parse the docstore stuff and shove it into attributes\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n      attributes.put(Lucene3xSegmentInfoFormat.DS_OFFSET_KEY, Integer.toString(docStoreOffset));\n      attributes.put(Lucene3xSegmentInfoFormat.DS_NAME_KEY, docStoreSegment);\n      attributes.put(Lucene3xSegmentInfoFormat.DS_COMPOUND_KEY, Boolean.toString(docStoreIsCompoundFile));\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    // pre-4.0 indexes write a byte if there is a single norms file\n    byte b = input.readByte();\n\n    //System.out.println(\"version=\" + version + \" name=\" + name + \" docCount=\" + docCount + \" delGen=\" + delGen + \" dso=\" + docStoreOffset + \" dss=\" + docStoreSegment + \" dssCFs=\" + docStoreIsCompoundFile + \" b=\" + b + \" format=\" + format);\n\n    assert 1 == b : \"expected 1 but was: \"+ b + \" format: \" + format;\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(j, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final boolean hasProx = input.readByte() == 1;\n\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    if (format <= Lucene3xSegmentInfoFormat.FORMAT_HAS_VECTORS) {\n      // NOTE: unused\n      final int hasVectors = input.readByte();\n    }\n\n    // Replicate logic from 3.x's SegmentInfo.files():\n    final Set<String> files = new HashSet<String>();\n    if (isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION));\n    } else {\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xFieldInfosReader.FIELD_INFOS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.FREQ_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.PROX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xPostingsFormat.TERMS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xNormsProducer.NORMS_EXTENSION));\n    }\n    \n    if (docStoreOffset != -1) {\n      if (docStoreIsCompoundFile) {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION));\n      } else {\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n        files.add(IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n        addIfExists(dir, files, IndexFileNames.segmentFileName(docStoreSegment, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n      }\n    } else if (!isCompoundFile) {\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_INDEX_EXTENSION));\n      files.add(IndexFileNames.segmentFileName(name, \"\", Lucene3xStoredFieldsReader.FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_INDEX_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_FIELDS_EXTENSION));\n      addIfExists(dir, files, IndexFileNames.segmentFileName(name, \"\", Lucene3xTermVectorsReader.VECTORS_DOCUMENTS_EXTENSION));\n    }\n    \n    // parse the normgen stuff and shove it into attributes\n    if (normGen != null) {\n      attributes.put(Lucene3xSegmentInfoFormat.NORMGEN_KEY, Integer.toString(numNormGen));\n      for(Map.Entry<Integer,Long> ent : normGen.entrySet()) {\n        long gen = ent.getValue();\n        if (gen >= SegmentInfo.YES) {\n          // Definitely a separate norm file, with generation:\n          files.add(IndexFileNames.fileNameFromGeneration(name, \"s\" + ent.getKey(), gen));\n          attributes.put(Lucene3xSegmentInfoFormat.NORMGEN_PREFIX + ent.getKey(), Long.toString(gen));\n        } else if (gen == SegmentInfo.NO) {\n          // No separate norm\n        } else {\n          // We should have already hit indexformat too old exception\n          assert false;\n        }\n      }\n    }\n\n    SegmentInfo info = new SegmentInfo(dir, version, name, docCount, isCompoundFile,\n                                       null, diagnostics, Collections.unmodifiableMap(attributes));\n    info.setFiles(files);\n\n    SegmentInfoPerCommit infoPerCommit = new SegmentInfoPerCommit(info, delCount, delGen);\n    return infoPerCommit;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ee3df95012e016c229172f87a6c4077957246c4a":["6842f2837919389de395b2bb61824335f40e5431"],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","764b942fd30efcae6e532c19771f32eeeb0037b2"],"764b942fd30efcae6e532c19771f32eeeb0037b2":["ee3df95012e016c229172f87a6c4077957246c4a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6842f2837919389de395b2bb61824335f40e5431":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"]},"commit2Childs":{"ee3df95012e016c229172f87a6c4077957246c4a":["764b942fd30efcae6e532c19771f32eeeb0037b2"],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"764b942fd30efcae6e532c19771f32eeeb0037b2":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","6842f2837919389de395b2bb61824335f40e5431"],"6842f2837919389de395b2bb61824335f40e5431":["ee3df95012e016c229172f87a6c4077957246c4a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}