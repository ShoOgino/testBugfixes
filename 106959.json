{"path":"lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders#MatchingReaders(MergeState).mjava","commits":[{"id":"22a2e66dfda83847e80095b8693c660742ab3e9c","date":1408628796,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders#MatchingReaders(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#setMatchingSegmentReaders().mjava","sourceNew":"  MatchingReaders(MergeState mergeState) {\n    // If the i'th reader is a SegmentReader and has\n    // identical fieldName -> number mapping, then this\n    // array will be non-null at position i:\n    int numReaders = mergeState.readers.size();\n    int matchedCount = 0;\n    matchingSegmentReaders = new SegmentReader[numReaders];\n\n    // If this reader is a SegmentReader, and all of its\n    // field name -> number mappings match the \"merged\"\n    // FieldInfos, then we can do a bulk copy of the\n    // stored fields:\n    for (int i = 0; i < numReaders; i++) {\n      AtomicReader reader = mergeState.readers.get(i);\n      // TODO: we may be able to broaden this to\n      // non-SegmentReaders, since FieldInfos is now\n      // required?  But... this'd also require exposing\n      // bulk-copy (TVs and stored fields) API in foreign\n      // readers..\n      if (reader instanceof SegmentReader) {\n        SegmentReader segmentReader = (SegmentReader) reader;\n        boolean same = true;\n        FieldInfos segmentFieldInfos = segmentReader.getFieldInfos();\n        for (FieldInfo fi : segmentFieldInfos) {\n          FieldInfo other = mergeState.fieldInfos.fieldInfo(fi.number);\n          if (other == null || !other.name.equals(fi.name)) {\n            same = false;\n            break;\n          }\n        }\n        if (same) {\n          matchingSegmentReaders[i] = segmentReader;\n          matchedCount++;\n        }\n      }\n    }\n    \n    this.count = matchedCount;\n\n    if (mergeState.infoStream.isEnabled(\"SM\")) {\n      mergeState.infoStream.message(\"SM\", \"merge store matchedCount=\" + count + \" vs \" + mergeState.readers.size());\n      if (count != mergeState.readers.size()) {\n        mergeState.infoStream.message(\"SM\", \"\" + (mergeState.readers.size() - count) + \" non-bulk merges\");\n      }\n    }\n  }\n\n","sourceOld":"  private void setMatchingSegmentReaders() {\n    // If the i'th reader is a SegmentReader and has\n    // identical fieldName -> number mapping, then this\n    // array will be non-null at position i:\n    int numReaders = mergeState.readers.size();\n    mergeState.matchingSegmentReaders = new SegmentReader[numReaders];\n\n    // If this reader is a SegmentReader, and all of its\n    // field name -> number mappings match the \"merged\"\n    // FieldInfos, then we can do a bulk copy of the\n    // stored fields:\n    for (int i = 0; i < numReaders; i++) {\n      AtomicReader reader = mergeState.readers.get(i);\n      // TODO: we may be able to broaden this to\n      // non-SegmentReaders, since FieldInfos is now\n      // required?  But... this'd also require exposing\n      // bulk-copy (TVs and stored fields) API in foreign\n      // readers..\n      if (reader instanceof SegmentReader) {\n        SegmentReader segmentReader = (SegmentReader) reader;\n        boolean same = true;\n        FieldInfos segmentFieldInfos = segmentReader.getFieldInfos();\n        for (FieldInfo fi : segmentFieldInfos) {\n          FieldInfo other = mergeState.fieldInfos.fieldInfo(fi.number);\n          if (other == null || !other.name.equals(fi.name)) {\n            same = false;\n            break;\n          }\n        }\n        if (same) {\n          mergeState.matchingSegmentReaders[i] = segmentReader;\n          mergeState.matchedCount++;\n        }\n      }\n    }\n\n    if (mergeState.infoStream.isEnabled(\"SM\")) {\n      mergeState.infoStream.message(\"SM\", \"merge store matchedCount=\" + mergeState.matchedCount + \" vs \" + mergeState.readers.size());\n      if (mergeState.matchedCount != mergeState.readers.size()) {\n        mergeState.infoStream.message(\"SM\", \"\" + (mergeState.readers.size() - mergeState.matchedCount) + \" non-bulk merges\");\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders#MatchingReaders(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders#MatchingReaders(MergeState).mjava","sourceNew":"  MatchingReaders(MergeState mergeState) {\n    // If the i'th reader is a SegmentReader and has\n    // identical fieldName -> number mapping, then this\n    // array will be non-null at position i:\n    int numReaders = mergeState.readers.size();\n    int matchedCount = 0;\n    matchingSegmentReaders = new SegmentReader[numReaders];\n\n    // If this reader is a SegmentReader, and all of its\n    // field name -> number mappings match the \"merged\"\n    // FieldInfos, then we can do a bulk copy of the\n    // stored fields:\n    for (int i = 0; i < numReaders; i++) {\n      LeafReader reader = mergeState.readers.get(i);\n      // TODO: we may be able to broaden this to\n      // non-SegmentReaders, since FieldInfos is now\n      // required?  But... this'd also require exposing\n      // bulk-copy (TVs and stored fields) API in foreign\n      // readers..\n      if (reader instanceof SegmentReader) {\n        SegmentReader segmentReader = (SegmentReader) reader;\n        boolean same = true;\n        FieldInfos segmentFieldInfos = segmentReader.getFieldInfos();\n        for (FieldInfo fi : segmentFieldInfos) {\n          FieldInfo other = mergeState.fieldInfos.fieldInfo(fi.number);\n          if (other == null || !other.name.equals(fi.name)) {\n            same = false;\n            break;\n          }\n        }\n        if (same) {\n          matchingSegmentReaders[i] = segmentReader;\n          matchedCount++;\n        }\n      }\n    }\n    \n    this.count = matchedCount;\n\n    if (mergeState.infoStream.isEnabled(\"SM\")) {\n      mergeState.infoStream.message(\"SM\", \"merge store matchedCount=\" + count + \" vs \" + mergeState.readers.size());\n      if (count != mergeState.readers.size()) {\n        mergeState.infoStream.message(\"SM\", \"\" + (mergeState.readers.size() - count) + \" non-bulk merges\");\n      }\n    }\n  }\n\n","sourceOld":"  MatchingReaders(MergeState mergeState) {\n    // If the i'th reader is a SegmentReader and has\n    // identical fieldName -> number mapping, then this\n    // array will be non-null at position i:\n    int numReaders = mergeState.readers.size();\n    int matchedCount = 0;\n    matchingSegmentReaders = new SegmentReader[numReaders];\n\n    // If this reader is a SegmentReader, and all of its\n    // field name -> number mappings match the \"merged\"\n    // FieldInfos, then we can do a bulk copy of the\n    // stored fields:\n    for (int i = 0; i < numReaders; i++) {\n      AtomicReader reader = mergeState.readers.get(i);\n      // TODO: we may be able to broaden this to\n      // non-SegmentReaders, since FieldInfos is now\n      // required?  But... this'd also require exposing\n      // bulk-copy (TVs and stored fields) API in foreign\n      // readers..\n      if (reader instanceof SegmentReader) {\n        SegmentReader segmentReader = (SegmentReader) reader;\n        boolean same = true;\n        FieldInfos segmentFieldInfos = segmentReader.getFieldInfos();\n        for (FieldInfo fi : segmentFieldInfos) {\n          FieldInfo other = mergeState.fieldInfos.fieldInfo(fi.number);\n          if (other == null || !other.name.equals(fi.name)) {\n            same = false;\n            break;\n          }\n        }\n        if (same) {\n          matchingSegmentReaders[i] = segmentReader;\n          matchedCount++;\n        }\n      }\n    }\n    \n    this.count = matchedCount;\n\n    if (mergeState.infoStream.isEnabled(\"SM\")) {\n      mergeState.infoStream.message(\"SM\", \"merge store matchedCount=\" + count + \" vs \" + mergeState.readers.size());\n      if (count != mergeState.readers.size()) {\n        mergeState.infoStream.message(\"SM\", \"\" + (mergeState.readers.size() - count) + \" non-bulk merges\");\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2131047ecceac64b54ba70feec3d26bbd7e483d7","date":1411862069,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders#MatchingReaders(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders#MatchingReaders(MergeState).mjava","sourceNew":"  MatchingReaders(MergeState mergeState) {\n    // If the i'th reader is a SegmentReader and has\n    // identical fieldName -> number mapping, then this\n    // array will be non-null at position i:\n    int numReaders = mergeState.maxDocs.length;\n    int matchedCount = 0;\n    matchingReaders = new boolean[numReaders];\n\n    // If this reader is a SegmentReader, and all of its\n    // field name -> number mappings match the \"merged\"\n    // FieldInfos, then we can do a bulk copy of the\n    // stored fields:\n\n    nextReader:\n    for (int i = 0; i < numReaders; i++) {\n      for (FieldInfo fi : mergeState.fieldInfos[i]) {\n        FieldInfo other = mergeState.mergeFieldInfos.fieldInfo(fi.number);\n        if (other == null || !other.name.equals(fi.name)) {\n          continue nextReader;\n        }\n      }\n      matchingReaders[i] = true;\n      matchedCount++;\n    }\n    \n    this.count = matchedCount;\n\n    if (mergeState.infoStream.isEnabled(\"SM\")) {\n      mergeState.infoStream.message(\"SM\", \"merge store matchedCount=\" + count + \" vs \" + numReaders);\n      if (count != numReaders) {\n        mergeState.infoStream.message(\"SM\", \"\" + (numReaders - count) + \" non-bulk merges\");\n      }\n    }\n  }\n\n","sourceOld":"  MatchingReaders(MergeState mergeState) {\n    // If the i'th reader is a SegmentReader and has\n    // identical fieldName -> number mapping, then this\n    // array will be non-null at position i:\n    int numReaders = mergeState.readers.size();\n    int matchedCount = 0;\n    matchingSegmentReaders = new SegmentReader[numReaders];\n\n    // If this reader is a SegmentReader, and all of its\n    // field name -> number mappings match the \"merged\"\n    // FieldInfos, then we can do a bulk copy of the\n    // stored fields:\n    for (int i = 0; i < numReaders; i++) {\n      LeafReader reader = mergeState.readers.get(i);\n      // TODO: we may be able to broaden this to\n      // non-SegmentReaders, since FieldInfos is now\n      // required?  But... this'd also require exposing\n      // bulk-copy (TVs and stored fields) API in foreign\n      // readers..\n      if (reader instanceof SegmentReader) {\n        SegmentReader segmentReader = (SegmentReader) reader;\n        boolean same = true;\n        FieldInfos segmentFieldInfos = segmentReader.getFieldInfos();\n        for (FieldInfo fi : segmentFieldInfos) {\n          FieldInfo other = mergeState.fieldInfos.fieldInfo(fi.number);\n          if (other == null || !other.name.equals(fi.name)) {\n            same = false;\n            break;\n          }\n        }\n        if (same) {\n          matchingSegmentReaders[i] = segmentReader;\n          matchedCount++;\n        }\n      }\n    }\n    \n    this.count = matchedCount;\n\n    if (mergeState.infoStream.isEnabled(\"SM\")) {\n      mergeState.infoStream.message(\"SM\", \"merge store matchedCount=\" + count + \" vs \" + mergeState.readers.size());\n      if (count != mergeState.readers.size()) {\n        mergeState.infoStream.message(\"SM\", \"\" + (mergeState.readers.size() - count) + \" non-bulk merges\");\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders#MatchingReaders(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders#MatchingReaders(MergeState).mjava","sourceNew":"  MatchingReaders(MergeState mergeState) {\n    // If the i'th reader is a SegmentReader and has\n    // identical fieldName -> number mapping, then this\n    // array will be non-null at position i:\n    int numReaders = mergeState.maxDocs.length;\n    int matchedCount = 0;\n    matchingReaders = new boolean[numReaders];\n\n    // If this reader is a SegmentReader, and all of its\n    // field name -> number mappings match the \"merged\"\n    // FieldInfos, then we can do a bulk copy of the\n    // stored fields:\n\n    nextReader:\n    for (int i = 0; i < numReaders; i++) {\n      for (FieldInfo fi : mergeState.fieldInfos[i]) {\n        FieldInfo other = mergeState.mergeFieldInfos.fieldInfo(fi.number);\n        if (other == null || !other.name.equals(fi.name)) {\n          continue nextReader;\n        }\n      }\n      matchingReaders[i] = true;\n      matchedCount++;\n    }\n    \n    this.count = matchedCount;\n\n    if (mergeState.infoStream.isEnabled(\"SM\")) {\n      mergeState.infoStream.message(\"SM\", \"merge store matchedCount=\" + count + \" vs \" + numReaders);\n      if (count != numReaders) {\n        mergeState.infoStream.message(\"SM\", \"\" + (numReaders - count) + \" non-bulk merges\");\n      }\n    }\n  }\n\n","sourceOld":"  MatchingReaders(MergeState mergeState) {\n    // If the i'th reader is a SegmentReader and has\n    // identical fieldName -> number mapping, then this\n    // array will be non-null at position i:\n    int numReaders = mergeState.readers.size();\n    int matchedCount = 0;\n    matchingSegmentReaders = new SegmentReader[numReaders];\n\n    // If this reader is a SegmentReader, and all of its\n    // field name -> number mappings match the \"merged\"\n    // FieldInfos, then we can do a bulk copy of the\n    // stored fields:\n    for (int i = 0; i < numReaders; i++) {\n      LeafReader reader = mergeState.readers.get(i);\n      // TODO: we may be able to broaden this to\n      // non-SegmentReaders, since FieldInfos is now\n      // required?  But... this'd also require exposing\n      // bulk-copy (TVs and stored fields) API in foreign\n      // readers..\n      if (reader instanceof SegmentReader) {\n        SegmentReader segmentReader = (SegmentReader) reader;\n        boolean same = true;\n        FieldInfos segmentFieldInfos = segmentReader.getFieldInfos();\n        for (FieldInfo fi : segmentFieldInfos) {\n          FieldInfo other = mergeState.fieldInfos.fieldInfo(fi.number);\n          if (other == null || !other.name.equals(fi.name)) {\n            same = false;\n            break;\n          }\n        }\n        if (same) {\n          matchingSegmentReaders[i] = segmentReader;\n          matchedCount++;\n        }\n      }\n    }\n    \n    this.count = matchedCount;\n\n    if (mergeState.infoStream.isEnabled(\"SM\")) {\n      mergeState.infoStream.message(\"SM\", \"merge store matchedCount=\" + count + \" vs \" + mergeState.readers.size());\n      if (count != mergeState.readers.size()) {\n        mergeState.infoStream.message(\"SM\", \"\" + (mergeState.readers.size() - count) + \" non-bulk merges\");\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9bb9a29a5e71a90295f175df8919802993142c9a":["c9fb5f46e264daf5ba3860defe623a89d202dd87","2131047ecceac64b54ba70feec3d26bbd7e483d7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2131047ecceac64b54ba70feec3d26bbd7e483d7":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"22a2e66dfda83847e80095b8693c660742ab3e9c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["22a2e66dfda83847e80095b8693c660742ab3e9c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9bb9a29a5e71a90295f175df8919802993142c9a"]},"commit2Childs":{"9bb9a29a5e71a90295f175df8919802993142c9a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["22a2e66dfda83847e80095b8693c660742ab3e9c"],"2131047ecceac64b54ba70feec3d26bbd7e483d7":["9bb9a29a5e71a90295f175df8919802993142c9a"],"22a2e66dfda83847e80095b8693c660742ab3e9c":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["9bb9a29a5e71a90295f175df8919802993142c9a","2131047ecceac64b54ba70feec3d26bbd7e483d7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}