{"path":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,boolean,int).mjava","commits":[{"id":"e1f693ce507c40f77e3a92acd16c6b79cdd730e4","date":1323036169,"type":1,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,boolean,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = true; // nocommit: remove readOnly at all\n    this.segmentInfos = sis;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b8414cdacb05e1277df96a30710f570f4251d9a","date":1323040348,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,boolean,int).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.segmentInfos = sis;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(true /** nocommit: remove readOnly */, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = true; // nocommit: remove readOnly at all\n    this.segmentInfos = sis;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4b8414cdacb05e1277df96a30710f570f4251d9a":["e1f693ce507c40f77e3a92acd16c6b79cdd730e4"],"e1f693ce507c40f77e3a92acd16c6b79cdd730e4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"4b8414cdacb05e1277df96a30710f570f4251d9a":[],"e1f693ce507c40f77e3a92acd16c6b79cdd730e4":["4b8414cdacb05e1277df96a30710f570f4251d9a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e1f693ce507c40f77e3a92acd16c6b79cdd730e4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4b8414cdacb05e1277df96a30710f570f4251d9a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}