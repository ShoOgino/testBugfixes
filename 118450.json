{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","commits":[{"id":"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","date":1346834651,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    @Override\n    public void close() throws IOException {\n      delegateFieldsConsumer.close();\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    @Override\n    public void close() throws IOException {\n      delegateFieldsConsumer.close();\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fa80a35d7c4b2b1e83082b275e3e8328ab93db52","date":1381766157,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    public void close() throws IOException {\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    @Override\n    public void close() throws IOException {\n      delegateFieldsConsumer.close();\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    public void close() throws IOException {\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    public void close() throws IOException {\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<Map.Entry<FieldInfo,FuzzySet>>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    public void close() throws IOException {\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    public void close() throws IOException {\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    public void close() throws IOException {\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    public void close() throws IOException {\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory\n            .createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME,\n            BLOOM_CODEC_VERSION);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7afb64ff3a701f68b2689cafff6c5bdeb4f67f63","date":1398957288,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    @Override\n    public void close() throws IOException {\n\n      delegateFieldsConsumer.close();\n\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    public void close() throws IOException {\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29a93e7fb303505e4a719e87f378d9a45db981d0","date":1412167802,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    @Override\n    public void close() throws IOException {\n\n      delegateFieldsConsumer.close();\n\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeSegmentHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    @Override\n    public void close() throws IOException {\n\n      delegateFieldsConsumer.close();\n\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    @Override\n    public void close() throws IOException {\n\n      delegateFieldsConsumer.close();\n\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeSegmentHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    @Override\n    public void close() throws IOException {\n\n      delegateFieldsConsumer.close();\n\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    @Override\n    public void close() throws IOException {\n\n      delegateFieldsConsumer.close();\n\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeIndexHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    @Override\n    public void close() throws IOException {\n\n      delegateFieldsConsumer.close();\n\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeSegmentHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    @Override\n    public void close() throws IOException {\n\n      delegateFieldsConsumer.close();\n\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeIndexHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    @Override\n    public void close() throws IOException {\n\n      delegateFieldsConsumer.close();\n\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeSegmentHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b07132423639577d6f68cebbec9c83599d5d5a3a","date":1419020622,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.BloomFilteredFieldsConsumer#close().mjava","sourceNew":"    @Override\n    public void close() throws IOException {\n      if (closed) {\n        return;\n      }\n      closed = true;\n      delegateFieldsConsumer.close();\n\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      try (IndexOutput bloomOutput = state.directory.createOutput(bloomFileName, state.context)) {\n        CodecUtil.writeIndexHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","sourceOld":"    @Override\n    public void close() throws IOException {\n\n      delegateFieldsConsumer.close();\n\n      // Now we are done accumulating values for these fields\n      List<Entry<FieldInfo,FuzzySet>> nonSaturatedBlooms = new ArrayList<>();\n      \n      for (Entry<FieldInfo,FuzzySet> entry : bloomFilters.entrySet()) {\n        FuzzySet bloomFilter = entry.getValue();\n        if(!bloomFilterFactory.isSaturated(bloomFilter,entry.getKey())){          \n          nonSaturatedBlooms.add(entry);\n        }\n      }\n      String bloomFileName = IndexFileNames.segmentFileName(\n          state.segmentInfo.name, state.segmentSuffix, BLOOM_EXTENSION);\n      IndexOutput bloomOutput = null;\n      try {\n        bloomOutput = state.directory.createOutput(bloomFileName, state.context);\n        CodecUtil.writeIndexHeader(bloomOutput, BLOOM_CODEC_NAME, VERSION_CURRENT, state.segmentInfo.getId(), state.segmentSuffix);\n        // remember the name of the postings format we will delegate to\n        bloomOutput.writeString(delegatePostingsFormat.getName());\n        \n        // First field in the output file is the number of fields+blooms saved\n        bloomOutput.writeInt(nonSaturatedBlooms.size());\n        for (Entry<FieldInfo,FuzzySet> entry : nonSaturatedBlooms) {\n          FieldInfo fieldInfo = entry.getKey();\n          FuzzySet bloomFilter = entry.getValue();\n          bloomOutput.writeInt(fieldInfo.number);\n          saveAppropriatelySizedBloomFilter(bloomOutput, bloomFilter, fieldInfo);\n        }\n        CodecUtil.writeFooter(bloomOutput);\n      } finally {\n        IOUtils.close(bloomOutput);\n      }\n      //We are done with large bitsets so no need to keep them hanging around\n      bloomFilters.clear(); \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"b07132423639577d6f68cebbec9c83599d5d5a3a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["fa80a35d7c4b2b1e83082b275e3e8328ab93db52"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["29a93e7fb303505e4a719e87f378d9a45db981d0"],"7afb64ff3a701f68b2689cafff6c5bdeb4f67f63":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"9bb9a29a5e71a90295f175df8919802993142c9a":["7afb64ff3a701f68b2689cafff6c5bdeb4f67f63","29a93e7fb303505e4a719e87f378d9a45db981d0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"29a93e7fb303505e4a719e87f378d9a45db981d0":["7afb64ff3a701f68b2689cafff6c5bdeb4f67f63"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b07132423639577d6f68cebbec9c83599d5d5a3a"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["5eb2511ababf862ea11e10761c70ee560cd84510","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5eb2511ababf862ea11e10761c70ee560cd84510","7afb64ff3a701f68b2689cafff6c5bdeb4f67f63"],"b07132423639577d6f68cebbec9c83599d5d5a3a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["fa80a35d7c4b2b1e83082b275e3e8328ab93db52"],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"7afb64ff3a701f68b2689cafff6c5bdeb4f67f63":["9bb9a29a5e71a90295f175df8919802993142c9a","29a93e7fb303505e4a719e87f378d9a45db981d0"],"9bb9a29a5e71a90295f175df8919802993142c9a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"29a93e7fb303505e4a719e87f378d9a45db981d0":["3384e6013a93e4d11b7d75388693f8d0388602bf","9bb9a29a5e71a90295f175df8919802993142c9a"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["b07132423639577d6f68cebbec9c83599d5d5a3a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}