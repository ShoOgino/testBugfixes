{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","commits":[{"id":"56df73d43b6fc340f5332322862382c7e30f4368","date":1378304988,"type":1,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/temp/TempFSTTermsReader#TempFSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    this.in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public TempFSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, TempFSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    this.in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f948dd442d23baa6cbb28daf77c8db78b351329","date":1378742876,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"/dev/null","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    this.in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      version = readHeader(in);\n      if (version >= FSTTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    this.in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      version = readHeader(in);\n      if (version >= FSTTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    this.in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, current, previous);\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d640273789c74bf4f1412b99c67294c14293d154","date":1412169281,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkSegmentHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      version = readHeader(in);\n      if (version >= FSTTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkSegmentHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      version = readHeader(in);\n      if (version >= FSTTermsWriter.TERMS_VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"99eb4a732d1a908f4636ace52928876136bf1896","date":1413829552,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkSegmentHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkSegmentHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkSegmentHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkSegmentHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2bb2842e561df4e8e9ad89010605fc86ac265465","date":1414768208,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"086ffe31d8fba0110227db122974163709ecc1b4","date":1509678141,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = in.readVLong();\n        // if frequencies are omitted, sumTotalTermFreq=sumDocFreq and we only write one value\n        long sumDocFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? sumTotalTermFreq : in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d523b8189b211dd1630166aa77b8c88bb48b3fcc","date":1510144168,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = in.readVLong();\n        // if frequencies are omitted, sumTotalTermFreq=sumDocFreq and we only write one value\n        long sumDocFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? sumTotalTermFreq : in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? -1 : in.readVLong();\n        long sumDocFreq = in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb77022ef17ff655c519a3f6ecd393747ac88bcf","date":1578579386,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":null,"sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = in.readVLong();\n        // if frequencies are omitted, sumTotalTermFreq=sumDocFreq and we only write one value\n        long sumDocFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? sumTotalTermFreq : in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06ab276a5660cb79daae8c5ede063531c700a03a","date":1578587874,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"/dev/null","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = in.readVLong();\n        // if frequencies are omitted, sumTotalTermFreq=sumDocFreq and we only write one value\n        long sumDocFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? sumTotalTermFreq : in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"08a5168e06e037794c0aba7f94f76ff3c09704d2","date":1579264785,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader#FSTTermsReader(SegmentReadState,PostingsReaderBase).mjava","sourceNew":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = in.readVLong();\n        // if frequencies are omitted, sumTotalTermFreq=sumDocFreq and we only write one value\n        long sumDocFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? sumTotalTermFreq : in.readVLong();\n        int docCount = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","sourceOld":"  public FSTTermsReader(SegmentReadState state, PostingsReaderBase postingsReader) throws IOException {\n    final String termsFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, FSTTermsWriter.TERMS_EXTENSION);\n\n    this.postingsReader = postingsReader;\n    final IndexInput in = state.directory.openInput(termsFileName, state.context);\n\n    boolean success = false;\n    try {\n      CodecUtil.checkIndexHeader(in, FSTTermsWriter.TERMS_CODEC_NAME,\n                                       FSTTermsWriter.TERMS_VERSION_START,\n                                       FSTTermsWriter.TERMS_VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      CodecUtil.checksumEntireFile(in);\n      this.postingsReader.init(in, state);\n      seekDir(in);\n\n      final FieldInfos fieldInfos = state.fieldInfos;\n      final int numFields = in.readVInt();\n      for (int i = 0; i < numFields; i++) {\n        int fieldNumber = in.readVInt();\n        FieldInfo fieldInfo = fieldInfos.fieldInfo(fieldNumber);\n        long numTerms = in.readVLong();\n        long sumTotalTermFreq = in.readVLong();\n        // if frequencies are omitted, sumTotalTermFreq=sumDocFreq and we only write one value\n        long sumDocFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? sumTotalTermFreq : in.readVLong();\n        int docCount = in.readVInt();\n        int longsSize = in.readVInt();\n        TermsReader current = new TermsReader(fieldInfo, in, numTerms, sumTotalTermFreq, sumDocFreq, docCount, longsSize);\n        TermsReader previous = fields.put(fieldInfo.name, current);\n        checkFieldSummary(state.segmentInfo, in, current, previous);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["2f948dd442d23baa6cbb28daf77c8db78b351329","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["2f948dd442d23baa6cbb28daf77c8db78b351329"],"56df73d43b6fc340f5332322862382c7e30f4368":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"99eb4a732d1a908f4636ace52928876136bf1896":["d640273789c74bf4f1412b99c67294c14293d154"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["2bb2842e561df4e8e9ad89010605fc86ac265465","086ffe31d8fba0110227db122974163709ecc1b4"],"cb77022ef17ff655c519a3f6ecd393747ac88bcf":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["99eb4a732d1a908f4636ace52928876136bf1896"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"086ffe31d8fba0110227db122974163709ecc1b4":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"9bb9a29a5e71a90295f175df8919802993142c9a":["1f3b037cd083286b2af89f96e768f85dcd8072d6","d640273789c74bf4f1412b99c67294c14293d154"],"d640273789c74bf4f1412b99c67294c14293d154":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"08a5168e06e037794c0aba7f94f76ff3c09704d2":["06ab276a5660cb79daae8c5ede063531c700a03a"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"2f948dd442d23baa6cbb28daf77c8db78b351329":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","56df73d43b6fc340f5332322862382c7e30f4368"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["08a5168e06e037794c0aba7f94f76ff3c09704d2"],"06ab276a5660cb79daae8c5ede063531c700a03a":["cb77022ef17ff655c519a3f6ecd393747ac88bcf"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5eb2511ababf862ea11e10761c70ee560cd84510","9bb9a29a5e71a90295f175df8919802993142c9a","d640273789c74bf4f1412b99c67294c14293d154"],"56df73d43b6fc340f5332322862382c7e30f4368":["2f948dd442d23baa6cbb28daf77c8db78b351329"],"99eb4a732d1a908f4636ace52928876136bf1896":["3384e6013a93e4d11b7d75388693f8d0388602bf"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["cb77022ef17ff655c519a3f6ecd393747ac88bcf"],"cb77022ef17ff655c519a3f6ecd393747ac88bcf":["06ab276a5660cb79daae8c5ede063531c700a03a"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"2bb2842e561df4e8e9ad89010605fc86ac265465":["d523b8189b211dd1630166aa77b8c88bb48b3fcc","086ffe31d8fba0110227db122974163709ecc1b4"],"086ffe31d8fba0110227db122974163709ecc1b4":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"d640273789c74bf4f1412b99c67294c14293d154":["99eb4a732d1a908f4636ace52928876136bf1896","9bb9a29a5e71a90295f175df8919802993142c9a"],"9bb9a29a5e71a90295f175df8919802993142c9a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["56df73d43b6fc340f5332322862382c7e30f4368","2f948dd442d23baa6cbb28daf77c8db78b351329"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["2bb2842e561df4e8e9ad89010605fc86ac265465"],"08a5168e06e037794c0aba7f94f76ff3c09704d2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2f948dd442d23baa6cbb28daf77c8db78b351329":["5eb2511ababf862ea11e10761c70ee560cd84510","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"06ab276a5660cb79daae8c5ede063531c700a03a":["08a5168e06e037794c0aba7f94f76ff3c09704d2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}