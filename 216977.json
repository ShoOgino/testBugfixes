{"path":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","commits":[{"id":"4522ffca5a1f420c6a02198c9332d7c596a30ca5","date":1457270822,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap);\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24df944aceb57e67b2594b585cf004783054b5b2","date":1458934816,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader values) throws IOException {\n\n            boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(fieldInfo.name),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(fieldInfo.name, new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap);\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"10005c6013abbd1102f2463cf95604d4c8774c99","date":1469460814,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader values, double maxMBSortInHeap) throws IOException {\n\n            boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(fieldInfo.name),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(fieldInfo.name, new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader values) throws IOException {\n\n            boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(fieldInfo.name),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(fieldInfo.name, new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d08973aa47f2cf98a588293a53af4e948952ccfb","date":1469518724,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader values, double maxMBSortInHeap) throws IOException {\n\n            boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(fieldInfo.name),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(fieldInfo.name, new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader values) throws IOException {\n\n            boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(fieldInfo.name),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(fieldInfo.name, new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0567940defa1ea6eb8a039d9d36e3682063f8a4","date":1469815320,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader values) throws IOException {\n\n            boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(fieldInfo.name),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(fieldInfo.name, new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader values, double maxMBSortInHeap) throws IOException {\n\n            boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(fieldInfo.name),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(fieldInfo.name, new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader values) throws IOException {\n\n            boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(fieldInfo.name),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(fieldInfo.name, new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader values, double maxMBSortInHeap) throws IOException {\n\n            boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(fieldInfo.name),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(fieldInfo.name, new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"367f57e2ee85b7f7e28cfe73370a22cf67624f65","date":1476778467,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n            boolean singleValuePerDoc = values.size() == values.getDocCount();\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader values) throws IOException {\n\n            boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(fieldInfo.name),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(fieldInfo.name, new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n            boolean singleValuePerDoc = values.size() == values.getDocCount();\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader values) throws IOException {\n\n            boolean singleValuePerDoc = values.size(fieldInfo.name) == values.getDocCount(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(fieldInfo.name),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(fieldInfo.name, new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6652c943595e92c187ee904c382863013eae28f","date":1539042663,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n            boolean singleValuePerDoc = values.size() == values.getDocCount();\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDataDimensionCount(),\n                                                                   fieldInfo.getPointIndexDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n            boolean singleValuePerDoc = values.size() == values.getDocCount();\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"78bdc7d6906146edb12a1a6c1f765ba680ed5124","date":1549523533,"type":3,"author":"iverase","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDataDimensionCount(),\n                                                                   fieldInfo.getPointIndexDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n            boolean singleValuePerDoc = values.size() == values.getDocCount();\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDataDimensionCount(),\n                                                                   fieldInfo.getPointIndexDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   singleValuePerDoc,\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"59ed8c026ba85e3c42fb89605b2032dc6f9cc241","date":1581113294,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointIndexDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDataDimensionCount(),\n                                                                   fieldInfo.getPointIndexDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"78e689a3b60e84c75dc6dd7b181a71fc19ef8482","date":1591689554,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splits:\n\n        return new Lucene86PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointIndexDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                Runnable finalizer = writer.finish(metaOut, indexOut, dataOut);\n                if (finalizer != null) {\n                  metaOut.writeInt(fieldInfo.number);\n                  finalizer.run();\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene86PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splis:\n\n        return new Lucene60PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointIndexDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                if (writer.getPointCount() > 0) {\n                  indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene60PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb94bf667d51f9c390c99d97afb36b7caab6b6e9","date":1599548621,"type":3,"author":"Ignacio Vera","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec#pointsFormat().mjava","sourceNew":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splits:\n\n        return new Lucene86PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n\n            BKDConfig config = new BKDConfig(fieldInfo.getPointDimensionCount(),\n                fieldInfo.getPointIndexDimensionCount(),\n                fieldInfo.getPointNumBytes(),\n                maxPointsInLeafNode);\n\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   config,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                Runnable finalizer = writer.finish(metaOut, indexOut, dataOut);\n                if (finalizer != null) {\n                  metaOut.writeInt(fieldInfo.number);\n                  finalizer.run();\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene86PointsReader(readState);\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public PointsFormat pointsFormat() {\n    return new AssertingPointsFormat(new PointsFormat() {\n      @Override\n      public PointsWriter fieldsWriter(SegmentWriteState writeState) throws IOException {\n\n        // Randomize how BKDWriter chooses its splits:\n\n        return new Lucene86PointsWriter(writeState, maxPointsInLeafNode, maxMBSortInHeap) {\n          @Override\n          public void writeField(FieldInfo fieldInfo, PointsReader reader) throws IOException {\n\n            PointValues values = reader.getValues(fieldInfo.name);\n\n            try (BKDWriter writer = new RandomlySplittingBKDWriter(writeState.segmentInfo.maxDoc(),\n                                                                   writeState.directory,\n                                                                   writeState.segmentInfo.name,\n                                                                   fieldInfo.getPointDimensionCount(),\n                                                                   fieldInfo.getPointIndexDimensionCount(),\n                                                                   fieldInfo.getPointNumBytes(),\n                                                                   maxPointsInLeafNode,\n                                                                   maxMBSortInHeap,\n                                                                   values.size(),\n                                                                   bkdSplitRandomSeed ^ fieldInfo.name.hashCode())) {\n                values.intersect(new IntersectVisitor() {\n                    @Override\n                    public void visit(int docID) {\n                      throw new IllegalStateException();\n                    }\n\n                    public void visit(int docID, byte[] packedValue) throws IOException {\n                      writer.add(packedValue, docID);\n                    }\n\n                    @Override\n                    public PointValues.Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n                      return PointValues.Relation.CELL_CROSSES_QUERY;\n                    }\n                  });\n\n                // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n                Runnable finalizer = writer.finish(metaOut, indexOut, dataOut);\n                if (finalizer != null) {\n                  metaOut.writeInt(fieldInfo.number);\n                  finalizer.run();\n                }\n              }\n          }\n        };\n      }\n\n      @Override\n      public PointsReader fieldsReader(SegmentReadState readState) throws IOException {\n        return new Lucene86PointsReader(readState);\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b0567940defa1ea6eb8a039d9d36e3682063f8a4":["d08973aa47f2cf98a588293a53af4e948952ccfb"],"bb94bf667d51f9c390c99d97afb36b7caab6b6e9":["78e689a3b60e84c75dc6dd7b181a71fc19ef8482"],"59ed8c026ba85e3c42fb89605b2032dc6f9cc241":["78bdc7d6906146edb12a1a6c1f765ba680ed5124"],"f6652c943595e92c187ee904c382863013eae28f":["367f57e2ee85b7f7e28cfe73370a22cf67624f65"],"78bdc7d6906146edb12a1a6c1f765ba680ed5124":["f6652c943595e92c187ee904c382863013eae28f"],"24df944aceb57e67b2594b585cf004783054b5b2":["4522ffca5a1f420c6a02198c9332d7c596a30ca5"],"367f57e2ee85b7f7e28cfe73370a22cf67624f65":["b0567940defa1ea6eb8a039d9d36e3682063f8a4"],"10005c6013abbd1102f2463cf95604d4c8774c99":["24df944aceb57e67b2594b585cf004783054b5b2"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["24df944aceb57e67b2594b585cf004783054b5b2","367f57e2ee85b7f7e28cfe73370a22cf67624f65"],"4522ffca5a1f420c6a02198c9332d7c596a30ca5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"78e689a3b60e84c75dc6dd7b181a71fc19ef8482":["59ed8c026ba85e3c42fb89605b2032dc6f9cc241"],"d08973aa47f2cf98a588293a53af4e948952ccfb":["24df944aceb57e67b2594b585cf004783054b5b2","10005c6013abbd1102f2463cf95604d4c8774c99"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["d08973aa47f2cf98a588293a53af4e948952ccfb","b0567940defa1ea6eb8a039d9d36e3682063f8a4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bb94bf667d51f9c390c99d97afb36b7caab6b6e9"]},"commit2Childs":{"b0567940defa1ea6eb8a039d9d36e3682063f8a4":["367f57e2ee85b7f7e28cfe73370a22cf67624f65","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"bb94bf667d51f9c390c99d97afb36b7caab6b6e9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"59ed8c026ba85e3c42fb89605b2032dc6f9cc241":["78e689a3b60e84c75dc6dd7b181a71fc19ef8482"],"f6652c943595e92c187ee904c382863013eae28f":["78bdc7d6906146edb12a1a6c1f765ba680ed5124"],"78bdc7d6906146edb12a1a6c1f765ba680ed5124":["59ed8c026ba85e3c42fb89605b2032dc6f9cc241"],"24df944aceb57e67b2594b585cf004783054b5b2":["10005c6013abbd1102f2463cf95604d4c8774c99","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d08973aa47f2cf98a588293a53af4e948952ccfb"],"367f57e2ee85b7f7e28cfe73370a22cf67624f65":["f6652c943595e92c187ee904c382863013eae28f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"10005c6013abbd1102f2463cf95604d4c8774c99":["d08973aa47f2cf98a588293a53af4e948952ccfb"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"4522ffca5a1f420c6a02198c9332d7c596a30ca5":["24df944aceb57e67b2594b585cf004783054b5b2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4522ffca5a1f420c6a02198c9332d7c596a30ca5"],"78e689a3b60e84c75dc6dd7b181a71fc19ef8482":["bb94bf667d51f9c390c99d97afb36b7caab6b6e9"],"d08973aa47f2cf98a588293a53af4e948952ccfb":["b0567940defa1ea6eb8a039d9d36e3682063f8a4","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}