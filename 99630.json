{"path":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[FieldAndText]).mjava","commits":[{"id":"08932c793647a36953d1816b1060121f48820d3f","date":1277386540,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[FieldAndText]).mjava","pathOld":"/dev/null","sourceNew":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<FieldAndText> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms);\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    BytesRef utf8 = new BytesRef(10);\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (DEBUG) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(new FieldAndText(t));\n      uniqueTermCount++;\n      lastText = text;\n      UnicodeUtil.UTF16toUTF8(text, 0, text.length(), utf8);\n\n      if (DEBUG) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, utf8.bytes, utf8.length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (DEBUG) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(FieldAndText t: fieldTerms) {\n        System.out.println(\"  \" + t.field + \":\" + UnicodeUtil.toHexString(t.text.utf8ToString()));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, -1, null, false, true, codec);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"256366680a61632ef0df879389a7715601d37823","date":1278264334,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[FieldAndText]).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[FieldAndText]).mjava","sourceNew":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<FieldAndText> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms);\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    BytesRef utf8 = new BytesRef(10);\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (VERBOSE) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(new FieldAndText(t));\n      uniqueTermCount++;\n      lastText = text;\n      UnicodeUtil.UTF16toUTF8(text, 0, text.length(), utf8);\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, utf8.bytes, utf8.length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(FieldAndText t: fieldTerms) {\n        System.out.println(\"  \" + t.field + \":\" + UnicodeUtil.toHexString(t.text.utf8ToString()));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, -1, null, false, true, codec);\n  }\n\n","sourceOld":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<FieldAndText> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms);\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    BytesRef utf8 = new BytesRef(10);\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (DEBUG) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(new FieldAndText(t));\n      uniqueTermCount++;\n      lastText = text;\n      UnicodeUtil.UTF16toUTF8(text, 0, text.length(), utf8);\n\n      if (DEBUG) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, utf8.bytes, utf8.length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (DEBUG) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(FieldAndText t: fieldTerms) {\n        System.out.println(\"  \" + t.field + \":\" + UnicodeUtil.toHexString(t.text.utf8ToString()));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, -1, null, false, true, codec);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4f29ba80b723649f5feb7e37afe1a558dd2c1304","date":1278318805,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[Term]).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#makePreFlexSegment(Random,String,Directory,FieldInfos,Codec,List[FieldAndText]).mjava","sourceNew":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<Term> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms, new Comparator<Term>() {\n      public int compare(Term o1, Term o2) {\n        return o1.compareToUTF16(o2);\n      }\n    });\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (VERBOSE) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(t);\n      uniqueTermCount++;\n      lastText = text;\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, t.bytes().bytes, t.bytes().length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + t.field() + \":\" + toHexString(t));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, -1, null, false, true, codec);\n  }\n\n","sourceOld":"  private SegmentInfo makePreFlexSegment(Random r, String segName, Directory dir, FieldInfos fieldInfos, Codec codec, List<FieldAndText> fieldTerms) throws IOException {\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    List<Term> terms = new ArrayList<Term>();\n\n    int tc = 0;\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      fieldInfos.add(field, true, false, false, false, false, false, false);\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n      for(int i=0;i<numTerms;i++) {\n        String s;\n        if (r.nextInt(3) == 1) {\n          s = makeDifficultRandomUnicodeString(r);\n        } else {\n          s = _TestUtil.randomUnicodeString(r);\n\n          // The surrogate dance uses 0xffff to seek-to-end\n          // of blocks.  Also, pre-4.0 indices are already\n          // guaranteed to not contain the char 0xffff since\n          // it's mapped during indexing:\n          s = s.replace((char) 0xffff, (char) 0xfffe);\n        }\n        terms.add(protoTerm.createTerm(s + \"_\" + (tc++)));\n      }\n    }\n\n    fieldInfos.write(dir, segName);\n\n    // sorts in UTF16 order, just like preflex:\n    Collections.sort(terms);\n\n    TermInfosWriter w = new TermInfosWriter(dir, segName, fieldInfos, 128);\n    TermInfo ti = new TermInfo();\n    BytesRef utf8 = new BytesRef(10);\n    String lastText = null;\n    int uniqueTermCount = 0;\n    if (VERBOSE) {\n      System.out.println(\"TEST: utf16 order:\");\n    }\n    for(Term t : terms) {\n      FieldInfo fi = fieldInfos.fieldInfo(t.field());\n\n      String text = t.text();\n      if (lastText != null && lastText.equals(text)) {\n        continue;\n      }\n      fieldTerms.add(new FieldAndText(t));\n      uniqueTermCount++;\n      lastText = text;\n      UnicodeUtil.UTF16toUTF8(text, 0, text.length(), utf8);\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n      w.add(fi.number, utf8.bytes, utf8.length, ti);\n    }\n    w.close();\n\n    Collections.sort(fieldTerms);\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(FieldAndText t: fieldTerms) {\n        System.out.println(\"  \" + t.field + \":\" + UnicodeUtil.toHexString(t.text.utf8ToString()));\n      }\n    }\n\n    dir.createOutput(segName + \".prx\").close();\n    dir.createOutput(segName + \".frq\").close();\n\n    // !!hack alert!! stuffing uniqueTermCount in as docCount\n    return new SegmentInfo(segName, uniqueTermCount, dir, false, -1, null, false, true, codec);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["256366680a61632ef0df879389a7715601d37823"],"08932c793647a36953d1816b1060121f48820d3f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"256366680a61632ef0df879389a7715601d37823":["08932c793647a36953d1816b1060121f48820d3f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4f29ba80b723649f5feb7e37afe1a558dd2c1304"]},"commit2Childs":{"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"08932c793647a36953d1816b1060121f48820d3f":["256366680a61632ef0df879389a7715601d37823"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["08932c793647a36953d1816b1060121f48820d3f"],"256366680a61632ef0df879389a7715601d37823":["4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}