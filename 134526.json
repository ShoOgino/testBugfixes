{"path":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","commits":[{"id":"b0c7a8f7304b75b1528814c5820fa23a96816c27","date":1298314239,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14ec33385f6fbb6ce172882d14605790418a5d31","date":1298910796,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1224a4027481acce15495b03bce9b48b93b42722","date":1300792329,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", TextField.TYPE_STORED, \"first field\"));\n    d1.add(new Field(\"f2\", TextField.TYPE_STORED, \"second field\"));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n    customType2.setStoreTermVectors(true);\n    d2.add(new Field(\"f2\", TextField.TYPE_STORED, \"second field\"));\n    d2.add(new Field(\"f1\", customType2, \"first field\"));\n    d2.add(new Field(\"f3\", TextField.TYPE_STORED, \"third field\"));\n    d2.add(new Field(\"f4\", TextField.TYPE_STORED, \"fourth field\"));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d1.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    d2.add(new Field(\"f2\", \"second field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f1\", \"first field\", Store.YES, Index.ANALYZED, TermVector.YES));\n    d2.add(new Field(\"f3\", \"third field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    d2.add(new Field(\"f4\", \"fourth field\", Store.YES, Index.ANALYZED, TermVector.NO));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd","date":1317197236,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", TextField.TYPE_STORED));\n    d1.add(new Field(\"f2\", \"second field\", TextField.TYPE_STORED));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n    customType2.setStoreTermVectors(true);\n    d2.add(new Field(\"f2\", \"second field\", TextField.TYPE_STORED));\n    d2.add(new Field(\"f1\", \"first field\", customType2));\n    d2.add(new Field(\"f3\", \"third field\", TextField.TYPE_STORED));\n    d2.add(new Field(\"f4\", \"fourth field\", TextField.TYPE_STORED));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", TextField.TYPE_STORED, \"first field\"));\n    d1.add(new Field(\"f2\", TextField.TYPE_STORED, \"second field\"));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n    customType2.setStoreTermVectors(true);\n    d2.add(new Field(\"f2\", TextField.TYPE_STORED, \"second field\"));\n    d2.add(new Field(\"f1\", customType2, \"first field\"));\n    d2.add(new Field(\"f3\", TextField.TYPE_STORED, \"third field\"));\n    d2.add(new Field(\"f4\", TextField.TYPE_STORED, \"fourth field\"));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", TextField.TYPE_STORED));\n    d1.add(new Field(\"f2\", \"second field\", TextField.TYPE_STORED));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n    customType2.setStoreTermVectors(true);\n    d2.add(new Field(\"f2\", \"second field\", TextField.TYPE_STORED));\n    d2.add(new Field(\"f1\", \"first field\", customType2));\n    d2.add(new Field(\"f3\", \"third field\", TextField.TYPE_STORED));\n    d2.add(new Field(\"f4\", \"fourth field\", TextField.TYPE_STORED));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.forceMerge(1);\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", TextField.TYPE_STORED));\n    d1.add(new Field(\"f2\", \"second field\", TextField.TYPE_STORED));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n    customType2.setStoreTermVectors(true);\n    d2.add(new Field(\"f2\", \"second field\", TextField.TYPE_STORED));\n    d2.add(new Field(\"f1\", \"first field\", customType2));\n    d2.add(new Field(\"f3\", \"third field\", TextField.TYPE_STORED));\n    d2.add(new Field(\"f4\", \"fourth field\", TextField.TYPE_STORED));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.optimize();\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestConsistentFieldNumbers#testAddIndexes().mjava","sourceNew":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", TextField.TYPE_STORED));\n    d1.add(new Field(\"f2\", \"second field\", TextField.TYPE_STORED));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n    customType2.setStoreTermVectors(true);\n    d2.add(new Field(\"f2\", \"second field\", TextField.TYPE_STORED));\n    d2.add(new Field(\"f1\", \"first field\", customType2));\n    d2.add(new Field(\"f3\", \"third field\", TextField.TYPE_STORED));\n    d2.add(new Field(\"f4\", \"fourth field\", TextField.TYPE_STORED));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.forceMerge(1);\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","sourceOld":"  @Test\n  public void testAddIndexes() throws Exception {\n    Directory dir1 = newDirectory();\n    Directory dir2 = newDirectory();\n    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d1 = new Document();\n    d1.add(new Field(\"f1\", \"first field\", TextField.TYPE_STORED));\n    d1.add(new Field(\"f2\", \"second field\", TextField.TYPE_STORED));\n    writer.addDocument(d1);\n\n    writer.close();\n    writer = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n\n    Document d2 = new Document();\n    FieldType customType2 = new FieldType(TextField.TYPE_STORED);\n    customType2.setStoreTermVectors(true);\n    d2.add(new Field(\"f2\", \"second field\", TextField.TYPE_STORED));\n    d2.add(new Field(\"f1\", \"first field\", customType2));\n    d2.add(new Field(\"f3\", \"third field\", TextField.TYPE_STORED));\n    d2.add(new Field(\"f4\", \"fourth field\", TextField.TYPE_STORED));\n    writer.addDocument(d2);\n\n    writer.close();\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(NoMergePolicy.COMPOUND_FILES));\n    writer.addIndexes(dir2);\n    writer.close();\n\n    SegmentInfos sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(2, sis.size());\n\n    FieldInfos fis1 = sis.info(0).getFieldInfos();\n    FieldInfos fis2 = sis.info(1).getFieldInfos();\n\n    assertEquals(\"f1\", fis1.fieldInfo(0).name);\n    assertEquals(\"f2\", fis1.fieldInfo(1).name);\n    // make sure the ordering of the \"external\" segment is preserved\n    assertEquals(\"f2\", fis2.fieldInfo(0).name);\n    assertEquals(\"f1\", fis2.fieldInfo(1).name);\n    assertEquals(\"f3\", fis2.fieldInfo(2).name);\n    assertEquals(\"f4\", fis2.fieldInfo(3).name);\n\n    writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.forceMerge(1);\n    writer.close();\n\n    sis = new SegmentInfos();\n    sis.read(dir1);\n    assertEquals(1, sis.size());\n\n    FieldInfos fis3 = sis.info(0).getFieldInfos();\n\n    // after merging the ordering should be identical to the first segment\n    assertEquals(\"f1\", fis3.fieldInfo(0).name);\n    assertEquals(\"f2\", fis3.fieldInfo(1).name);\n    assertEquals(\"f3\", fis3.fieldInfo(2).name);\n    assertEquals(\"f4\", fis3.fieldInfo(3).name);\n\n    dir1.close();\n    dir2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["d619839baa8ce5503e496b94a9e42ad6f079293f","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["1224a4027481acce15495b03bce9b48b93b42722"],"14ec33385f6fbb6ce172882d14605790418a5d31":["b0c7a8f7304b75b1528814c5820fa23a96816c27"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1224a4027481acce15495b03bce9b48b93b42722"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a3776dccca01c11e7046323cfad46a3b4a471233":["1224a4027481acce15495b03bce9b48b93b42722","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"1224a4027481acce15495b03bce9b48b93b42722":["14ec33385f6fbb6ce172882d14605790418a5d31"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"962d04139994fce5193143ef35615499a9a96d78":[],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"14ec33385f6fbb6ce172882d14605790418a5d31":["1224a4027481acce15495b03bce9b48b93b42722"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["14ec33385f6fbb6ce172882d14605790418a5d31","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d619839baa8ce5503e496b94a9e42ad6f079293f","b0c7a8f7304b75b1528814c5820fa23a96816c27","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7e4db59c6b6c10e25322cfb41c4c19d78b4298bd"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"7e4db59c6b6c10e25322cfb41c4c19d78b4298bd":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"1224a4027481acce15495b03bce9b48b93b42722":["f2c5f0cb44df114db4228c8f77861714b5cabaea","d619839baa8ce5503e496b94a9e42ad6f079293f","a3776dccca01c11e7046323cfad46a3b4a471233"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}