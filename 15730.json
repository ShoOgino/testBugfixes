{"path":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","commits":[{"id":"540f57ba7d9d46ccc6f0157e8b8021a4c969770d","date":1272974241,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","pathOld":"solr/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilter#testChain().mjava","sourceNew":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharStream cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\", \".\",\n        CharReader.get( new StringReader( BLOCK ) ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", \".\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", \".\", cs );\n    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 });\n  }\n\n","sourceOld":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharStream cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\", \".\",\n        CharReader.get( new StringReader( BLOCK ) ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", \".\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", \".\", cs );\n    TokenStream ts = new WhitespaceTokenizer(DEFAULT_VERSION, cs );\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f080986da691a3bba7b757f43ab72cdc82b57ce","date":1273069619,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","pathOld":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","sourceNew":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharStream cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\", \".\",\n        CharReader.get( new StringReader( BLOCK ) ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", \".\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", \".\", cs );\n    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 });\n  }\n\n","sourceOld":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharStream cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\", \".\",\n        CharReader.get( new StringReader( BLOCK ) ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", \".\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", \".\", cs );\n    TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, cs );\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"540f57ba7d9d46ccc6f0157e8b8021a4c969770d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["540f57ba7d9d46ccc6f0157e8b8021a4c969770d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0f080986da691a3bba7b757f43ab72cdc82b57ce"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["540f57ba7d9d46ccc6f0157e8b8021a4c969770d"],"540f57ba7d9d46ccc6f0157e8b8021a4c969770d":["0f080986da691a3bba7b757f43ab72cdc82b57ce"],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}