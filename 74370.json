{"path":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","commits":[{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","sourceNew":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","sourceOld":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","sourceNew":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","sourceOld":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71387d8cb6923eb831b17a8b734608ba2e21c653","date":1414126093,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","sourceNew":null,"sourceOld":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cc45c615dbb82bf79d5f9550286098367874fbf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71387d8cb6923eb831b17a8b734608ba2e21c653"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4cc45c615dbb82bf79d5f9550286098367874fbf"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4cc45c615dbb82bf79d5f9550286098367874fbf","402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["71387d8cb6923eb831b17a8b734608ba2e21c653"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}