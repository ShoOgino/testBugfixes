{"path":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random.nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random.nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random.nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random.nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random.nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random.nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random.nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random.nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random.nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random.nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random.nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random.nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random.nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random.nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random.nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random.nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random.nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random.nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random.nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random.nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random, 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c1fc791afc075c00a9ce29ca03eca7a6c143c28a","date":1341671452,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2acf500f78aa12b92e371fd89c719291986b6b90","date":1341846236,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"46d8ada1fff8d18cb197c38c7983225162599948","date":1341853497,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(\"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(\"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f45457a742a53533c348c4b990b1c579ff364467","date":1353197071,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29f7cc7c185412da66c1d0089d9e75da01329a00","date":1353364851,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d7e5f3aa5935964617824d1f9b2599ddb334464","date":1353762831,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2dd9934a49477c83301120ba51827d91eb3606d5","date":1353767072,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":["87d6f9603307ae2ad642fb01deedf031320fd0c3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"32608e0a08e76fe8668cd1dcca0e7a8f6d7f3f0a","date":1357739321,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"49bbfc33f80659ba9aa9d301edaae82dd4e01b5a","date":1358789155,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b9624d6812569ade79b26877d8ed1fc0e0b75e0e","date":1359417950,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    // nocommit\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"848c1fa47fde81f7cc5c0ac72af419407f8a6d53","date":1359418767,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    // nocommit\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    double [] doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    assertTrue(\"doubles Size: \" + doubles.length + \" is not: \" + NUM_DOCS, doubles.length == NUM_DOCS);\n    for (int i = 0; i < doubles.length; i++) {\n      assertTrue(doubles[i] + \" does not equal: \" + (Double.MAX_VALUE - i), doubles[i] == (Double.MAX_VALUE - i));\n\n    }\n    \n    long [] longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    assertTrue(\"longs Size: \" + longs.length + \" is not: \" + NUM_DOCS, longs.length == NUM_DOCS);\n    for (int i = 0; i < longs.length; i++) {\n      assertTrue(longs[i] + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs[i] == (Long.MAX_VALUE - i));\n\n    }\n    \n    byte [] bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    assertTrue(\"bytes Size: \" + bytes.length + \" is not: \" + NUM_DOCS, bytes.length == NUM_DOCS);\n    for (int i = 0; i < bytes.length; i++) {\n      assertTrue(bytes[i] + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes[i] == (byte) (Byte.MAX_VALUE - i));\n\n    }\n    \n    short [] shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    assertTrue(\"shorts Size: \" + shorts.length + \" is not: \" + NUM_DOCS, shorts.length == NUM_DOCS);\n    for (int i = 0; i < shorts.length; i++) {\n      assertTrue(shorts[i] + \" does not equal: \" + (Short.MAX_VALUE - i), shorts[i] == (short) (Short.MAX_VALUE - i));\n\n    }\n    \n    int [] ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    assertTrue(\"ints Size: \" + ints.length + \" is not: \" + NUM_DOCS, ints.length == NUM_DOCS);\n    for (int i = 0; i < ints.length; i++) {\n      assertTrue(ints[i] + \" does not equal: \" + (Integer.MAX_VALUE - i), ints[i] == (Integer.MAX_VALUE - i));\n\n    }\n    \n    float [] floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    assertTrue(\"floats Size: \" + floats.length + \" is not: \" + NUM_DOCS, floats.length == NUM_DOCS);\n    for (int i = 0; i < floats.length; i++) {\n      assertTrue(floats[i] + \" does not equal: \" + (Float.MAX_VALUE - i), floats[i] == (Float.MAX_VALUE - i));\n\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    FieldCache.DocTermsIndex termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + termsIndex.size() + \" is not: \" + NUM_DOCS, termsIndex.size() == NUM_DOCS);\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = termsIndex.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.numOrd();\n    // System.out.println(\"nTerms=\"+nTerms);\n\n    TermsEnum tenum = termsIndex.getTermsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=1; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      BytesRef val2 = termsIndex.lookup(i,val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val2, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = _TestUtil.nextInt(random(), 1, nTerms-1);\n      BytesRef val1 = termsIndex.lookup(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val1));\n      assertEquals(val1, tenum.term());\n    }\n    \n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    FieldCache.DocTerms terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    assertTrue(\"doubles Size: \" + terms.size() + \" is not: \" + NUM_DOCS, terms.size() == NUM_DOCS);\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term = terms.getTerm(i, br);\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":["e9069c2e665572658f846820b6cb8ad53de19df0","fd9cc9d77712aba3662f24632df7539ab75e3667","629c38c4ae4e303d0617e05fbfe508140b32f0a3","b1add9ddc0005b07550d4350720aac22dc9886b3","65eb076d345a794256daba691a2b366657c807e8","be20f9fed1d3edcb1c84abcc39df87a90fab22df","25833e37398c5210d7bddaca9d14de45e194439a"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f438915b81b54f1fdff40443da8c4fb15c61c777","date":1360597404,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    // nocommit: test this with reflection or something, that its really from the same DTO\n    // assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    // nocommit: what exactly does this test?\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3e4a9d2228b1d0367ab23ab19e1b1af63b83c70d","date":1360736371,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    // nocommit: test this with reflection or something, that its really from the same DTO\n    // assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    // nocommit: what exactly does this test?\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ddbb72a33557d2b5bc22ee95daf3281c43560502","date":1361334582,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    DocTermOrds termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    TermsEnum termsEnum = termOrds.getOrdTermsEnum(reader);\n    assertSame(\"Second request to cache return same DocTermOrds\", termOrds, cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\"));\n    DocTermOrds.TermOrdsIterator reuse = null;\n    for (int i = 0; i < NUM_DOCS; i++) {\n      reuse = termOrds.lookup(i, reuse);\n      final int[] buffer = new int[5];\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (;;) {\n        int chunk = reuse.read(buffer);\n        if (chunk == 0) {\n          for (int ord = 0; ord < values.size(); ord++) {\n            BytesRef term = values.get(ord);\n            assertNull(String.format(Locale.ROOT, \"Document[%d] misses field must be null. Has value %s for ord %d\", i, term, ord), term);\n          }\n          break;\n        }\n\n        for(int idx=0; idx < chunk; idx++) {\n          int key = buffer[idx];\n          termsEnum.seekExact((long) key);\n          String actual = termsEnum.term().utf8ToString();\n          String expected = values.get(idx).utf8ToString();\n          if (!expected.equals(actual)) {\n              reuse = termOrds.lookup(i, reuse);\n              reuse.read(buffer);\n          }\n          assertTrue(String.format(Locale.ROOT, \"Expected value %s for doc %d and ord %d, but was %s\", expected, i, idx, actual), expected.equals(actual));\n        }\n\n        if (chunk <= buffer.length) {\n          break;\n        }\n      }\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e129598ae448211d969dd7cdf2ad4558a0658a1","date":1362963550,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"64e6baad25b7155a116cb0126b4e2a06b945a5c5","date":1362976847,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5c2b6033d1fc841b41dbf56c765ce3dc053ecba6","date":1363054647,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = new SortedDocValuesTermsEnum(termsIndex);\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"59a0020b413d44dd79d85d7a66ed5004265fb453","date":1371758877,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n\n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n\n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.DEFAULT_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.DEFAULT_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n    \n    FieldCache.Bytes bytes = cache.getBytes(reader, \"theByte\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", bytes, cache.getBytes(reader, \"theByte\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", bytes, cache.getBytes(reader, \"theByte\", FieldCache.DEFAULT_BYTE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(bytes.get(i) + \" does not equal: \" + (Byte.MAX_VALUE - i), bytes.get(i) == (byte) (Byte.MAX_VALUE - i));\n    }\n    \n    FieldCache.Shorts shorts = cache.getShorts(reader, \"theShort\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", shorts, cache.getShorts(reader, \"theShort\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", shorts, cache.getShorts(reader, \"theShort\", FieldCache.DEFAULT_SHORT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(shorts.get(i) + \" does not equal: \" + (Short.MAX_VALUE - i), shorts.get(i) == (short) (Short.MAX_VALUE - i));\n    }\n    \n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.DEFAULT_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.DEFAULT_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"87d6f9603307ae2ad642fb01deedf031320fd0c3","date":1377877563,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n\n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\", true);\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\", true));\n    Bits bits = cache.getDocsWithField(reader, \"theRandomUnicodeString\");\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (!bits.get(i)) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\", false);\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n\n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\"));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (br.bytes == BinaryDocValues.MISSING) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\");\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":["2dd9934a49477c83301120ba51827d91eb3606d5","be20f9fed1d3edcb1c84abcc39df87a90fab22df"],"bugIntro":["8c146731a64debc22c115bbf11ee1a060aa7ea02","8c146731a64debc22c115bbf11ee1a060aa7ea02","8c146731a64debc22c115bbf11ee1a060aa7ea02"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d2dcffe8fc78b093a5f4207f492bbae185740f6a","date":1380887572,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n\n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\", true);\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\", true));\n    Bits bits = cache.getDocsWithField(reader, \"theRandomUnicodeString\");\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (!bits.get(i)) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\", false);\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purgeByCacheKey(reader.getCoreCacheKey());\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n\n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\", true);\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\", true));\n    Bits bits = cache.getDocsWithField(reader, \"theRandomUnicodeString\");\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (!bits.get(i)) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\", false);\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purge(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n\n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\", true);\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\", true));\n    Bits bits = cache.getDocsWithField(reader, \"theRandomUnicodeString\");\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (!bits.get(i)) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\", false);\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<>(new LinkedHashSet<>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purgeByCacheKey(reader.getCoreCacheKey());\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n\n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\", true);\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\", true));\n    Bits bits = cache.getDocsWithField(reader, \"theRandomUnicodeString\");\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (!bits.get(i)) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\", false);\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<BytesRef>(new LinkedHashSet<BytesRef>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purgeByCacheKey(reader.getCoreCacheKey());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c","date":1399816179,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    NumericDocValues doubles = cache.getNumerics(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getNumerics(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Double.doubleToLongBits(Double.MAX_VALUE - i), doubles.get(i));\n    }\n    \n    NumericDocValues longs = cache.getNumerics(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getNumerics(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Long.MAX_VALUE - i, longs.get(i));\n    }\n\n    NumericDocValues ints = cache.getNumerics(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getNumerics(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Integer.MAX_VALUE - i, ints.get(i));\n    }\n    \n    NumericDocValues floats = cache.getNumerics(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getNumerics(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Float.floatToIntBits(Float.MAX_VALUE - i), floats.get(i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\", true);\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\", true));\n    Bits bits = cache.getDocsWithField(reader, \"theRandomUnicodeString\");\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (!bits.get(i)) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\", false);\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<>(new LinkedHashSet<>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purgeByCacheKey(reader.getCoreCacheKey());\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n\n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\", true);\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\", true));\n    Bits bits = cache.getDocsWithField(reader, \"theRandomUnicodeString\");\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (!bits.get(i)) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\", false);\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<>(new LinkedHashSet<>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purgeByCacheKey(reader.getCoreCacheKey());\n  }\n\n","bugFix":null,"bugIntro":["8c146731a64debc22c115bbf11ee1a060aa7ea02","8c146731a64debc22c115bbf11ee1a060aa7ea02","8c146731a64debc22c115bbf11ee1a060aa7ea02"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93dd449115a9247533e44bab47e8429e5dccbc6d","date":1400258396,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    NumericDocValues doubles = cache.getNumerics(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getNumerics(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Double.doubleToLongBits(Double.MAX_VALUE - i), doubles.get(i));\n    }\n    \n    NumericDocValues longs = cache.getNumerics(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getNumerics(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Long.MAX_VALUE - i, longs.get(i));\n    }\n\n    NumericDocValues ints = cache.getNumerics(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getNumerics(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Integer.MAX_VALUE - i, ints.get(i));\n    }\n    \n    NumericDocValues floats = cache.getNumerics(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getNumerics(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Float.floatToIntBits(Float.MAX_VALUE - i), floats.get(i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\", true);\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\", true));\n    Bits bits = cache.getDocsWithField(reader, \"theRandomUnicodeString\");\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (!bits.get(i)) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\", false);\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\", null);\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\", null);\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<>(new LinkedHashSet<>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\", null);\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purgeByCacheKey(reader.getCoreCacheKey());\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n\n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\", true);\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\", true));\n    Bits bits = cache.getDocsWithField(reader, \"theRandomUnicodeString\");\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (!bits.get(i)) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\", false);\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<>(new LinkedHashSet<>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purgeByCacheKey(reader.getCoreCacheKey());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"56572ec06f1407c066d6b7399413178b33176cd8","date":1400495675,"type":5,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCache#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldCache#test().mjava","sourceNew":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    NumericDocValues doubles = cache.getNumerics(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getNumerics(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Double.doubleToLongBits(Double.MAX_VALUE - i), doubles.get(i));\n    }\n    \n    NumericDocValues longs = cache.getNumerics(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getNumerics(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Long.MAX_VALUE - i, longs.get(i));\n    }\n\n    NumericDocValues ints = cache.getNumerics(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getNumerics(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Integer.MAX_VALUE - i, ints.get(i));\n    }\n    \n    NumericDocValues floats = cache.getNumerics(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getNumerics(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertEquals(Float.floatToIntBits(Float.MAX_VALUE - i), floats.get(i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\", true);\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\", true));\n    Bits bits = cache.getDocsWithField(reader, \"theRandomUnicodeString\");\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (!bits.get(i)) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\", false);\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\", null);\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\", null);\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<>(new LinkedHashSet<>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\", null);\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purgeByCacheKey(reader.getCoreCacheKey());\n  }\n\n","sourceOld":"  public void test() throws IOException {\n    FieldCache cache = FieldCache.DEFAULT;\n    FieldCache.Doubles doubles = cache.getDoubles(reader, \"theDouble\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", doubles, cache.getDoubles(reader, \"theDouble\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", doubles, cache.getDoubles(reader, \"theDouble\", FieldCache.NUMERIC_UTILS_DOUBLE_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(doubles.get(i) + \" does not equal: \" + (Double.MAX_VALUE - i), doubles.get(i) == (Double.MAX_VALUE - i));\n    }\n    \n    FieldCache.Longs longs = cache.getLongs(reader, \"theLong\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", longs, cache.getLongs(reader, \"theLong\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", longs, cache.getLongs(reader, \"theLong\", FieldCache.NUMERIC_UTILS_LONG_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(longs.get(i) + \" does not equal: \" + (Long.MAX_VALUE - i) + \" i=\" + i, longs.get(i) == (Long.MAX_VALUE - i));\n    }\n\n    FieldCache.Ints ints = cache.getInts(reader, \"theInt\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", ints, cache.getInts(reader, \"theInt\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", ints, cache.getInts(reader, \"theInt\", FieldCache.NUMERIC_UTILS_INT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(ints.get(i) + \" does not equal: \" + (Integer.MAX_VALUE - i), ints.get(i) == (Integer.MAX_VALUE - i));\n    }\n    \n    FieldCache.Floats floats = cache.getFloats(reader, \"theFloat\", random().nextBoolean());\n    assertSame(\"Second request to cache return same array\", floats, cache.getFloats(reader, \"theFloat\", random().nextBoolean()));\n    assertSame(\"Second request with explicit parser return same array\", floats, cache.getFloats(reader, \"theFloat\", FieldCache.NUMERIC_UTILS_FLOAT_PARSER, random().nextBoolean()));\n    for (int i = 0; i < NUM_DOCS; i++) {\n      assertTrue(floats.get(i) + \" does not equal: \" + (Float.MAX_VALUE - i), floats.get(i) == (Float.MAX_VALUE - i));\n    }\n\n    Bits docsWithField = cache.getDocsWithField(reader, \"theLong\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"theLong\"));\n    assertTrue(\"docsWithField(theLong) must be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(theLong) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertTrue(docsWithField.get(i));\n    }\n    \n    docsWithField = cache.getDocsWithField(reader, \"sparse\");\n    assertSame(\"Second request to cache return same array\", docsWithField, cache.getDocsWithField(reader, \"sparse\"));\n    assertFalse(\"docsWithField(sparse) must not be class Bits.MatchAllBits\", docsWithField instanceof Bits.MatchAllBits);\n    assertTrue(\"docsWithField(sparse) Size: \" + docsWithField.length() + \" is not: \" + NUM_DOCS, docsWithField.length() == NUM_DOCS);\n    for (int i = 0; i < docsWithField.length(); i++) {\n      assertEquals(i%2 == 0, docsWithField.get(i));\n    }\n\n    // getTermsIndex\n    SortedDocValues termsIndex = cache.getTermsIndex(reader, \"theRandomUnicodeString\");\n    assertSame(\"Second request to cache return same array\", termsIndex, cache.getTermsIndex(reader, \"theRandomUnicodeString\"));\n    final BytesRef br = new BytesRef();\n    for (int i = 0; i < NUM_DOCS; i++) {\n      final BytesRef term;\n      final int ord = termsIndex.getOrd(i);\n      if (ord == -1) {\n        term = null;\n      } else {\n        termsIndex.lookupOrd(ord, br);\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    int nTerms = termsIndex.getValueCount();\n\n    TermsEnum tenum = termsIndex.termsEnum();\n    BytesRef val = new BytesRef();\n    for (int i=0; i<nTerms; i++) {\n      BytesRef val1 = tenum.next();\n      termsIndex.lookupOrd(i, val);\n      // System.out.println(\"i=\"+i);\n      assertEquals(val, val1);\n    }\n\n    // seek the enum around (note this isn't a great test here)\n    int num = atLeast(100);\n    for (int i = 0; i < num; i++) {\n      int k = random().nextInt(nTerms);\n      termsIndex.lookupOrd(k, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    for(int i=0;i<nTerms;i++) {\n      termsIndex.lookupOrd(i, val);\n      assertEquals(TermsEnum.SeekStatus.FOUND, tenum.seekCeil(val));\n      assertEquals(val, tenum.term());\n    }\n\n    // test bad field\n    termsIndex = cache.getTermsIndex(reader, \"bogusfield\");\n\n    // getTerms\n    BinaryDocValues terms = cache.getTerms(reader, \"theRandomUnicodeString\", true);\n    assertSame(\"Second request to cache return same array\", terms, cache.getTerms(reader, \"theRandomUnicodeString\", true));\n    Bits bits = cache.getDocsWithField(reader, \"theRandomUnicodeString\");\n    for (int i = 0; i < NUM_DOCS; i++) {\n      terms.get(i, br);\n      final BytesRef term;\n      if (!bits.get(i)) {\n        term = null;\n      } else {\n        term = br;\n      }\n      final String s = term == null ? null : term.utf8ToString();\n      assertTrue(\"for doc \" + i + \": \" + s + \" does not equal: \" + unicodeStrings[i], unicodeStrings[i] == null || unicodeStrings[i].equals(s));\n    }\n\n    // test bad field\n    terms = cache.getTerms(reader, \"bogusfield\", false);\n\n    // getDocTermOrds\n    SortedSetDocValues termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    int numEntries = cache.getCacheEntries().length;\n    // ask for it again, and check that we didnt create any additional entries:\n    termOrds = cache.getDocTermOrds(reader, \"theRandomUnicodeMultiValuedField\");\n    assertEquals(numEntries, cache.getCacheEntries().length);\n\n    for (int i = 0; i < NUM_DOCS; i++) {\n      termOrds.setDocument(i);\n      // This will remove identical terms. A DocTermOrds doesn't return duplicate ords for a docId\n      List<BytesRef> values = new ArrayList<>(new LinkedHashSet<>(Arrays.asList(multiValued[i])));\n      for (BytesRef v : values) {\n        if (v == null) {\n          // why does this test use null values... instead of an empty list: confusing\n          break;\n        }\n        long ord = termOrds.nextOrd();\n        assert ord != SortedSetDocValues.NO_MORE_ORDS;\n        BytesRef scratch = new BytesRef();\n        termOrds.lookupOrd(ord, scratch);\n        assertEquals(v, scratch);\n      }\n      assertEquals(SortedSetDocValues.NO_MORE_ORDS, termOrds.nextOrd());\n    }\n\n    // test bad field\n    termOrds = cache.getDocTermOrds(reader, \"bogusfield\");\n    assertTrue(termOrds.getValueCount() == 0);\n\n    FieldCache.DEFAULT.purgeByCacheKey(reader.getCoreCacheKey());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b9624d6812569ade79b26877d8ed1fc0e0b75e0e":["49bbfc33f80659ba9aa9d301edaae82dd4e01b5a"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["5c2b6033d1fc841b41dbf56c765ce3dc053ecba6","59a0020b413d44dd79d85d7a66ed5004265fb453"],"2dd9934a49477c83301120ba51827d91eb3606d5":["9d7e5f3aa5935964617824d1f9b2599ddb334464"],"29f7cc7c185412da66c1d0089d9e75da01329a00":["f45457a742a53533c348c4b990b1c579ff364467"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2acf500f78aa12b92e371fd89c719291986b6b90":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","c1fc791afc075c00a9ce29ca03eca7a6c143c28a"],"ddbb72a33557d2b5bc22ee95daf3281c43560502":["d4d69c535930b5cce125cff868d40f6373dc27d4","3e4a9d2228b1d0367ab23ab19e1b1af63b83c70d"],"56572ec06f1407c066d6b7399413178b33176cd8":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","93dd449115a9247533e44bab47e8429e5dccbc6d"],"f45457a742a53533c348c4b990b1c579ff364467":["2acf500f78aa12b92e371fd89c719291986b6b90"],"7e129598ae448211d969dd7cdf2ad4558a0658a1":["ddbb72a33557d2b5bc22ee95daf3281c43560502"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"59a0020b413d44dd79d85d7a66ed5004265fb453":["5c2b6033d1fc841b41dbf56c765ce3dc053ecba6"],"9d7e5f3aa5935964617824d1f9b2599ddb334464":["29f7cc7c185412da66c1d0089d9e75da01329a00"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["d2dcffe8fc78b093a5f4207f492bbae185740f6a"],"d2dcffe8fc78b093a5f4207f492bbae185740f6a":["87d6f9603307ae2ad642fb01deedf031320fd0c3"],"848c1fa47fde81f7cc5c0ac72af419407f8a6d53":["b9624d6812569ade79b26877d8ed1fc0e0b75e0e"],"f438915b81b54f1fdff40443da8c4fb15c61c777":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"87d6f9603307ae2ad642fb01deedf031320fd0c3":["59a0020b413d44dd79d85d7a66ed5004265fb453"],"49bbfc33f80659ba9aa9d301edaae82dd4e01b5a":["32608e0a08e76fe8668cd1dcca0e7a8f6d7f3f0a"],"32608e0a08e76fe8668cd1dcca0e7a8f6d7f3f0a":["2dd9934a49477c83301120ba51827d91eb3606d5"],"46d8ada1fff8d18cb197c38c7983225162599948":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","2acf500f78aa12b92e371fd89c719291986b6b90"],"5c2b6033d1fc841b41dbf56c765ce3dc053ecba6":["64e6baad25b7155a116cb0126b4e2a06b945a5c5"],"3e4a9d2228b1d0367ab23ab19e1b1af63b83c70d":["f438915b81b54f1fdff40443da8c4fb15c61c777"],"c1fc791afc075c00a9ce29ca03eca7a6c143c28a":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["2acf500f78aa12b92e371fd89c719291986b6b90","848c1fa47fde81f7cc5c0ac72af419407f8a6d53"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","2acf500f78aa12b92e371fd89c719291986b6b90"],"64e6baad25b7155a116cb0126b4e2a06b945a5c5":["7e129598ae448211d969dd7cdf2ad4558a0658a1"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["93dd449115a9247533e44bab47e8429e5dccbc6d"]},"commit2Childs":{"b9624d6812569ade79b26877d8ed1fc0e0b75e0e":["848c1fa47fde81f7cc5c0ac72af419407f8a6d53"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"2dd9934a49477c83301120ba51827d91eb3606d5":["32608e0a08e76fe8668cd1dcca0e7a8f6d7f3f0a"],"29f7cc7c185412da66c1d0089d9e75da01329a00":["9d7e5f3aa5935964617824d1f9b2599ddb334464"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"2acf500f78aa12b92e371fd89c719291986b6b90":["f45457a742a53533c348c4b990b1c579ff364467","46d8ada1fff8d18cb197c38c7983225162599948","d4d69c535930b5cce125cff868d40f6373dc27d4","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"ddbb72a33557d2b5bc22ee95daf3281c43560502":["7e129598ae448211d969dd7cdf2ad4558a0658a1"],"56572ec06f1407c066d6b7399413178b33176cd8":[],"f45457a742a53533c348c4b990b1c579ff364467":["29f7cc7c185412da66c1d0089d9e75da01329a00"],"7e129598ae448211d969dd7cdf2ad4558a0658a1":["64e6baad25b7155a116cb0126b4e2a06b945a5c5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"59a0020b413d44dd79d85d7a66ed5004265fb453":["37a0f60745e53927c4c876cfe5b5a58170f0646c","87d6f9603307ae2ad642fb01deedf031320fd0c3"],"9d7e5f3aa5935964617824d1f9b2599ddb334464":["2dd9934a49477c83301120ba51827d91eb3606d5"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["56572ec06f1407c066d6b7399413178b33176cd8","b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c","93dd449115a9247533e44bab47e8429e5dccbc6d"],"d2dcffe8fc78b093a5f4207f492bbae185740f6a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"848c1fa47fde81f7cc5c0ac72af419407f8a6d53":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"f438915b81b54f1fdff40443da8c4fb15c61c777":["3e4a9d2228b1d0367ab23ab19e1b1af63b83c70d"],"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"87d6f9603307ae2ad642fb01deedf031320fd0c3":["d2dcffe8fc78b093a5f4207f492bbae185740f6a"],"49bbfc33f80659ba9aa9d301edaae82dd4e01b5a":["b9624d6812569ade79b26877d8ed1fc0e0b75e0e"],"32608e0a08e76fe8668cd1dcca0e7a8f6d7f3f0a":["49bbfc33f80659ba9aa9d301edaae82dd4e01b5a"],"46d8ada1fff8d18cb197c38c7983225162599948":[],"5c2b6033d1fc841b41dbf56c765ce3dc053ecba6":["37a0f60745e53927c4c876cfe5b5a58170f0646c","59a0020b413d44dd79d85d7a66ed5004265fb453"],"3e4a9d2228b1d0367ab23ab19e1b1af63b83c70d":["ddbb72a33557d2b5bc22ee95daf3281c43560502"],"c1fc791afc075c00a9ce29ca03eca7a6c143c28a":["2acf500f78aa12b92e371fd89c719291986b6b90"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["ddbb72a33557d2b5bc22ee95daf3281c43560502","f438915b81b54f1fdff40443da8c4fb15c61c777"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["56572ec06f1407c066d6b7399413178b33176cd8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["2acf500f78aa12b92e371fd89c719291986b6b90","46d8ada1fff8d18cb197c38c7983225162599948","c1fc791afc075c00a9ce29ca03eca7a6c143c28a","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"64e6baad25b7155a116cb0126b4e2a06b945a5c5":["5c2b6033d1fc841b41dbf56c765ce3dc053ecba6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","56572ec06f1407c066d6b7399413178b33176cd8","46d8ada1fff8d18cb197c38c7983225162599948","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}