{"path":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","commits":[{"id":"b17aab72b6576c145865eafaf502403b11caeaea","date":1353012500,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","pathOld":"/dev/null","sourceNew":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 1));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 3));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    DocValues dv = ireader.leaves().get(0).reader().docValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = 1;\n      } else {\n        expected = 3;\n      }\n      assertEquals(expected, dv.getSource().getInt(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7cd329bd749496f6c58b586a6c0dd0dc8201206f","date":1353092226,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","sourceNew":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 1));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 3));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\", random().nextBoolean());\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = 1;\n      } else {\n        expected = 3;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 1));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 3));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    DocValues dv = ireader.leaves().get(0).reader().docValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = 1;\n      } else {\n        expected = 3;\n      }\n      assertEquals(expected, dv.getSource().getInt(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4d374b2bebd0d52acaa61038fbf23068620fba7","date":1353240004,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","sourceNew":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 1));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 3));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = 1;\n      } else {\n        expected = 3;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 1));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 3));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\", random().nextBoolean());\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = 1;\n      } else {\n        expected = 3;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1ed65f3455364344c6d2ff76ea5421aac754eae7","date":1353261762,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","sourceNew":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 1));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 3));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = 1;\n      } else {\n        expected = 3;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 1));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 3));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = 1;\n      } else {\n        expected = 3;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3ee07e8e258de164ee9346427b4307823c0b041d","date":1353263551,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","sourceNew":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", -10));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 99));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = -10;\n      } else {\n        expected = 99;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 1));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 3));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = 1;\n      } else {\n        expected = 3;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef","date":1358808656,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","sourceNew":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new LongDocValuesField(\"dv\", -10));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new LongDocValuesField(\"dv\", 99));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = -10;\n      } else {\n        expected = 99;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", -10));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new PackedLongDocValuesField(\"dv\", 99));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = -10;\n      } else {\n        expected = 99;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"423d89a2b3cc419b647c07c2b3fdbc54311d07f9","date":1358836612,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","sourceNew":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new NumericDocValuesField(\"dv\", -10));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new NumericDocValuesField(\"dv\", 99));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = -10;\n      } else {\n        expected = 99;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new LongDocValuesField(\"dv\", -10));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new LongDocValuesField(\"dv\", 99));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = -10;\n      } else {\n        expected = 99;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2ec08217282b5e9df023dcdff55c745ff68b1c7d","date":1359392781,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#testTwoDocumentsMerged().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","sourceNew":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    conf.setCodec(getCodec());\n    conf.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, conf);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new NumericDocValuesField(\"dv\", -10));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new NumericDocValuesField(\"dv\", 99));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = -10;\n      } else {\n        expected = 99;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    IndexWriter iwriter = new IndexWriter(directory, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"0\", StringField.TYPE_STORED));\n    doc.add(new NumericDocValuesField(\"dv\", -10));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    doc.add(new NumericDocValuesField(\"dv\", 99));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    assert ireader.leaves().size() == 1;\n    NumericDocValues dv = ireader.leaves().get(0).reader().getNumericDocValues(\"dv\");\n    for(int i=0;i<2;i++) {\n      StoredDocument doc2 = ireader.leaves().get(0).reader().document(i);\n      long expected;\n      if (doc2.get(\"id\").equals(\"0\")) {\n        expected = -10;\n      } else {\n        expected = 99;\n      }\n      assertEquals(expected, dv.get(i));\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f366ce28775e2b8ea4e06355009471328711666d","date":1360551293,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","pathOld":"/dev/null","sourceNew":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    IndexWriterConfig iwconfig = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwconfig.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory, iwconfig);\n    Document doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"hello\")));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"world\")));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    DirectoryReader ireader = DirectoryReader.open(directory); // read-only=true\n    SortedSetDocValues dv = getOnlySegmentReader(ireader).getSortedSetDocValues(\"field\");\n    OrdIterator oi = dv.getOrds(0, null);\n    assertEquals(0, oi.nextOrd());\n    assertEquals(OrdIterator.NO_MORE_ORDS, oi.nextOrd());\n    \n    BytesRef bytes = new BytesRef();\n    dv.lookupOrd(0, bytes);\n    assertEquals(new BytesRef(\"hello\"), bytes);\n    \n    oi = dv.getOrds(1, oi);\n    assertEquals(1, oi.nextOrd());\n    assertEquals(OrdIterator.NO_MORE_ORDS, oi.nextOrd());\n    \n    dv.lookupOrd(1, bytes);\n    assertEquals(new BytesRef(\"world\"), bytes);\n    \n    assertEquals(2, dv.getValueCount());\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"988e3f44fe797ee94a0135abfe27e5872b99844d","date":1360563792,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","sourceNew":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    IndexWriterConfig iwconfig = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwconfig.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory, iwconfig);\n    Document doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"hello\")));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"world\")));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    DirectoryReader ireader = DirectoryReader.open(directory); // read-only=true\n    SortedSetDocValues dv = getOnlySegmentReader(ireader).getSortedSetDocValues(\"field\");\n    dv.setDocument(0);\n    assertEquals(0, dv.nextOrd());\n    assertEquals(SortedSetDocValues.NO_MORE_ORDS, dv.nextOrd());\n    \n    BytesRef bytes = new BytesRef();\n    dv.lookupOrd(0, bytes);\n    assertEquals(new BytesRef(\"hello\"), bytes);\n    \n    dv.setDocument(1);\n    assertEquals(1, dv.nextOrd());\n    assertEquals(SortedSetDocValues.NO_MORE_ORDS, dv.nextOrd());\n    \n    dv.lookupOrd(1, bytes);\n    assertEquals(new BytesRef(\"world\"), bytes);\n    \n    assertEquals(2, dv.getValueCount());\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    IndexWriterConfig iwconfig = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwconfig.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory, iwconfig);\n    Document doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"hello\")));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"world\")));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    DirectoryReader ireader = DirectoryReader.open(directory); // read-only=true\n    SortedSetDocValues dv = getOnlySegmentReader(ireader).getSortedSetDocValues(\"field\");\n    OrdIterator oi = dv.getOrds(0, null);\n    assertEquals(0, oi.nextOrd());\n    assertEquals(OrdIterator.NO_MORE_ORDS, oi.nextOrd());\n    \n    BytesRef bytes = new BytesRef();\n    dv.lookupOrd(0, bytes);\n    assertEquals(new BytesRef(\"hello\"), bytes);\n    \n    oi = dv.getOrds(1, oi);\n    assertEquals(1, oi.nextOrd());\n    assertEquals(OrdIterator.NO_MORE_ORDS, oi.nextOrd());\n    \n    dv.lookupOrd(1, bytes);\n    assertEquals(new BytesRef(\"world\"), bytes);\n    \n    assertEquals(2, dv.getValueCount());\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1272e04e4f27b1c1f8cdb786b642c536a429386e","date":1360592091,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","sourceNew":"  public void testTwoDocumentsMerged() throws IOException {\n    Directory directory = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwconfig = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwconfig.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory, iwconfig);\n  \n    Document doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"hello\")));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    \n    doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"world\")));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    \n    DirectoryReader ireader = iwriter.getReader();\n    iwriter.close();\n\n    SortedSetDocValues dv = getOnlySegmentReader(ireader).getSortedSetDocValues(\"field\");\n    assertEquals(2, dv.getValueCount());\n    \n    dv.setDocument(0);\n    assertEquals(0, dv.nextOrd());\n    assertEquals(NO_MORE_ORDS, dv.nextOrd());\n    \n    BytesRef bytes = new BytesRef();\n    dv.lookupOrd(0, bytes);\n    assertEquals(new BytesRef(\"hello\"), bytes);\n    \n    dv.setDocument(1);\n    assertEquals(1, dv.nextOrd());\n    assertEquals(NO_MORE_ORDS, dv.nextOrd());\n    \n    dv.lookupOrd(1, bytes);\n    assertEquals(new BytesRef(\"world\"), bytes);   \n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testTwoDocumentsMerged() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    IndexWriterConfig iwconfig = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwconfig.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory, iwconfig);\n    Document doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"hello\")));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"world\")));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    iwriter.close();\n    \n    // Now search the index:\n    DirectoryReader ireader = DirectoryReader.open(directory); // read-only=true\n    SortedSetDocValues dv = getOnlySegmentReader(ireader).getSortedSetDocValues(\"field\");\n    dv.setDocument(0);\n    assertEquals(0, dv.nextOrd());\n    assertEquals(SortedSetDocValues.NO_MORE_ORDS, dv.nextOrd());\n    \n    BytesRef bytes = new BytesRef();\n    dv.lookupOrd(0, bytes);\n    assertEquals(new BytesRef(\"hello\"), bytes);\n    \n    dv.setDocument(1);\n    assertEquals(1, dv.nextOrd());\n    assertEquals(SortedSetDocValues.NO_MORE_ORDS, dv.nextOrd());\n    \n    dv.lookupOrd(1, bytes);\n    assertEquals(new BytesRef(\"world\"), bytes);\n    \n    assertEquals(2, dv.getValueCount());\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"56fca4cf418a84a71d0701bbb6fda4db84fa5796","date":1361031660,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testSortedSetTwoDocumentsMerged().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testTwoDocumentsMerged().mjava","sourceNew":"  public void testSortedSetTwoDocumentsMerged() throws IOException {\n    Directory directory = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwconfig = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwconfig.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory, iwconfig);\n  \n    Document doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"hello\")));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    \n    doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"world\")));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    \n    DirectoryReader ireader = iwriter.getReader();\n    iwriter.close();\n\n    SortedSetDocValues dv = getOnlySegmentReader(ireader).getSortedSetDocValues(\"field\");\n    assertEquals(2, dv.getValueCount());\n    \n    dv.setDocument(0);\n    assertEquals(0, dv.nextOrd());\n    assertEquals(NO_MORE_ORDS, dv.nextOrd());\n    \n    BytesRef bytes = new BytesRef();\n    dv.lookupOrd(0, bytes);\n    assertEquals(new BytesRef(\"hello\"), bytes);\n    \n    dv.setDocument(1);\n    assertEquals(1, dv.nextOrd());\n    assertEquals(NO_MORE_ORDS, dv.nextOrd());\n    \n    dv.lookupOrd(1, bytes);\n    assertEquals(new BytesRef(\"world\"), bytes);   \n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testTwoDocumentsMerged() throws IOException {\n    Directory directory = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwconfig = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwconfig.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iwriter = new RandomIndexWriter(random(), directory, iwconfig);\n  \n    Document doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"hello\")));\n    iwriter.addDocument(doc);\n    iwriter.commit();\n    \n    doc = new Document();\n    doc.add(new SortedSetDocValuesField(\"field\", new BytesRef(\"world\")));\n    iwriter.addDocument(doc);\n    iwriter.forceMerge(1);\n    \n    DirectoryReader ireader = iwriter.getReader();\n    iwriter.close();\n\n    SortedSetDocValues dv = getOnlySegmentReader(ireader).getSortedSetDocValues(\"field\");\n    assertEquals(2, dv.getValueCount());\n    \n    dv.setDocument(0);\n    assertEquals(0, dv.nextOrd());\n    assertEquals(NO_MORE_ORDS, dv.nextOrd());\n    \n    BytesRef bytes = new BytesRef();\n    dv.lookupOrd(0, bytes);\n    assertEquals(new BytesRef(\"hello\"), bytes);\n    \n    dv.setDocument(1);\n    assertEquals(1, dv.nextOrd());\n    assertEquals(NO_MORE_ORDS, dv.nextOrd());\n    \n    dv.lookupOrd(1, bytes);\n    assertEquals(new BytesRef(\"world\"), bytes);   \n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef":["3ee07e8e258de164ee9346427b4307823c0b041d"],"1ed65f3455364344c6d2ff76ea5421aac754eae7":["a4d374b2bebd0d52acaa61038fbf23068620fba7"],"56fca4cf418a84a71d0701bbb6fda4db84fa5796":["1272e04e4f27b1c1f8cdb786b642c536a429386e"],"a4d374b2bebd0d52acaa61038fbf23068620fba7":["7cd329bd749496f6c58b586a6c0dd0dc8201206f"],"b17aab72b6576c145865eafaf502403b11caeaea":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3ee07e8e258de164ee9346427b4307823c0b041d":["1ed65f3455364344c6d2ff76ea5421aac754eae7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7cd329bd749496f6c58b586a6c0dd0dc8201206f":["b17aab72b6576c145865eafaf502403b11caeaea"],"1272e04e4f27b1c1f8cdb786b642c536a429386e":["988e3f44fe797ee94a0135abfe27e5872b99844d"],"f366ce28775e2b8ea4e06355009471328711666d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"423d89a2b3cc419b647c07c2b3fdbc54311d07f9":["ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef"],"988e3f44fe797ee94a0135abfe27e5872b99844d":["f366ce28775e2b8ea4e06355009471328711666d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2ec08217282b5e9df023dcdff55c745ff68b1c7d":["423d89a2b3cc419b647c07c2b3fdbc54311d07f9"]},"commit2Childs":{"ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef":["423d89a2b3cc419b647c07c2b3fdbc54311d07f9"],"1ed65f3455364344c6d2ff76ea5421aac754eae7":["3ee07e8e258de164ee9346427b4307823c0b041d"],"56fca4cf418a84a71d0701bbb6fda4db84fa5796":[],"a4d374b2bebd0d52acaa61038fbf23068620fba7":["1ed65f3455364344c6d2ff76ea5421aac754eae7"],"b17aab72b6576c145865eafaf502403b11caeaea":["7cd329bd749496f6c58b586a6c0dd0dc8201206f"],"3ee07e8e258de164ee9346427b4307823c0b041d":["ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef"],"7cd329bd749496f6c58b586a6c0dd0dc8201206f":["a4d374b2bebd0d52acaa61038fbf23068620fba7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b17aab72b6576c145865eafaf502403b11caeaea","f366ce28775e2b8ea4e06355009471328711666d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1272e04e4f27b1c1f8cdb786b642c536a429386e":["56fca4cf418a84a71d0701bbb6fda4db84fa5796"],"f366ce28775e2b8ea4e06355009471328711666d":["988e3f44fe797ee94a0135abfe27e5872b99844d"],"423d89a2b3cc419b647c07c2b3fdbc54311d07f9":["2ec08217282b5e9df023dcdff55c745ff68b1c7d"],"988e3f44fe797ee94a0135abfe27e5872b99844d":["1272e04e4f27b1c1f8cdb786b642c536a429386e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"2ec08217282b5e9df023dcdff55c745ff68b1c7d":[]},"heads":["56fca4cf418a84a71d0701bbb6fda4db84fa5796","cd5edd1f2b162a5cfa08efd17851a07373a96817","2ec08217282b5e9df023dcdff55c745ff68b1c7d"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}