{"path":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","commits":[{"id":"dd81b1d062b9688a18721a1adfc489577479856a","date":1390711758,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","pathOld":"/dev/null","sourceNew":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if its the first one, or if its connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // its possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // its possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","sourceNew":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if its the first one, or if its connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // its possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // its possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if its the first one, or if its connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // its possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // its possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","sourceNew":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if its the first one, or if its connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // its possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // its possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if its the first one, or if its connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // its possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // its possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","sourceNew":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if its the first one, or if its connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // its possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // its possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if its the first one, or if its connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // its possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // its possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","date":1419400138,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","sourceNew":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if it's the first one, or if it's connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // it's possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // it's possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if its the first one, or if its connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // its possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // its possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","sourceNew":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if it's the first one, or if it's connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // it's possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // it's possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if it's the first one, or if it's connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // it's possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // it's possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f68d01cf19df971dcdcb05e30247f4ad7ec9747","date":1434611645,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","sourceNew":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery.Builder query = new BooleanQuery.Builder();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query.build(), 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query.build(), searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if it's the first one, or if it's connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // it's possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // it's possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query.build(), searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery query = new BooleanQuery();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if it's the first one, or if it's connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // it's possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // it's possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"381618eac2691bb34ab9a3fca76ad55c6274517e","date":1495564791,"type":4,"author":"David Smiley","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","sourceNew":null,"sourceOld":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery.Builder query = new BooleanQuery.Builder();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query.build(), 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query.build(), searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if it's the first one, or if it's connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // it's possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // it's possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query.build(), searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":4,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testWhichMTQMatched().mjava","sourceNew":null,"sourceOld":"  /** Runs a query with two MTQs and confirms the formatter\n   *  can tell which query matched which hit. */\n  public void testWhichMTQMatched() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    BooleanQuery.Builder query = new BooleanQuery.Builder();\n    query.add(new WildcardQuery(new Term(\"body\", \"te*\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"one\")), BooleanClause.Occur.SHOULD);\n    query.add(new WildcardQuery(new Term(\"body\", \"se*\")), BooleanClause.Occur.SHOULD);\n    TopDocs topDocs = searcher.search(query.build(), 10, Sort.INDEXORDER);\n    assertEquals(1, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query.build(), searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter just bolds each hit:\n    assertEquals(\"<b>Test</b> a <b>one</b> <b>sentence</b> document.\", snippets[0]);\n    \n    // Now use our own formatter, that also stuffs the\n    // matching term's text into the result:\n    highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n      \n      @Override\n      protected PassageFormatter getFormatter(String field) {\n        return new PassageFormatter() {\n          \n          @Override\n          public Object format(Passage passages[], String content) {\n            // Copied from DefaultPassageFormatter, but\n            // tweaked to include the matched term:\n            StringBuilder sb = new StringBuilder();\n            int pos = 0;\n            for (Passage passage : passages) {\n              // don't add ellipsis if it's the first one, or if it's connected.\n              if (passage.startOffset > pos && pos > 0) {\n                sb.append(\"... \");\n              }\n              pos = passage.startOffset;\n              for (int i = 0; i < passage.numMatches; i++) {\n                int start = passage.matchStarts[i];\n                int end = passage.matchEnds[i];\n                // it's possible to have overlapping terms\n                if (start > pos) {\n                  sb.append(content, pos, start);\n                }\n                if (end > pos) {\n                  sb.append(\"<b>\");\n                  sb.append(content, Math.max(pos, start), end);\n                  sb.append('(');\n                  sb.append(passage.getMatchTerms()[i].utf8ToString());\n                  sb.append(')');\n                  sb.append(\"</b>\");\n                  pos = end;\n                }\n              }\n              // it's possible a \"term\" from the analyzer could span a sentence boundary.\n              sb.append(content, pos, Math.max(pos, passage.endOffset));\n              pos = passage.endOffset;\n            }\n            return sb.toString();\n          }\n        };\n      }\n    };\n    \n    assertEquals(1, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query.build(), searcher, topDocs);\n    assertEquals(1, snippets.length);\n    \n    // Default formatter bolds each hit:\n    assertEquals(\"<b>Test(body:te*)</b> a <b>one(body:one)</b> <b>sentence(body:se*)</b> document.\", snippets[0]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"381618eac2691bb34ab9a3fca76ad55c6274517e":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747","381618eac2691bb34ab9a3fca76ad55c6274517e"],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["dd81b1d062b9688a18721a1adfc489577479856a"],"dd81b1d062b9688a18721a1adfc489577479856a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["381618eac2691bb34ab9a3fca76ad55c6274517e"]},"commit2Childs":{"381618eac2691bb34ab9a3fca76ad55c6274517e":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["381618eac2691bb34ab9a3fca76ad55c6274517e","e9017cf144952056066919f1ebc7897ff9bd71b1"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["dd81b1d062b9688a18721a1adfc489577479856a"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"dd81b1d062b9688a18721a1adfc489577479856a":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}