{"path":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","commits":[{"id":"303b28b90016c2de1b5870759794476dbf4fd6ce","date":1206052767,"type":0,"author":"Mike Klaas","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n\n          // get highlighter, and number of fragments for this field\n          Highlighter highlighter = getHighlighter(query, fieldName, req);\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n           String[] summaries = null;\n           TextFragment[] frag;\n           if (docTexts.length == 1) {\n              // single-valued field\n              TokenStream tstream;\n              try {\n                 // attempt term vectors\n                 tstream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n              }\n              catch (IllegalArgumentException e) {\n                 // fall back to analyzer\n                 tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[0])), 10);\n              }\n              frag = highlighter.getBestTextFragments(tstream, docTexts[0], mergeContiguousFragments, numFragments);\n           }\n           else {\n              // multi-valued field\n              MultiValueTokenStream tstream;\n              tstream = new MultiValueTokenStream(fieldName, docTexts, schema.getAnalyzer(), true);\n              frag = highlighter.getBestTextFragments(tstream, tstream.asSingleValue(), false, numFragments);\n           }\n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n           if (frag.length > 0) {\n              ArrayList<String> fragTexts = new ArrayList<String>();\n              for (int j = 0; j < frag.length; j++) {\n                 if ((frag[j] != null) && (frag[j].getScore() > 0)) {\n                    fragTexts.add(frag[j].toString());\n                 }\n              }\n              summaries = fragTexts.toArray(new String[0]);\n              if (summaries.length > 0) \n                docSummaries.add(fieldName, summaries);\n           }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                 String[] altTexts = doc.getValues(alternateField);\n                    if (altTexts != null && altTexts.length > 0)\n                       docSummaries.add(fieldName, altTexts);\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["82fff9df8ebf1830fe880d4d1cbed04e81684a4d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a48c0fe230530bd2b1e52e00bab51dc742acd0db","date":1207854443,"type":3,"author":"Mike Klaas","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n\n          // get highlighter, and number of fragments for this field\n          Highlighter highlighter = getHighlighter(query, fieldName, req);\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n           String[] summaries = null;\n           TextFragment[] frag;\n           if (docTexts.length == 1) {\n              // single-valued field\n              TokenStream tstream;\n              try {\n                 // attempt term vectors\n                 tstream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n              }\n              catch (IllegalArgumentException e) {\n                 // fall back to analyzer\n                 tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[0])), 10);\n              }\n              frag = highlighter.getBestTextFragments(tstream, docTexts[0], mergeContiguousFragments, numFragments);\n           }\n           else {\n              // multi-valued field\n              MultiValueTokenStream tstream;\n              tstream = new MultiValueTokenStream(fieldName, docTexts, schema.getAnalyzer(), true);\n              frag = highlighter.getBestTextFragments(tstream, tstream.asSingleValue(), false, numFragments);\n           }\n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n           if (frag.length > 0) {\n              ArrayList<String> fragTexts = new ArrayList<String>();\n              for (int j = 0; j < frag.length; j++) {\n                 if ((frag[j] != null) && (frag[j].getScore() > 0)) {\n                    fragTexts.add(frag[j].toString());\n                 }\n              }\n              summaries = fragTexts.toArray(new String[0]);\n              if (summaries.length > 0) \n                docSummaries.add(fieldName, summaries);\n           }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   altText.substring( 0, alternateFieldLen - len ) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n\n          // get highlighter, and number of fragments for this field\n          Highlighter highlighter = getHighlighter(query, fieldName, req);\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n           String[] summaries = null;\n           TextFragment[] frag;\n           if (docTexts.length == 1) {\n              // single-valued field\n              TokenStream tstream;\n              try {\n                 // attempt term vectors\n                 tstream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n              }\n              catch (IllegalArgumentException e) {\n                 // fall back to analyzer\n                 tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[0])), 10);\n              }\n              frag = highlighter.getBestTextFragments(tstream, docTexts[0], mergeContiguousFragments, numFragments);\n           }\n           else {\n              // multi-valued field\n              MultiValueTokenStream tstream;\n              tstream = new MultiValueTokenStream(fieldName, docTexts, schema.getAnalyzer(), true);\n              frag = highlighter.getBestTextFragments(tstream, tstream.asSingleValue(), false, numFragments);\n           }\n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n           if (frag.length > 0) {\n              ArrayList<String> fragTexts = new ArrayList<String>();\n              for (int j = 0; j < frag.length; j++) {\n                 if ((frag[j] != null) && (frag[j].getScore() > 0)) {\n                    fragTexts.add(frag[j].toString());\n                 }\n              }\n              summaries = fragTexts.toArray(new String[0]);\n              if (summaries.length > 0) \n                docSummaries.add(fieldName, summaries);\n           }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                 String[] altTexts = doc.getValues(alternateField);\n                    if (altTexts != null && altTexts.length > 0)\n                       docSummaries.add(fieldName, altTexts);\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c013889a237f29c0b690ee86faa24c165860f3f8","date":1211577805,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n\n          // create TokenStream\n          if (docTexts.length == 1) {\n            // single-valued field\n            try {\n              // attempt term vectors\n              tstream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[0])), 10);\n            }\n          }\n          else {\n            // multi-valued field\n            tstream = new MultiValueTokenStream(fieldName, docTexts, schema.getAnalyzer(), true);\n          }\n          \n          Highlighter highlighter;\n          \n          if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n            // wrap CachingTokenFilter around TokenStream for reuse\n            tstream = new CachingTokenFilter(tstream);\n            \n            // get highlighter\n            highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n            \n            // after highlighter initialization, reset tstream since construction of highlighter already used it\n            tstream.reset();\n          }\n          else {\n            // use \"the old way\"\n            highlighter = getHighlighter(query, fieldName, req);\n          }\n\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n           String[] summaries = null;\n           TextFragment[] frag;\n           if (docTexts.length == 1) {\n              frag = highlighter.getBestTextFragments(tstream, docTexts[0], mergeContiguousFragments, numFragments);\n           }\n           else {\n               StringBuilder singleValue = new StringBuilder();\n               \n               for (String txt:docTexts) {\n             \t  singleValue.append(txt);\n               }\n             \n              frag = highlighter.getBestTextFragments(tstream, singleValue.toString(), false, numFragments);\n           }\n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n           if (frag.length > 0) {\n              ArrayList<String> fragTexts = new ArrayList<String>();\n              for (int j = 0; j < frag.length; j++) {\n                 if ((frag[j] != null) && (frag[j].getScore() > 0)) {\n                    fragTexts.add(frag[j].toString());\n                 }\n              }\n              summaries = fragTexts.toArray(new String[0]);\n              if (summaries.length > 0) \n                docSummaries.add(fieldName, summaries);\n           }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   altText.substring( 0, alternateFieldLen - len ) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n\n          // get highlighter, and number of fragments for this field\n          Highlighter highlighter = getHighlighter(query, fieldName, req);\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n           String[] summaries = null;\n           TextFragment[] frag;\n           if (docTexts.length == 1) {\n              // single-valued field\n              TokenStream tstream;\n              try {\n                 // attempt term vectors\n                 tstream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n              }\n              catch (IllegalArgumentException e) {\n                 // fall back to analyzer\n                 tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[0])), 10);\n              }\n              frag = highlighter.getBestTextFragments(tstream, docTexts[0], mergeContiguousFragments, numFragments);\n           }\n           else {\n              // multi-valued field\n              MultiValueTokenStream tstream;\n              tstream = new MultiValueTokenStream(fieldName, docTexts, schema.getAnalyzer(), true);\n              frag = highlighter.getBestTextFragments(tstream, tstream.asSingleValue(), false, numFragments);\n           }\n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n           if (frag.length > 0) {\n              ArrayList<String> fragTexts = new ArrayList<String>();\n              for (int j = 0; j < frag.length; j++) {\n                 if ((frag[j] != null) && (frag[j].getScore() > 0)) {\n                    fragTexts.add(frag[j].toString());\n                 }\n              }\n              summaries = fragTexts.toArray(new String[0]);\n              if (summaries.length > 0) \n                docSummaries.add(fieldName, summaries);\n           }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   altText.substring( 0, alternateFieldLen - len ) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","bugFix":null,"bugIntro":["f3d1495bedca26db3edbddf239a3ad48f6131e21","82fff9df8ebf1830fe880d4d1cbed04e81684a4d","f3371f30061b8f0256a0d2f11478c9c43e5a9156","701cd8aa1cd4df80734205800f295a1e4189d1d8"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"82fff9df8ebf1830fe880d4d1cbed04e81684a4d","date":1215474756,"type":3,"author":"Mike Klaas","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              tstream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[j])), 10);\n            }\n             \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n            \n            TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n            for (int k = 0; k < bestTextFragments.length; k++) {\n              if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                frags.add(bestTextFragments[k]);\n              }\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   altText.substring( 0, alternateFieldLen - len ) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n\n          // create TokenStream\n          if (docTexts.length == 1) {\n            // single-valued field\n            try {\n              // attempt term vectors\n              tstream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[0])), 10);\n            }\n          }\n          else {\n            // multi-valued field\n            tstream = new MultiValueTokenStream(fieldName, docTexts, schema.getAnalyzer(), true);\n          }\n          \n          Highlighter highlighter;\n          \n          if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n            // wrap CachingTokenFilter around TokenStream for reuse\n            tstream = new CachingTokenFilter(tstream);\n            \n            // get highlighter\n            highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n            \n            // after highlighter initialization, reset tstream since construction of highlighter already used it\n            tstream.reset();\n          }\n          else {\n            // use \"the old way\"\n            highlighter = getHighlighter(query, fieldName, req);\n          }\n\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n           String[] summaries = null;\n           TextFragment[] frag;\n           if (docTexts.length == 1) {\n              frag = highlighter.getBestTextFragments(tstream, docTexts[0], mergeContiguousFragments, numFragments);\n           }\n           else {\n               StringBuilder singleValue = new StringBuilder();\n               \n               for (String txt:docTexts) {\n             \t  singleValue.append(txt);\n               }\n             \n              frag = highlighter.getBestTextFragments(tstream, singleValue.toString(), false, numFragments);\n           }\n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n           if (frag.length > 0) {\n              ArrayList<String> fragTexts = new ArrayList<String>();\n              for (int j = 0; j < frag.length; j++) {\n                 if ((frag[j] != null) && (frag[j].getScore() > 0)) {\n                    fragTexts.add(frag[j].toString());\n                 }\n              }\n              summaries = fragTexts.toArray(new String[0]);\n              if (summaries.length > 0) \n                docSummaries.add(fieldName, summaries);\n           }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   altText.substring( 0, alternateFieldLen - len ) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","bugFix":["303b28b90016c2de1b5870759794476dbf4fd6ce","c013889a237f29c0b690ee86faa24c165860f3f8"],"bugIntro":["f3d1495bedca26db3edbddf239a3ad48f6131e21","d72e3710bede9618eb9b2b5c6936369f3d3f9579","be29e0e2cef1fd569147732e48caf8538790339b","f3371f30061b8f0256a0d2f11478c9c43e5a9156"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"701cd8aa1cd4df80734205800f295a1e4189d1d8","date":1230253698,"type":3,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null )\n                tots = new TermOffsetsTokenStream( TokenSources.getTokenStream(searcher.getReader(), docId, fieldName) );\n              tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[j])), 10);\n            }\n             \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n            \n            TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n            for (int k = 0; k < bestTextFragments.length; k++) {\n              if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                frags.add(bestTextFragments[k]);\n              }\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   altText.substring( 0, alternateFieldLen - len ) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              tstream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[j])), 10);\n            }\n             \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n            \n            TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n            for (int k = 0; k < bestTextFragments.length; k++) {\n              if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                frags.add(bestTextFragments[k]);\n              }\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   altText.substring( 0, alternateFieldLen - len ) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","bugFix":["c013889a237f29c0b690ee86faa24c165860f3f8"],"bugIntro":["f3d1495bedca26db3edbddf239a3ad48f6131e21","f3371f30061b8f0256a0d2f11478c9c43e5a9156"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d72e3710bede9618eb9b2b5c6936369f3d3f9579","date":1239534189,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null )\n                tots = new TermOffsetsTokenStream( TokenSources.getTokenStream(searcher.getReader(), docId, fieldName) );\n              tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[j])), 10);\n            }\n             \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   altText.substring( 0, alternateFieldLen - len ) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null )\n                tots = new TermOffsetsTokenStream( TokenSources.getTokenStream(searcher.getReader(), docId, fieldName) );\n              tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[j])), 10);\n            }\n             \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n            \n            TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n            for (int k = 0; k < bestTextFragments.length; k++) {\n              if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                frags.add(bestTextFragments[k]);\n              }\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   altText.substring( 0, alternateFieldLen - len ) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","bugFix":["82fff9df8ebf1830fe880d4d1cbed04e81684a4d"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f277fbbf132590b41d0ceaa9cb8af2697cdbc673","date":1245160405,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Set<String> fset = new HashSet<String>();\n     \n     {\n       // pre-fetch documents using the Searcher's doc cache\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = searcher.doc(docId, fset);\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null )\n                tots = new TermOffsetsTokenStream( TokenSources.getTokenStream(searcher.getReader(), docId, fieldName) );\n              tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[j])), 10);\n            }\n             \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   new String(altText.substring( 0, alternateFieldLen - len )) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Document[] readDocs = new Document[docs.size()];\n     {\n       // pre-fetch documents using the Searcher's doc cache\n       Set<String> fset = new HashSet<String>();\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n       searcher.readDocs(readDocs, docs, fset);\n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = readDocs[i];\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null )\n                tots = new TermOffsetsTokenStream( TokenSources.getTokenStream(searcher.getReader(), docId, fieldName) );\n              tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[j])), 10);\n            }\n             \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   altText.substring( 0, alternateFieldLen - len ) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"be29e0e2cef1fd569147732e48caf8538790339b","date":1250443738,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Set<String> fset = new HashSet<String>();\n     \n     {\n       // pre-fetch documents using the Searcher's doc cache\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = searcher.doc(docId, fset);\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null )\n                tots = new TermOffsetsTokenStream( TokenSources.getTokenStream(searcher.getReader(), docId, fieldName) );\n              tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              TokenStream ts = schema.getAnalyzer().reusableTokenStream(fieldName, new StringReader(docTexts[j]));\n              ts.reset();\n              tstream = new TokenOrderingFilter(ts, 10);\n            }\n             \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   new String(altText.substring( 0, alternateFieldLen - len )) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Set<String> fset = new HashSet<String>();\n     \n     {\n       // pre-fetch documents using the Searcher's doc cache\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = searcher.doc(docId, fset);\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null )\n                tots = new TermOffsetsTokenStream( TokenSources.getTokenStream(searcher.getReader(), docId, fieldName) );\n              tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              tstream = new TokenOrderingFilter(schema.getAnalyzer().tokenStream(fieldName, new StringReader(docTexts[j])), 10);\n            }\n             \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   new String(altText.substring( 0, alternateFieldLen - len )) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","bugFix":["82fff9df8ebf1830fe880d4d1cbed04e81684a4d"],"bugIntro":["f3371f30061b8f0256a0d2f11478c9c43e5a9156"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f3371f30061b8f0256a0d2f11478c9c43e5a9156","date":1252601275,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Set<String> fset = new HashSet<String>();\n     \n     {\n       // pre-fetch documents using the Searcher's doc cache\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = searcher.doc(docId, fset);\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null ) {\n                TokenStream tvStream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n                if (tvStream != null) {\n                  tots = new TermOffsetsTokenStream(tvStream);\n                  tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n                } else {\n                  // fall back to analyzer\n                  tstream = createAnalyzerTStream(schema, fieldName, docTexts[j]);\n                }\n              }\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to analyzer\n              tstream = createAnalyzerTStream(schema, fieldName, docTexts[j]);\n            }\n                         \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   new String(altText.substring( 0, alternateFieldLen - len )) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Set<String> fset = new HashSet<String>();\n     \n     {\n       // pre-fetch documents using the Searcher's doc cache\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = searcher.doc(docId, fset);\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null )\n                tots = new TermOffsetsTokenStream( TokenSources.getTokenStream(searcher.getReader(), docId, fieldName) );\n              tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to anaylzer\n              TokenStream ts = schema.getAnalyzer().reusableTokenStream(fieldName, new StringReader(docTexts[j]));\n              ts.reset();\n              tstream = new TokenOrderingFilter(ts, 10);\n            }\n             \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   new String(altText.substring( 0, alternateFieldLen - len )) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","bugFix":["701cd8aa1cd4df80734205800f295a1e4189d1d8","be29e0e2cef1fd569147732e48caf8538790339b","c013889a237f29c0b690ee86faa24c165860f3f8","82fff9df8ebf1830fe880d4d1cbed04e81684a4d"],"bugIntro":["f3d1495bedca26db3edbddf239a3ad48f6131e21"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7181b75752244f676e4634e90792409f5a3457f5","date":1254059910,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Set<String> fset = new HashSet<String>();\n     \n     {\n       // pre-fetch documents using the Searcher's doc cache\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = searcher.doc(docId, fset);\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null ) {\n                TokenStream tvStream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n                if (tvStream != null) {\n                  tots = new TermOffsetsTokenStream(tvStream);\n                  tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n                } else {\n                  // fall back to analyzer\n                  tstream = createAnalyzerTStream(schema, fieldName, docTexts[j]);\n                }\n              }\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to analyzer\n              tstream = createAnalyzerTStream(schema, fieldName, docTexts[j]);\n            }\n                         \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER, \"true\"))) {\n              // TODO: this is not always necessary - eventually we would like to avoid this wrap\n              //       when it is not needed.\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   new String(altText.substring( 0, alternateFieldLen - len )) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Set<String> fset = new HashSet<String>();\n     \n     {\n       // pre-fetch documents using the Searcher's doc cache\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = searcher.doc(docId, fset);\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null ) {\n                TokenStream tvStream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n                if (tvStream != null) {\n                  tots = new TermOffsetsTokenStream(tvStream);\n                  tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n                } else {\n                  // fall back to analyzer\n                  tstream = createAnalyzerTStream(schema, fieldName, docTexts[j]);\n                }\n              }\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to analyzer\n              tstream = createAnalyzerTStream(schema, fieldName, docTexts[j]);\n            }\n                         \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER))) {\n              // wrap CachingTokenFilter around TokenStream for reuse\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   new String(altText.substring( 0, alternateFieldLen - len )) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f3d1495bedca26db3edbddf239a3ad48f6131e21","date":1260213855,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Set<String> fset = new HashSet<String>();\n     \n     {\n       // pre-fetch documents using the Searcher's doc cache\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = searcher.doc(docId, fset);\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n\n          TermOffsetsTokenStream tots = null; // to be non-null iff we're using TermOffsets optimization\n          try {\n              TokenStream tvStream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n              if (tvStream != null) {\n                tots = new TermOffsetsTokenStream(tvStream);\n              }\n          }\n          catch (IllegalArgumentException e) {\n            // No problem. But we can't use TermOffsets optimization.\n          }\n\n          for (int j = 0; j < docTexts.length; j++) {\n            if( tots != null ) {\n              // if we're using TermOffsets optimization, then get the next\n              // field value's TokenStream (i.e. get field j's TokenStream) from tots:\n              tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n            } else {\n              // fall back to analyzer\n              tstream = createAnalyzerTStream(schema, fieldName, docTexts[j]);\n            }\n                         \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER, \"true\"))) {\n              // TODO: this is not always necessary - eventually we would like to avoid this wrap\n              //       when it is not needed.\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   new String(altText.substring( 0, alternateFieldLen - len )) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Set<String> fset = new HashSet<String>();\n     \n     {\n       // pre-fetch documents using the Searcher's doc cache\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = searcher.doc(docId, fset);\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n          TermOffsetsTokenStream tots = null;\n          for (int j = 0; j < docTexts.length; j++) {\n            // create TokenStream\n            try {\n              // attempt term vectors\n              if( tots == null ) {\n                TokenStream tvStream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n                if (tvStream != null) {\n                  tots = new TermOffsetsTokenStream(tvStream);\n                  tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n                } else {\n                  // fall back to analyzer\n                  tstream = createAnalyzerTStream(schema, fieldName, docTexts[j]);\n                }\n              }\n            }\n            catch (IllegalArgumentException e) {\n              // fall back to analyzer\n              tstream = createAnalyzerTStream(schema, fieldName, docTexts[j]);\n            }\n                         \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER, \"true\"))) {\n              // TODO: this is not always necessary - eventually we would like to avoid this wrap\n              //       when it is not needed.\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   new String(altText.substring( 0, alternateFieldLen - len )) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","bugFix":["701cd8aa1cd4df80734205800f295a1e4189d1d8","f3371f30061b8f0256a0d2f11478c9c43e5a9156","82fff9df8ebf1830fe880d4d1cbed04e81684a4d","c013889a237f29c0b690ee86faa24c165860f3f8"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5df1793b9dbc0f17ba1d1dddb8a15748fdc3aaf3","date":1263013040,"type":3,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n    SolrIndexSearcher searcher = req.getSearcher();\n    IndexSchema schema = searcher.getSchema();\n    NamedList fragments = new SimpleOrderedMap();\n    String[] fieldNames = getHighlightFields(query, req, defaultFields);\n    Set<String> fset = new HashSet<String>();\n     \n    {\n      // pre-fetch documents using the Searcher's doc cache\n      for(String f : fieldNames) { fset.add(f); }\n      // fetch unique key if one exists.\n      SchemaField keyField = schema.getUniqueKeyField();\n      if(null != keyField)\n        fset.add(keyField.getName());  \n    }\n\n    // get FastVectorHighlighter instance out of the processing loop\n    FastVectorHighlighter fvh = new FastVectorHighlighter(\n        // FVH cannot process hl.usePhraseHighlighter parameter per-field basis\n        params.getBool( HighlightParams.USE_PHRASE_HIGHLIGHTER, true ),\n        // FVH cannot process hl.requireFieldMatch parameter per-field basis\n        params.getBool( HighlightParams.FIELD_MATCH, false ),\n        getFragListBuilder( params ),\n        getFragmentsBuilder( params ) );\n    FieldQuery fieldQuery = fvh.getFieldQuery( query );\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n      int docId = iterator.nextDoc();\n      Document doc = searcher.doc(docId, fset);\n      NamedList docSummaries = new SimpleOrderedMap();\n      for (String fieldName : fieldNames) {\n        fieldName = fieldName.trim();\n        if( useFastVectorHighlighter( params, schema, fieldName ) )\n          doHighlightingByFastVectorHighlighter( fvh, fieldQuery, req, docSummaries, docId, doc, fieldName );\n        else\n          doHighlightingByHighlighter( query, req, docSummaries, docId, doc, fieldName );\n      }\n      String printId = schema.printableUniqueKey(doc);\n      fragments.add(printId == null ? null : printId, docSummaries);\n    }\n    return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n     SolrIndexSearcher searcher = req.getSearcher();\n     IndexSchema schema = searcher.getSchema();\n     NamedList fragments = new SimpleOrderedMap();\n     String[] fieldNames = getHighlightFields(query, req, defaultFields);\n     Set<String> fset = new HashSet<String>();\n     \n     {\n       // pre-fetch documents using the Searcher's doc cache\n       for(String f : fieldNames) { fset.add(f); }\n       // fetch unique key if one exists.\n       SchemaField keyField = schema.getUniqueKeyField();\n       if(null != keyField)\n         fset.add(keyField.getName());  \n     }\n\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n       int docId = iterator.nextDoc();\n       Document doc = searcher.doc(docId, fset);\n       NamedList docSummaries = new SimpleOrderedMap();\n       for (String fieldName : fieldNames) {\n          fieldName = fieldName.trim();\n          String[] docTexts = doc.getValues(fieldName);\n          if (docTexts == null) continue;\n          \n          TokenStream tstream = null;\n          int numFragments = getMaxSnippets(fieldName, params);\n          boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);\n\n          String[] summaries = null;\n          List<TextFragment> frags = new ArrayList<TextFragment>();\n\n          TermOffsetsTokenStream tots = null; // to be non-null iff we're using TermOffsets optimization\n          try {\n              TokenStream tvStream = TokenSources.getTokenStream(searcher.getReader(), docId, fieldName);\n              if (tvStream != null) {\n                tots = new TermOffsetsTokenStream(tvStream);\n              }\n          }\n          catch (IllegalArgumentException e) {\n            // No problem. But we can't use TermOffsets optimization.\n          }\n\n          for (int j = 0; j < docTexts.length; j++) {\n            if( tots != null ) {\n              // if we're using TermOffsets optimization, then get the next\n              // field value's TokenStream (i.e. get field j's TokenStream) from tots:\n              tstream = tots.getMultiValuedTokenStream( docTexts[j].length() );\n            } else {\n              // fall back to analyzer\n              tstream = createAnalyzerTStream(schema, fieldName, docTexts[j]);\n            }\n                         \n            Highlighter highlighter;\n            if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER, \"true\"))) {\n              // TODO: this is not always necessary - eventually we would like to avoid this wrap\n              //       when it is not needed.\n              tstream = new CachingTokenFilter(tstream);\n              \n              // get highlighter\n              highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);\n               \n              // after highlighter initialization, reset tstream since construction of highlighter already used it\n              tstream.reset();\n            }\n            else {\n              // use \"the old way\"\n              highlighter = getHighlighter(query, fieldName, req);\n            }\n            \n            int maxCharsToAnalyze = params.getFieldInt(fieldName,\n                HighlightParams.MAX_CHARS,\n                Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);\n            if (maxCharsToAnalyze < 0) {\n              highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());\n            } else {\n              highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);\n            }\n\n            try {\n              TextFragment[] bestTextFragments = highlighter.getBestTextFragments(tstream, docTexts[j], mergeContiguousFragments, numFragments);\n              for (int k = 0; k < bestTextFragments.length; k++) {\n                if ((bestTextFragments[k] != null) && (bestTextFragments[k].getScore() > 0)) {\n                  frags.add(bestTextFragments[k]);\n                }\n              }\n            } catch (InvalidTokenOffsetsException e) {\n              throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n            }\n          }\n          // sort such that the fragments with the highest score come first\n          Collections.sort(frags, new Comparator<TextFragment>() {\n            public int compare(TextFragment arg0, TextFragment arg1) {\n              return Math.round(arg1.getScore() - arg0.getScore());\n            }\n          });\n          \n           // convert fragments back into text\n           // TODO: we can include score and position information in output as snippet attributes\n          if (frags.size() > 0) {\n            ArrayList<String> fragTexts = new ArrayList<String>();\n            for (TextFragment fragment: frags) {\n              if ((fragment != null) && (fragment.getScore() > 0)) {\n                fragTexts.add(fragment.toString());\n              }\n              if (fragTexts.size() >= numFragments) break;\n            }\n            summaries = fragTexts.toArray(new String[0]);\n            if (summaries.length > 0) \n            docSummaries.add(fieldName, summaries);\n          }\n           // no summeries made, copy text from alternate field\n           if (summaries == null || summaries.length == 0) {\n              String alternateField = req.getParams().getFieldParam(fieldName, HighlightParams.ALTERNATE_FIELD);\n              if (alternateField != null && alternateField.length() > 0) {\n                String[] altTexts = doc.getValues(alternateField);\n                if (altTexts != null && altTexts.length > 0){\n                  int alternateFieldLen = req.getParams().getFieldInt(fieldName, HighlightParams.ALTERNATE_FIELD_LENGTH,0);\n                  if( alternateFieldLen <= 0 ){\n                    docSummaries.add(fieldName, altTexts);\n                  }\n                  else{\n                    List<String> altList = new ArrayList<String>();\n                    int len = 0;\n                    for( String altText: altTexts ){\n                      altList.add( len + altText.length() > alternateFieldLen ?\n                                   new String(altText.substring( 0, alternateFieldLen - len )) : altText );\n                      len += altText.length();\n                      if( len >= alternateFieldLen ) break;\n                    }\n                    docSummaries.add(fieldName, altList);\n                  }\n                }\n              }\n           }\n \n        }\n        String printId = schema.printableUniqueKey(doc);\n        fragments.add(printId == null ? null : printId, docSummaries);\n     }\n     return fragments;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","pathOld":"src/java/org/apache/solr/highlight/DefaultSolrHighlighter#doHighlighting(DocList,Query,SolrQueryRequest,String[]).mjava","sourceNew":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n    SolrIndexSearcher searcher = req.getSearcher();\n    IndexSchema schema = searcher.getSchema();\n    NamedList fragments = new SimpleOrderedMap();\n    String[] fieldNames = getHighlightFields(query, req, defaultFields);\n    Set<String> fset = new HashSet<String>();\n     \n    {\n      // pre-fetch documents using the Searcher's doc cache\n      for(String f : fieldNames) { fset.add(f); }\n      // fetch unique key if one exists.\n      SchemaField keyField = schema.getUniqueKeyField();\n      if(null != keyField)\n        fset.add(keyField.getName());  \n    }\n\n    // get FastVectorHighlighter instance out of the processing loop\n    FastVectorHighlighter fvh = new FastVectorHighlighter(\n        // FVH cannot process hl.usePhraseHighlighter parameter per-field basis\n        params.getBool( HighlightParams.USE_PHRASE_HIGHLIGHTER, true ),\n        // FVH cannot process hl.requireFieldMatch parameter per-field basis\n        params.getBool( HighlightParams.FIELD_MATCH, false ),\n        getFragListBuilder( params ),\n        getFragmentsBuilder( params ) );\n    FieldQuery fieldQuery = fvh.getFieldQuery( query );\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n      int docId = iterator.nextDoc();\n      Document doc = searcher.doc(docId, fset);\n      NamedList docSummaries = new SimpleOrderedMap();\n      for (String fieldName : fieldNames) {\n        fieldName = fieldName.trim();\n        if( useFastVectorHighlighter( params, schema, fieldName ) )\n          doHighlightingByFastVectorHighlighter( fvh, fieldQuery, req, docSummaries, docId, doc, fieldName );\n        else\n          doHighlightingByHighlighter( query, req, docSummaries, docId, doc, fieldName );\n      }\n      String printId = schema.printableUniqueKey(doc);\n      fragments.add(printId == null ? null : printId, docSummaries);\n    }\n    return fragments;\n  }\n\n","sourceOld":"  /**\n   * Generates a list of Highlighted query fragments for each item in a list\n   * of documents, or returns null if highlighting is disabled.\n   *\n   * @param docs query results\n   * @param query the query\n   * @param req the current request\n   * @param defaultFields default list of fields to summarize\n   *\n   * @return NamedList containing a NamedList for each document, which in \n   * turns contains sets (field, summary) pairs.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public NamedList<Object> doHighlighting(DocList docs, Query query, SolrQueryRequest req, String[] defaultFields) throws IOException {\n    SolrParams params = req.getParams(); \n    if (!isHighlightingEnabled(params))\n        return null;\n     \n    SolrIndexSearcher searcher = req.getSearcher();\n    IndexSchema schema = searcher.getSchema();\n    NamedList fragments = new SimpleOrderedMap();\n    String[] fieldNames = getHighlightFields(query, req, defaultFields);\n    Set<String> fset = new HashSet<String>();\n     \n    {\n      // pre-fetch documents using the Searcher's doc cache\n      for(String f : fieldNames) { fset.add(f); }\n      // fetch unique key if one exists.\n      SchemaField keyField = schema.getUniqueKeyField();\n      if(null != keyField)\n        fset.add(keyField.getName());  \n    }\n\n    // get FastVectorHighlighter instance out of the processing loop\n    FastVectorHighlighter fvh = new FastVectorHighlighter(\n        // FVH cannot process hl.usePhraseHighlighter parameter per-field basis\n        params.getBool( HighlightParams.USE_PHRASE_HIGHLIGHTER, true ),\n        // FVH cannot process hl.requireFieldMatch parameter per-field basis\n        params.getBool( HighlightParams.FIELD_MATCH, false ),\n        getFragListBuilder( params ),\n        getFragmentsBuilder( params ) );\n    FieldQuery fieldQuery = fvh.getFieldQuery( query );\n\n    // Highlight each document\n    DocIterator iterator = docs.iterator();\n    for (int i = 0; i < docs.size(); i++) {\n      int docId = iterator.nextDoc();\n      Document doc = searcher.doc(docId, fset);\n      NamedList docSummaries = new SimpleOrderedMap();\n      for (String fieldName : fieldNames) {\n        fieldName = fieldName.trim();\n        if( useFastVectorHighlighter( params, schema, fieldName ) )\n          doHighlightingByFastVectorHighlighter( fvh, fieldQuery, req, docSummaries, docId, doc, fieldName );\n        else\n          doHighlightingByHighlighter( query, req, docSummaries, docId, doc, fieldName );\n      }\n      String printId = schema.printableUniqueKey(doc);\n      fragments.add(printId == null ? null : printId, docSummaries);\n    }\n    return fragments;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d72e3710bede9618eb9b2b5c6936369f3d3f9579":["701cd8aa1cd4df80734205800f295a1e4189d1d8"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"a48c0fe230530bd2b1e52e00bab51dc742acd0db":["303b28b90016c2de1b5870759794476dbf4fd6ce"],"701cd8aa1cd4df80734205800f295a1e4189d1d8":["82fff9df8ebf1830fe880d4d1cbed04e81684a4d"],"5df1793b9dbc0f17ba1d1dddb8a15748fdc3aaf3":["f3d1495bedca26db3edbddf239a3ad48f6131e21"],"303b28b90016c2de1b5870759794476dbf4fd6ce":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"f3d1495bedca26db3edbddf239a3ad48f6131e21":["7181b75752244f676e4634e90792409f5a3457f5"],"82fff9df8ebf1830fe880d4d1cbed04e81684a4d":["c013889a237f29c0b690ee86faa24c165860f3f8"],"c013889a237f29c0b690ee86faa24c165860f3f8":["a48c0fe230530bd2b1e52e00bab51dc742acd0db"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"be29e0e2cef1fd569147732e48caf8538790339b":["f277fbbf132590b41d0ceaa9cb8af2697cdbc673"],"f3371f30061b8f0256a0d2f11478c9c43e5a9156":["be29e0e2cef1fd569147732e48caf8538790339b"],"ad94625fb8d088209f46650c8097196fec67f00c":["5df1793b9dbc0f17ba1d1dddb8a15748fdc3aaf3"],"7181b75752244f676e4634e90792409f5a3457f5":["f3371f30061b8f0256a0d2f11478c9c43e5a9156"],"f277fbbf132590b41d0ceaa9cb8af2697cdbc673":["d72e3710bede9618eb9b2b5c6936369f3d3f9579"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"d72e3710bede9618eb9b2b5c6936369f3d3f9579":["f277fbbf132590b41d0ceaa9cb8af2697cdbc673"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["303b28b90016c2de1b5870759794476dbf4fd6ce"],"a48c0fe230530bd2b1e52e00bab51dc742acd0db":["c013889a237f29c0b690ee86faa24c165860f3f8"],"701cd8aa1cd4df80734205800f295a1e4189d1d8":["d72e3710bede9618eb9b2b5c6936369f3d3f9579"],"5df1793b9dbc0f17ba1d1dddb8a15748fdc3aaf3":["ad94625fb8d088209f46650c8097196fec67f00c"],"303b28b90016c2de1b5870759794476dbf4fd6ce":["a48c0fe230530bd2b1e52e00bab51dc742acd0db"],"f3d1495bedca26db3edbddf239a3ad48f6131e21":["5df1793b9dbc0f17ba1d1dddb8a15748fdc3aaf3"],"82fff9df8ebf1830fe880d4d1cbed04e81684a4d":["701cd8aa1cd4df80734205800f295a1e4189d1d8"],"c013889a237f29c0b690ee86faa24c165860f3f8":["82fff9df8ebf1830fe880d4d1cbed04e81684a4d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"be29e0e2cef1fd569147732e48caf8538790339b":["f3371f30061b8f0256a0d2f11478c9c43e5a9156"],"f3371f30061b8f0256a0d2f11478c9c43e5a9156":["7181b75752244f676e4634e90792409f5a3457f5"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"7181b75752244f676e4634e90792409f5a3457f5":["f3d1495bedca26db3edbddf239a3ad48f6131e21"],"f277fbbf132590b41d0ceaa9cb8af2697cdbc673":["be29e0e2cef1fd569147732e48caf8538790339b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}