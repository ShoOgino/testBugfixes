{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","commits":[{"id":"cf8086c7e11dc41303ef1b8050bd355ddfaee76d","date":1350007219,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#startDoc(int,int).mjava","sourceNew":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" ) (docOut: \" + docOut + \")\");\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (fieldHasFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (fieldHasFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","sourceOld":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" ) (docOut: \" + docOut + \")\");\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (fieldHasFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (fieldHasFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7492bcb52be51e55d596134b95b2e53cc4ffb91","date":1350223278,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#startDoc(int,int).mjava","sourceNew":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" ) (docOut: \" + docOut + \")\");\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (fieldHasFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (fieldHasFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","sourceOld":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" ) (docOut: \" + docOut + \")\");\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (fieldHasFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (fieldHasFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db4fdbf3d262768eabc027cd8321edca0cd11fa8","date":1350574784,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/block/BlockPostingsWriter#startDoc(int,int).mjava","sourceNew":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" ) (docOut: \" + docOut + \")\");\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (fieldHasFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (fieldHasFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","sourceOld":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" ) (docOut: \" + docOut + \")\");\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (fieldHasFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (fieldHasFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fa80a35d7c4b2b1e83082b275e3e8328ab93db52","date":1381766157,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","sourceNew":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" ) (docOut: \" + docOut + \")\");\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (writeFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (writeFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","sourceOld":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" ) (docOut: \" + docOut + \")\");\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (fieldHasFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (fieldHasFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a70ce9bddc6f985feb8e5e182aebe20872328d4","date":1411172748,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","sourceNew":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" )\", docOut.toString());\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (writeFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (writeFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","sourceOld":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" ) (docOut: \" + docOut + \")\");\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (writeFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (writeFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","bugFix":["e885d2b1e112b1d9db6a2dae82b3b493dfba1df1"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"99eb4a732d1a908f4636ace52928876136bf1896","date":1413829552,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","sourceNew":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" )\", docOut.toString());\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (writeFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (writeFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","sourceOld":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" )\", docOut.toString());\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (writeFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (writeFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene41/Lucene41PostingsWriter#startDoc(int,int).mjava","sourceNew":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" )\", docOut.toString());\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (writeFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (writeFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","sourceOld":"  @Override\n  public void startDoc(int docID, int termDocFreq) throws IOException {\n    // if (DEBUG) {\n    //   System.out.println(\"FPW.startDoc docID[\"+docBufferUpto+\"]=\" + docID);\n    // }\n    // Have collected a block of docs, and get a new doc. \n    // Should write skip data as well as postings list for\n    // current block.\n    if (lastBlockDocID != -1 && docBufferUpto == 0) {\n      // if (DEBUG) {\n      //   System.out.println(\"  bufferSkip at writeBlock: lastDocID=\" + lastBlockDocID + \" docCount=\" + (docCount-1));\n      // }\n      skipWriter.bufferSkip(lastBlockDocID, docCount, lastBlockPosFP, lastBlockPayFP, lastBlockPosBufferUpto, lastBlockPayloadByteUpto);\n    }\n\n    final int docDelta = docID - lastDocID;\n\n    if (docID < 0 || (docCount > 0 && docDelta <= 0)) {\n      throw new CorruptIndexException(\"docs out of order (\" + docID + \" <= \" + lastDocID + \" )\", docOut.toString());\n    }\n\n    docDeltaBuffer[docBufferUpto] = docDelta;\n    // if (DEBUG) {\n    //   System.out.println(\"  docDeltaBuffer[\" + docBufferUpto + \"]=\" + docDelta);\n    // }\n    if (writeFreqs) {\n      freqBuffer[docBufferUpto] = termDocFreq;\n    }\n    docBufferUpto++;\n    docCount++;\n\n    if (docBufferUpto == BLOCK_SIZE) {\n      // if (DEBUG) {\n      //   System.out.println(\"  write docDelta block @ fp=\" + docOut.getFilePointer());\n      // }\n      forUtil.writeBlock(docDeltaBuffer, encoded, docOut);\n      if (writeFreqs) {\n        // if (DEBUG) {\n        //   System.out.println(\"  write freq block @ fp=\" + docOut.getFilePointer());\n        // }\n        forUtil.writeBlock(freqBuffer, encoded, docOut);\n      }\n      // NOTE: don't set docBufferUpto back to 0 here;\n      // finishDoc will do so (because it needs to see that\n      // the block was filled so it can save skip data)\n    }\n\n\n    lastDocID = docID;\n    lastPosition = 0;\n    lastStartOffset = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["fa80a35d7c4b2b1e83082b275e3e8328ab93db52"],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","cf8086c7e11dc41303ef1b8050bd355ddfaee76d"],"99eb4a732d1a908f4636ace52928876136bf1896":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"cf8086c7e11dc41303ef1b8050bd355ddfaee76d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9a70ce9bddc6f985feb8e5e182aebe20872328d4","99eb4a732d1a908f4636ace52928876136bf1896"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"]},"commit2Childs":{"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["99eb4a732d1a908f4636ace52928876136bf1896","db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["db4fdbf3d262768eabc027cd8321edca0cd11fa8","fa80a35d7c4b2b1e83082b275e3e8328ab93db52"],"99eb4a732d1a908f4636ace52928876136bf1896":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"cf8086c7e11dc41303ef1b8050bd355ddfaee76d":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c7492bcb52be51e55d596134b95b2e53cc4ffb91","cf8086c7e11dc41303ef1b8050bd355ddfaee76d","db4fdbf3d262768eabc027cd8321edca0cd11fa8"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":[],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["db4fdbf3d262768eabc027cd8321edca0cd11fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}