{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","sourceNew":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n      .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()).setMergePolicy(newLogMergePolicy());\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    MockIndexWriter3 w = new MockIndexWriter3(dir, conf);\n    w.doFail = true;\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"a field\", TextField.TYPE_STORED));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(w.failed);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n      .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()).setMergePolicy(newLogMergePolicy());\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    MockIndexWriter3 w = new MockIndexWriter3(dir, conf);\n    w.doFail = true;\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"a field\", TextField.TYPE_STORED));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(w.failed);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","sourceNew":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()).setMergePolicy(newLogMergePolicy());\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    MockIndexWriter3 w = new MockIndexWriter3(dir, conf);\n    w.doFail = true;\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"a field\", TextField.TYPE_STORED));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(w.failed);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random))\n      .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()).setMergePolicy(newLogMergePolicy());\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    MockIndexWriter3 w = new MockIndexWriter3(dir, conf);\n    w.doFail = true;\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"a field\", TextField.TYPE_STORED));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(w.failed);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","sourceNew":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()).setMergePolicy(newLogMergePolicy());\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    MockIndexWriter3 w = new MockIndexWriter3(dir, conf);\n    w.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(w.failed);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()).setMergePolicy(newLogMergePolicy());\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    MockIndexWriter3 w = new MockIndexWriter3(dir, conf);\n    w.doFail = true;\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"a field\", TextField.TYPE_STORED));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(w.failed);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"94b4f4bf8892e6006d66f4231d6d1873bbe56e73","date":1352661595,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","sourceNew":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    MockIndexWriter3 w = new MockIndexWriter3(dir, conf);\n    w.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(w.failed);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()).setMergePolicy(newLogMergePolicy());\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    MockIndexWriter3 w = new MockIndexWriter3(dir, conf);\n    w.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(w.failed);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":["c19f985e36a65cc969e8e564fe337a0d41512075"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","sourceNew":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    MockIndexWriter3 w = new MockIndexWriter3(dir, conf);\n    w.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(w.failed);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()).setMergePolicy(newLogMergePolicy());\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    MockIndexWriter3 w = new MockIndexWriter3(dir, conf);\n    w.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(w.failed);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"978de4e2d23054c6624dd5928ddeb734dca68eec","date":1370592803,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","sourceNew":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    TestPoint3 testPoint = new TestPoint3();\n    IndexWriter w = RandomIndexWriter.mockIndexWriter(dir, conf, testPoint);\n    testPoint.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(testPoint.failed);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    MockIndexWriter3 w = new MockIndexWriter3(dir, conf);\n    w.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(w.failed);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","sourceNew":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    TestPoint3 testPoint = new TestPoint3();\n    IndexWriter w = RandomIndexWriter.mockIndexWriter(dir, conf, testPoint);\n    testPoint.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(testPoint.failed);\n    w.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    TestPoint3 testPoint = new TestPoint3();\n    IndexWriter w = RandomIndexWriter.mockIndexWriter(dir, conf, testPoint);\n    testPoint.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(testPoint.failed);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","sourceNew":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2)\n      .setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    TestPoint3 testPoint = new TestPoint3();\n    IndexWriter w = RandomIndexWriter.mockIndexWriter(dir, conf, testPoint);\n    testPoint.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(testPoint.failed);\n    w.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    TestPoint3 testPoint = new TestPoint3();\n    IndexWriter w = RandomIndexWriter.mockIndexWriter(dir, conf, testPoint);\n    testPoint.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(testPoint.failed);\n    w.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","sourceNew":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2)\n      .setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    TestPoint3 testPoint = new TestPoint3();\n    IndexWriter w = RandomIndexWriter.mockIndexWriter(dir, conf, testPoint);\n    testPoint.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(testPoint.failed);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2)\n      .setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    TestPoint3 testPoint = new TestPoint3();\n    IndexWriter w = RandomIndexWriter.mockIndexWriter(dir, conf, testPoint);\n    testPoint.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(testPoint.failed);\n    w.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a6b82a3644db30161c3cbd3e23aeefe19cb88113","date":1435478870,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","sourceNew":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2)\n      .setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    TestPoint3 testPoint = new TestPoint3();\n    IndexWriter w = RandomIndexWriter.mockIndexWriter(random(), dir, conf, testPoint);\n    testPoint.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(testPoint.failed);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2)\n      .setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    TestPoint3 testPoint = new TestPoint3();\n    IndexWriter w = RandomIndexWriter.mockIndexWriter(dir, conf, testPoint);\n    testPoint.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(testPoint.failed);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d9e22bdf0692bfa61e342b04a6ac7078670c1e16","date":1436866730,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterExceptions#testExceptionOnMergeInit().mjava","sourceNew":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2)\n      .setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    TestPoint3 testPoint = new TestPoint3();\n    IndexWriter w = RandomIndexWriter.mockIndexWriter(random(), dir, conf, testPoint);\n    testPoint.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++) {\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n    }\n\n    try {\n      ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    } catch (IllegalStateException ise) {\n      // OK: merge exc causes tragedy\n    }\n    assertTrue(testPoint.failed);\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1210\n  public void testExceptionOnMergeInit() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()))\n      .setMaxBufferedDocs(2)\n      .setMergePolicy(newLogMergePolicy());\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();\n    cms.setSuppressExceptions();\n    conf.setMergeScheduler(cms);\n    ((LogMergePolicy) conf.getMergePolicy()).setMergeFactor(2);\n    TestPoint3 testPoint = new TestPoint3();\n    IndexWriter w = RandomIndexWriter.mockIndexWriter(random(), dir, conf, testPoint);\n    testPoint.doFail = true;\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"a field\", Field.Store.YES));\n    for(int i=0;i<10;i++)\n      try {\n        w.addDocument(doc);\n      } catch (RuntimeException re) {\n        break;\n      }\n\n    ((ConcurrentMergeScheduler) w.getConfig().getMergeScheduler()).sync();\n    assertTrue(testPoint.failed);\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"978de4e2d23054c6624dd5928ddeb734dca68eec":["94b4f4bf8892e6006d66f4231d6d1873bbe56e73"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"94b4f4bf8892e6006d66f4231d6d1873bbe56e73":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"407687e67faf6e1f02a211ca078d8e3eed631027":["04f07771a2a7dd3a395700665ed839c3dae2def2","94b4f4bf8892e6006d66f4231d6d1873bbe56e73"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"d9e22bdf0692bfa61e342b04a6ac7078670c1e16":["a6b82a3644db30161c3cbd3e23aeefe19cb88113"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"a6b82a3644db30161c3cbd3e23aeefe19cb88113":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["978de4e2d23054c6624dd5928ddeb734dca68eec"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d9e22bdf0692bfa61e342b04a6ac7078670c1e16"]},"commit2Childs":{"978de4e2d23054c6624dd5928ddeb734dca68eec":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"94b4f4bf8892e6006d66f4231d6d1873bbe56e73":["978de4e2d23054c6624dd5928ddeb734dca68eec","407687e67faf6e1f02a211ca078d8e3eed631027"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"04f07771a2a7dd3a395700665ed839c3dae2def2":["94b4f4bf8892e6006d66f4231d6d1873bbe56e73","407687e67faf6e1f02a211ca078d8e3eed631027"],"d9e22bdf0692bfa61e342b04a6ac7078670c1e16":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["a6b82a3644db30161c3cbd3e23aeefe19cb88113"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"a6b82a3644db30161c3cbd3e23aeefe19cb88113":["d9e22bdf0692bfa61e342b04a6ac7078670c1e16"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["407687e67faf6e1f02a211ca078d8e3eed631027","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}