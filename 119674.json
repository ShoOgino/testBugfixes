{"path":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testAddDocs().mjava","commits":[{"id":"61c45e99cf6676da48f19d7511c73712ad39402b","date":1495508331,"type":0,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testAddDocs().mjava","pathOld":"/dev/null","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testAddDocs() throws Exception {\n    int numTlogReplicas = 1 + random().nextInt(3);\n    DocCollection docCollection = createAndWaitForCollection(1, 0, numTlogReplicas, 0);\n    assertEquals(1, docCollection.getSlices().size());\n    \n    cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", \"1\", \"foo\", \"bar\"));\n    cluster.getSolrClient().commit(collectionName);\n    \n    Slice s = docCollection.getSlices().iterator().next();\n    try (HttpSolrClient leaderClient = getHttpSolrClient(s.getLeader().getCoreUrl())) {\n      assertEquals(1, leaderClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n    \n    TimeOut t = new TimeOut(REPLICATION_TIMEOUT_SECS, TimeUnit.SECONDS);\n    for (Replica r:s.getReplicas(EnumSet.of(Replica.Type.TLOG))) {\n      //TODO: assert replication < REPLICATION_TIMEOUT_SECS\n      try (HttpSolrClient tlogReplicaClient = getHttpSolrClient(r.getCoreUrl())) {\n        while (true) {\n          try {\n            assertEquals(\"Replica \" + r.getName() + \" not up to date after 10 seconds\",\n                1, tlogReplicaClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n            // Append replicas process all updates\n            SolrQuery req = new SolrQuery(\n                \"qt\", \"/admin/plugins\",\n                \"stats\", \"true\");\n            QueryResponse statsResponse = tlogReplicaClient.query(req);\n            assertEquals(\"Append replicas should recive all updates. Replica: \" + r + \", response: \" + statsResponse, \n                1L, ((Map<String, Object>)((NamedList<Object>)statsResponse.getResponse()).findRecursive(\"plugins\", \"UPDATE\", \"updateHandler\", \"stats\")).get(\"UPDATE.updateHandler.cumulativeAdds.count\"));\n            break;\n          } catch (AssertionError e) {\n            if (t.hasTimedOut()) {\n              throw e;\n            } else {\n              Thread.sleep(100);\n            }\n          }\n        }\n      }\n    }\n    assertUlogPresence(docCollection);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testAddDocs().mjava","pathOld":"/dev/null","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testAddDocs() throws Exception {\n    int numTlogReplicas = 1 + random().nextInt(3);\n    DocCollection docCollection = createAndWaitForCollection(1, 0, numTlogReplicas, 0);\n    assertEquals(1, docCollection.getSlices().size());\n    \n    cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", \"1\", \"foo\", \"bar\"));\n    cluster.getSolrClient().commit(collectionName);\n    \n    Slice s = docCollection.getSlices().iterator().next();\n    try (HttpSolrClient leaderClient = getHttpSolrClient(s.getLeader().getCoreUrl())) {\n      assertEquals(1, leaderClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n    \n    TimeOut t = new TimeOut(REPLICATION_TIMEOUT_SECS, TimeUnit.SECONDS);\n    for (Replica r:s.getReplicas(EnumSet.of(Replica.Type.TLOG))) {\n      //TODO: assert replication < REPLICATION_TIMEOUT_SECS\n      try (HttpSolrClient tlogReplicaClient = getHttpSolrClient(r.getCoreUrl())) {\n        while (true) {\n          try {\n            assertEquals(\"Replica \" + r.getName() + \" not up to date after 10 seconds\",\n                1, tlogReplicaClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n            // Append replicas process all updates\n            SolrQuery req = new SolrQuery(\n                \"qt\", \"/admin/plugins\",\n                \"stats\", \"true\");\n            QueryResponse statsResponse = tlogReplicaClient.query(req);\n            assertEquals(\"Append replicas should recive all updates. Replica: \" + r + \", response: \" + statsResponse, \n                1L, ((Map<String, Object>)((NamedList<Object>)statsResponse.getResponse()).findRecursive(\"plugins\", \"UPDATE\", \"updateHandler\", \"stats\")).get(\"UPDATE.updateHandler.cumulativeAdds.count\"));\n            break;\n          } catch (AssertionError e) {\n            if (t.hasTimedOut()) {\n              throw e;\n            } else {\n              Thread.sleep(100);\n            }\n          }\n        }\n      }\n    }\n    assertUlogPresence(docCollection);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testAddDocs().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testAddDocs().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testAddDocs() throws Exception {\n    int numTlogReplicas = 1 + random().nextInt(3);\n    DocCollection docCollection = createAndWaitForCollection(1, 0, numTlogReplicas, 0);\n    assertEquals(1, docCollection.getSlices().size());\n    \n    cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", \"1\", \"foo\", \"bar\"));\n    cluster.getSolrClient().commit(collectionName);\n    \n    Slice s = docCollection.getSlices().iterator().next();\n    try (HttpSolrClient leaderClient = getHttpSolrClient(s.getLeader().getCoreUrl())) {\n      assertEquals(1, leaderClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n    \n    TimeOut t = new TimeOut(REPLICATION_TIMEOUT_SECS, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    for (Replica r:s.getReplicas(EnumSet.of(Replica.Type.TLOG))) {\n      //TODO: assert replication < REPLICATION_TIMEOUT_SECS\n      try (HttpSolrClient tlogReplicaClient = getHttpSolrClient(r.getCoreUrl())) {\n        while (true) {\n          try {\n            assertEquals(\"Replica \" + r.getName() + \" not up to date after 10 seconds\",\n                1, tlogReplicaClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n            // Append replicas process all updates\n            SolrQuery req = new SolrQuery(\n                \"qt\", \"/admin/plugins\",\n                \"stats\", \"true\");\n            QueryResponse statsResponse = tlogReplicaClient.query(req);\n            assertEquals(\"Append replicas should recive all updates. Replica: \" + r + \", response: \" + statsResponse, \n                1L, ((Map<String, Object>)((NamedList<Object>)statsResponse.getResponse()).findRecursive(\"plugins\", \"UPDATE\", \"updateHandler\", \"stats\")).get(\"UPDATE.updateHandler.cumulativeAdds.count\"));\n            break;\n          } catch (AssertionError e) {\n            if (t.hasTimedOut()) {\n              throw e;\n            } else {\n              Thread.sleep(100);\n            }\n          }\n        }\n      }\n    }\n    assertUlogPresence(docCollection);\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testAddDocs() throws Exception {\n    int numTlogReplicas = 1 + random().nextInt(3);\n    DocCollection docCollection = createAndWaitForCollection(1, 0, numTlogReplicas, 0);\n    assertEquals(1, docCollection.getSlices().size());\n    \n    cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", \"1\", \"foo\", \"bar\"));\n    cluster.getSolrClient().commit(collectionName);\n    \n    Slice s = docCollection.getSlices().iterator().next();\n    try (HttpSolrClient leaderClient = getHttpSolrClient(s.getLeader().getCoreUrl())) {\n      assertEquals(1, leaderClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n    \n    TimeOut t = new TimeOut(REPLICATION_TIMEOUT_SECS, TimeUnit.SECONDS);\n    for (Replica r:s.getReplicas(EnumSet.of(Replica.Type.TLOG))) {\n      //TODO: assert replication < REPLICATION_TIMEOUT_SECS\n      try (HttpSolrClient tlogReplicaClient = getHttpSolrClient(r.getCoreUrl())) {\n        while (true) {\n          try {\n            assertEquals(\"Replica \" + r.getName() + \" not up to date after 10 seconds\",\n                1, tlogReplicaClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n            // Append replicas process all updates\n            SolrQuery req = new SolrQuery(\n                \"qt\", \"/admin/plugins\",\n                \"stats\", \"true\");\n            QueryResponse statsResponse = tlogReplicaClient.query(req);\n            assertEquals(\"Append replicas should recive all updates. Replica: \" + r + \", response: \" + statsResponse, \n                1L, ((Map<String, Object>)((NamedList<Object>)statsResponse.getResponse()).findRecursive(\"plugins\", \"UPDATE\", \"updateHandler\", \"stats\")).get(\"UPDATE.updateHandler.cumulativeAdds.count\"));\n            break;\n          } catch (AssertionError e) {\n            if (t.hasTimedOut()) {\n              throw e;\n            } else {\n              Thread.sleep(100);\n            }\n          }\n        }\n      }\n    }\n    assertUlogPresence(docCollection);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15","date":1554259533,"type":3,"author":"Gus Heck","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testAddDocs().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testAddDocs().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testAddDocs() throws Exception {\n    int numTlogReplicas = 1 + random().nextInt(3);\n    DocCollection docCollection = createAndWaitForCollection(1, 0, numTlogReplicas, 0);\n    assertEquals(1, docCollection.getSlices().size());\n\n    cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", \"1\", \"foo\", \"bar\"));\n    cluster.getSolrClient().commit(collectionName);\n\n    Slice s = docCollection.getSlices().iterator().next();\n    try (HttpSolrClient leaderClient = getHttpSolrClient(s.getLeader().getCoreUrl())) {\n      assertEquals(1, leaderClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    TimeOut t = new TimeOut(REPLICATION_TIMEOUT_SECS, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    for (Replica r:s.getReplicas(EnumSet.of(Replica.Type.TLOG))) {\n      //TODO: assert replication < REPLICATION_TIMEOUT_SECS\n      try (HttpSolrClient tlogReplicaClient = getHttpSolrClient(r.getCoreUrl())) {\n        while (true) {\n          try {\n            assertEquals(\"Replica \" + r.getName() + \" not up to date after 10 seconds\",\n                1, tlogReplicaClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n            // Append replicas process all updates\n            SolrQuery req = new SolrQuery(\n                \"qt\", \"/admin/plugins\",\n                \"stats\", \"true\");\n            QueryResponse statsResponse = tlogReplicaClient.query(req);\n            assertEquals(\"Append replicas should recive all updates. Replica: \" + r + \", response: \" + statsResponse,\n                1L, ((Map<String, Object>)((NamedList<Object>)statsResponse.getResponse()).findRecursive(\"plugins\", \"UPDATE\", \"updateHandler\", \"stats\")).get(\"UPDATE.updateHandler.cumulativeAdds.count\"));\n            break;\n          } catch (AssertionError e) {\n            if (t.hasTimedOut()) {\n              throw e;\n            } else {\n              Thread.sleep(100);\n            }\n          }\n        }\n      }\n    }\n    assertUlogPresence(docCollection);\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testAddDocs() throws Exception {\n    int numTlogReplicas = 1 + random().nextInt(3);\n    DocCollection docCollection = createAndWaitForCollection(1, 0, numTlogReplicas, 0);\n    assertEquals(1, docCollection.getSlices().size());\n    \n    cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", \"1\", \"foo\", \"bar\"));\n    cluster.getSolrClient().commit(collectionName);\n    \n    Slice s = docCollection.getSlices().iterator().next();\n    try (HttpSolrClient leaderClient = getHttpSolrClient(s.getLeader().getCoreUrl())) {\n      assertEquals(1, leaderClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n    \n    TimeOut t = new TimeOut(REPLICATION_TIMEOUT_SECS, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    for (Replica r:s.getReplicas(EnumSet.of(Replica.Type.TLOG))) {\n      //TODO: assert replication < REPLICATION_TIMEOUT_SECS\n      try (HttpSolrClient tlogReplicaClient = getHttpSolrClient(r.getCoreUrl())) {\n        while (true) {\n          try {\n            assertEquals(\"Replica \" + r.getName() + \" not up to date after 10 seconds\",\n                1, tlogReplicaClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n            // Append replicas process all updates\n            SolrQuery req = new SolrQuery(\n                \"qt\", \"/admin/plugins\",\n                \"stats\", \"true\");\n            QueryResponse statsResponse = tlogReplicaClient.query(req);\n            assertEquals(\"Append replicas should recive all updates. Replica: \" + r + \", response: \" + statsResponse, \n                1L, ((Map<String, Object>)((NamedList<Object>)statsResponse.getResponse()).findRecursive(\"plugins\", \"UPDATE\", \"updateHandler\", \"stats\")).get(\"UPDATE.updateHandler.cumulativeAdds.count\"));\n            break;\n          } catch (AssertionError e) {\n            if (t.hasTimedOut()) {\n              throw e;\n            } else {\n              Thread.sleep(100);\n            }\n          }\n        }\n      }\n    }\n    assertUlogPresence(docCollection);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e98520789adb1d5ad05afb4956eca0944a929688","date":1592430701,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testAddDocs().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTlogReplica#testAddDocs().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testAddDocs() throws Exception {\n    int numTlogReplicas = 1 + random().nextInt(3);\n    DocCollection docCollection = createAndWaitForCollection(1, 0, numTlogReplicas, 0);\n    assertEquals(1, docCollection.getSlices().size());\n\n    cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", \"1\", \"foo\", \"bar\"));\n    cluster.getSolrClient().commit(collectionName);\n\n    Slice s = docCollection.getSlices().iterator().next();\n    try (HttpSolrClient leaderClient = getHttpSolrClient(s.getLeader().getCoreUrl())) {\n      assertEquals(1, leaderClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    TimeOut t = new TimeOut(REPLICATION_TIMEOUT_SECS, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    for (Replica r:s.getReplicas(EnumSet.of(Replica.Type.TLOG))) {\n      //TODO: assert replication < REPLICATION_TIMEOUT_SECS\n      try (HttpSolrClient tlogReplicaClient = getHttpSolrClient(r.getCoreUrl())) {\n        while (true) {\n          try {\n            assertEquals(\"Replica \" + r.getName() + \" not up to date after 10 seconds\",\n                1, tlogReplicaClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n            // Append replicas process all updates\n            SolrQuery req = new SolrQuery(\n                \"qt\", \"/admin/plugins\",\n                \"stats\", \"true\");\n            QueryResponse statsResponse = tlogReplicaClient.query(req);\n            assertEquals(\"Append replicas should recive all updates. Replica: \" + r + \", response: \" + statsResponse,\n                1L, ((Map<String, Object>)(statsResponse.getResponse()).findRecursive(\"plugins\", \"UPDATE\", \"updateHandler\", \"stats\")).get(\"UPDATE.updateHandler.cumulativeAdds.count\"));\n            break;\n          } catch (AssertionError e) {\n            if (t.hasTimedOut()) {\n              throw e;\n            } else {\n              Thread.sleep(100);\n            }\n          }\n        }\n      }\n    }\n    assertUlogPresence(docCollection);\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testAddDocs() throws Exception {\n    int numTlogReplicas = 1 + random().nextInt(3);\n    DocCollection docCollection = createAndWaitForCollection(1, 0, numTlogReplicas, 0);\n    assertEquals(1, docCollection.getSlices().size());\n\n    cluster.getSolrClient().add(collectionName, new SolrInputDocument(\"id\", \"1\", \"foo\", \"bar\"));\n    cluster.getSolrClient().commit(collectionName);\n\n    Slice s = docCollection.getSlices().iterator().next();\n    try (HttpSolrClient leaderClient = getHttpSolrClient(s.getLeader().getCoreUrl())) {\n      assertEquals(1, leaderClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    }\n\n    TimeOut t = new TimeOut(REPLICATION_TIMEOUT_SECS, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    for (Replica r:s.getReplicas(EnumSet.of(Replica.Type.TLOG))) {\n      //TODO: assert replication < REPLICATION_TIMEOUT_SECS\n      try (HttpSolrClient tlogReplicaClient = getHttpSolrClient(r.getCoreUrl())) {\n        while (true) {\n          try {\n            assertEquals(\"Replica \" + r.getName() + \" not up to date after 10 seconds\",\n                1, tlogReplicaClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n            // Append replicas process all updates\n            SolrQuery req = new SolrQuery(\n                \"qt\", \"/admin/plugins\",\n                \"stats\", \"true\");\n            QueryResponse statsResponse = tlogReplicaClient.query(req);\n            assertEquals(\"Append replicas should recive all updates. Replica: \" + r + \", response: \" + statsResponse,\n                1L, ((Map<String, Object>)((NamedList<Object>)statsResponse.getResponse()).findRecursive(\"plugins\", \"UPDATE\", \"updateHandler\", \"stats\")).get(\"UPDATE.updateHandler.cumulativeAdds.count\"));\n            break;\n          } catch (AssertionError e) {\n            if (t.hasTimedOut()) {\n              throw e;\n            } else {\n              Thread.sleep(100);\n            }\n          }\n        }\n      }\n    }\n    assertUlogPresence(docCollection);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e9017cf144952056066919f1ebc7897ff9bd71b1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","61c45e99cf6676da48f19d7511c73712ad39402b"],"61c45e99cf6676da48f19d7511c73712ad39402b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["61c45e99cf6676da48f19d7511c73712ad39402b"],"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e98520789adb1d5ad05afb4956eca0944a929688"],"e98520789adb1d5ad05afb4956eca0944a929688":["0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15"]},"commit2Childs":{"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"61c45e99cf6676da48f19d7511c73712ad39402b":["e9017cf144952056066919f1ebc7897ff9bd71b1","1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e9017cf144952056066919f1ebc7897ff9bd71b1","61c45e99cf6676da48f19d7511c73712ad39402b"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15"],"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15":["e98520789adb1d5ad05afb4956eca0944a929688"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"e98520789adb1d5ad05afb4956eca0944a929688":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}