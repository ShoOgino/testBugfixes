{"path":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","commits":[{"id":"edfbc64812ce67598712702d2e4c81bfefccdd57","date":1310457524,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"75ec8c9aaa10ac00b30fd4c2465409770c838f7b","date":1323020115,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2dd8cac059f4a5d4491e279aa2d07064392f9357","date":1323099195,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param in source index, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param in source index, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param in source index, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d7bbf8cffd2321f26cf9f6487f1571d325f20bc3","date":1328092914,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param in source index, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      // pass the subreaders directly, as our wrapper's numDocs/hasDeletetions are not up-to-date\n      w.addIndexes(input.getSequentialSubReaders());\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param in source index, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(input);\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(Version,IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param in source index, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      // pass the subreaders directly, as our wrapper's numDocs/hasDeletetions are not up-to-date\n      w.addIndexes(input.getSequentialSubReaders());\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param in source index, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(Version version, IndexReader in, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (in == null || in.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    FakeDeleteIndexReader input = new FakeDeleteIndexReader(in);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          version,\n          null)\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      // pass the subreaders directly, as our wrapper's numDocs/hasDeletetions are not up-to-date\n      w.addIndexes(input.getSequentialSubReaders());\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["d7bbf8cffd2321f26cf9f6487f1571d325f20bc3"],"75ec8c9aaa10ac00b30fd4c2465409770c838f7b":["edfbc64812ce67598712702d2e4c81bfefccdd57"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["edfbc64812ce67598712702d2e4c81bfefccdd57","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"edfbc64812ce67598712702d2e4c81bfefccdd57":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["edfbc64812ce67598712702d2e4c81bfefccdd57","2dd8cac059f4a5d4491e279aa2d07064392f9357"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"d7bbf8cffd2321f26cf9f6487f1571d325f20bc3":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"2dd8cac059f4a5d4491e279aa2d07064392f9357":["75ec8c9aaa10ac00b30fd4c2465409770c838f7b"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"75ec8c9aaa10ac00b30fd4c2465409770c838f7b":["2dd8cac059f4a5d4491e279aa2d07064392f9357"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"edfbc64812ce67598712702d2e4c81bfefccdd57":["75ec8c9aaa10ac00b30fd4c2465409770c838f7b","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["edfbc64812ce67598712702d2e4c81bfefccdd57"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","d7bbf8cffd2321f26cf9f6487f1571d325f20bc3"],"d7bbf8cffd2321f26cf9f6487f1571d325f20bc3":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"2dd8cac059f4a5d4491e279aa2d07064392f9357":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}