{"path":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","commits":[{"id":"0f44610301174bfb430443d89a88dc1c502feea1","date":1231194664,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(),\n                                         IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setMaxBufferedDocs(2);\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection commits = IndexReader.listCommits(dir);\n    Iterator it = commits.iterator();\n    while(it.hasNext()) {\n      IndexCommit commit = (IndexCommit) it.next();\n      Collection files = commit.getFileNames();\n      HashSet seen = new HashSet();\n      Iterator it2 = files.iterator();\n      while(it2.hasNext()) {\n        String fileName = (String) it2.next();\n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9","date":1256127131,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),\n                                         IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setMaxBufferedDocs(2);\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection commits = IndexReader.listCommits(dir);\n    Iterator it = commits.iterator();\n    while(it.hasNext()) {\n      IndexCommit commit = (IndexCommit) it.next();\n      Collection files = commit.getFileNames();\n      HashSet seen = new HashSet();\n      Iterator it2 = files.iterator();\n      while(it2.hasNext()) {\n        String fileName = (String) it2.next();\n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(),\n                                         IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setMaxBufferedDocs(2);\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection commits = IndexReader.listCommits(dir);\n    Iterator it = commits.iterator();\n    while(it.hasNext()) {\n      IndexCommit commit = (IndexCommit) it.next();\n      Collection files = commit.getFileNames();\n      HashSet seen = new HashSet();\n      Iterator it2 = files.iterator();\n      while(it2.hasNext()) {\n        String fileName = (String) it2.next();\n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e450c7d50c2fc84c963d0d7ade9d3217d868064d","date":1259932067,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),\n                                         IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setMaxBufferedDocs(2);\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = IndexReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),\n                                         IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setMaxBufferedDocs(2);\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection commits = IndexReader.listCommits(dir);\n    Iterator it = commits.iterator();\n    while(it.hasNext()) {\n      IndexCommit commit = (IndexCommit) it.next();\n      Collection files = commit.getFileNames();\n      HashSet seen = new HashSet();\n      Iterator it2 = files.iterator();\n      while(it2.hasNext()) {\n        String fileName = (String) it2.next();\n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6","date":1265808957,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(TEST_VERSION_CURRENT),\n                                         IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setMaxBufferedDocs(2);\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = IndexReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(org.apache.lucene.util.Version.LUCENE_CURRENT),\n                                         IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setMaxBufferedDocs(2);\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = IndexReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT).setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = IndexReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(TEST_VERSION_CURRENT),\n                                         IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setMaxBufferedDocs(2);\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = IndexReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(TEST_VERSION_CURRENT),\n                                         IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setMaxBufferedDocs(2);\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = IndexReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT).setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = IndexReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = IndexReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new StandardAnalyzer(TEST_VERSION_CURRENT),\n                                         IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setMaxBufferedDocs(2);\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = IndexReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","pathOld":"src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = IndexReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = new MockRAMDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = IndexReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"0f44610301174bfb430443d89a88dc1c502feea1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1cedb00d2dd44640194401179358a2e3ba6051bf":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9":["0f44610301174bfb430443d89a88dc1c502feea1"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["4b41b991de69ba7b72d5e90cfcee25699a1a7fc9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"]},"commit2Childs":{"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"0f44610301174bfb430443d89a88dc1c502feea1":["4b41b991de69ba7b72d5e90cfcee25699a1a7fc9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0f44610301174bfb430443d89a88dc1c502feea1"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}