{"path":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse, false);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse, false);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse, false);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse, false);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse, false);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"a b b c c c d e f g g h i i j j k\", TextField.TYPE_UNSTORED));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse, false);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":["905f6760f432211e868cf7d229c8797382853a7a"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"322360ac5185a8446d3e0b530b2068bef67cd3d5","date":1343669494,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse, false);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse, false);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, false);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse, false);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","date":1346834651,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/pulsing/TestPulsingReuse#testSophisticatedReuse().mjava","sourceNew":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // TODO: this is a basic test. this thing is complicated, add more\n  public void testSophisticatedReuse() throws Exception {\n    // we always run this test with pulsing codec.\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Pulsing40PostingsFormat(1));\n    Directory dir = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setCodec(cp));\n    Document doc = new Document();\n    doc.add(new TextField(\"foo\", \"a b b c c c d e f g g h i i j j k\", Field.Store.NO));\n    iw.addDocument(doc);\n    DirectoryReader ir = iw.getReader();\n    iw.close();\n    \n    AtomicReader segment = getOnlySegmentReader(ir);\n    DocsEnum reuse = null;\n    Map<DocsEnum,Boolean> allEnums = new IdentityHashMap<DocsEnum,Boolean>();\n    TermsEnum te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      reuse = te.docs(null, reuse, 0);\n      allEnums.put(reuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    allEnums.clear();\n    DocsAndPositionsEnum posReuse = null;\n    te = segment.terms(\"foo\").iterator(null);\n    while (te.next() != null) {\n      posReuse = te.docsAndPositions(null, posReuse);\n      allEnums.put(posReuse, true);\n    }\n    \n    assertEquals(2, allEnums.size());\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["02331260bb246364779cb6f04919ca47900d01bb"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["04f07771a2a7dd3a395700665ed839c3dae2def2","02331260bb246364779cb6f04919ca47900d01bb"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["04f07771a2a7dd3a395700665ed839c3dae2def2","02331260bb246364779cb6f04919ca47900d01bb"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"02331260bb246364779cb6f04919ca47900d01bb":["322360ac5185a8446d3e0b530b2068bef67cd3d5"]},"commit2Childs":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["02331260bb246364779cb6f04919ca47900d01bb"],"02331260bb246364779cb6f04919ca47900d01bb":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}