{"path":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","commits":[{"id":"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1","date":1523453934,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (cloudManager instanceof SimCloudManager) {\n      log.warn(\"Requires SOLR-12208\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : 150000,\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43345f1452f9510f8aaadae6156fe0c834e7d957","date":1523483670,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (cloudManager instanceof SimCloudManager) {\n      log.warn(\"Requires SOLR-12208\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : 150000,\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc86fee106bfbba46a22faf82a93b3af3f08006","date":1523877365,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (cloudManager instanceof SimCloudManager) {\n      log.warn(\"Requires SOLR-12208\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (cloudManager instanceof SimCloudManager) {\n      log.warn(\"Requires SOLR-12208\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : 150000,\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e4aa99957dcb54cefbbec762eb896b084deac1b9","date":1526471995,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (cloudManager instanceof SimCloudManager) {\n      log.warn(\"Requires SOLR-12208\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (cloudManager instanceof SimCloudManager) {\n      log.warn(\"Requires SOLR-12208\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b55cd711a129fb7fc4c3c4672d652149c9a4faa","date":1528813320,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  public void testMixedBounds() throws Exception {\n//    if (cloudManager instanceof SimCloudManager) {\n//      log.warn(\"Requires SOLR-12208\");\n//      return;\n//    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (cloudManager instanceof SimCloudManager) {\n      log.warn(\"Requires SOLR-12208\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f607a0a2e930f55385c7a24afb68ef661ef7e3ee","date":1530823671,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMixedBounds() throws Exception {\n//    if (cloudManager instanceof SimCloudManager) {\n//      log.warn(\"Requires SOLR-12208\");\n//      return;\n//    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n//    if (cloudManager instanceof SimCloudManager) {\n//      log.warn(\"Requires SOLR-12208\");\n//      return;\n//    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMixedBounds() throws Exception {\n//    if (cloudManager instanceof SimCloudManager) {\n//      log.warn(\"Requires SOLR-12208\");\n//      return;\n//    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (cloudManager instanceof SimCloudManager) {\n      log.warn(\"Requires SOLR-12208\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMixedBounds() throws Exception {\n//    if (cloudManager instanceof SimCloudManager) {\n//      log.warn(\"Requires SOLR-12208\");\n//      return;\n//    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (cloudManager instanceof SimCloudManager) {\n      log.warn(\"Requires SOLR-12208\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"042b92cf48996255bedb0c3c4bf772d7e06e4dea","date":1534272102,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMixedBounds() throws Exception {\n//    if (cloudManager instanceof SimCloudManager) {\n//      log.warn(\"Requires SOLR-12208\");\n//      return;\n//    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMixedBounds() throws Exception {\n//    if (cloudManager instanceof SimCloudManager) {\n//      log.warn(\"Requires SOLR-12208\");\n//      return;\n//    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":["ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1","f607a0a2e930f55385c7a24afb68ef661ef7e3ee"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"023604b80bedb02c79b94b0e4ae06c6ddff1937c","date":1534449927,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    solrClient.request(ur, collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMixedBounds() throws Exception {\n//    if (cloudManager instanceof SimCloudManager) {\n//      log.warn(\"Requires SOLR-12208\");\n//      return;\n//    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 8; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 95; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"976feb6756f29529c6ce5b578e7d6fa8b1efcb30","date":1535461878,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    solrClient.request(ur, collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    solrClient.request(ur, collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    solrClient.request(ur, collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    solrClient.request(ur, collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"89948af0461fead48f44ba8fb7866f107ce83f22","date":1545157711,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    solrClient.request(ur, collectionName);\n\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    solrClient.request(ur, collectionName);\n\n    // resume trigger\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7cac1f2920f8057198f04505797cbabf74dd9a97","date":1546884894,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n//    System.exit(-1);\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    long waitForSeconds = 3 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    solrClient.request(ur, collectionName);\n\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5","date":1556572478,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n//    System.exit(-1);\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n//    System.exit(-1);\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2d80c1ad9241ae005a167d7ee8ac473601b0e57c","date":1559036097,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  //@AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMixedBounds() throws Exception {\n    if (!realCluster) {\n      log.info(\"This test doesn't work with a simulated cluster\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n//    System.exit(-1);\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMixedBounds() throws Exception {\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n//    System.exit(-1);\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a97a72dc16d01fda8ca5c9e0264b3604e30ab539","date":1565639985,"type":3,"author":"Megan Carey","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (!realCluster) {\n      log.info(\"This test doesn't work with a simulated cluster\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  //@AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMixedBounds() throws Exception {\n    if (!realCluster) {\n      log.info(\"This test doesn't work with a simulated cluster\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n//    System.exit(-1);\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4","date":1576125737,"type":5,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  public void testMixedBounds() throws Exception {\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (!realCluster) {\n      log.info(\"This test doesn't work with a simulated cluster\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"df724d84dab24a0cc54bec95a8680867adc7f171","date":1576156608,"type":5,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest#testMixedBounds().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMixedBounds().mjava","sourceNew":"  @Test\n  public void testMixedBounds() throws Exception {\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMixedBounds() throws Exception {\n    if (!realCluster) {\n      log.info(\"This test doesn't work with a simulated cluster\");\n      return;\n    }\n\n    String collectionName = \"testMixedBounds_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(2, 2, false, true));\n\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 100; i++) {\n        SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n        doc.addField(\"foo\", TestUtil.randomSimpleString(random(), 130, 130));\n        ureq.add(doc);\n      }\n      solrClient.request(ureq);\n    }\n    solrClient.commit(collectionName);\n\n    // check the actual size of shard to set the threshold\n    QueryResponse rsp = solrClient.query(params(CommonParams.QT, \"/admin/metrics\", \"group\", \"core\"));\n    NamedList<Object> nl = rsp.getResponse();\n    nl = (NamedList<Object>)nl.get(\"metrics\");\n    int maxSize = 0;\n    for (Iterator<Map.Entry<String, Object>> it = nl.iterator(); it.hasNext(); ) {\n      Map.Entry<String, Object> e = it.next();\n      NamedList<Object> metrics = (NamedList<Object>)e.getValue();\n      Object o = metrics.get(\"INDEX.sizeInBytes\");\n      assertNotNull(\"INDEX.sizeInBytes missing: \" + metrics, o);\n      assertTrue(\"not a number\", o instanceof Number);\n      if (maxSize < ((Number)o).intValue()) {\n        maxSize = ((Number)o).intValue();\n      }\n    }\n    assertTrue(\"maxSize should be non-zero\", maxSize > 0);\n\n    int aboveBytes = maxSize * 2 / 3;\n\n    // need to wait for recovery after splitting\n    long waitForSeconds = 10 + random().nextInt(5);\n\n    // the trigger is initially disabled so that we have time to add listeners\n    // and have them capture all events once the trigger is enabled\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger4',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        // don't hit this limit when indexing\n        \"'aboveDocs' : 10000,\" +\n        // hit this limit when deleting\n        \"'belowDocs' : 100,\" +\n        // hit this limit when indexing\n        \"'aboveBytes' : \" + aboveBytes + \",\" +\n        // don't hit this limit when deleting\n        \"'belowBytes' : 10,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing4',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger4',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // now enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    log.info(\"-- resuming trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    // suspend the trigger to avoid generating more events\n    String suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // collection should have 2 inactive and 4 active shards\n    CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudUtil.clusterShape(6, 2, true, true));\n\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertEquals(\"number of ops\", 2, ops.size());\n    boolean shard1 = false;\n    boolean shard2 = false;\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.SPLITSHARD, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 1, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n      if (p.second().equals(\"shard1\")) {\n        shard1 = true;\n      } else if (p.second().equals(\"shard2\")) {\n        shard2 = true;\n      } else {\n        fail(\"unexpected shard name \" + p.second());\n      }\n    }\n    assertTrue(\"shard1 should be split\", shard1);\n    assertTrue(\"shard2 should be split\", shard2);\n\n    // now delete most of docs to trigger belowDocs condition\n    listenerEvents.clear();\n    finished = new CountDownLatch(1);\n\n    // suspend the trigger first so that we can safely delete all docs\n    suspendTriggerCommand = \"{\" +\n        \"'suspend-trigger' : {\" +\n        \"'name' : 'index_size_trigger4'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    log.info(\"-- deleting documents\");\n    for (int j = 0; j < 10; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.deleteById(\"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n    cloudManager.getTimeSource().sleep(5000);\n    // make sure the actual index size is reduced by deletions, otherwise we may still violate aboveBytes\n    UpdateRequest ur = new UpdateRequest();\n    ur.setParam(UpdateParams.COMMIT, \"true\");\n    ur.setParam(UpdateParams.EXPUNGE_DELETES, \"true\");\n    ur.setParam(UpdateParams.OPTIMIZE, \"true\");\n    ur.setParam(UpdateParams.MAX_OPTIMIZE_SEGMENTS, \"1\");\n    ur.setParam(UpdateParams.WAIT_SEARCHER, \"true\");\n    ur.setParam(UpdateParams.OPEN_SEARCHER, \"true\");\n    log.info(\"-- requesting optimize / expungeDeletes / commit\");\n    solrClient.request(ur, collectionName);\n\n    // wait for the segments to merge to reduce the index size\n    cloudManager.getTimeSource().sleep(50000);\n\n    // add some docs so that every shard gets an update\n    // we can reduce the number of docs here but this also works\n    for (int j = 0; j < 1; j++) {\n      UpdateRequest ureq = new UpdateRequest();\n      ureq.setParam(\"collection\", collectionName);\n      for (int i = 0; i < 98; i++) {\n        ureq.add(\"id\", \"id-\" + (i * 100) + \"-\" + j);\n      }\n      solrClient.request(ureq);\n    }\n\n    log.info(\"-- requesting commit\");\n    solrClient.commit(collectionName, true, true);\n\n    // resume the trigger\n    log.info(\"-- resuming trigger\");\n    // resume trigger\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    log.info(\"-- suspending trigger\");\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, suspendTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    assertEquals(1, listenerEvents.size());\n    events = listenerEvents.get(\"capturing4\");\n    assertNotNull(\"'capturing4' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n\n    // check ops\n    ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e4aa99957dcb54cefbbec762eb896b084deac1b9":["7dc86fee106bfbba46a22faf82a93b3af3f08006"],"7cac1f2920f8057198f04505797cbabf74dd9a97":["89948af0461fead48f44ba8fb7866f107ce83f22"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["976feb6756f29529c6ce5b578e7d6fa8b1efcb30"],"023604b80bedb02c79b94b0e4ae06c6ddff1937c":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1"],"7dc86fee106bfbba46a22faf82a93b3af3f08006":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"a97a72dc16d01fda8ca5c9e0264b3604e30ab539":["2d80c1ad9241ae005a167d7ee8ac473601b0e57c"],"a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4":["a97a72dc16d01fda8ca5c9e0264b3604e30ab539"],"042b92cf48996255bedb0c3c4bf772d7e06e4dea":["f607a0a2e930f55385c7a24afb68ef661ef7e3ee"],"df724d84dab24a0cc54bec95a8680867adc7f171":["a97a72dc16d01fda8ca5c9e0264b3604e30ab539","a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4"],"6b55cd711a129fb7fc4c3c4672d652149c9a4faa":["e4aa99957dcb54cefbbec762eb896b084deac1b9"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["e4aa99957dcb54cefbbec762eb896b084deac1b9","f607a0a2e930f55385c7a24afb68ef661ef7e3ee"],"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2d80c1ad9241ae005a167d7ee8ac473601b0e57c":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["7cac1f2920f8057198f04505797cbabf74dd9a97"],"f607a0a2e930f55385c7a24afb68ef661ef7e3ee":["6b55cd711a129fb7fc4c3c4672d652149c9a4faa"],"976feb6756f29529c6ce5b578e7d6fa8b1efcb30":["023604b80bedb02c79b94b0e4ae06c6ddff1937c"],"89948af0461fead48f44ba8fb7866f107ce83f22":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["e4aa99957dcb54cefbbec762eb896b084deac1b9","f607a0a2e930f55385c7a24afb68ef661ef7e3ee"]},"commit2Childs":{"e4aa99957dcb54cefbbec762eb896b084deac1b9":["6b55cd711a129fb7fc4c3c4672d652149c9a4faa","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"7cac1f2920f8057198f04505797cbabf74dd9a97":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["89948af0461fead48f44ba8fb7866f107ce83f22"],"023604b80bedb02c79b94b0e4ae06c6ddff1937c":["976feb6756f29529c6ce5b578e7d6fa8b1efcb30"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["7dc86fee106bfbba46a22faf82a93b3af3f08006"],"7dc86fee106bfbba46a22faf82a93b3af3f08006":["e4aa99957dcb54cefbbec762eb896b084deac1b9"],"a97a72dc16d01fda8ca5c9e0264b3604e30ab539":["a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4","df724d84dab24a0cc54bec95a8680867adc7f171"],"042b92cf48996255bedb0c3c4bf772d7e06e4dea":["023604b80bedb02c79b94b0e4ae06c6ddff1937c"],"a250c410a74277b5acb7ef5d8b5cb3e60fbd71a4":["df724d84dab24a0cc54bec95a8680867adc7f171","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"df724d84dab24a0cc54bec95a8680867adc7f171":[],"6b55cd711a129fb7fc4c3c4672d652149c9a4faa":["f607a0a2e930f55385c7a24afb68ef661ef7e3ee"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["43345f1452f9510f8aaadae6156fe0c834e7d957","ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1"],"2d80c1ad9241ae005a167d7ee8ac473601b0e57c":["a97a72dc16d01fda8ca5c9e0264b3604e30ab539"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["2d80c1ad9241ae005a167d7ee8ac473601b0e57c"],"f607a0a2e930f55385c7a24afb68ef661ef7e3ee":["042b92cf48996255bedb0c3c4bf772d7e06e4dea","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"976feb6756f29529c6ce5b578e7d6fa8b1efcb30":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"89948af0461fead48f44ba8fb7866f107ce83f22":["7cac1f2920f8057198f04505797cbabf74dd9a97"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["df724d84dab24a0cc54bec95a8680867adc7f171","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}