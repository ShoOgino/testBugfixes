{"path":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.fillBytesRef();\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.fillBytesRef();\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30fe9fa09df804ce770f1b667401a7a7647301ed","date":1397554534,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      bytesAtt.fillBytesRef();\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      final int hash = bytesAtt.fillBytesRef();\n      assertEquals(\"Hash incorrect\", bytes.hashCode(), hash);\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"63241596de245e96a0a3c36c7b03eb92130b81db","date":1398708795,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      bytesAtt.fillBytesRef();\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      bytesAtt.fillBytesRef();\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3394716f52b34ab259ad5247e7595d9f9db6e935","date":1398791921,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      bytesAtt.fillBytesRef();\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      bytesAtt.fillBytesRef();\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      bytesAtt.fillBytesRef();\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    // use getAttribute to test if attributes really exist, if not an IAE will be throwed\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      bytesAtt.fillBytesRef();\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5824040d7a4884dc1ce62a8c60d0c34571701d35","date":1420895330,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      bytesAtt.fillBytesRef();\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      bytesAtt.fillBytesRef();\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"804b857d1066ab5185b3b9101bde41b0b71426ec","date":1435846169,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    final BytesRef bytes = bytesAtt.getBytesRef();\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      bytesAtt.fillBytesRef();\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytes));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"770342641f7b505eaa8dccdc666158bff2419109","date":1449868421,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final LegacyNumericTokenStream.LegacyNumericTermAttribute numericAtt = stream.getAttribute(LegacyNumericTokenStream.LegacyNumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+= LegacyNumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), LegacyNumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? LegacyNumericTokenStream.TOKEN_TYPE_FULL_PREC : LegacyNumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final NumericTokenStream.NumericTermAttribute numericAtt = stream.getAttribute(NumericTokenStream.NumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), NumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? NumericTokenStream.TOKEN_TYPE_FULL_PREC : NumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5af5ba0166322092193d4c29880b0f7670fc7ca0","date":1471440525,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/legacy/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final LegacyNumericTokenStream.LegacyNumericTermAttribute numericAtt = stream.getAttribute(LegacyNumericTokenStream.LegacyNumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+= LegacyNumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), LegacyNumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? LegacyNumericTokenStream.TOKEN_TYPE_FULL_PREC : LegacyNumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final LegacyNumericTokenStream.LegacyNumericTermAttribute numericAtt = stream.getAttribute(LegacyNumericTokenStream.LegacyNumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+= LegacyNumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), LegacyNumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? LegacyNumericTokenStream.TOKEN_TYPE_FULL_PREC : LegacyNumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","date":1471496851,"type":5,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/legacy/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final LegacyNumericTokenStream.LegacyNumericTermAttribute numericAtt = stream.getAttribute(LegacyNumericTokenStream.LegacyNumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+= LegacyNumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), LegacyNumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? LegacyNumericTokenStream.TOKEN_TYPE_FULL_PREC : LegacyNumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final LegacyNumericTokenStream.LegacyNumericTermAttribute numericAtt = stream.getAttribute(LegacyNumericTokenStream.LegacyNumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+= LegacyNumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), LegacyNumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? LegacyNumericTokenStream.TOKEN_TYPE_FULL_PREC : LegacyNumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/legacy/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final LegacyNumericTokenStream.LegacyNumericTermAttribute numericAtt = stream.getAttribute(LegacyNumericTokenStream.LegacyNumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+= LegacyNumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), LegacyNumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? LegacyNumericTokenStream.TOKEN_TYPE_FULL_PREC : LegacyNumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final LegacyNumericTokenStream.LegacyNumericTermAttribute numericAtt = stream.getAttribute(LegacyNumericTokenStream.LegacyNumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+= LegacyNumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), LegacyNumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? LegacyNumericTokenStream.TOKEN_TYPE_FULL_PREC : LegacyNumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":5,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/legacy/TestNumericTokenStream#testLongStream().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestNumericTokenStream#testLongStream().mjava","sourceNew":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final LegacyNumericTokenStream.LegacyNumericTermAttribute numericAtt = stream.getAttribute(LegacyNumericTokenStream.LegacyNumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+= LegacyNumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), LegacyNumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? LegacyNumericTokenStream.TOKEN_TYPE_FULL_PREC : LegacyNumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","sourceOld":"  public void testLongStream() throws Exception {\n    @SuppressWarnings(\"resource\")\n    final LegacyNumericTokenStream stream=new LegacyNumericTokenStream().setLongValue(lvalue);\n    final TermToBytesRefAttribute bytesAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n    assertNotNull(bytesAtt);\n    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);\n    assertNotNull(typeAtt);\n    final LegacyNumericTokenStream.LegacyNumericTermAttribute numericAtt = stream.getAttribute(LegacyNumericTokenStream.LegacyNumericTermAttribute.class);\n    assertNotNull(numericAtt);\n    stream.reset();\n    assertEquals(64, numericAtt.getValueSize());\n    for (int shift=0; shift<64; shift+= LegacyNumericUtils.PRECISION_STEP_DEFAULT) {\n      assertTrue(\"New token is available\", stream.incrementToken());\n      assertEquals(\"Shift value wrong\", shift, numericAtt.getShift());\n      assertEquals(\"Term is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), LegacyNumericUtils.prefixCodedToLong(bytesAtt.getBytesRef()));\n      assertEquals(\"Term raw value is incorrectly encoded\", lvalue & ~((1L << shift) - 1L), numericAtt.getRawValue());\n      assertEquals(\"Type incorrect\", (shift == 0) ? LegacyNumericTokenStream.TOKEN_TYPE_FULL_PREC : LegacyNumericTokenStream.TOKEN_TYPE_LOWER_PREC, typeAtt.type());\n    }\n    assertFalse(\"More tokens available\", stream.incrementToken());\n    stream.end();\n    stream.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["5824040d7a4884dc1ce62a8c60d0c34571701d35"],"30fe9fa09df804ce770f1b667401a7a7647301ed":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["770342641f7b505eaa8dccdc666158bff2419109","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["30fe9fa09df804ce770f1b667401a7a7647301ed","3394716f52b34ab259ad5247e7595d9f9db6e935"],"5824040d7a4884dc1ce62a8c60d0c34571701d35":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5af5ba0166322092193d4c29880b0f7670fc7ca0":["770342641f7b505eaa8dccdc666158bff2419109"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["770342641f7b505eaa8dccdc666158bff2419109","5af5ba0166322092193d4c29880b0f7670fc7ca0"],"770342641f7b505eaa8dccdc666158bff2419109":["804b857d1066ab5185b3b9101bde41b0b71426ec"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["770342641f7b505eaa8dccdc666158bff2419109","403d05f7f8d69b65659157eff1bc1d2717f04c66"],"3394716f52b34ab259ad5247e7595d9f9db6e935":["30fe9fa09df804ce770f1b667401a7a7647301ed","63241596de245e96a0a3c36c7b03eb92130b81db"],"63241596de245e96a0a3c36c7b03eb92130b81db":["30fe9fa09df804ce770f1b667401a7a7647301ed"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["403d05f7f8d69b65659157eff1bc1d2717f04c66"]},"commit2Childs":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["770342641f7b505eaa8dccdc666158bff2419109"],"30fe9fa09df804ce770f1b667401a7a7647301ed":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","3394716f52b34ab259ad5247e7595d9f9db6e935","63241596de245e96a0a3c36c7b03eb92130b81db"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"5824040d7a4884dc1ce62a8c60d0c34571701d35":["804b857d1066ab5185b3b9101bde41b0b71426ec"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["30fe9fa09df804ce770f1b667401a7a7647301ed"],"5af5ba0166322092193d4c29880b0f7670fc7ca0":["2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"770342641f7b505eaa8dccdc666158bff2419109":["403d05f7f8d69b65659157eff1bc1d2717f04c66","5af5ba0166322092193d4c29880b0f7670fc7ca0","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"3394716f52b34ab259ad5247e7595d9f9db6e935":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","5824040d7a4884dc1ce62a8c60d0c34571701d35"],"63241596de245e96a0a3c36c7b03eb92130b81db":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}