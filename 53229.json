{"path":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelPriorityStream().mjava","commits":[{"id":"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf","date":1522951207,"type":1,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelPriorityStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelPriorityStream().mjava","sourceNew":"  @Test\n  public void testParallelPriorityStream() throws Exception {\n    Assume.assumeTrue(!useAlias);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello1\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello1\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello1\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello1\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"topic\", TopicStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"priority\", PriorityStream.class);\n\n    StreamExpression expression;\n    TupleStream stream;\n    List<Tuple> tuples;\n\n    SolrClientCache cache = new SolrClientCache();\n\n    try {\n      FieldComparator comp = new FieldComparator(\"a_i\", ComparatorOrder.ASCENDING);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      StreamContext context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      Collections.sort(tuples, comp);\n      //The tuples from the first topic (high priority) should be returned.\n\n      assertEquals(tuples.size(), 4);\n      assertOrder(tuples, 5, 6, 7, 8);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n      Collections.sort(tuples, comp);\n\n      //The Tuples from the second topic (Low priority) should be returned.\n      assertEquals(tuples.size(), 6);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 9);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      //Both queus are empty.\n      assertEquals(tuples.size(), 0);\n\n    } finally {\n      cache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelPriorityStream() throws Exception {\n    Assume.assumeTrue(!useAlias);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello1\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello1\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello1\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello1\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"topic\", TopicStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"priority\", PriorityStream.class);\n\n    StreamExpression expression;\n    TupleStream stream;\n    List<Tuple> tuples;\n\n    SolrClientCache cache = new SolrClientCache();\n\n    try {\n      FieldComparator comp = new FieldComparator(\"a_i\", ComparatorOrder.ASCENDING);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      StreamContext context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      Collections.sort(tuples, comp);\n      //The tuples from the first topic (high priority) should be returned.\n\n      assertEquals(tuples.size(), 4);\n      assertOrder(tuples, 5, 6, 7, 8);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n      Collections.sort(tuples, comp);\n\n      //The Tuples from the second topic (Low priority) should be returned.\n      assertEquals(tuples.size(), 6);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 9);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      //Both queus are empty.\n      assertEquals(tuples.size(), 0);\n\n    } finally {\n      cache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108","date":1533256859,"type":3,"author":"Erick","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelPriorityStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelPriorityStream().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelPriorityStream() throws Exception {\n    Assume.assumeTrue(!useAlias);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello1\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello1\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello1\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello1\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"topic\", TopicStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"priority\", PriorityStream.class);\n\n    StreamExpression expression;\n    TupleStream stream;\n    List<Tuple> tuples;\n\n    SolrClientCache cache = new SolrClientCache();\n\n    try {\n      FieldComparator comp = new FieldComparator(\"a_i\", ComparatorOrder.ASCENDING);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      StreamContext context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      Collections.sort(tuples, comp);\n      //The tuples from the first topic (high priority) should be returned.\n\n      assertEquals(tuples.size(), 4);\n      assertOrder(tuples, 5, 6, 7, 8);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n      Collections.sort(tuples, comp);\n\n      //The Tuples from the second topic (Low priority) should be returned.\n      assertEquals(tuples.size(), 6);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 9);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      //Both queus are empty.\n      assertEquals(tuples.size(), 0);\n\n    } finally {\n      cache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelPriorityStream() throws Exception {\n    Assume.assumeTrue(!useAlias);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello1\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello1\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello1\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello1\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"topic\", TopicStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"priority\", PriorityStream.class);\n\n    StreamExpression expression;\n    TupleStream stream;\n    List<Tuple> tuples;\n\n    SolrClientCache cache = new SolrClientCache();\n\n    try {\n      FieldComparator comp = new FieldComparator(\"a_i\", ComparatorOrder.ASCENDING);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      StreamContext context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      Collections.sort(tuples, comp);\n      //The tuples from the first topic (high priority) should be returned.\n\n      assertEquals(tuples.size(), 4);\n      assertOrder(tuples, 5, 6, 7, 8);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n      Collections.sort(tuples, comp);\n\n      //The Tuples from the second topic (Low priority) should be returned.\n      assertEquals(tuples.size(), 6);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 9);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      //Both queus are empty.\n      assertEquals(tuples.size(), 0);\n\n    } finally {\n      cache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d35c84fdef07284c122012ca4000d3b7285a66e","date":1545962630,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelPriorityStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelPriorityStream().mjava","sourceNew":"  @Test\n  // commented out on: 24-Dec-2018   @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelPriorityStream() throws Exception {\n    Assume.assumeTrue(!useAlias);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello1\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello1\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello1\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello1\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"topic\", TopicStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"priority\", PriorityStream.class);\n\n    StreamExpression expression;\n    TupleStream stream;\n    List<Tuple> tuples;\n\n    SolrClientCache cache = new SolrClientCache();\n\n    try {\n      FieldComparator comp = new FieldComparator(\"a_i\", ComparatorOrder.ASCENDING);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      StreamContext context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      Collections.sort(tuples, comp);\n      //The tuples from the first topic (high priority) should be returned.\n\n      assertEquals(tuples.size(), 4);\n      assertOrder(tuples, 5, 6, 7, 8);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n      Collections.sort(tuples, comp);\n\n      //The Tuples from the second topic (Low priority) should be returned.\n      assertEquals(tuples.size(), 6);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 9);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      //Both queus are empty.\n      assertEquals(tuples.size(), 0);\n\n    } finally {\n      cache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelPriorityStream() throws Exception {\n    Assume.assumeTrue(!useAlias);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello1\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello1\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello1\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello1\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"topic\", TopicStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"priority\", PriorityStream.class);\n\n    StreamExpression expression;\n    TupleStream stream;\n    List<Tuple> tuples;\n\n    SolrClientCache cache = new SolrClientCache();\n\n    try {\n      FieldComparator comp = new FieldComparator(\"a_i\", ComparatorOrder.ASCENDING);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      StreamContext context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      Collections.sort(tuples, comp);\n      //The tuples from the first topic (high priority) should be returned.\n\n      assertEquals(tuples.size(), 4);\n      assertOrder(tuples, 5, 6, 7, 8);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n      Collections.sort(tuples, comp);\n\n      //The Tuples from the second topic (Low priority) should be returned.\n      assertEquals(tuples.size(), 6);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 9);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      //Both queus are empty.\n      assertEquals(tuples.size(), 0);\n\n    } finally {\n      cache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a1cae9aea470e88146567017129e8280d21ca76","date":1563504024,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelPriorityStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelPriorityStream().mjava","sourceNew":"  @Test\n  public void testParallelPriorityStream() throws Exception {\n    Assume.assumeTrue(!useAlias);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello1\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello1\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello1\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello1\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"topic\", TopicStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"priority\", PriorityStream.class);\n\n    StreamExpression expression;\n    TupleStream stream;\n    List<Tuple> tuples;\n\n    SolrClientCache cache = new SolrClientCache();\n\n    try {\n      FieldComparator comp = new FieldComparator(\"a_i\", ComparatorOrder.ASCENDING);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      StreamContext context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      Collections.sort(tuples, comp);\n      //The tuples from the first topic (high priority) should be returned.\n\n      assertEquals(tuples.size(), 4);\n      assertOrder(tuples, 5, 6, 7, 8);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n      Collections.sort(tuples, comp);\n\n      //The Tuples from the second topic (Low priority) should be returned.\n      assertEquals(tuples.size(), 6);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 9);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      //Both queus are empty.\n      assertEquals(tuples.size(), 0);\n\n    } finally {\n      cache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  // commented out on: 24-Dec-2018   @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 2-Aug-2018\n  public void testParallelPriorityStream() throws Exception {\n    Assume.assumeTrue(!useAlias);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello1\", \"a_i\", \"0\", \"a_f\", \"1\")\n        .add(id, \"2\", \"a_s\", \"hello1\", \"a_i\", \"2\", \"a_f\", \"2\")\n        .add(id, \"3\", \"a_s\", \"hello1\", \"a_i\", \"3\", \"a_f\", \"3\")\n        .add(id, \"4\", \"a_s\", \"hello1\", \"a_i\", \"4\", \"a_f\", \"4\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"5\")\n        .add(id, \"5\", \"a_s\", \"hello\", \"a_i\", \"10\", \"a_f\", \"6\")\n        .add(id, \"6\", \"a_s\", \"hello\", \"a_i\", \"11\", \"a_f\", \"7\")\n        .add(id, \"7\", \"a_s\", \"hello\", \"a_i\", \"12\", \"a_f\", \"8\")\n        .add(id, \"8\", \"a_s\", \"hello\", \"a_i\", \"13\", \"a_f\", \"9\")\n        .add(id, \"9\", \"a_s\", \"hello1\", \"a_i\", \"14\", \"a_f\", \"10\")\n        .commit(cluster.getSolrClient(), COLLECTIONORALIAS);\n\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"topic\", TopicStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"priority\", PriorityStream.class);\n\n    StreamExpression expression;\n    TupleStream stream;\n    List<Tuple> tuples;\n\n    SolrClientCache cache = new SolrClientCache();\n\n    try {\n      FieldComparator comp = new FieldComparator(\"a_i\", ComparatorOrder.ASCENDING);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      StreamContext context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      Collections.sort(tuples, comp);\n      //The tuples from the first topic (high priority) should be returned.\n\n      assertEquals(tuples.size(), 4);\n      assertOrder(tuples, 5, 6, 7, 8);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n      Collections.sort(tuples, comp);\n\n      //The Tuples from the second topic (Low priority) should be returned.\n      assertEquals(tuples.size(), 6);\n      assertOrder(tuples, 0, 1, 2, 3, 4, 9);\n\n      expression = StreamExpressionParser.parse(\"parallel(collection1, workers=2, sort=\\\"_version_ asc\\\", priority(topic(collection1, collection1, q=\\\"a_s:hello\\\", fl=\\\"id,a_i\\\", id=1000000, initialCheckpoint=0, partitionKeys=id),\" +\n          \"topic(collection1, collection1, q=\\\"a_s:hello1\\\", fl=\\\"id,a_i\\\", id=2000000, initialCheckpoint=0, partitionKeys=id)))\");\n      stream = factory.constructStream(expression);\n      context = new StreamContext();\n      context.setSolrClientCache(cache);\n      stream.setStreamContext(context);\n      tuples = getTuples(stream);\n\n      //Both queus are empty.\n      assertEquals(tuples.size(), 0);\n\n    } finally {\n      cache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8a1cae9aea470e88146567017129e8280d21ca76":["8d35c84fdef07284c122012ca4000d3b7285a66e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8a1cae9aea470e88146567017129e8280d21ca76"],"8d35c84fdef07284c122012ca4000d3b7285a66e":["05a3c9b5f1dfb39879069eb1dac3ca104d3e4108"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108":["8d35c84fdef07284c122012ca4000d3b7285a66e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"8a1cae9aea470e88146567017129e8280d21ca76":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["05a3c9b5f1dfb39879069eb1dac3ca104d3e4108"],"8d35c84fdef07284c122012ca4000d3b7285a66e":["8a1cae9aea470e88146567017129e8280d21ca76"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}