{"path":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#getTokenArray(TokenStream).mjava","commits":[{"id":"134a24d0cb66520908d88384f1a559875704ed25","date":1445326601,"type":0,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#getTokenArray(TokenStream).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Returns a token array from the {@link org.apache.lucene.analysis.TokenStream} in input\n   *\n   * @param tokenizedText the tokenized content of a field\n   * @return a {@code String} array of the resulting tokens\n   * @throws java.io.IOException If tokenization fails because there is a low-level I/O error\n   */\n  protected String[] getTokenArray(TokenStream tokenizedText) throws IOException {\n    Collection<String> tokens = new LinkedList<>();\n    CharTermAttribute charTermAttribute = tokenizedText.addAttribute(CharTermAttribute.class);\n    tokenizedText.reset();\n    while (tokenizedText.incrementToken()) {\n      tokens.add(charTermAttribute.toString());\n    }\n    tokenizedText.end();\n    tokenizedText.close();\n    return tokens.toArray(new String[tokens.size()]);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33bfee30277584028170135002def66f9d57732b","date":1547842233,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#getTokenArray(TokenStream).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#getTokenArray(TokenStream).mjava","sourceNew":"  /**\n   * Returns a token array from the {@link org.apache.lucene.analysis.TokenStream} in input\n   *\n   * @param tokenizedText the tokenized content of a field\n   * @return a {@code String} array of the resulting tokens\n   * @throws java.io.IOException If tokenization fails because there is a low-level I/O error\n   */\n  protected String[] getTokenArray(TokenStream tokenizedText) throws IOException {\n    Collection<String> tokens = new LinkedList<>();\n    CharTermAttribute charTermAttribute = tokenizedText.addAttribute(CharTermAttribute.class);\n    tokenizedText.reset();\n    while (tokenizedText.incrementToken()) {\n      tokens.add(charTermAttribute.toString());\n    }\n    tokenizedText.end();\n    tokenizedText.close();\n    return tokens.toArray(new String[0]);\n  }\n\n","sourceOld":"  /**\n   * Returns a token array from the {@link org.apache.lucene.analysis.TokenStream} in input\n   *\n   * @param tokenizedText the tokenized content of a field\n   * @return a {@code String} array of the resulting tokens\n   * @throws java.io.IOException If tokenization fails because there is a low-level I/O error\n   */\n  protected String[] getTokenArray(TokenStream tokenizedText) throws IOException {\n    Collection<String> tokens = new LinkedList<>();\n    CharTermAttribute charTermAttribute = tokenizedText.addAttribute(CharTermAttribute.class);\n    tokenizedText.reset();\n    while (tokenizedText.incrementToken()) {\n      tokens.add(charTermAttribute.toString());\n    }\n    tokenizedText.end();\n    tokenizedText.close();\n    return tokens.toArray(new String[tokens.size()]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d","date":1548322018,"type":3,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#getTokenArray(TokenStream).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/document/SimpleNaiveBayesDocumentClassifier#getTokenArray(TokenStream).mjava","sourceNew":"  /**\n   * Returns a token array from the {@link org.apache.lucene.analysis.TokenStream} in input\n   *\n   * @param tokenizedText the tokenized content of a field\n   * @return a {@code String} array of the resulting tokens\n   * @throws java.io.IOException If tokenization fails because there is a low-level I/O error\n   */\n  protected String[] getTokenArray(TokenStream tokenizedText) throws IOException {\n    Collection<String> tokens = new LinkedList<>();\n    CharTermAttribute charTermAttribute = tokenizedText.addAttribute(CharTermAttribute.class);\n    tokenizedText.reset();\n    while (tokenizedText.incrementToken()) {\n      tokens.add(charTermAttribute.toString());\n    }\n    tokenizedText.end();\n    tokenizedText.close();\n    return tokens.toArray(new String[0]);\n  }\n\n","sourceOld":"  /**\n   * Returns a token array from the {@link org.apache.lucene.analysis.TokenStream} in input\n   *\n   * @param tokenizedText the tokenized content of a field\n   * @return a {@code String} array of the resulting tokens\n   * @throws java.io.IOException If tokenization fails because there is a low-level I/O error\n   */\n  protected String[] getTokenArray(TokenStream tokenizedText) throws IOException {\n    Collection<String> tokens = new LinkedList<>();\n    CharTermAttribute charTermAttribute = tokenizedText.addAttribute(CharTermAttribute.class);\n    tokenizedText.reset();\n    while (tokenizedText.incrementToken()) {\n      tokens.add(charTermAttribute.toString());\n    }\n    tokenizedText.end();\n    tokenizedText.close();\n    return tokens.toArray(new String[tokens.size()]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d":["134a24d0cb66520908d88384f1a559875704ed25","33bfee30277584028170135002def66f9d57732b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"134a24d0cb66520908d88384f1a559875704ed25":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"33bfee30277584028170135002def66f9d57732b":["134a24d0cb66520908d88384f1a559875704ed25"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d"]},"commit2Childs":{"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["134a24d0cb66520908d88384f1a559875704ed25"],"134a24d0cb66520908d88384f1a559875704ed25":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d","33bfee30277584028170135002def66f9d57732b"],"33bfee30277584028170135002def66f9d57732b":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}