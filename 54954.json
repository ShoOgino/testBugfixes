{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#analyze(Analyzer,String,CharsRef).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#analyze(Analyzer,String,CharsRef).mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#analyze(Analyzer,String,CharsRef).mjava","sourceNew":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public static CharsRef analyze(Analyzer analyzer, String text, CharsRef reuse) throws IOException {\n      TokenStream ts = analyzer.tokenStream(\"\", new StringReader(text));\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n      ts.reset();\n      reuse.length = 0;\n      while (ts.incrementToken()) {\n        int length = termAtt.length();\n        if (length == 0) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n        }\n        if (posIncAtt.getPositionIncrement() != 1) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n        }\n        reuse.grow(reuse.length + length + 1); /* current + word + separator */\n        int end = reuse.offset + reuse.length;\n        if (reuse.length > 0) {\n          reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n          reuse.length++;\n        }\n        System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n        reuse.length += length;\n      }\n      ts.end();\n      ts.close();\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","sourceOld":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public static CharsRef analyze(Analyzer analyzer, String text, CharsRef reuse) throws IOException {\n      TokenStream ts = analyzer.tokenStream(\"\", new StringReader(text));\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n      ts.reset();\n      reuse.length = 0;\n      while (ts.incrementToken()) {\n        int length = termAtt.length();\n        if (length == 0) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n        }\n        if (posIncAtt.getPositionIncrement() != 1) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n        }\n        reuse.grow(reuse.length + length + 1); /* current + word + separator */\n        int end = reuse.offset + reuse.length;\n        if (reuse.length > 0) {\n          reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n          reuse.length++;\n        }\n        System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n        reuse.length += length;\n      }\n      ts.end();\n      ts.close();\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#analyze(Analyzer,String,CharsRef).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#analyze(Analyzer,String,CharsRef).mjava","sourceNew":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public static CharsRef analyze(Analyzer analyzer, String text, CharsRef reuse) throws IOException {\n      TokenStream ts = analyzer.tokenStream(\"\", text);\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n      ts.reset();\n      reuse.length = 0;\n      while (ts.incrementToken()) {\n        int length = termAtt.length();\n        if (length == 0) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n        }\n        if (posIncAtt.getPositionIncrement() != 1) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n        }\n        reuse.grow(reuse.length + length + 1); /* current + word + separator */\n        int end = reuse.offset + reuse.length;\n        if (reuse.length > 0) {\n          reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n          reuse.length++;\n        }\n        System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n        reuse.length += length;\n      }\n      ts.end();\n      ts.close();\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","sourceOld":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public static CharsRef analyze(Analyzer analyzer, String text, CharsRef reuse) throws IOException {\n      TokenStream ts = analyzer.tokenStream(\"\", new StringReader(text));\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n      ts.reset();\n      reuse.length = 0;\n      while (ts.incrementToken()) {\n        int length = termAtt.length();\n        if (length == 0) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n        }\n        if (posIncAtt.getPositionIncrement() != 1) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n        }\n        reuse.grow(reuse.length + length + 1); /* current + word + separator */\n        int end = reuse.offset + reuse.length;\n        if (reuse.length > 0) {\n          reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n          reuse.length++;\n        }\n        System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n        reuse.length += length;\n      }\n      ts.end();\n      ts.close();\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","bugFix":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#analyze(Analyzer,String,CharsRef).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#analyze(Analyzer,String,CharsRef).mjava","sourceNew":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public static CharsRef analyze(Analyzer analyzer, String text, CharsRef reuse) throws IOException {\n      TokenStream ts = analyzer.tokenStream(\"\", text);\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n      ts.reset();\n      reuse.length = 0;\n      while (ts.incrementToken()) {\n        int length = termAtt.length();\n        if (length == 0) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n        }\n        if (posIncAtt.getPositionIncrement() != 1) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n        }\n        reuse.grow(reuse.length + length + 1); /* current + word + separator */\n        int end = reuse.offset + reuse.length;\n        if (reuse.length > 0) {\n          reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n          reuse.length++;\n        }\n        System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n        reuse.length += length;\n      }\n      ts.end();\n      ts.close();\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","sourceOld":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public static CharsRef analyze(Analyzer analyzer, String text, CharsRef reuse) throws IOException {\n      TokenStream ts = analyzer.tokenStream(\"\", new StringReader(text));\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n      ts.reset();\n      reuse.length = 0;\n      while (ts.incrementToken()) {\n        int length = termAtt.length();\n        if (length == 0) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n        }\n        if (posIncAtt.getPositionIncrement() != 1) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n        }\n        reuse.grow(reuse.length + length + 1); /* current + word + separator */\n        int end = reuse.offset + reuse.length;\n        if (reuse.length > 0) {\n          reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n          reuse.length++;\n        }\n        System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n        reuse.length += length;\n      }\n      ts.end();\n      ts.close();\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85f3a2d749715373feb8529516e92d3538103525","date":1379624134,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Parser#analyze(String,CharsRef).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#analyze(Analyzer,String,CharsRef).mjava","sourceNew":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public CharsRef analyze(String text, CharsRef reuse) throws IOException {\n      TokenStream ts = analyzer.tokenStream(\"\", text);\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n      ts.reset();\n      reuse.length = 0;\n      while (ts.incrementToken()) {\n        int length = termAtt.length();\n        if (length == 0) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n        }\n        if (posIncAtt.getPositionIncrement() != 1) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n        }\n        reuse.grow(reuse.length + length + 1); /* current + word + separator */\n        int end = reuse.offset + reuse.length;\n        if (reuse.length > 0) {\n          reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n          reuse.length++;\n        }\n        System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n        reuse.length += length;\n      }\n      ts.end();\n      ts.close();\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","sourceOld":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public static CharsRef analyze(Analyzer analyzer, String text, CharsRef reuse) throws IOException {\n      TokenStream ts = analyzer.tokenStream(\"\", text);\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n      ts.reset();\n      reuse.length = 0;\n      while (ts.incrementToken()) {\n        int length = termAtt.length();\n        if (length == 0) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n        }\n        if (posIncAtt.getPositionIncrement() != 1) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n        }\n        reuse.grow(reuse.length + length + 1); /* current + word + separator */\n        int end = reuse.offset + reuse.length;\n        if (reuse.length > 0) {\n          reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n          reuse.length++;\n        }\n        System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n        reuse.length += length;\n      }\n      ts.end();\n      ts.close();\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["b89678825b68eccaf09e6ab71675fc0b0af1e099","c83d6c4335f31cae14f625a222bc842f20073dcd"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"85f3a2d749715373feb8529516e92d3538103525":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["85f3a2d749715373feb8529516e92d3538103525"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"c83d6c4335f31cae14f625a222bc842f20073dcd":["37a0f60745e53927c4c876cfe5b5a58170f0646c","85f3a2d749715373feb8529516e92d3538103525"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"85f3a2d749715373feb8529516e92d3538103525":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}