{"path":"modules/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeRangePart(String,String).mjava","commits":[{"id":"91a3609ac9a09ca0c8eee1b765401bbdacaceaf8","date":1310355420,"type":1,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeRangePart(String,String).mjava","pathOld":"lucene/src/java/org/apache/lucene/queryParser/QueryParserBase#analyzeRangePart(String,String).mjava","sourceNew":"  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for range part: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException ignored) {}\n    \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":"  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for range part: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException ignored) {}\n    \n    return new BytesRef(bytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60c9885566d6f83ba835be67d76ecbf214685052","date":1317096458,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeRangePart(String,String).mjava","pathOld":"modules/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeRangePart(String,String).mjava","sourceNew":"  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for range part: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n    \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":"  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for range part: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException ignored) {}\n    \n    return new BytesRef(bytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"69e043c521d4e8db770cc140c63f5ef51f03426a","date":1317187614,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeRangePart(String,String).mjava","pathOld":"modules/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeRangePart(String,String).mjava","sourceNew":"  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for range part: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n    \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":"  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for range part: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n    \n    return new BytesRef(bytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e6e919043fa85ee891123768dd655a98edbbf63c","date":1322225413,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeRangePart(String,String).mjava","pathOld":"modules/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeRangePart(String,String).mjava","sourceNew":"  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for range part: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n    \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","sourceOld":"  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for range part: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n    \n    return new BytesRef(bytes);\n  }\n\n","bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f8d5405ac4f2510f9f83e07236792d1056c19640","date":1322235986,"type":5,"author":"Erick Erickson","isMerge":false,"pathNew":"modules/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeMultitermTerm(String,String,Analyzer).mjava","pathOld":"modules/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase#analyzeRangePart(String,String).mjava","sourceNew":"  protected BytesRef analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n    TokenStream source;\n\n    if (analyzerIn == null) analyzerIn = analyzer;\n\n    try {\n      source = analyzerIn.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze multiTerm term: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing multiTerm term: \" + part, e);\n    }\n    \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","sourceOld":"  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.tokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to initialize TokenStream to analyze range part: \" + part, e);\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      if (source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned too many terms for range part: \" + part);\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.end();\n      source.close();\n    } catch (IOException e) {\n      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing range part: \" + part, e);\n    }\n    \n    return BytesRef.deepCopyOf(bytes);\n  }\n\n","bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"60c9885566d6f83ba835be67d76ecbf214685052":["91a3609ac9a09ca0c8eee1b765401bbdacaceaf8"],"91a3609ac9a09ca0c8eee1b765401bbdacaceaf8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f8d5405ac4f2510f9f83e07236792d1056c19640":["e6e919043fa85ee891123768dd655a98edbbf63c"],"e6e919043fa85ee891123768dd655a98edbbf63c":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["60c9885566d6f83ba835be67d76ecbf214685052"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f8d5405ac4f2510f9f83e07236792d1056c19640"]},"commit2Childs":{"60c9885566d6f83ba835be67d76ecbf214685052":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"91a3609ac9a09ca0c8eee1b765401bbdacaceaf8":["60c9885566d6f83ba835be67d76ecbf214685052"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["91a3609ac9a09ca0c8eee1b765401bbdacaceaf8"],"f8d5405ac4f2510f9f83e07236792d1056c19640":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e6e919043fa85ee891123768dd655a98edbbf63c":["f8d5405ac4f2510f9f83e07236792d1056c19640"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["e6e919043fa85ee891123768dd655a98edbbf63c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}