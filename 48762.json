{"path":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader#BlockTreeTermsReader(Directory,FieldInfos,String,PostingsReaderBase,IOContext,String,int).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader#BlockTreeTermsReader(Directory,FieldInfos,String,PostingsReaderBase,IOContext,String,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/BlockTreeTermsReader#BlockTreeTermsReader(Directory,FieldInfos,String,PostingsReaderBase,IOContext,String,int).mjava","sourceNew":"  public BlockTreeTermsReader(Directory dir, FieldInfos fieldInfos, String segment,\n                              PostingsReaderBase postingsReader, IOContext ioContext,\n                              String segmentSuffix, int indexDivisor)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_EXTENSION),\n                       ioContext);\n\n    boolean success = false;\n    IndexInput indexIn = null;\n\n    try {\n      readHeader(in);\n      if (indexDivisor != -1) {\n        indexIn = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_INDEX_EXTENSION),\n                                ioContext);\n        readIndexHeader(indexIn);\n      }\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n      if (indexDivisor != -1) {\n        seekDir(indexIn, indexDirOffset);\n      }\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final int numBytes = in.readVInt();\n        final BytesRef rootCode = new BytesRef(new byte[numBytes]);\n        in.readBytes(rootCode.bytes, 0, numBytes);\n        rootCode.length = numBytes;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        assert fieldInfo != null: \"field=\" + field;\n        final long sumTotalTermFreq = fieldInfo.indexOptions == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        final long indexStartFP = indexDivisor != -1 ? indexIn.readVLong() : 0;\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, rootCode, sumTotalTermFreq, sumDocFreq, docCount, indexStartFP, indexIn));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexIn, this);\n      } else if (indexDivisor != -1) {\n        indexIn.close();\n      }\n    }\n  }\n\n","sourceOld":"  public BlockTreeTermsReader(Directory dir, FieldInfos fieldInfos, String segment,\n                              PostingsReaderBase postingsReader, IOContext ioContext,\n                              String segmentSuffix, int indexDivisor)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_EXTENSION),\n                       ioContext);\n\n    boolean success = false;\n    IndexInput indexIn = null;\n\n    try {\n      readHeader(in);\n      if (indexDivisor != -1) {\n        indexIn = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_INDEX_EXTENSION),\n                                ioContext);\n        readIndexHeader(indexIn);\n      }\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n      if (indexDivisor != -1) {\n        seekDir(indexIn, indexDirOffset);\n      }\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final int numBytes = in.readVInt();\n        final BytesRef rootCode = new BytesRef(new byte[numBytes]);\n        in.readBytes(rootCode.bytes, 0, numBytes);\n        rootCode.length = numBytes;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        assert fieldInfo != null: \"field=\" + field;\n        final long sumTotalTermFreq = fieldInfo.indexOptions == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        final long indexStartFP = indexDivisor != -1 ? indexIn.readVLong() : 0;\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, rootCode, sumTotalTermFreq, sumDocFreq, docCount, indexStartFP, indexIn));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexIn, this);\n      } else if (indexDivisor != -1) {\n        indexIn.close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"76923f6a33f2c4bec7f584e3f251261afe7ea276","date":1337149711,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader#BlockTreeTermsReader(Directory,FieldInfos,String,PostingsReaderBase,IOContext,String,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader#BlockTreeTermsReader(Directory,FieldInfos,String,PostingsReaderBase,IOContext,String,int).mjava","sourceNew":"  public BlockTreeTermsReader(Directory dir, FieldInfos fieldInfos, String segment,\n                              PostingsReaderBase postingsReader, IOContext ioContext,\n                              String segmentSuffix, int indexDivisor)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_EXTENSION),\n                       ioContext);\n\n    boolean success = false;\n    IndexInput indexIn = null;\n\n    try {\n      readHeader(in);\n      if (indexDivisor != -1) {\n        indexIn = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_INDEX_EXTENSION),\n                                ioContext);\n        readIndexHeader(indexIn);\n      }\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n      if (indexDivisor != -1) {\n        seekDir(indexIn, indexDirOffset);\n      }\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final int numBytes = in.readVInt();\n        final BytesRef rootCode = new BytesRef(new byte[numBytes]);\n        in.readBytes(rootCode.bytes, 0, numBytes);\n        rootCode.length = numBytes;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        assert fieldInfo != null: \"field=\" + field;\n        final long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        final long indexStartFP = indexDivisor != -1 ? indexIn.readVLong() : 0;\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, rootCode, sumTotalTermFreq, sumDocFreq, docCount, indexStartFP, indexIn));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexIn, this);\n      } else if (indexDivisor != -1) {\n        indexIn.close();\n      }\n    }\n  }\n\n","sourceOld":"  public BlockTreeTermsReader(Directory dir, FieldInfos fieldInfos, String segment,\n                              PostingsReaderBase postingsReader, IOContext ioContext,\n                              String segmentSuffix, int indexDivisor)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_EXTENSION),\n                       ioContext);\n\n    boolean success = false;\n    IndexInput indexIn = null;\n\n    try {\n      readHeader(in);\n      if (indexDivisor != -1) {\n        indexIn = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_INDEX_EXTENSION),\n                                ioContext);\n        readIndexHeader(indexIn);\n      }\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n      if (indexDivisor != -1) {\n        seekDir(indexIn, indexDirOffset);\n      }\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final int numBytes = in.readVInt();\n        final BytesRef rootCode = new BytesRef(new byte[numBytes]);\n        in.readBytes(rootCode.bytes, 0, numBytes);\n        rootCode.length = numBytes;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        assert fieldInfo != null: \"field=\" + field;\n        final long sumTotalTermFreq = fieldInfo.indexOptions == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        final long indexStartFP = indexDivisor != -1 ? indexIn.readVLong() : 0;\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, rootCode, sumTotalTermFreq, sumDocFreq, docCount, indexStartFP, indexIn));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexIn, this);\n      } else if (indexDivisor != -1) {\n        indexIn.close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader#BlockTreeTermsReader(Directory,FieldInfos,String,PostingsReaderBase,IOContext,String,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader#BlockTreeTermsReader(Directory,FieldInfos,String,PostingsReaderBase,IOContext,String,int).mjava","sourceNew":"  public BlockTreeTermsReader(Directory dir, FieldInfos fieldInfos, String segment,\n                              PostingsReaderBase postingsReader, IOContext ioContext,\n                              String segmentSuffix, int indexDivisor)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_EXTENSION),\n                       ioContext);\n\n    boolean success = false;\n    IndexInput indexIn = null;\n\n    try {\n      readHeader(in);\n      if (indexDivisor != -1) {\n        indexIn = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_INDEX_EXTENSION),\n                                ioContext);\n        readIndexHeader(indexIn);\n      }\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n      if (indexDivisor != -1) {\n        seekDir(indexIn, indexDirOffset);\n      }\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final int numBytes = in.readVInt();\n        final BytesRef rootCode = new BytesRef(new byte[numBytes]);\n        in.readBytes(rootCode.bytes, 0, numBytes);\n        rootCode.length = numBytes;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        assert fieldInfo != null: \"field=\" + field;\n        final long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        final long indexStartFP = indexDivisor != -1 ? indexIn.readVLong() : 0;\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, rootCode, sumTotalTermFreq, sumDocFreq, docCount, indexStartFP, indexIn));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexIn, this);\n      } else if (indexDivisor != -1) {\n        indexIn.close();\n      }\n    }\n  }\n\n","sourceOld":"  public BlockTreeTermsReader(Directory dir, FieldInfos fieldInfos, String segment,\n                              PostingsReaderBase postingsReader, IOContext ioContext,\n                              String segmentSuffix, int indexDivisor)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_EXTENSION),\n                       ioContext);\n\n    boolean success = false;\n    IndexInput indexIn = null;\n\n    try {\n      readHeader(in);\n      if (indexDivisor != -1) {\n        indexIn = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_INDEX_EXTENSION),\n                                ioContext);\n        readIndexHeader(indexIn);\n      }\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n      if (indexDivisor != -1) {\n        seekDir(indexIn, indexDirOffset);\n      }\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final int numBytes = in.readVInt();\n        final BytesRef rootCode = new BytesRef(new byte[numBytes]);\n        in.readBytes(rootCode.bytes, 0, numBytes);\n        rootCode.length = numBytes;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        assert fieldInfo != null: \"field=\" + field;\n        final long sumTotalTermFreq = fieldInfo.indexOptions == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        final long indexStartFP = indexDivisor != -1 ? indexIn.readVLong() : 0;\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, rootCode, sumTotalTermFreq, sumDocFreq, docCount, indexStartFP, indexIn));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexIn, this);\n      } else if (indexDivisor != -1) {\n        indexIn.close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6e5adcbe5a27941451fdb6194bcbff96c8630e14","date":1346419102,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader#BlockTreeTermsReader(Directory,FieldInfos,SegmentInfo,PostingsReaderBase,IOContext,String,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader#BlockTreeTermsReader(Directory,FieldInfos,String,PostingsReaderBase,IOContext,String,int).mjava","sourceNew":"  public BlockTreeTermsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo info,\n                              PostingsReaderBase postingsReader, IOContext ioContext,\n                              String segmentSuffix, int indexDivisor)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n\n    this.segment = info.name;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_EXTENSION),\n                       ioContext);\n\n    boolean success = false;\n    IndexInput indexIn = null;\n\n    try {\n      readHeader(in);\n      if (indexDivisor != -1) {\n        indexIn = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_INDEX_EXTENSION),\n                                ioContext);\n        readIndexHeader(indexIn);\n      }\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n      if (indexDivisor != -1) {\n        seekDir(indexIn, indexDirOffset);\n      }\n\n      final int numFields = in.readVInt();\n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final int numBytes = in.readVInt();\n        final BytesRef rootCode = new BytesRef(new byte[numBytes]);\n        in.readBytes(rootCode.bytes, 0, numBytes);\n        rootCode.length = numBytes;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        assert fieldInfo != null: \"field=\" + field;\n        final long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        if (docCount < 0 || docCount > info.getDocCount()) { // #docs with field must be <= #docs\n          throw new CorruptIndexException(\"invalid docCount: \" + docCount + \" maxDoc: \" + info.getDocCount() + \" (resource=\" + in + \")\");\n        }\n        if (sumDocFreq < docCount) {  // #postings must be >= #docs with field\n          throw new CorruptIndexException(\"invalid sumDocFreq: \" + sumDocFreq + \" docCount: \" + docCount + \" (resource=\" + in + \")\");\n        }\n        if (sumTotalTermFreq != -1 && sumTotalTermFreq < sumDocFreq) { // #positions must be >= #postings\n          throw new CorruptIndexException(\"invalid sumTotalTermFreq: \" + sumTotalTermFreq + \" sumDocFreq: \" + sumDocFreq + \" (resource=\" + in + \")\");\n        }\n        final long indexStartFP = indexDivisor != -1 ? indexIn.readVLong() : 0;\n        FieldReader previous = fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, rootCode, sumTotalTermFreq, sumDocFreq, docCount, indexStartFP, indexIn));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexIn, this);\n      } else if (indexDivisor != -1) {\n        indexIn.close();\n      }\n    }\n  }\n\n","sourceOld":"  public BlockTreeTermsReader(Directory dir, FieldInfos fieldInfos, String segment,\n                              PostingsReaderBase postingsReader, IOContext ioContext,\n                              String segmentSuffix, int indexDivisor)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_EXTENSION),\n                       ioContext);\n\n    boolean success = false;\n    IndexInput indexIn = null;\n\n    try {\n      readHeader(in);\n      if (indexDivisor != -1) {\n        indexIn = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_INDEX_EXTENSION),\n                                ioContext);\n        readIndexHeader(indexIn);\n      }\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n      if (indexDivisor != -1) {\n        seekDir(indexIn, indexDirOffset);\n      }\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final int numBytes = in.readVInt();\n        final BytesRef rootCode = new BytesRef(new byte[numBytes]);\n        in.readBytes(rootCode.bytes, 0, numBytes);\n        rootCode.length = numBytes;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        assert fieldInfo != null: \"field=\" + field;\n        final long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        final long indexStartFP = indexDivisor != -1 ? indexIn.readVLong() : 0;\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, rootCode, sumTotalTermFreq, sumDocFreq, docCount, indexStartFP, indexIn));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexIn, this);\n      } else if (indexDivisor != -1) {\n        indexIn.close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0d1f90e969803cc84174589b5e4a39b7935fecd","date":1346584861,"type":5,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader#BlockTreeTermsReader(Directory,FieldInfos,SegmentInfo,PostingsReaderBase,IOContext,String,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader#BlockTreeTermsReader(Directory,FieldInfos,String,PostingsReaderBase,IOContext,String,int).mjava","sourceNew":"  public BlockTreeTermsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo info,\n                              PostingsReaderBase postingsReader, IOContext ioContext,\n                              String segmentSuffix, int indexDivisor)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n\n    this.segment = info.name;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_EXTENSION),\n                       ioContext);\n\n    boolean success = false;\n    IndexInput indexIn = null;\n\n    try {\n      readHeader(in);\n      if (indexDivisor != -1) {\n        indexIn = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_INDEX_EXTENSION),\n                                ioContext);\n        readIndexHeader(indexIn);\n      }\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n      if (indexDivisor != -1) {\n        seekDir(indexIn, indexDirOffset);\n      }\n\n      final int numFields = in.readVInt();\n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final int numBytes = in.readVInt();\n        final BytesRef rootCode = new BytesRef(new byte[numBytes]);\n        in.readBytes(rootCode.bytes, 0, numBytes);\n        rootCode.length = numBytes;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        assert fieldInfo != null: \"field=\" + field;\n        final long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        if (docCount < 0 || docCount > info.getDocCount()) { // #docs with field must be <= #docs\n          throw new CorruptIndexException(\"invalid docCount: \" + docCount + \" maxDoc: \" + info.getDocCount() + \" (resource=\" + in + \")\");\n        }\n        if (sumDocFreq < docCount) {  // #postings must be >= #docs with field\n          throw new CorruptIndexException(\"invalid sumDocFreq: \" + sumDocFreq + \" docCount: \" + docCount + \" (resource=\" + in + \")\");\n        }\n        if (sumTotalTermFreq != -1 && sumTotalTermFreq < sumDocFreq) { // #positions must be >= #postings\n          throw new CorruptIndexException(\"invalid sumTotalTermFreq: \" + sumTotalTermFreq + \" sumDocFreq: \" + sumDocFreq + \" (resource=\" + in + \")\");\n        }\n        final long indexStartFP = indexDivisor != -1 ? indexIn.readVLong() : 0;\n        FieldReader previous = fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, rootCode, sumTotalTermFreq, sumDocFreq, docCount, indexStartFP, indexIn));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexIn, this);\n      } else if (indexDivisor != -1) {\n        indexIn.close();\n      }\n    }\n  }\n\n","sourceOld":"  public BlockTreeTermsReader(Directory dir, FieldInfos fieldInfos, String segment,\n                              PostingsReaderBase postingsReader, IOContext ioContext,\n                              String segmentSuffix, int indexDivisor)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n\n    this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_EXTENSION),\n                       ioContext);\n\n    boolean success = false;\n    IndexInput indexIn = null;\n\n    try {\n      readHeader(in);\n      if (indexDivisor != -1) {\n        indexIn = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, BlockTreeTermsWriter.TERMS_INDEX_EXTENSION),\n                                ioContext);\n        readIndexHeader(indexIn);\n      }\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n      if (indexDivisor != -1) {\n        seekDir(indexIn, indexDirOffset);\n      }\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final int numBytes = in.readVInt();\n        final BytesRef rootCode = new BytesRef(new byte[numBytes]);\n        in.readBytes(rootCode.bytes, 0, numBytes);\n        rootCode.length = numBytes;\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        assert fieldInfo != null: \"field=\" + field;\n        final long sumTotalTermFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS_ONLY ? -1 : in.readVLong();\n        final long sumDocFreq = in.readVLong();\n        final int docCount = in.readVInt();\n        final long indexStartFP = indexDivisor != -1 ? indexIn.readVLong() : 0;\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, rootCode, sumTotalTermFreq, sumDocFreq, docCount, indexStartFP, indexIn));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(indexIn, this);\n      } else if (indexDivisor != -1) {\n        indexIn.close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"76923f6a33f2c4bec7f584e3f251261afe7ea276":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0d1f90e969803cc84174589b5e4a39b7935fecd":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","6e5adcbe5a27941451fdb6194bcbff96c8630e14"],"6e5adcbe5a27941451fdb6194bcbff96c8630e14":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","76923f6a33f2c4bec7f584e3f251261afe7ea276"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6e5adcbe5a27941451fdb6194bcbff96c8630e14"]},"commit2Childs":{"76923f6a33f2c4bec7f584e3f251261afe7ea276":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"d0d1f90e969803cc84174589b5e4a39b7935fecd":[],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["d0d1f90e969803cc84174589b5e4a39b7935fecd","6e5adcbe5a27941451fdb6194bcbff96c8630e14"],"6e5adcbe5a27941451fdb6194bcbff96c8630e14":["d0d1f90e969803cc84174589b5e4a39b7935fecd","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["76923f6a33f2c4bec7f584e3f251261afe7ea276","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d0d1f90e969803cc84174589b5e4a39b7935fecd","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}