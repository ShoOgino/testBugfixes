{"path":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","commits":[{"id":"60fc78d9a827f6a8c5102f6509dd224f19ca23b4","date":1359479140,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BDocValues#testNumerics().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"/dev/null","sourceNew":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(_TestUtil.getTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0d579490a72f2e6297eaa648940611234c57cf1","date":1395917140,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c","date":1396633078,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a0f5bb79c600763ffe7b8141df59a3169d31e48","date":1396689440,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(TestUtil.getTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.shutdown();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.shutdown();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (AtomicReaderContext context : r.leaves()) {\n      AtomicReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fc1451a888296ae68f6a92f5e9550a5788428fbf","date":1412414951,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9a47902d6207303f5ed3e7aaca62ca33433af66","date":1412435312,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes Integer.MAX_VALUE docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < Integer.MAX_VALUE; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"656cfb06eff2244ff5a25ffb3ed3a79942ece85c","date":1413181096,"type":3,"author":"Shawn Heisey","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":["94654d096bbdfae1ffdc35a51fa505a53750938d"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(i, dv.nextDoc());\n        assertEquals(expectedValue, dv.longValue());\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(i, dv.nextDoc());\n        assertEquals(expectedValue, dv.longValue());\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/Test2BNumericDocValues#testNumerics().mjava","sourceNew":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(i, dv.nextDoc());\n        assertEquals(expectedValue, dv.longValue());\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // indexes IndexWriter.MAX_DOCS docs with an increasing dv field\n  public void testNumerics() throws Exception {\n    BaseDirectoryWrapper dir = newFSDirectory(createTempDir(\"2BNumerics\"));\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n    }\n    \n    IndexWriter w = new IndexWriter(dir,\n        new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)\n        .setRAMBufferSizeMB(256.0)\n        .setMergeScheduler(new ConcurrentMergeScheduler())\n        .setMergePolicy(newLogMergePolicy(false, 10))\n        .setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        .setCodec(TestUtil.getDefaultCodec()));\n\n    Document doc = new Document();\n    NumericDocValuesField dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(dvField);\n    \n    for (int i = 0; i < IndexWriter.MAX_DOCS; i++) {\n      dvField.setLongValue(i);\n      w.addDocument(doc);\n      if (i % 100000 == 0) {\n        System.out.println(\"indexed: \" + i);\n        System.out.flush();\n      }\n    }\n    \n    w.forceMerge(1);\n    w.close();\n    \n    System.out.println(\"verifying...\");\n    System.out.flush();\n    \n    DirectoryReader r = DirectoryReader.open(dir);\n    long expectedValue = 0;\n    for (LeafReaderContext context : r.leaves()) {\n      LeafReader reader = context.reader();\n      NumericDocValues dv = reader.getNumericDocValues(\"dv\");\n      for (int i = 0; i < reader.maxDoc(); i++) {\n        assertEquals(expectedValue, dv.get(i));\n        expectedValue++;\n      }\n    }\n    \n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"55980207f1977bd1463465de1659b821347e2fa8":["d9a47902d6207303f5ed3e7aaca62ca33433af66","656cfb06eff2244ff5a25ffb3ed3a79942ece85c"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["6613659748fe4411a7dcf85266e55db1f95f7315","a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c"],"6613659748fe4411a7dcf85266e55db1f95f7315":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["c9fb5f46e264daf5ba3860defe623a89d202dd87","fc1451a888296ae68f6a92f5e9550a5788428fbf"],"d0d579490a72f2e6297eaa648940611234c57cf1":["6613659748fe4411a7dcf85266e55db1f95f7315"],"fc1451a888296ae68f6a92f5e9550a5788428fbf":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"60fc78d9a827f6a8c5102f6509dd224f19ca23b4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["656cfb06eff2244ff5a25ffb3ed3a79942ece85c","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","60fc78d9a827f6a8c5102f6509dd224f19ca23b4"],"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c":["d0d579490a72f2e6297eaa648940611234c57cf1"],"656cfb06eff2244ff5a25ffb3ed3a79942ece85c":["fc1451a888296ae68f6a92f5e9550a5788428fbf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["656cfb06eff2244ff5a25ffb3ed3a79942ece85c","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["656cfb06eff2244ff5a25ffb3ed3a79942ece85c"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"]},"commit2Childs":{"55980207f1977bd1463465de1659b821347e2fa8":[],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"6613659748fe4411a7dcf85266e55db1f95f7315":["2a0f5bb79c600763ffe7b8141df59a3169d31e48","d0d579490a72f2e6297eaa648940611234c57cf1"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["55980207f1977bd1463465de1659b821347e2fa8"],"d0d579490a72f2e6297eaa648940611234c57cf1":["a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c"],"fc1451a888296ae68f6a92f5e9550a5788428fbf":["d9a47902d6207303f5ed3e7aaca62ca33433af66","656cfb06eff2244ff5a25ffb3ed3a79942ece85c"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d9a47902d6207303f5ed3e7aaca62ca33433af66","fc1451a888296ae68f6a92f5e9550a5788428fbf"],"60fc78d9a827f6a8c5102f6509dd224f19ca23b4":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d4d69c535930b5cce125cff868d40f6373dc27d4":["6613659748fe4411a7dcf85266e55db1f95f7315"],"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"656cfb06eff2244ff5a25ffb3ed3a79942ece85c":["55980207f1977bd1463465de1659b821347e2fa8","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["60fc78d9a827f6a8c5102f6509dd224f19ca23b4","d4d69c535930b5cce125cff868d40f6373dc27d4"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["55980207f1977bd1463465de1659b821347e2fa8","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}