{"path":"lucene/core/src/test/org/apache/lucene/index/TestTragicIndexWriterDeadlock#testDeadlockStalledMerges().mjava","commits":[{"id":"ddaef9c801f985de924507f0cceea9786b55ac1f","date":1481326890,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTragicIndexWriterDeadlock#testDeadlockStalledMerges().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-7570\n  public void testDeadlockStalledMerges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig();\n\n    // so we merge every 2 segments:\n    LogMergePolicy mp = new LogDocMergePolicy();\n    mp.setMergeFactor(2);\n    iwc.setMergePolicy(mp);\n    CountDownLatch done = new CountDownLatch(1);\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler() {\n        @Override\n        protected void doMerge(IndexWriter writer, MergePolicy.OneMerge merge) throws IOException {\n          // let merge takes forever, until commit thread is stalled\n          try {\n            done.await();\n          } catch (InterruptedException ie) {\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(ie);\n          }\n          super.doMerge(writer, merge);\n        }\n\n        @Override\n        protected synchronized void doStall() {\n          done.countDown();\n          super.doStall();\n        }\n\n        @Override\n        protected void handleMergeException(Directory dir, Throwable exc) {\n        }\n      };\n\n    // so we stall once the 2nd merge wants to run:\n    cms.setMaxMergesAndThreads(1, 1);\n    iwc.setMergeScheduler(cms);\n\n    // so we write a segment every 2 indexed docs:\n    iwc.setMaxBufferedDocs(2);\n\n    final IndexWriter w = new IndexWriter(dir, iwc) {\n      @Override\n      void mergeSuccess(MergePolicy.OneMerge merge) {\n        // tragedy strikes!\n        throw new OutOfMemoryError();\n      }\n      };\n\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes first segment\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes second segment, and kicks off merge, that takes forever (done.await)\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes third segment\n    w.addDocument(new Document());\n    w.commit();\n    // w writes fourth segment, and commit flushes and kicks off merge that stalls\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9856095f7afb5a607bf5e65077615ed91273508c","date":1481837697,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTragicIndexWriterDeadlock#testDeadlockStalledMerges().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-7570\n  public void testDeadlockStalledMerges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig();\n\n    // so we merge every 2 segments:\n    LogMergePolicy mp = new LogDocMergePolicy();\n    mp.setMergeFactor(2);\n    iwc.setMergePolicy(mp);\n    CountDownLatch done = new CountDownLatch(1);\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler() {\n        @Override\n        protected void doMerge(IndexWriter writer, MergePolicy.OneMerge merge) throws IOException {\n          // let merge takes forever, until commit thread is stalled\n          try {\n            done.await();\n          } catch (InterruptedException ie) {\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(ie);\n          }\n          super.doMerge(writer, merge);\n        }\n\n        @Override\n        protected synchronized void doStall() {\n          done.countDown();\n          super.doStall();\n        }\n\n        @Override\n        protected void handleMergeException(Directory dir, Throwable exc) {\n        }\n      };\n\n    // so we stall once the 2nd merge wants to run:\n    cms.setMaxMergesAndThreads(1, 1);\n    iwc.setMergeScheduler(cms);\n\n    // so we write a segment every 2 indexed docs:\n    iwc.setMaxBufferedDocs(2);\n\n    final IndexWriter w = new IndexWriter(dir, iwc) {\n      @Override\n      void mergeSuccess(MergePolicy.OneMerge merge) {\n        // tragedy strikes!\n        throw new OutOfMemoryError();\n      }\n      };\n\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes first segment\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes second segment, and kicks off merge, that takes forever (done.await)\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes third segment\n    w.addDocument(new Document());\n    w.commit();\n    // w writes fourth segment, and commit flushes and kicks off merge that stalls\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"89697e7abc9807639c384eecf5a2a6eef1080426","date":1587733375,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTragicIndexWriterDeadlock#testDeadlockStalledMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTragicIndexWriterDeadlock#testDeadlockStalledMerges().mjava","sourceNew":"  // LUCENE-7570\n  public void testDeadlockStalledMerges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig();\n\n    // so we merge every 2 segments:\n    LogMergePolicy mp = new LogDocMergePolicy();\n    mp.setMergeFactor(2);\n    iwc.setMergePolicy(mp);\n    CountDownLatch done = new CountDownLatch(1);\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler() {\n        @Override\n        protected void doMerge(MergeSource mergeSource, MergePolicy.OneMerge merge) throws IOException {\n          // let merge takes forever, until commit thread is stalled\n          try {\n            done.await();\n          } catch (InterruptedException ie) {\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(ie);\n          }\n          super.doMerge(mergeSource, merge);\n        }\n\n        @Override\n        protected synchronized void doStall() {\n          done.countDown();\n          super.doStall();\n        }\n\n        @Override\n        protected void handleMergeException(Throwable exc) {\n        }\n      };\n\n    // so we stall once the 2nd merge wants to run:\n    cms.setMaxMergesAndThreads(1, 1);\n    iwc.setMergeScheduler(cms);\n\n    // so we write a segment every 2 indexed docs:\n    iwc.setMaxBufferedDocs(2);\n\n    final IndexWriter w = new IndexWriter(dir, iwc) {\n      @Override\n      void mergeSuccess(MergePolicy.OneMerge merge) {\n        // tragedy strikes!\n        throw new OutOfMemoryError();\n      }\n      };\n\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes first segment\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes second segment, and kicks off merge, that takes forever (done.await)\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes third segment\n    w.addDocument(new Document());\n    w.commit();\n    // w writes fourth segment, and commit flushes and kicks off merge that stalls\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-7570\n  public void testDeadlockStalledMerges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig();\n\n    // so we merge every 2 segments:\n    LogMergePolicy mp = new LogDocMergePolicy();\n    mp.setMergeFactor(2);\n    iwc.setMergePolicy(mp);\n    CountDownLatch done = new CountDownLatch(1);\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler() {\n        @Override\n        protected void doMerge(IndexWriter writer, MergePolicy.OneMerge merge) throws IOException {\n          // let merge takes forever, until commit thread is stalled\n          try {\n            done.await();\n          } catch (InterruptedException ie) {\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(ie);\n          }\n          super.doMerge(writer, merge);\n        }\n\n        @Override\n        protected synchronized void doStall() {\n          done.countDown();\n          super.doStall();\n        }\n\n        @Override\n        protected void handleMergeException(Directory dir, Throwable exc) {\n        }\n      };\n\n    // so we stall once the 2nd merge wants to run:\n    cms.setMaxMergesAndThreads(1, 1);\n    iwc.setMergeScheduler(cms);\n\n    // so we write a segment every 2 indexed docs:\n    iwc.setMaxBufferedDocs(2);\n\n    final IndexWriter w = new IndexWriter(dir, iwc) {\n      @Override\n      void mergeSuccess(MergePolicy.OneMerge merge) {\n        // tragedy strikes!\n        throw new OutOfMemoryError();\n      }\n      };\n\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes first segment\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes second segment, and kicks off merge, that takes forever (done.await)\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes third segment\n    w.addDocument(new Document());\n    w.commit();\n    // w writes fourth segment, and commit flushes and kicks off merge that stalls\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2","date":1588002560,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTragicIndexWriterDeadlock#testDeadlockStalledMerges().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTragicIndexWriterDeadlock#testDeadlockStalledMerges().mjava","sourceNew":"  // LUCENE-7570\n  public void testDeadlockStalledMerges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig();\n\n    // so we merge every 2 segments:\n    LogMergePolicy mp = new LogDocMergePolicy();\n    mp.setMergeFactor(2);\n    iwc.setMergePolicy(mp);\n    CountDownLatch done = new CountDownLatch(1);\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler() {\n        @Override\n        protected void doMerge(MergeSource mergeSource, MergePolicy.OneMerge merge) throws IOException {\n          // let merge takes forever, until commit thread is stalled\n          try {\n            done.await();\n          } catch (InterruptedException ie) {\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(ie);\n          }\n          super.doMerge(mergeSource, merge);\n        }\n\n        @Override\n        protected synchronized void doStall() {\n          done.countDown();\n          super.doStall();\n        }\n\n        @Override\n        protected void handleMergeException(Throwable exc) {\n        }\n      };\n\n    // so we stall once the 2nd merge wants to run:\n    cms.setMaxMergesAndThreads(1, 1);\n    iwc.setMergeScheduler(cms);\n\n    // so we write a segment every 2 indexed docs:\n    iwc.setMaxBufferedDocs(2);\n\n    final IndexWriter w = new IndexWriter(dir, iwc) {\n      @Override\n      protected void mergeSuccess(MergePolicy.OneMerge merge) {\n        // tragedy strikes!\n        throw new OutOfMemoryError();\n      }\n      };\n\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes first segment\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes second segment, and kicks off merge, that takes forever (done.await)\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes third segment\n    w.addDocument(new Document());\n    w.commit();\n    // w writes fourth segment, and commit flushes and kicks off merge that stalls\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-7570\n  public void testDeadlockStalledMerges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig();\n\n    // so we merge every 2 segments:\n    LogMergePolicy mp = new LogDocMergePolicy();\n    mp.setMergeFactor(2);\n    iwc.setMergePolicy(mp);\n    CountDownLatch done = new CountDownLatch(1);\n    ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler() {\n        @Override\n        protected void doMerge(MergeSource mergeSource, MergePolicy.OneMerge merge) throws IOException {\n          // let merge takes forever, until commit thread is stalled\n          try {\n            done.await();\n          } catch (InterruptedException ie) {\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(ie);\n          }\n          super.doMerge(mergeSource, merge);\n        }\n\n        @Override\n        protected synchronized void doStall() {\n          done.countDown();\n          super.doStall();\n        }\n\n        @Override\n        protected void handleMergeException(Throwable exc) {\n        }\n      };\n\n    // so we stall once the 2nd merge wants to run:\n    cms.setMaxMergesAndThreads(1, 1);\n    iwc.setMergeScheduler(cms);\n\n    // so we write a segment every 2 indexed docs:\n    iwc.setMaxBufferedDocs(2);\n\n    final IndexWriter w = new IndexWriter(dir, iwc) {\n      @Override\n      void mergeSuccess(MergePolicy.OneMerge merge) {\n        // tragedy strikes!\n        throw new OutOfMemoryError();\n      }\n      };\n\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes first segment\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes second segment, and kicks off merge, that takes forever (done.await)\n    w.addDocument(new Document());\n    w.addDocument(new Document());\n    // w writes third segment\n    w.addDocument(new Document());\n    w.commit();\n    // w writes fourth segment, and commit flushes and kicks off merge that stalls\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"89697e7abc9807639c384eecf5a2a6eef1080426":["ddaef9c801f985de924507f0cceea9786b55ac1f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["89697e7abc9807639c384eecf5a2a6eef1080426"],"9856095f7afb5a607bf5e65077615ed91273508c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ddaef9c801f985de924507f0cceea9786b55ac1f"],"ddaef9c801f985de924507f0cceea9786b55ac1f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"]},"commit2Childs":{"89697e7abc9807639c384eecf5a2a6eef1080426":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9856095f7afb5a607bf5e65077615ed91273508c","ddaef9c801f985de924507f0cceea9786b55ac1f"],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9856095f7afb5a607bf5e65077615ed91273508c":[],"ddaef9c801f985de924507f0cceea9786b55ac1f":["89697e7abc9807639c384eecf5a2a6eef1080426","9856095f7afb5a607bf5e65077615ed91273508c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9856095f7afb5a607bf5e65077615ed91273508c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}