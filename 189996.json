{"path":"lucene/facet/src/test/org/apache/lucene/facet/util/TestFacetsPayloadMigrationReader#verifyIndexOrdinals(DirectoryReader,TaxonomyReader,FacetIndexingParams).mjava","commits":[{"id":"607428da722dcb3e86bbd11c63de8986e6275c36","date":1360334150,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/util/TestFacetsPayloadMigrationReader#verifyIndexOrdinals(DirectoryReader,TaxonomyReader,FacetIndexingParams).mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/index/TestFacetsPayloadMigrationReader#verifyIndexOrdinals(DirectoryReader,TaxonomyReader,FacetIndexingParams).mjava","sourceNew":"  private void verifyIndexOrdinals(DirectoryReader indexReader, TaxonomyReader taxoReader, FacetIndexingParams fip) \n      throws IOException {\n    // verify that the ordinals in the index match the ones in the taxonomy, and vice versa\n    \n    // collect all fields which have DocValues, to assert later that all were\n    // visited i.e. that during migration we didn't add FieldInfos with no\n    // DocValues\n    HashSet<String> docValuesFields = new HashSet<String>();\n    for (AtomicReaderContext context : indexReader.leaves()) {\n      FieldInfos infos = context.reader().getFieldInfos();\n      for (FieldInfo info : infos) {\n        if (info.hasDocValues()) {\n          docValuesFields.add(info.name);\n        }\n      }\n    }\n    \n    // check that all visited ordinals are found in the taxonomy and vice versa\n    boolean[] foundOrdinals = new boolean[taxoReader.getSize()];\n    for (int i = 0; i < foundOrdinals.length; i++) {\n      foundOrdinals[i] = false; // init to be on the safe side\n    }\n    foundOrdinals[0] = true; // ROOT ordinals isn't indexed\n    // mark 'dummy' category ordinal as seen\n    int dummyOrdinal = taxoReader.getOrdinal(new CategoryPath(\"dummy\"));\n    if (dummyOrdinal > 0) {\n      foundOrdinals[dummyOrdinal] = true;\n    }\n    \n    int partitionSize = fip.getPartitionSize();\n    int numPartitions = (int) Math.ceil(taxoReader.getSize() / (double) partitionSize);\n    final IntsRef ordinals = new IntsRef(32);\n    for (String dim : DIMENSIONS) {\n      CategoryListParams clp = fip.getCategoryListParams(new CategoryPath(dim));\n      int partitionOffset = 0;\n      for (int partition = 0; partition < numPartitions; partition++, partitionOffset += partitionSize) {\n        final CategoryListIterator cli = clp.createCategoryListIterator(partition);\n        for (AtomicReaderContext context : indexReader.leaves()) {\n          if (cli.setNextReader(context)) { // not all fields may exist in all segments\n            // remove that field from the list of DocValues fields\n            docValuesFields.remove(clp.field + PartitionsUtils.partitionName(partition));\n            int maxDoc = context.reader().maxDoc();\n            for (int doc = 0; doc < maxDoc; doc++) {\n              cli.getOrdinals(doc, ordinals);\n              for (int j = 0; j < ordinals.length; j++) {\n                // verify that the ordinal is recognized by the taxonomy\n                int ordinal = ordinals.ints[j] + partitionOffset;\n                assertTrue(\"should not have received dummy ordinal (\" + dummyOrdinal + \")\", dummyOrdinal != ordinal);\n                assertNotNull(\"missing category for ordinal \" + ordinal, taxoReader.getPath(ordinal));\n                foundOrdinals[ordinal] = true;\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    assertTrue(\"some fields which have docValues were not visited: \" + docValuesFields, docValuesFields.isEmpty());\n    \n    for (int i = 0; i < foundOrdinals.length; i++) {\n      assertTrue(\"ordinal \" + i + \" not visited\", foundOrdinals[i]);\n    }\n  }\n\n","sourceOld":"  private void verifyIndexOrdinals(DirectoryReader indexReader, TaxonomyReader taxoReader, FacetIndexingParams fip) \n      throws IOException {\n    // verify that the ordinals in the index match the ones in the taxonomy, and vice versa\n    \n    // collect all fields which have DocValues, to assert later that all were\n    // visited i.e. that during migration we didn't add FieldInfos with no\n    // DocValues\n    HashSet<String> docValuesFields = new HashSet<String>();\n    for (AtomicReaderContext context : indexReader.leaves()) {\n      FieldInfos infos = context.reader().getFieldInfos();\n      for (FieldInfo info : infos) {\n        if (info.hasDocValues()) {\n          docValuesFields.add(info.name);\n        }\n      }\n    }\n    \n    // check that all visited ordinals are found in the taxonomy and vice versa\n    boolean[] foundOrdinals = new boolean[taxoReader.getSize()];\n    for (int i = 0; i < foundOrdinals.length; i++) {\n      foundOrdinals[i] = false; // init to be on the safe side\n    }\n    foundOrdinals[0] = true; // ROOT ordinals isn't indexed\n    // mark 'dummy' category ordinal as seen\n    int dummyOrdinal = taxoReader.getOrdinal(new CategoryPath(\"dummy\"));\n    if (dummyOrdinal > 0) {\n      foundOrdinals[dummyOrdinal] = true;\n    }\n    \n    int partitionSize = fip.getPartitionSize();\n    int numPartitions = (int) Math.ceil(taxoReader.getSize() / (double) partitionSize);\n    final IntsRef ordinals = new IntsRef(32);\n    for (String dim : DIMENSIONS) {\n      CategoryListParams clp = fip.getCategoryListParams(new CategoryPath(dim));\n      int partitionOffset = 0;\n      for (int partition = 0; partition < numPartitions; partition++, partitionOffset += partitionSize) {\n        final CategoryListIterator cli = clp.createCategoryListIterator(partition);\n        for (AtomicReaderContext context : indexReader.leaves()) {\n          if (cli.setNextReader(context)) { // not all fields may exist in all segments\n            // remove that field from the list of DocValues fields\n            docValuesFields.remove(clp.field + PartitionsUtils.partitionName(partition));\n            int maxDoc = context.reader().maxDoc();\n            for (int doc = 0; doc < maxDoc; doc++) {\n              cli.getOrdinals(doc, ordinals);\n              for (int j = 0; j < ordinals.length; j++) {\n                // verify that the ordinal is recognized by the taxonomy\n                int ordinal = ordinals.ints[j] + partitionOffset;\n                assertTrue(\"should not have received dummy ordinal (\" + dummyOrdinal + \")\", dummyOrdinal != ordinal);\n                assertNotNull(\"missing category for ordinal \" + ordinal, taxoReader.getPath(ordinal));\n                foundOrdinals[ordinal] = true;\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    assertTrue(\"some fields which have docValues were not visited: \" + docValuesFields, docValuesFields.isEmpty());\n    \n    for (int i = 0; i < foundOrdinals.length; i++) {\n      assertTrue(\"ordinal \" + i + \" not visited\", foundOrdinals[i]);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c190847801a50f4dd20fd639bdc29b54ea3b288b","date":1384461522,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/util/TestFacetsPayloadMigrationReader#verifyIndexOrdinals(DirectoryReader,TaxonomyReader,FacetIndexingParams).mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/util/TestFacetsPayloadMigrationReader#verifyIndexOrdinals(DirectoryReader,TaxonomyReader,FacetIndexingParams).mjava","sourceNew":"  private void verifyIndexOrdinals(DirectoryReader indexReader, TaxonomyReader taxoReader, FacetIndexingParams fip) \n      throws IOException {\n    // verify that the ordinals in the index match the ones in the taxonomy, and vice versa\n    \n    // collect all fields which have DocValues, to assert later that all were\n    // visited i.e. that during migration we didn't add FieldInfos with no\n    // DocValues\n    HashSet<String> docValuesFields = new HashSet<String>();\n    for (AtomicReaderContext context : indexReader.leaves()) {\n      FieldInfos infos = context.reader().getFieldInfos();\n      for (FieldInfo info : infos) {\n        if (info.hasDocValues()) {\n          docValuesFields.add(info.name);\n        }\n      }\n    }\n    \n    // check that all visited ordinals are found in the taxonomy and vice versa\n    boolean[] foundOrdinals = new boolean[taxoReader.getSize()];\n    for (int i = 0; i < foundOrdinals.length; i++) {\n      foundOrdinals[i] = false; // init to be on the safe side\n    }\n    foundOrdinals[0] = true; // ROOT ordinals isn't indexed\n    // mark 'dummy' category ordinal as seen\n    int dummyOrdinal = taxoReader.getOrdinal(new FacetLabel(\"dummy\"));\n    if (dummyOrdinal > 0) {\n      foundOrdinals[dummyOrdinal] = true;\n    }\n    \n    int partitionSize = fip.getPartitionSize();\n    int numPartitions = (int) Math.ceil(taxoReader.getSize() / (double) partitionSize);\n    final IntsRef ordinals = new IntsRef(32);\n    for (String dim : DIMENSIONS) {\n      CategoryListParams clp = fip.getCategoryListParams(new FacetLabel(dim));\n      int partitionOffset = 0;\n      for (int partition = 0; partition < numPartitions; partition++, partitionOffset += partitionSize) {\n        final CategoryListIterator cli = clp.createCategoryListIterator(partition);\n        for (AtomicReaderContext context : indexReader.leaves()) {\n          if (cli.setNextReader(context)) { // not all fields may exist in all segments\n            // remove that field from the list of DocValues fields\n            docValuesFields.remove(clp.field + PartitionsUtils.partitionName(partition));\n            int maxDoc = context.reader().maxDoc();\n            for (int doc = 0; doc < maxDoc; doc++) {\n              cli.getOrdinals(doc, ordinals);\n              for (int j = 0; j < ordinals.length; j++) {\n                // verify that the ordinal is recognized by the taxonomy\n                int ordinal = ordinals.ints[j] + partitionOffset;\n                assertTrue(\"should not have received dummy ordinal (\" + dummyOrdinal + \")\", dummyOrdinal != ordinal);\n                assertNotNull(\"missing category for ordinal \" + ordinal, taxoReader.getPath(ordinal));\n                foundOrdinals[ordinal] = true;\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    assertTrue(\"some fields which have docValues were not visited: \" + docValuesFields, docValuesFields.isEmpty());\n    \n    for (int i = 0; i < foundOrdinals.length; i++) {\n      assertTrue(\"ordinal \" + i + \" not visited\", foundOrdinals[i]);\n    }\n  }\n\n","sourceOld":"  private void verifyIndexOrdinals(DirectoryReader indexReader, TaxonomyReader taxoReader, FacetIndexingParams fip) \n      throws IOException {\n    // verify that the ordinals in the index match the ones in the taxonomy, and vice versa\n    \n    // collect all fields which have DocValues, to assert later that all were\n    // visited i.e. that during migration we didn't add FieldInfos with no\n    // DocValues\n    HashSet<String> docValuesFields = new HashSet<String>();\n    for (AtomicReaderContext context : indexReader.leaves()) {\n      FieldInfos infos = context.reader().getFieldInfos();\n      for (FieldInfo info : infos) {\n        if (info.hasDocValues()) {\n          docValuesFields.add(info.name);\n        }\n      }\n    }\n    \n    // check that all visited ordinals are found in the taxonomy and vice versa\n    boolean[] foundOrdinals = new boolean[taxoReader.getSize()];\n    for (int i = 0; i < foundOrdinals.length; i++) {\n      foundOrdinals[i] = false; // init to be on the safe side\n    }\n    foundOrdinals[0] = true; // ROOT ordinals isn't indexed\n    // mark 'dummy' category ordinal as seen\n    int dummyOrdinal = taxoReader.getOrdinal(new CategoryPath(\"dummy\"));\n    if (dummyOrdinal > 0) {\n      foundOrdinals[dummyOrdinal] = true;\n    }\n    \n    int partitionSize = fip.getPartitionSize();\n    int numPartitions = (int) Math.ceil(taxoReader.getSize() / (double) partitionSize);\n    final IntsRef ordinals = new IntsRef(32);\n    for (String dim : DIMENSIONS) {\n      CategoryListParams clp = fip.getCategoryListParams(new CategoryPath(dim));\n      int partitionOffset = 0;\n      for (int partition = 0; partition < numPartitions; partition++, partitionOffset += partitionSize) {\n        final CategoryListIterator cli = clp.createCategoryListIterator(partition);\n        for (AtomicReaderContext context : indexReader.leaves()) {\n          if (cli.setNextReader(context)) { // not all fields may exist in all segments\n            // remove that field from the list of DocValues fields\n            docValuesFields.remove(clp.field + PartitionsUtils.partitionName(partition));\n            int maxDoc = context.reader().maxDoc();\n            for (int doc = 0; doc < maxDoc; doc++) {\n              cli.getOrdinals(doc, ordinals);\n              for (int j = 0; j < ordinals.length; j++) {\n                // verify that the ordinal is recognized by the taxonomy\n                int ordinal = ordinals.ints[j] + partitionOffset;\n                assertTrue(\"should not have received dummy ordinal (\" + dummyOrdinal + \")\", dummyOrdinal != ordinal);\n                assertNotNull(\"missing category for ordinal \" + ordinal, taxoReader.getPath(ordinal));\n                foundOrdinals[ordinal] = true;\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    assertTrue(\"some fields which have docValues were not visited: \" + docValuesFields, docValuesFields.isEmpty());\n    \n    for (int i = 0; i < foundOrdinals.length; i++) {\n      assertTrue(\"ordinal \" + i + \" not visited\", foundOrdinals[i]);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d33e19a97046248623a7591aeaa6547233fd15e2","date":1385424777,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/util/TestFacetsPayloadMigrationReader#verifyIndexOrdinals(DirectoryReader,TaxonomyReader,FacetIndexingParams).mjava","sourceNew":null,"sourceOld":"  private void verifyIndexOrdinals(DirectoryReader indexReader, TaxonomyReader taxoReader, FacetIndexingParams fip) \n      throws IOException {\n    // verify that the ordinals in the index match the ones in the taxonomy, and vice versa\n    \n    // collect all fields which have DocValues, to assert later that all were\n    // visited i.e. that during migration we didn't add FieldInfos with no\n    // DocValues\n    HashSet<String> docValuesFields = new HashSet<String>();\n    for (AtomicReaderContext context : indexReader.leaves()) {\n      FieldInfos infos = context.reader().getFieldInfos();\n      for (FieldInfo info : infos) {\n        if (info.hasDocValues()) {\n          docValuesFields.add(info.name);\n        }\n      }\n    }\n    \n    // check that all visited ordinals are found in the taxonomy and vice versa\n    boolean[] foundOrdinals = new boolean[taxoReader.getSize()];\n    for (int i = 0; i < foundOrdinals.length; i++) {\n      foundOrdinals[i] = false; // init to be on the safe side\n    }\n    foundOrdinals[0] = true; // ROOT ordinals isn't indexed\n    // mark 'dummy' category ordinal as seen\n    int dummyOrdinal = taxoReader.getOrdinal(new FacetLabel(\"dummy\"));\n    if (dummyOrdinal > 0) {\n      foundOrdinals[dummyOrdinal] = true;\n    }\n    \n    int partitionSize = fip.getPartitionSize();\n    int numPartitions = (int) Math.ceil(taxoReader.getSize() / (double) partitionSize);\n    final IntsRef ordinals = new IntsRef(32);\n    for (String dim : DIMENSIONS) {\n      CategoryListParams clp = fip.getCategoryListParams(new FacetLabel(dim));\n      int partitionOffset = 0;\n      for (int partition = 0; partition < numPartitions; partition++, partitionOffset += partitionSize) {\n        final CategoryListIterator cli = clp.createCategoryListIterator(partition);\n        for (AtomicReaderContext context : indexReader.leaves()) {\n          if (cli.setNextReader(context)) { // not all fields may exist in all segments\n            // remove that field from the list of DocValues fields\n            docValuesFields.remove(clp.field + PartitionsUtils.partitionName(partition));\n            int maxDoc = context.reader().maxDoc();\n            for (int doc = 0; doc < maxDoc; doc++) {\n              cli.getOrdinals(doc, ordinals);\n              for (int j = 0; j < ordinals.length; j++) {\n                // verify that the ordinal is recognized by the taxonomy\n                int ordinal = ordinals.ints[j] + partitionOffset;\n                assertTrue(\"should not have received dummy ordinal (\" + dummyOrdinal + \")\", dummyOrdinal != ordinal);\n                assertNotNull(\"missing category for ordinal \" + ordinal, taxoReader.getPath(ordinal));\n                foundOrdinals[ordinal] = true;\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    assertTrue(\"some fields which have docValues were not visited: \" + docValuesFields, docValuesFields.isEmpty());\n    \n    for (int i = 0; i < foundOrdinals.length; i++) {\n      assertTrue(\"ordinal \" + i + \" not visited\", foundOrdinals[i]);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc728b07df73b197e6d940d27f9b08b63918f13","date":1388834348,"type":4,"author":"Michael McCandless","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/util/TestFacetsPayloadMigrationReader#verifyIndexOrdinals(DirectoryReader,TaxonomyReader,FacetIndexingParams).mjava","sourceNew":null,"sourceOld":"  private void verifyIndexOrdinals(DirectoryReader indexReader, TaxonomyReader taxoReader, FacetIndexingParams fip) \n      throws IOException {\n    // verify that the ordinals in the index match the ones in the taxonomy, and vice versa\n    \n    // collect all fields which have DocValues, to assert later that all were\n    // visited i.e. that during migration we didn't add FieldInfos with no\n    // DocValues\n    HashSet<String> docValuesFields = new HashSet<String>();\n    for (AtomicReaderContext context : indexReader.leaves()) {\n      FieldInfos infos = context.reader().getFieldInfos();\n      for (FieldInfo info : infos) {\n        if (info.hasDocValues()) {\n          docValuesFields.add(info.name);\n        }\n      }\n    }\n    \n    // check that all visited ordinals are found in the taxonomy and vice versa\n    boolean[] foundOrdinals = new boolean[taxoReader.getSize()];\n    for (int i = 0; i < foundOrdinals.length; i++) {\n      foundOrdinals[i] = false; // init to be on the safe side\n    }\n    foundOrdinals[0] = true; // ROOT ordinals isn't indexed\n    // mark 'dummy' category ordinal as seen\n    int dummyOrdinal = taxoReader.getOrdinal(new CategoryPath(\"dummy\"));\n    if (dummyOrdinal > 0) {\n      foundOrdinals[dummyOrdinal] = true;\n    }\n    \n    int partitionSize = fip.getPartitionSize();\n    int numPartitions = (int) Math.ceil(taxoReader.getSize() / (double) partitionSize);\n    final IntsRef ordinals = new IntsRef(32);\n    for (String dim : DIMENSIONS) {\n      CategoryListParams clp = fip.getCategoryListParams(new CategoryPath(dim));\n      int partitionOffset = 0;\n      for (int partition = 0; partition < numPartitions; partition++, partitionOffset += partitionSize) {\n        final CategoryListIterator cli = clp.createCategoryListIterator(partition);\n        for (AtomicReaderContext context : indexReader.leaves()) {\n          if (cli.setNextReader(context)) { // not all fields may exist in all segments\n            // remove that field from the list of DocValues fields\n            docValuesFields.remove(clp.field + PartitionsUtils.partitionName(partition));\n            int maxDoc = context.reader().maxDoc();\n            for (int doc = 0; doc < maxDoc; doc++) {\n              cli.getOrdinals(doc, ordinals);\n              for (int j = 0; j < ordinals.length; j++) {\n                // verify that the ordinal is recognized by the taxonomy\n                int ordinal = ordinals.ints[j] + partitionOffset;\n                assertTrue(\"should not have received dummy ordinal (\" + dummyOrdinal + \")\", dummyOrdinal != ordinal);\n                assertNotNull(\"missing category for ordinal \" + ordinal, taxoReader.getPath(ordinal));\n                foundOrdinals[ordinal] = true;\n              }\n            }\n          }\n        }\n      }\n    }\n    \n    assertTrue(\"some fields which have docValues were not visited: \" + docValuesFields, docValuesFields.isEmpty());\n    \n    for (int i = 0; i < foundOrdinals.length; i++) {\n      assertTrue(\"ordinal \" + i + \" not visited\", foundOrdinals[i]);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"607428da722dcb3e86bbd11c63de8986e6275c36":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d33e19a97046248623a7591aeaa6547233fd15e2":["c190847801a50f4dd20fd639bdc29b54ea3b288b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cc728b07df73b197e6d940d27f9b08b63918f13":["607428da722dcb3e86bbd11c63de8986e6275c36","d33e19a97046248623a7591aeaa6547233fd15e2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"c190847801a50f4dd20fd639bdc29b54ea3b288b":["607428da722dcb3e86bbd11c63de8986e6275c36"]},"commit2Childs":{"607428da722dcb3e86bbd11c63de8986e6275c36":["3cc728b07df73b197e6d940d27f9b08b63918f13","c190847801a50f4dd20fd639bdc29b54ea3b288b"],"d33e19a97046248623a7591aeaa6547233fd15e2":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["607428da722dcb3e86bbd11c63de8986e6275c36"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c190847801a50f4dd20fd639bdc29b54ea3b288b":["d33e19a97046248623a7591aeaa6547233fd15e2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}