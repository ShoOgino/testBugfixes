{"path":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/ReplicaNode#finishNRTCopy(CopyJob,long).mjava","commits":[{"id":"0d49a158012a8ff48f328a4558e4bfcffbaed16f","date":1453677440,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/ReplicaNode#finishNRTCopy(CopyJob,long).mjava","pathOld":"/dev/null","sourceNew":"  void finishNRTCopy(CopyJob job, long startNS) throws IOException {\n    CopyState copyState = job.getCopyState();\n    message(\"top: finishNRTCopy: version=\" + copyState.version + (job.getFailed() ? \" FAILED\" : \"\") + \" job=\" + job);\n\n    // NOTE: if primary crashed while we were still copying then the job will hit an exc trying to read bytes for the files from the primary node,\n    // and the job will be marked as failed here:\n\n    synchronized (this) {\n\n      if (\"syncing\".equals(state)) {\n        state = \"idle\";\n      }\n\n      if (curNRTCopy == job) {\n        message(\"top: now clear curNRTCopy; job=\" + job);\n        curNRTCopy = null;\n      } else {\n        assert job.getFailed();\n        message(\"top: skip clear curNRTCopy: we were cancelled; job=\" + job);\n      }\n\n      if (job.getFailed()) {\n        return;\n      }\n\n      // Does final file renames:\n      job.finish();\n\n      // Turn byte[] back to SegmentInfos:\n      byte[] infosBytes = copyState.infosBytes;\n      SegmentInfos infos = SegmentInfos.readCommit(dir,\n                                                   new BufferedChecksumIndexInput(new ByteArrayIndexInput(\"SegmentInfos\", copyState.infosBytes)),\n                                                   copyState.gen);\n      assert infos.getVersion() == copyState.version;\n\n      message(\"  version=\" + infos.getVersion() + \" segments=\" + infos.toString());\n\n      // Cutover to new searcher:\n      if (mgr != null) {\n        ((SegmentInfosSearcherManager) mgr).setCurrentInfos(infos);\n      }\n\n      // Must first incRef new NRT files, then decRef old ones, to make sure we don't remove an NRT file that's in common to both:\n      Collection<String> newFiles = copyState.files.keySet();\n      message(\"top: incRef newNRTFiles=\" + newFiles);\n      deleter.incRef(newFiles);\n\n      // If any of our new files were previously copied merges, we clear them now, so we don't try to later delete a non-existent file:\n      pendingMergeFiles.removeAll(newFiles);\n      message(\"top: after remove from pending merges pendingMergeFiles=\" + pendingMergeFiles);\n\n      message(\"top: decRef lastNRTFiles=\" + lastNRTFiles);\n      deleter.decRef(lastNRTFiles);\n      lastNRTFiles.clear();\n      lastNRTFiles.addAll(newFiles);\n      message(\"top: set lastNRTFiles=\" + lastNRTFiles);\n\n      // At this point we can remove any completed merge segment files that we still do not reference.  This can happen when a merge\n      // finishes, copies its files out to us, but is then merged away (or dropped due to 100% deletions) before we ever cutover to it\n      // in an NRT point:\n      if (copyState.completedMergeFiles.isEmpty() == false) {\n        message(\"now remove-if-not-ref'd completed merge files: \" + copyState.completedMergeFiles);\n        for(String fileName : copyState.completedMergeFiles) {\n          if (pendingMergeFiles.contains(fileName)) {\n            pendingMergeFiles.remove(fileName);\n            deleter.deleteIfNoRef(fileName);\n          }\n        }\n      }\n\n      lastFileMetaData = copyState.files;\n\n      // It's a good time to delete pending files, since we just refreshed and some previously open files are now closed:\n      deleter.deletePending();\n    }\n\n    int markerCount;\n    IndexSearcher s = mgr.acquire();\n    try {\n      markerCount = s.search(new TermQuery(new Term(\"marker\", \"marker\")), 1).totalHits;\n    } finally {\n      mgr.release(s);\n    }\n\n    message(String.format(Locale.ROOT, \"top: done sync: took %.3fs for %s, opened NRT reader version=%d markerCount=%d\",\n                          (System.nanoTime()-startNS)/1000000000.0,\n                          bytesToString(job.getTotalBytesCopied()),\n                          copyState.version,\n                          markerCount));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["7047018dca394809a6c77a991eece1f1994b704e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ec317d5d3de749e12abcc9e6f976d765638fe9e2","date":1454411397,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/ReplicaNode#finishNRTCopy(CopyJob,long).mjava","pathOld":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/ReplicaNode#finishNRTCopy(CopyJob,long).mjava","sourceNew":"  void finishNRTCopy(CopyJob job, long startNS) throws IOException {\n    CopyState copyState = job.getCopyState();\n    message(\"top: finishNRTCopy: version=\" + copyState.version + (job.getFailed() ? \" FAILED\" : \"\") + \" job=\" + job);\n\n    // NOTE: if primary crashed while we were still copying then the job will hit an exc trying to read bytes for the files from the primary node,\n    // and the job will be marked as failed here:\n\n    synchronized (this) {\n\n      if (\"syncing\".equals(state)) {\n        state = \"idle\";\n      }\n\n      if (curNRTCopy == job) {\n        message(\"top: now clear curNRTCopy; job=\" + job);\n        curNRTCopy = null;\n      } else {\n        assert job.getFailed();\n        message(\"top: skip clear curNRTCopy: we were cancelled; job=\" + job);\n      }\n\n      if (job.getFailed()) {\n        return;\n      }\n\n      // Does final file renames:\n      job.finish();\n\n      // Turn byte[] back to SegmentInfos:\n      byte[] infosBytes = copyState.infosBytes;\n      SegmentInfos infos = SegmentInfos.readCommit(dir,\n                                                   new BufferedChecksumIndexInput(new ByteArrayIndexInput(\"SegmentInfos\", copyState.infosBytes)),\n                                                   copyState.gen);\n      assert infos.getVersion() == copyState.version;\n\n      message(\"  version=\" + infos.getVersion() + \" segments=\" + infos.toString());\n\n      // Cutover to new searcher:\n      if (mgr != null) {\n        ((SegmentInfosSearcherManager) mgr).setCurrentInfos(infos);\n      }\n\n      // Must first incRef new NRT files, then decRef old ones, to make sure we don't remove an NRT file that's in common to both:\n      Collection<String> newFiles = copyState.files.keySet();\n      message(\"top: incRef newNRTFiles=\" + newFiles);\n      deleter.incRef(newFiles);\n\n      // If any of our new files were previously copied merges, we clear them now, so we don't try to later delete a non-existent file:\n      pendingMergeFiles.removeAll(newFiles);\n      message(\"top: after remove from pending merges pendingMergeFiles=\" + pendingMergeFiles);\n\n      message(\"top: decRef lastNRTFiles=\" + lastNRTFiles);\n      deleter.decRef(lastNRTFiles);\n      lastNRTFiles.clear();\n      lastNRTFiles.addAll(newFiles);\n      message(\"top: set lastNRTFiles=\" + lastNRTFiles);\n\n      // At this point we can remove any completed merge segment files that we still do not reference.  This can happen when a merge\n      // finishes, copies its files out to us, but is then merged away (or dropped due to 100% deletions) before we ever cutover to it\n      // in an NRT point:\n      if (copyState.completedMergeFiles.isEmpty() == false) {\n        message(\"now remove-if-not-ref'd completed merge files: \" + copyState.completedMergeFiles);\n        for(String fileName : copyState.completedMergeFiles) {\n          if (pendingMergeFiles.contains(fileName)) {\n            pendingMergeFiles.remove(fileName);\n            deleter.deleteIfNoRef(fileName);\n          }\n        }\n      }\n\n      lastFileMetaData = copyState.files;\n\n      // It's a good time to delete pending files, since we just refreshed and some previously open files are now closed:\n      deleter.deletePending();\n    }\n\n    int markerCount;\n    IndexSearcher s = mgr.acquire();\n    try {\n      markerCount = s.count(new TermQuery(new Term(\"marker\", \"marker\")));\n    } finally {\n      mgr.release(s);\n    }\n\n    message(String.format(Locale.ROOT, \"top: done sync: took %.3fs for %s, opened NRT reader version=%d markerCount=%d\",\n                          (System.nanoTime()-startNS)/1000000000.0,\n                          bytesToString(job.getTotalBytesCopied()),\n                          copyState.version,\n                          markerCount));\n  }\n\n","sourceOld":"  void finishNRTCopy(CopyJob job, long startNS) throws IOException {\n    CopyState copyState = job.getCopyState();\n    message(\"top: finishNRTCopy: version=\" + copyState.version + (job.getFailed() ? \" FAILED\" : \"\") + \" job=\" + job);\n\n    // NOTE: if primary crashed while we were still copying then the job will hit an exc trying to read bytes for the files from the primary node,\n    // and the job will be marked as failed here:\n\n    synchronized (this) {\n\n      if (\"syncing\".equals(state)) {\n        state = \"idle\";\n      }\n\n      if (curNRTCopy == job) {\n        message(\"top: now clear curNRTCopy; job=\" + job);\n        curNRTCopy = null;\n      } else {\n        assert job.getFailed();\n        message(\"top: skip clear curNRTCopy: we were cancelled; job=\" + job);\n      }\n\n      if (job.getFailed()) {\n        return;\n      }\n\n      // Does final file renames:\n      job.finish();\n\n      // Turn byte[] back to SegmentInfos:\n      byte[] infosBytes = copyState.infosBytes;\n      SegmentInfos infos = SegmentInfos.readCommit(dir,\n                                                   new BufferedChecksumIndexInput(new ByteArrayIndexInput(\"SegmentInfos\", copyState.infosBytes)),\n                                                   copyState.gen);\n      assert infos.getVersion() == copyState.version;\n\n      message(\"  version=\" + infos.getVersion() + \" segments=\" + infos.toString());\n\n      // Cutover to new searcher:\n      if (mgr != null) {\n        ((SegmentInfosSearcherManager) mgr).setCurrentInfos(infos);\n      }\n\n      // Must first incRef new NRT files, then decRef old ones, to make sure we don't remove an NRT file that's in common to both:\n      Collection<String> newFiles = copyState.files.keySet();\n      message(\"top: incRef newNRTFiles=\" + newFiles);\n      deleter.incRef(newFiles);\n\n      // If any of our new files were previously copied merges, we clear them now, so we don't try to later delete a non-existent file:\n      pendingMergeFiles.removeAll(newFiles);\n      message(\"top: after remove from pending merges pendingMergeFiles=\" + pendingMergeFiles);\n\n      message(\"top: decRef lastNRTFiles=\" + lastNRTFiles);\n      deleter.decRef(lastNRTFiles);\n      lastNRTFiles.clear();\n      lastNRTFiles.addAll(newFiles);\n      message(\"top: set lastNRTFiles=\" + lastNRTFiles);\n\n      // At this point we can remove any completed merge segment files that we still do not reference.  This can happen when a merge\n      // finishes, copies its files out to us, but is then merged away (or dropped due to 100% deletions) before we ever cutover to it\n      // in an NRT point:\n      if (copyState.completedMergeFiles.isEmpty() == false) {\n        message(\"now remove-if-not-ref'd completed merge files: \" + copyState.completedMergeFiles);\n        for(String fileName : copyState.completedMergeFiles) {\n          if (pendingMergeFiles.contains(fileName)) {\n            pendingMergeFiles.remove(fileName);\n            deleter.deleteIfNoRef(fileName);\n          }\n        }\n      }\n\n      lastFileMetaData = copyState.files;\n\n      // It's a good time to delete pending files, since we just refreshed and some previously open files are now closed:\n      deleter.deletePending();\n    }\n\n    int markerCount;\n    IndexSearcher s = mgr.acquire();\n    try {\n      markerCount = s.search(new TermQuery(new Term(\"marker\", \"marker\")), 1).totalHits;\n    } finally {\n      mgr.release(s);\n    }\n\n    message(String.format(Locale.ROOT, \"top: done sync: took %.3fs for %s, opened NRT reader version=%d markerCount=%d\",\n                          (System.nanoTime()-startNS)/1000000000.0,\n                          bytesToString(job.getTotalBytesCopied()),\n                          copyState.version,\n                          markerCount));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b72a3c8c250ce67d9dd59e06316f982cd77bdb3c","date":1454874368,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/ReplicaNode#finishNRTCopy(CopyJob,long).mjava","pathOld":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/ReplicaNode#finishNRTCopy(CopyJob,long).mjava","sourceNew":"  void finishNRTCopy(CopyJob job, long startNS) throws IOException {\n    CopyState copyState = job.getCopyState();\n    message(\"top: finishNRTCopy: version=\" + copyState.version + (job.getFailed() ? \" FAILED\" : \"\") + \" job=\" + job);\n\n    // NOTE: if primary crashed while we were still copying then the job will hit an exc trying to read bytes for the files from the primary node,\n    // and the job will be marked as failed here:\n\n    synchronized (this) {\n\n      if (\"syncing\".equals(state)) {\n        state = \"idle\";\n      }\n\n      if (curNRTCopy == job) {\n        message(\"top: now clear curNRTCopy; job=\" + job);\n        curNRTCopy = null;\n      } else {\n        assert job.getFailed();\n        message(\"top: skip clear curNRTCopy: we were cancelled; job=\" + job);\n      }\n\n      if (job.getFailed()) {\n        return;\n      }\n\n      // Does final file renames:\n      job.finish();\n\n      // Turn byte[] back to SegmentInfos:\n      byte[] infosBytes = copyState.infosBytes;\n      SegmentInfos infos = SegmentInfos.readCommit(dir,\n                                                   new BufferedChecksumIndexInput(new ByteArrayIndexInput(\"SegmentInfos\", copyState.infosBytes)),\n                                                   copyState.gen);\n      assert infos.getVersion() == copyState.version;\n\n      message(\"  version=\" + infos.getVersion() + \" segments=\" + infos.toString());\n\n      // Cutover to new searcher:\n      if (mgr != null) {\n        ((SegmentInfosSearcherManager) mgr).setCurrentInfos(infos);\n      }\n\n      // Must first incRef new NRT files, then decRef old ones, to make sure we don't remove an NRT file that's in common to both:\n      Collection<String> newFiles = copyState.files.keySet();\n      message(\"top: incRef newNRTFiles=\" + newFiles);\n      deleter.incRef(newFiles);\n\n      // If any of our new files were previously copied merges, we clear them now, so we don't try to later delete a non-existent file:\n      pendingMergeFiles.removeAll(newFiles);\n      message(\"top: after remove from pending merges pendingMergeFiles=\" + pendingMergeFiles);\n\n      message(\"top: decRef lastNRTFiles=\" + lastNRTFiles);\n      deleter.decRef(lastNRTFiles);\n      lastNRTFiles.clear();\n      lastNRTFiles.addAll(newFiles);\n      message(\"top: set lastNRTFiles=\" + lastNRTFiles);\n\n      // At this point we can remove any completed merge segment files that we still do not reference.  This can happen when a merge\n      // finishes, copies its files out to us, but is then merged away (or dropped due to 100% deletions) before we ever cutover to it\n      // in an NRT point:\n      if (copyState.completedMergeFiles.isEmpty() == false) {\n        message(\"now remove-if-not-ref'd completed merge files: \" + copyState.completedMergeFiles);\n        for(String fileName : copyState.completedMergeFiles) {\n          if (pendingMergeFiles.contains(fileName)) {\n            pendingMergeFiles.remove(fileName);\n            deleter.deleteIfNoRef(fileName);\n          }\n        }\n      }\n\n      lastFileMetaData = copyState.files;\n    }\n\n    int markerCount;\n    IndexSearcher s = mgr.acquire();\n    try {\n      markerCount = s.count(new TermQuery(new Term(\"marker\", \"marker\")));\n    } finally {\n      mgr.release(s);\n    }\n\n    message(String.format(Locale.ROOT, \"top: done sync: took %.3fs for %s, opened NRT reader version=%d markerCount=%d\",\n                          (System.nanoTime()-startNS)/1000000000.0,\n                          bytesToString(job.getTotalBytesCopied()),\n                          copyState.version,\n                          markerCount));\n  }\n\n","sourceOld":"  void finishNRTCopy(CopyJob job, long startNS) throws IOException {\n    CopyState copyState = job.getCopyState();\n    message(\"top: finishNRTCopy: version=\" + copyState.version + (job.getFailed() ? \" FAILED\" : \"\") + \" job=\" + job);\n\n    // NOTE: if primary crashed while we were still copying then the job will hit an exc trying to read bytes for the files from the primary node,\n    // and the job will be marked as failed here:\n\n    synchronized (this) {\n\n      if (\"syncing\".equals(state)) {\n        state = \"idle\";\n      }\n\n      if (curNRTCopy == job) {\n        message(\"top: now clear curNRTCopy; job=\" + job);\n        curNRTCopy = null;\n      } else {\n        assert job.getFailed();\n        message(\"top: skip clear curNRTCopy: we were cancelled; job=\" + job);\n      }\n\n      if (job.getFailed()) {\n        return;\n      }\n\n      // Does final file renames:\n      job.finish();\n\n      // Turn byte[] back to SegmentInfos:\n      byte[] infosBytes = copyState.infosBytes;\n      SegmentInfos infos = SegmentInfos.readCommit(dir,\n                                                   new BufferedChecksumIndexInput(new ByteArrayIndexInput(\"SegmentInfos\", copyState.infosBytes)),\n                                                   copyState.gen);\n      assert infos.getVersion() == copyState.version;\n\n      message(\"  version=\" + infos.getVersion() + \" segments=\" + infos.toString());\n\n      // Cutover to new searcher:\n      if (mgr != null) {\n        ((SegmentInfosSearcherManager) mgr).setCurrentInfos(infos);\n      }\n\n      // Must first incRef new NRT files, then decRef old ones, to make sure we don't remove an NRT file that's in common to both:\n      Collection<String> newFiles = copyState.files.keySet();\n      message(\"top: incRef newNRTFiles=\" + newFiles);\n      deleter.incRef(newFiles);\n\n      // If any of our new files were previously copied merges, we clear them now, so we don't try to later delete a non-existent file:\n      pendingMergeFiles.removeAll(newFiles);\n      message(\"top: after remove from pending merges pendingMergeFiles=\" + pendingMergeFiles);\n\n      message(\"top: decRef lastNRTFiles=\" + lastNRTFiles);\n      deleter.decRef(lastNRTFiles);\n      lastNRTFiles.clear();\n      lastNRTFiles.addAll(newFiles);\n      message(\"top: set lastNRTFiles=\" + lastNRTFiles);\n\n      // At this point we can remove any completed merge segment files that we still do not reference.  This can happen when a merge\n      // finishes, copies its files out to us, but is then merged away (or dropped due to 100% deletions) before we ever cutover to it\n      // in an NRT point:\n      if (copyState.completedMergeFiles.isEmpty() == false) {\n        message(\"now remove-if-not-ref'd completed merge files: \" + copyState.completedMergeFiles);\n        for(String fileName : copyState.completedMergeFiles) {\n          if (pendingMergeFiles.contains(fileName)) {\n            pendingMergeFiles.remove(fileName);\n            deleter.deleteIfNoRef(fileName);\n          }\n        }\n      }\n\n      lastFileMetaData = copyState.files;\n\n      // It's a good time to delete pending files, since we just refreshed and some previously open files are now closed:\n      deleter.deletePending();\n    }\n\n    int markerCount;\n    IndexSearcher s = mgr.acquire();\n    try {\n      markerCount = s.count(new TermQuery(new Term(\"marker\", \"marker\")));\n    } finally {\n      mgr.release(s);\n    }\n\n    message(String.format(Locale.ROOT, \"top: done sync: took %.3fs for %s, opened NRT reader version=%d markerCount=%d\",\n                          (System.nanoTime()-startNS)/1000000000.0,\n                          bytesToString(job.getTotalBytesCopied()),\n                          copyState.version,\n                          markerCount));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"68496c2200e559fb7802f7575427b7a482659afb","date":1455207618,"type":0,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/ReplicaNode#finishNRTCopy(CopyJob,long).mjava","pathOld":"/dev/null","sourceNew":"  void finishNRTCopy(CopyJob job, long startNS) throws IOException {\n    CopyState copyState = job.getCopyState();\n    message(\"top: finishNRTCopy: version=\" + copyState.version + (job.getFailed() ? \" FAILED\" : \"\") + \" job=\" + job);\n\n    // NOTE: if primary crashed while we were still copying then the job will hit an exc trying to read bytes for the files from the primary node,\n    // and the job will be marked as failed here:\n\n    synchronized (this) {\n\n      if (\"syncing\".equals(state)) {\n        state = \"idle\";\n      }\n\n      if (curNRTCopy == job) {\n        message(\"top: now clear curNRTCopy; job=\" + job);\n        curNRTCopy = null;\n      } else {\n        assert job.getFailed();\n        message(\"top: skip clear curNRTCopy: we were cancelled; job=\" + job);\n      }\n\n      if (job.getFailed()) {\n        return;\n      }\n\n      // Does final file renames:\n      job.finish();\n\n      // Turn byte[] back to SegmentInfos:\n      byte[] infosBytes = copyState.infosBytes;\n      SegmentInfos infos = SegmentInfos.readCommit(dir,\n                                                   new BufferedChecksumIndexInput(new ByteArrayIndexInput(\"SegmentInfos\", copyState.infosBytes)),\n                                                   copyState.gen);\n      assert infos.getVersion() == copyState.version;\n\n      message(\"  version=\" + infos.getVersion() + \" segments=\" + infos.toString());\n\n      // Cutover to new searcher:\n      if (mgr != null) {\n        ((SegmentInfosSearcherManager) mgr).setCurrentInfos(infos);\n      }\n\n      // Must first incRef new NRT files, then decRef old ones, to make sure we don't remove an NRT file that's in common to both:\n      Collection<String> newFiles = copyState.files.keySet();\n      message(\"top: incRef newNRTFiles=\" + newFiles);\n      deleter.incRef(newFiles);\n\n      // If any of our new files were previously copied merges, we clear them now, so we don't try to later delete a non-existent file:\n      pendingMergeFiles.removeAll(newFiles);\n      message(\"top: after remove from pending merges pendingMergeFiles=\" + pendingMergeFiles);\n\n      message(\"top: decRef lastNRTFiles=\" + lastNRTFiles);\n      deleter.decRef(lastNRTFiles);\n      lastNRTFiles.clear();\n      lastNRTFiles.addAll(newFiles);\n      message(\"top: set lastNRTFiles=\" + lastNRTFiles);\n\n      // At this point we can remove any completed merge segment files that we still do not reference.  This can happen when a merge\n      // finishes, copies its files out to us, but is then merged away (or dropped due to 100% deletions) before we ever cutover to it\n      // in an NRT point:\n      if (copyState.completedMergeFiles.isEmpty() == false) {\n        message(\"now remove-if-not-ref'd completed merge files: \" + copyState.completedMergeFiles);\n        for(String fileName : copyState.completedMergeFiles) {\n          if (pendingMergeFiles.contains(fileName)) {\n            pendingMergeFiles.remove(fileName);\n            deleter.deleteIfNoRef(fileName);\n          }\n        }\n      }\n\n      lastFileMetaData = copyState.files;\n    }\n\n    int markerCount;\n    IndexSearcher s = mgr.acquire();\n    try {\n      markerCount = s.count(new TermQuery(new Term(\"marker\", \"marker\")));\n    } finally {\n      mgr.release(s);\n    }\n\n    message(String.format(Locale.ROOT, \"top: done sync: took %.3fs for %s, opened NRT reader version=%d markerCount=%d\",\n                          (System.nanoTime()-startNS)/1000000000.0,\n                          bytesToString(job.getTotalBytesCopied()),\n                          copyState.version,\n                          markerCount));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"69e8e94253e98b8836cfd91172f9c059641f21fd","date":1509618119,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/ReplicaNode#finishNRTCopy(CopyJob,long).mjava","pathOld":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/ReplicaNode#finishNRTCopy(CopyJob,long).mjava","sourceNew":"  protected void finishNRTCopy(CopyJob job, long startNS) throws IOException {\n    CopyState copyState = job.getCopyState();\n    message(\"top: finishNRTCopy: version=\" + copyState.version + (job.getFailed() ? \" FAILED\" : \"\") + \" job=\" + job);\n\n    // NOTE: if primary crashed while we were still copying then the job will hit an exc trying to read bytes for the files from the primary node,\n    // and the job will be marked as failed here:\n\n    synchronized (this) {\n\n      if (\"syncing\".equals(state)) {\n        state = \"idle\";\n      }\n\n      if (curNRTCopy == job) {\n        message(\"top: now clear curNRTCopy; job=\" + job);\n        curNRTCopy = null;\n      } else {\n        assert job.getFailed();\n        message(\"top: skip clear curNRTCopy: we were cancelled; job=\" + job);\n      }\n\n      if (job.getFailed()) {\n        return;\n      }\n\n      // Does final file renames:\n      job.finish();\n\n      // Turn byte[] back to SegmentInfos:\n      byte[] infosBytes = copyState.infosBytes;\n      SegmentInfos infos = SegmentInfos.readCommit(dir,\n                                                   new BufferedChecksumIndexInput(new ByteArrayIndexInput(\"SegmentInfos\", copyState.infosBytes)),\n                                                   copyState.gen);\n      assert infos.getVersion() == copyState.version;\n\n      message(\"  version=\" + infos.getVersion() + \" segments=\" + infos.toString());\n\n      // Cutover to new searcher:\n      if (mgr != null) {\n        ((SegmentInfosSearcherManager) mgr).setCurrentInfos(infos);\n      }\n\n      // Must first incRef new NRT files, then decRef old ones, to make sure we don't remove an NRT file that's in common to both:\n      Collection<String> newFiles = copyState.files.keySet();\n      message(\"top: incRef newNRTFiles=\" + newFiles);\n      deleter.incRef(newFiles);\n\n      // If any of our new files were previously copied merges, we clear them now, so we don't try to later delete a non-existent file:\n      pendingMergeFiles.removeAll(newFiles);\n      message(\"top: after remove from pending merges pendingMergeFiles=\" + pendingMergeFiles);\n\n      message(\"top: decRef lastNRTFiles=\" + lastNRTFiles);\n      deleter.decRef(lastNRTFiles);\n      lastNRTFiles.clear();\n      lastNRTFiles.addAll(newFiles);\n      message(\"top: set lastNRTFiles=\" + lastNRTFiles);\n\n      // At this point we can remove any completed merge segment files that we still do not reference.  This can happen when a merge\n      // finishes, copies its files out to us, but is then merged away (or dropped due to 100% deletions) before we ever cutover to it\n      // in an NRT point:\n      if (copyState.completedMergeFiles.isEmpty() == false) {\n        message(\"now remove-if-not-ref'd completed merge files: \" + copyState.completedMergeFiles);\n        for(String fileName : copyState.completedMergeFiles) {\n          if (pendingMergeFiles.contains(fileName)) {\n            pendingMergeFiles.remove(fileName);\n            deleter.deleteIfNoRef(fileName);\n          }\n        }\n      }\n\n      lastFileMetaData = copyState.files;\n    }\n\n    int markerCount;\n    IndexSearcher s = mgr.acquire();\n    try {\n      markerCount = s.count(new TermQuery(new Term(\"marker\", \"marker\")));\n    } finally {\n      mgr.release(s);\n    }\n\n    message(String.format(Locale.ROOT, \"top: done sync: took %.3fs for %s, opened NRT reader version=%d markerCount=%d\",\n                          (System.nanoTime()-startNS)/1000000000.0,\n                          bytesToString(job.getTotalBytesCopied()),\n                          copyState.version,\n                          markerCount));\n  }\n\n","sourceOld":"  void finishNRTCopy(CopyJob job, long startNS) throws IOException {\n    CopyState copyState = job.getCopyState();\n    message(\"top: finishNRTCopy: version=\" + copyState.version + (job.getFailed() ? \" FAILED\" : \"\") + \" job=\" + job);\n\n    // NOTE: if primary crashed while we were still copying then the job will hit an exc trying to read bytes for the files from the primary node,\n    // and the job will be marked as failed here:\n\n    synchronized (this) {\n\n      if (\"syncing\".equals(state)) {\n        state = \"idle\";\n      }\n\n      if (curNRTCopy == job) {\n        message(\"top: now clear curNRTCopy; job=\" + job);\n        curNRTCopy = null;\n      } else {\n        assert job.getFailed();\n        message(\"top: skip clear curNRTCopy: we were cancelled; job=\" + job);\n      }\n\n      if (job.getFailed()) {\n        return;\n      }\n\n      // Does final file renames:\n      job.finish();\n\n      // Turn byte[] back to SegmentInfos:\n      byte[] infosBytes = copyState.infosBytes;\n      SegmentInfos infos = SegmentInfos.readCommit(dir,\n                                                   new BufferedChecksumIndexInput(new ByteArrayIndexInput(\"SegmentInfos\", copyState.infosBytes)),\n                                                   copyState.gen);\n      assert infos.getVersion() == copyState.version;\n\n      message(\"  version=\" + infos.getVersion() + \" segments=\" + infos.toString());\n\n      // Cutover to new searcher:\n      if (mgr != null) {\n        ((SegmentInfosSearcherManager) mgr).setCurrentInfos(infos);\n      }\n\n      // Must first incRef new NRT files, then decRef old ones, to make sure we don't remove an NRT file that's in common to both:\n      Collection<String> newFiles = copyState.files.keySet();\n      message(\"top: incRef newNRTFiles=\" + newFiles);\n      deleter.incRef(newFiles);\n\n      // If any of our new files were previously copied merges, we clear them now, so we don't try to later delete a non-existent file:\n      pendingMergeFiles.removeAll(newFiles);\n      message(\"top: after remove from pending merges pendingMergeFiles=\" + pendingMergeFiles);\n\n      message(\"top: decRef lastNRTFiles=\" + lastNRTFiles);\n      deleter.decRef(lastNRTFiles);\n      lastNRTFiles.clear();\n      lastNRTFiles.addAll(newFiles);\n      message(\"top: set lastNRTFiles=\" + lastNRTFiles);\n\n      // At this point we can remove any completed merge segment files that we still do not reference.  This can happen when a merge\n      // finishes, copies its files out to us, but is then merged away (or dropped due to 100% deletions) before we ever cutover to it\n      // in an NRT point:\n      if (copyState.completedMergeFiles.isEmpty() == false) {\n        message(\"now remove-if-not-ref'd completed merge files: \" + copyState.completedMergeFiles);\n        for(String fileName : copyState.completedMergeFiles) {\n          if (pendingMergeFiles.contains(fileName)) {\n            pendingMergeFiles.remove(fileName);\n            deleter.deleteIfNoRef(fileName);\n          }\n        }\n      }\n\n      lastFileMetaData = copyState.files;\n    }\n\n    int markerCount;\n    IndexSearcher s = mgr.acquire();\n    try {\n      markerCount = s.count(new TermQuery(new Term(\"marker\", \"marker\")));\n    } finally {\n      mgr.release(s);\n    }\n\n    message(String.format(Locale.ROOT, \"top: done sync: took %.3fs for %s, opened NRT reader version=%d markerCount=%d\",\n                          (System.nanoTime()-startNS)/1000000000.0,\n                          bytesToString(job.getTotalBytesCopied()),\n                          copyState.version,\n                          markerCount));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7047018dca394809a6c77a991eece1f1994b704e","date":1541865268,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/ReplicaNode#finishNRTCopy(CopyJob,long).mjava","pathOld":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/ReplicaNode#finishNRTCopy(CopyJob,long).mjava","sourceNew":"  protected void finishNRTCopy(CopyJob job, long startNS) throws IOException {\n    CopyState copyState = job.getCopyState();\n    message(\"top: finishNRTCopy: version=\" + copyState.version + (job.getFailed() ? \" FAILED\" : \"\") + \" job=\" + job);\n\n    // NOTE: if primary crashed while we were still copying then the job will hit an exc trying to read bytes for the files from the primary node,\n    // and the job will be marked as failed here:\n\n    synchronized (this) {\n\n      if (\"syncing\".equals(state)) {\n        state = \"idle\";\n      }\n\n      if (curNRTCopy == job) {\n        message(\"top: now clear curNRTCopy; job=\" + job);\n        curNRTCopy = null;\n      } else {\n        assert job.getFailed();\n        message(\"top: skip clear curNRTCopy: we were cancelled; job=\" + job);\n      }\n\n      if (job.getFailed()) {\n        return;\n      }\n\n      // Does final file renames:\n      job.finish();\n\n      // Turn byte[] back to SegmentInfos:\n      byte[] infosBytes = copyState.infosBytes;\n      SegmentInfos infos = SegmentInfos.readCommit(dir,\n                                                   toIndexInput(copyState.infosBytes),\n                                                   copyState.gen);\n      assert infos.getVersion() == copyState.version;\n\n      message(\"  version=\" + infos.getVersion() + \" segments=\" + infos.toString());\n\n      // Cutover to new searcher:\n      if (mgr != null) {\n        ((SegmentInfosSearcherManager) mgr).setCurrentInfos(infos);\n      }\n\n      // Must first incRef new NRT files, then decRef old ones, to make sure we don't remove an NRT file that's in common to both:\n      Collection<String> newFiles = copyState.files.keySet();\n      message(\"top: incRef newNRTFiles=\" + newFiles);\n      deleter.incRef(newFiles);\n\n      // If any of our new files were previously copied merges, we clear them now, so we don't try to later delete a non-existent file:\n      pendingMergeFiles.removeAll(newFiles);\n      message(\"top: after remove from pending merges pendingMergeFiles=\" + pendingMergeFiles);\n\n      message(\"top: decRef lastNRTFiles=\" + lastNRTFiles);\n      deleter.decRef(lastNRTFiles);\n      lastNRTFiles.clear();\n      lastNRTFiles.addAll(newFiles);\n      message(\"top: set lastNRTFiles=\" + lastNRTFiles);\n\n      // At this point we can remove any completed merge segment files that we still do not reference.  This can happen when a merge\n      // finishes, copies its files out to us, but is then merged away (or dropped due to 100% deletions) before we ever cutover to it\n      // in an NRT point:\n      if (copyState.completedMergeFiles.isEmpty() == false) {\n        message(\"now remove-if-not-ref'd completed merge files: \" + copyState.completedMergeFiles);\n        for(String fileName : copyState.completedMergeFiles) {\n          if (pendingMergeFiles.contains(fileName)) {\n            pendingMergeFiles.remove(fileName);\n            deleter.deleteIfNoRef(fileName);\n          }\n        }\n      }\n\n      lastFileMetaData = copyState.files;\n    }\n\n    int markerCount;\n    IndexSearcher s = mgr.acquire();\n    try {\n      markerCount = s.count(new TermQuery(new Term(\"marker\", \"marker\")));\n    } finally {\n      mgr.release(s);\n    }\n\n    message(String.format(Locale.ROOT, \"top: done sync: took %.3fs for %s, opened NRT reader version=%d markerCount=%d\",\n                          (System.nanoTime()-startNS)/1000000000.0,\n                          bytesToString(job.getTotalBytesCopied()),\n                          copyState.version,\n                          markerCount));\n  }\n\n","sourceOld":"  protected void finishNRTCopy(CopyJob job, long startNS) throws IOException {\n    CopyState copyState = job.getCopyState();\n    message(\"top: finishNRTCopy: version=\" + copyState.version + (job.getFailed() ? \" FAILED\" : \"\") + \" job=\" + job);\n\n    // NOTE: if primary crashed while we were still copying then the job will hit an exc trying to read bytes for the files from the primary node,\n    // and the job will be marked as failed here:\n\n    synchronized (this) {\n\n      if (\"syncing\".equals(state)) {\n        state = \"idle\";\n      }\n\n      if (curNRTCopy == job) {\n        message(\"top: now clear curNRTCopy; job=\" + job);\n        curNRTCopy = null;\n      } else {\n        assert job.getFailed();\n        message(\"top: skip clear curNRTCopy: we were cancelled; job=\" + job);\n      }\n\n      if (job.getFailed()) {\n        return;\n      }\n\n      // Does final file renames:\n      job.finish();\n\n      // Turn byte[] back to SegmentInfos:\n      byte[] infosBytes = copyState.infosBytes;\n      SegmentInfos infos = SegmentInfos.readCommit(dir,\n                                                   new BufferedChecksumIndexInput(new ByteArrayIndexInput(\"SegmentInfos\", copyState.infosBytes)),\n                                                   copyState.gen);\n      assert infos.getVersion() == copyState.version;\n\n      message(\"  version=\" + infos.getVersion() + \" segments=\" + infos.toString());\n\n      // Cutover to new searcher:\n      if (mgr != null) {\n        ((SegmentInfosSearcherManager) mgr).setCurrentInfos(infos);\n      }\n\n      // Must first incRef new NRT files, then decRef old ones, to make sure we don't remove an NRT file that's in common to both:\n      Collection<String> newFiles = copyState.files.keySet();\n      message(\"top: incRef newNRTFiles=\" + newFiles);\n      deleter.incRef(newFiles);\n\n      // If any of our new files were previously copied merges, we clear them now, so we don't try to later delete a non-existent file:\n      pendingMergeFiles.removeAll(newFiles);\n      message(\"top: after remove from pending merges pendingMergeFiles=\" + pendingMergeFiles);\n\n      message(\"top: decRef lastNRTFiles=\" + lastNRTFiles);\n      deleter.decRef(lastNRTFiles);\n      lastNRTFiles.clear();\n      lastNRTFiles.addAll(newFiles);\n      message(\"top: set lastNRTFiles=\" + lastNRTFiles);\n\n      // At this point we can remove any completed merge segment files that we still do not reference.  This can happen when a merge\n      // finishes, copies its files out to us, but is then merged away (or dropped due to 100% deletions) before we ever cutover to it\n      // in an NRT point:\n      if (copyState.completedMergeFiles.isEmpty() == false) {\n        message(\"now remove-if-not-ref'd completed merge files: \" + copyState.completedMergeFiles);\n        for(String fileName : copyState.completedMergeFiles) {\n          if (pendingMergeFiles.contains(fileName)) {\n            pendingMergeFiles.remove(fileName);\n            deleter.deleteIfNoRef(fileName);\n          }\n        }\n      }\n\n      lastFileMetaData = copyState.files;\n    }\n\n    int markerCount;\n    IndexSearcher s = mgr.acquire();\n    try {\n      markerCount = s.count(new TermQuery(new Term(\"marker\", \"marker\")));\n    } finally {\n      mgr.release(s);\n    }\n\n    message(String.format(Locale.ROOT, \"top: done sync: took %.3fs for %s, opened NRT reader version=%d markerCount=%d\",\n                          (System.nanoTime()-startNS)/1000000000.0,\n                          bytesToString(job.getTotalBytesCopied()),\n                          copyState.version,\n                          markerCount));\n  }\n\n","bugFix":["0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b72a3c8c250ce67d9dd59e06316f982cd77bdb3c":["ec317d5d3de749e12abcc9e6f976d765638fe9e2"],"ec317d5d3de749e12abcc9e6f976d765638fe9e2":["0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7047018dca394809a6c77a991eece1f1994b704e":["69e8e94253e98b8836cfd91172f9c059641f21fd"],"68496c2200e559fb7802f7575427b7a482659afb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b72a3c8c250ce67d9dd59e06316f982cd77bdb3c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7047018dca394809a6c77a991eece1f1994b704e"],"69e8e94253e98b8836cfd91172f9c059641f21fd":["68496c2200e559fb7802f7575427b7a482659afb"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"b72a3c8c250ce67d9dd59e06316f982cd77bdb3c":["68496c2200e559fb7802f7575427b7a482659afb"],"ec317d5d3de749e12abcc9e6f976d765638fe9e2":["b72a3c8c250ce67d9dd59e06316f982cd77bdb3c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["68496c2200e559fb7802f7575427b7a482659afb","0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"7047018dca394809a6c77a991eece1f1994b704e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"68496c2200e559fb7802f7575427b7a482659afb":["69e8e94253e98b8836cfd91172f9c059641f21fd"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["ec317d5d3de749e12abcc9e6f976d765638fe9e2"],"69e8e94253e98b8836cfd91172f9c059641f21fd":["7047018dca394809a6c77a991eece1f1994b704e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}