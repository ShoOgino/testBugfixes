{"path":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumFromReader(LeafReader,int).mjava","commits":[{"id":"8764ca7bb74ee716c839b9545a93ec4a578c2005","date":1517564468,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumFromReader(LeafReader,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","sourceNew":"  protected OffsetsEnum createOffsetsEnumFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(field);\n    if (termsIndex == null) {\n      return OffsetsEnum.EMPTY;\n    }\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(terms.length + automata.length);\n\n    // Handle position insensitive terms (a subset of this.terms field):\n    final BytesRef[] insensitiveTerms;\n    if (phraseHelper.hasPositionSensitivity()) {\n      insensitiveTerms = phraseHelper.getAllPositionInsensitiveTerms();\n      assert insensitiveTerms.length <= terms.length : \"insensitive terms should be smaller set of all terms\";\n    } else {\n      insensitiveTerms = terms;\n    }\n    if (insensitiveTerms.length > 0) {\n      createOffsetsEnumsForTerms(insensitiveTerms, termsIndex, doc, offsetsEnums);\n    }\n\n    // Handle spans\n    if (phraseHelper.hasPositionSensitivity()) {\n      phraseHelper.createOffsetsEnumsForSpans(leafReader, doc, offsetsEnums);\n    }\n\n    // Handle automata\n    if (automata.length > 0) {\n      createOffsetsEnumsForAutomata(termsIndex, doc, offsetsEnums);\n    }\n\n    return new OffsetsEnum.MultiOffsetsEnum(offsetsEnums);\n  }\n\n","sourceOld":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(field);\n    if (termsIndex == null) {\n      return Collections.emptyList();\n    }\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(terms.length + automata.length);\n\n    // Handle position insensitive terms (a subset of this.terms field):\n    final BytesRef[] insensitiveTerms;\n    if (phraseHelper.hasPositionSensitivity()) {\n      insensitiveTerms = phraseHelper.getAllPositionInsensitiveTerms();\n      assert insensitiveTerms.length <= terms.length : \"insensitive terms should be smaller set of all terms\";\n    } else {\n      insensitiveTerms = terms;\n    }\n    if (insensitiveTerms.length > 0) {\n      createOffsetsEnumsForTerms(insensitiveTerms, termsIndex, doc, offsetsEnums);\n    }\n\n    // Handle spans\n    if (phraseHelper.hasPositionSensitivity()) {\n      phraseHelper.createOffsetsEnumsForSpans(leafReader, doc, offsetsEnums);\n    }\n\n    // Handle automata\n    if (automata.length > 0) {\n      createOffsetsEnumsForAutomata(termsIndex, doc, offsetsEnums);\n    }\n\n    return offsetsEnums;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"795822cce6616d4035b5a4bdbb6c113ea2f715ba","date":1535599765,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumFromReader(LeafReader,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumFromReader(LeafReader,int).mjava","sourceNew":"  protected OffsetsEnum createOffsetsEnumFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(getField());\n    if (termsIndex == null) {\n      return OffsetsEnum.EMPTY;\n    }\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>();\n\n    // Handle Weight.matches approach\n    if (components.getHighlightFlags().contains(UnifiedHighlighter.HighlightFlag.WEIGHT_MATCHES)) {\n\n      createOffsetsEnumsWeightMatcher(leafReader, doc, offsetsEnums);\n\n    } else { // classic approach\n\n      // Handle position insensitive terms (a subset of this.terms field):\n      final BytesRef[] insensitiveTerms;\n      final PhraseHelper phraseHelper = components.getPhraseHelper();\n      final BytesRef[] terms = components.getTerms();\n      if (phraseHelper.hasPositionSensitivity()) {\n        insensitiveTerms = phraseHelper.getAllPositionInsensitiveTerms();\n        assert insensitiveTerms.length <= terms.length : \"insensitive terms should be smaller set of all terms\";\n      } else {\n        insensitiveTerms = terms;\n      }\n      if (insensitiveTerms.length > 0) {\n        createOffsetsEnumsForTerms(insensitiveTerms, termsIndex, doc, offsetsEnums);\n      }\n\n      // Handle spans\n      if (phraseHelper.hasPositionSensitivity()) {\n        phraseHelper.createOffsetsEnumsForSpans(leafReader, doc, offsetsEnums);\n      }\n\n      // Handle automata\n      if (components.getAutomata().length > 0) {\n        createOffsetsEnumsForAutomata(termsIndex, doc, offsetsEnums);\n      }\n    }\n\n    switch (offsetsEnums.size()) {\n      case 0: return OffsetsEnum.EMPTY;\n      case 1: return offsetsEnums.get(0);\n      default: return new OffsetsEnum.MultiOffsetsEnum(offsetsEnums);\n    }\n  }\n\n","sourceOld":"  protected OffsetsEnum createOffsetsEnumFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(field);\n    if (termsIndex == null) {\n      return OffsetsEnum.EMPTY;\n    }\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(terms.length + automata.length);\n\n    // Handle position insensitive terms (a subset of this.terms field):\n    final BytesRef[] insensitiveTerms;\n    if (phraseHelper.hasPositionSensitivity()) {\n      insensitiveTerms = phraseHelper.getAllPositionInsensitiveTerms();\n      assert insensitiveTerms.length <= terms.length : \"insensitive terms should be smaller set of all terms\";\n    } else {\n      insensitiveTerms = terms;\n    }\n    if (insensitiveTerms.length > 0) {\n      createOffsetsEnumsForTerms(insensitiveTerms, termsIndex, doc, offsetsEnums);\n    }\n\n    // Handle spans\n    if (phraseHelper.hasPositionSensitivity()) {\n      phraseHelper.createOffsetsEnumsForSpans(leafReader, doc, offsetsEnums);\n    }\n\n    // Handle automata\n    if (automata.length > 0) {\n      createOffsetsEnumsForAutomata(termsIndex, doc, offsetsEnums);\n    }\n\n    return new OffsetsEnum.MultiOffsetsEnum(offsetsEnums);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8764ca7bb74ee716c839b9545a93ec4a578c2005":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"795822cce6616d4035b5a4bdbb6c113ea2f715ba":["8764ca7bb74ee716c839b9545a93ec4a578c2005"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["795822cce6616d4035b5a4bdbb6c113ea2f715ba"]},"commit2Childs":{"8764ca7bb74ee716c839b9545a93ec4a578c2005":["795822cce6616d4035b5a4bdbb6c113ea2f715ba"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8764ca7bb74ee716c839b9545a93ec4a578c2005"],"795822cce6616d4035b5a4bdbb6c113ea2f715ba":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}