{"path":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","commits":[{"id":"f20bb72b0dfa147c6f1fcd7693102c63a2714eae","date":1303767270,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField = types.get(random.nextInt(types.size())).fname;\n        String toField = types.get(random.nextInt(types.size())).fname;\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use filters\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"GROUPING MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0663cc678850ea2c51151f9fd217342ea35b8568","date":1303828523,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField = types.get(random.nextInt(types.size())).fname;\n        String toField = types.get(random.nextInt(types.size())).fname;\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use filters\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"GROUPING MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"21486a8058ee8d7503c7d7a5e55b6c3a218d0942","date":1303841712,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField = types.get(random.nextInt(types.size())).fname;\n        String toField = types.get(random.nextInt(types.size())).fname;\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use filters\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"GROUPING MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a405e749df166cf8c456ac9381f77f6c99a6270","date":1303842176,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField = types.get(random.nextInt(types.size())).fname;\n        String toField = types.get(random.nextInt(types.size())).fname;\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use filters\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"GROUPING MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8f944ac3fe3f9d40d825177507fb381d2b106b3","date":1303868525,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField = types.get(random.nextInt(types.size())).fname;\n        String toField = types.get(random.nextInt(types.size())).fname;\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use filters\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"GROUPING MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["843b845d397272dbafe8b80ebb8f9336d94568ef"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d5df8e07c035d62d982894b439322da40e0938","date":1303923139,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField = types.get(random.nextInt(types.size())).fname;\n        String toField = types.get(random.nextInt(types.size())).fname;\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use filters\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"GROUPING MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField = types.get(random.nextInt(types.size())).fname;\n        String toField = types.get(random.nextInt(types.size())).fname;\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use filters\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"GROUPING MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"843b845d397272dbafe8b80ebb8f9336d94568ef","date":1305726695,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField = types.get(random.nextInt(types.size())).fname;\n        String toField = types.get(random.nextInt(types.size())).fname;\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use filters\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"GROUPING MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":["f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"bugIntro":["487de3f55283f58d7e02a16993f8be55bbe32061","487de3f55283f58d7e02a16993f8be55bbe32061","487de3f55283f58d7e02a16993f8be55bbe32061"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField = types.get(random.nextInt(types.size())).fname;\n        String toField = types.get(random.nextInt(types.size())).fname;\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use filters\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"GROUPING MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"d4d5df8e07c035d62d982894b439322da40e0938":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"7a405e749df166cf8c456ac9381f77f6c99a6270":["21486a8058ee8d7503c7d7a5e55b6c3a218d0942"],"f20bb72b0dfa147c6f1fcd7693102c63a2714eae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c26f00b574427b55127e869b935845554afde1fa":["843b845d397272dbafe8b80ebb8f9336d94568ef","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"0663cc678850ea2c51151f9fd217342ea35b8568":["f20bb72b0dfa147c6f1fcd7693102c63a2714eae"],"f8f944ac3fe3f9d40d825177507fb381d2b106b3":["7a405e749df166cf8c456ac9381f77f6c99a6270"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["135621f3a0670a9394eb563224a3b76cc4dddc0f","843b845d397272dbafe8b80ebb8f9336d94568ef"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a3776dccca01c11e7046323cfad46a3b4a471233"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","843b845d397272dbafe8b80ebb8f9336d94568ef"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["843b845d397272dbafe8b80ebb8f9336d94568ef"],"843b845d397272dbafe8b80ebb8f9336d94568ef":["f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"],"21486a8058ee8d7503c7d7a5e55b6c3a218d0942":["0663cc678850ea2c51151f9fd217342ea35b8568"]},"commit2Childs":{"d4d5df8e07c035d62d982894b439322da40e0938":[],"7a405e749df166cf8c456ac9381f77f6c99a6270":["f8f944ac3fe3f9d40d825177507fb381d2b106b3"],"f20bb72b0dfa147c6f1fcd7693102c63a2714eae":["0663cc678850ea2c51151f9fd217342ea35b8568"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["c3a8a449466c1ff7ce2274fe73dab487256964b4"],"0663cc678850ea2c51151f9fd217342ea35b8568":["21486a8058ee8d7503c7d7a5e55b6c3a218d0942"],"f8f944ac3fe3f9d40d825177507fb381d2b106b3":["d4d5df8e07c035d62d982894b439322da40e0938","135621f3a0670a9394eb563224a3b76cc4dddc0f","843b845d397272dbafe8b80ebb8f9336d94568ef"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":[],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a3776dccca01c11e7046323cfad46a3b4a471233":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d4d5df8e07c035d62d982894b439322da40e0938","f20bb72b0dfa147c6f1fcd7693102c63a2714eae","135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"843b845d397272dbafe8b80ebb8f9336d94568ef":["c26f00b574427b55127e869b935845554afde1fa","c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233","a258fbb26824fd104ed795e5d9033d2d040049ee"],"21486a8058ee8d7503c7d7a5e55b6c3a218d0942":["7a405e749df166cf8c456ac9381f77f6c99a6270"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d4d5df8e07c035d62d982894b439322da40e0938","c3a8a449466c1ff7ce2274fe73dab487256964b4","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}