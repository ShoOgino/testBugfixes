{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","commits":[{"id":"5c00b79f9ef0eddb49044fff3fd0e5208efff795","date":1399517909,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","pathOld":"/dev/null","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.shutdown();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d14ffaac9c4a4a2c750bf0cd956506802561e062","date":1402602036,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          if (defaultCodecSupportsSortedNumeric()) {\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.shutdown();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.shutdown();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c6f080a2ab37c464dd98db173f6cbf10dc74f211","date":1402946779,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          if (defaultCodecSupportsSortedNumeric()) {\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.shutdown();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.shutdown();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          if (defaultCodecSupportsSortedNumeric()) {\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.shutdown();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          if (defaultCodecSupportsSortedNumeric()) {\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.shutdown();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          if (defaultCodecSupportsSortedNumeric()) {\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          if (defaultCodecSupportsSortedNumeric()) {\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.shutdown();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13","date":1409346855,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          if (defaultCodecSupportsSortedNumeric()) {\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          if (defaultCodecSupportsSortedNumeric()) {\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad2a673349939e48652bf304cccf673c3412198f","date":1409585169,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          if (defaultCodecSupportsSortedNumeric()) {\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","sourceNew":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          if (defaultCodecSupportsSortedSet()) {\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n            doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          }\n          if (defaultCodecSupportsSortedNumeric()) {\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n            doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          }\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2 && defaultCodecSupportsFieldUpdates()) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":["d14ffaac9c4a4a2c750bf0cd956506802561e062","5c00b79f9ef0eddb49044fff3fd0e5208efff795"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30310b71978c10ec44d08c346837a2f4bfe7dfed","date":1410955605,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","sourceNew":"  public void testBasics() throws Exception {\n    final Random r = new Random(random().nextLong());\n    doTest(new Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        Exception e = new Exception();\n        StackTraceElement stack[] = e.getStackTrace();\n        boolean ok = false;\n        for (int i = 0; i < stack.length; i++) {\n          if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n            ok = true;\n          }\n        }\n        if (ok && r.nextInt(3000) == 0) {\n          throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n        }\n      }\n    });\n  }\n\n","sourceOld":"  // just one thread, serial merge policy, hopefully debuggable\n  public void testBasics() throws Exception {   \n    // log all exceptions we hit, in case we fail (for debugging)\n    ByteArrayOutputStream exceptionLog = new ByteArrayOutputStream();\n    PrintStream exceptionStream = new PrintStream(exceptionLog, true, \"UTF-8\");\n    //PrintStream exceptionStream = System.out;\n    \n    final long analyzerSeed = random().nextLong();\n    final Analyzer analyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        tokenizer.setEnableChecks(false); // we are gonna make it angry\n        TokenStream stream = tokenizer;\n        // emit some payloads\n        if (fieldName.contains(\"payloads\")) {\n          stream = new MockVariableLengthPayloadFilter(new Random(analyzerSeed), stream);\n        }\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    };\n    \n    MockDirectoryWrapper dir = null;\n    \n    final int numIterations = TEST_NIGHTLY ? atLeast(500) : atLeast(20);\n    \n    STARTOVER:\n    for (int iter = 0; iter < numIterations; iter++) {\n      try {\n        // close from last run\n        if (dir != null) {\n          dir.close();\n        }\n        // disable slow things: we don't rely upon sleeps here.\n        dir = newMockDirectory();\n        dir.setThrottling(MockDirectoryWrapper.Throttling.NEVER);\n        dir.setUseSlowOpenClosers(false);\n      \n        IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n        // just for now, try to keep this test reproducible\n        conf.setMergeScheduler(new SerialMergeScheduler());\n      \n        // test never makes it this far...\n        int numDocs = atLeast(2000);\n      \n        IndexWriter iw = new IndexWriter(dir, conf);\n        iw.commit(); // ensure there is always a commit\n\n        final Random r = new Random(random().nextLong());\n        dir.failOn(new Failure() {\n          @Override\n          public void eval(MockDirectoryWrapper dir) throws IOException {\n            Exception e = new Exception();\n            StackTraceElement stack[] = e.getStackTrace();\n            boolean ok = false;\n            for (int i = 0; i < stack.length; i++) {\n              if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n                ok = true;\n                // don't make life difficult though\n                if (stack[i].getMethodName().equals(\"rollback\")) {\n                  return;\n                }\n              }\n            }\n            if (ok && r.nextInt(3000) == 0) {\n              throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n            }\n          }\n        });\n        \n        for (int i = 0; i < numDocs; i++) {\n          Document doc = new Document();\n          doc.add(newStringField(\"id\", Integer.toString(i), Field.Store.NO));\n          doc.add(new NumericDocValuesField(\"dv\", i));\n          doc.add(new BinaryDocValuesField(\"dv2\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedDocValuesField(\"dv3\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i))));\n          doc.add(new SortedSetDocValuesField(\"dv4\", new BytesRef(Integer.toString(i-1))));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i));\n          doc.add(new SortedNumericDocValuesField(\"dv5\", i-1));\n          doc.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n          // ensure we store something\n          doc.add(new StoredField(\"stored1\", \"foo\"));\n          doc.add(new StoredField(\"stored1\", \"bar\"));    \n          // ensure we get some payloads\n          doc.add(newTextField(\"text_payloads\", TestUtil.randomAnalysisString(random(), 6, true), Field.Store.NO));\n          // ensure we get some vectors\n          FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n          ft.setStoreTermVectors(true);\n          doc.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n          \n          if (random().nextInt(10) > 0) {\n            // single doc\n            try {\n              iw.addDocument(doc);\n              // we made it, sometimes delete our doc, or update a dv\n              int thingToDo = random().nextInt(4);\n              if (thingToDo == 0) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n              } else if (thingToDo == 1) {\n                iw.updateNumericDocValue(new Term(\"id\", Integer.toString(i)), \"dv\", i+1L);\n              } else if (thingToDo == 2) {\n                iw.updateBinaryDocValue(new Term(\"id\", Integer.toString(i)), \"dv2\", new BytesRef(Integer.toString(i+1)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n                try {\n                  iw.rollback();\n                } catch (Throwable t) {}\n                continue STARTOVER;\n              } else {\n                Rethrow.rethrow(e);\n              }\n            }\n          } else {\n            // block docs\n            Document doc2 = new Document();\n            doc2.add(newStringField(\"id\", Integer.toString(-i), Field.Store.NO));\n            doc2.add(newTextField(\"text1\", TestUtil.randomAnalysisString(random(), 20, true), Field.Store.NO));\n            doc2.add(new StoredField(\"stored1\", \"foo\"));\n            doc2.add(new StoredField(\"stored1\", \"bar\"));\n            doc2.add(newField(\"text_vectors\", TestUtil.randomAnalysisString(random(), 6, true), ft));\n            \n            try {\n              iw.addDocuments(Arrays.asList(doc, doc2));\n              // we made it, sometimes delete our docs\n              if (random().nextBoolean()) {\n                iw.deleteDocuments(new Term(\"id\", Integer.toString(i)), new Term(\"id\", Integer.toString(-i)));\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n          \n          if (random().nextInt(10) == 0) {\n            // trigger flush:\n            try {\n              if (random().nextBoolean()) {\n                DirectoryReader ir = null;\n                try {\n                  ir = DirectoryReader.open(iw, random().nextBoolean());\n                  TestUtil.checkReader(ir);\n                } finally {\n                  IOUtils.closeWhileHandlingException(ir);\n                }\n              } else {\n                iw.commit();\n              }\n              if (DirectoryReader.indexExists(dir)) {\n                TestUtil.checkIndex(dir);\n              }\n            } catch (OutOfMemoryError e) {\n              if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n                exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n                e.printStackTrace(exceptionStream);\n              } else {\n                Rethrow.rethrow(e);\n              }\n              try {\n                iw.rollback();\n              } catch (Throwable t) {}\n              continue STARTOVER;\n            }\n          }\n        }\n        \n        try {\n          iw.close();\n        } catch (OutOfMemoryError e) {\n          if (e.getMessage() != null && e.getMessage().startsWith(\"Fake OutOfMemoryError\")) {\n            exceptionStream.println(\"\\nTEST: got expected fake exc:\" + e.getMessage());\n            e.printStackTrace(exceptionStream);\n            try {\n              iw.rollback();\n            } catch (Throwable t) {}\n            continue STARTOVER;\n          } else {\n            Rethrow.rethrow(e);\n          }\n        }\n      } catch (Throwable t) {\n        System.out.println(\"Unexpected exception: dumping fake-exception-log:...\");\n        exceptionStream.flush();\n        System.out.println(exceptionLog.toString(\"UTF-8\"));\n        System.out.flush();\n        Rethrow.rethrow(t);\n      }\n    }\n    dir.close();\n    if (VERBOSE) {\n      System.out.println(\"TEST PASSED: dumping fake-exception-log:...\");\n      System.out.println(exceptionLog.toString(\"UTF-8\"));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a87ce200bba7d88024e2f1c4012212072ce8a5ae","date":1417031281,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","sourceNew":"  public void testBasics() throws Exception {\n    final Random r = new Random(random().nextLong());\n    doTest(new Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        if (r.nextInt(3000) == 0) {\n          StackTraceElement stack[] = Thread.currentThread().getStackTrace();\n          boolean ok = false;\n          for (int i = 0; i < stack.length; i++) {\n            if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n              ok = true;\n            }\n          }\n          if (ok) {\n            throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n          }\n        }\n      }\n    });\n  }\n\n","sourceOld":"  public void testBasics() throws Exception {\n    final Random r = new Random(random().nextLong());\n    doTest(new Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        Exception e = new Exception();\n        StackTraceElement stack[] = e.getStackTrace();\n        boolean ok = false;\n        for (int i = 0; i < stack.length; i++) {\n          if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n            ok = true;\n          }\n        }\n        if (ok && r.nextInt(3000) == 0) {\n          throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n        }\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c48871ed951104729f5e17a8ee1091b43fa18980","date":1446564542,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#testOOM().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","sourceNew":"  public void testOOM() throws Exception {\n    final Random r = new Random(random().nextLong());\n    doTest(new Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        if (r.nextInt(3000) == 0) {\n          StackTraceElement stack[] = Thread.currentThread().getStackTrace();\n          boolean ok = false;\n          for (int i = 0; i < stack.length; i++) {\n            if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n              ok = true;\n            }\n          }\n          if (ok) {\n            throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n          }\n        }\n      }\n    });\n  }\n\n","sourceOld":"  public void testBasics() throws Exception {\n    final Random r = new Random(random().nextLong());\n    doTest(new Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        if (r.nextInt(3000) == 0) {\n          StackTraceElement stack[] = Thread.currentThread().getStackTrace();\n          boolean ok = false;\n          for (int i = 0; i < stack.length; i++) {\n            if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n              ok = true;\n            }\n          }\n          if (ok) {\n            throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n          }\n        }\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c48871ed951104729f5e17a8ee1091b43fa18980","date":1446564542,"type":6,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnVMError#testUnknownError().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOutOfMemory#testBasics().mjava","sourceNew":"  public void testUnknownError() throws Exception {\n    final Random r = new Random(random().nextLong());\n    doTest(new Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        if (r.nextInt(3000) == 0) {\n          StackTraceElement stack[] = Thread.currentThread().getStackTrace();\n          boolean ok = false;\n          for (int i = 0; i < stack.length; i++) {\n            if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n              ok = true;\n            }\n          }\n          if (ok) {\n            throw new UnknownError(\"Fake UnknownError\");\n          }\n        }\n      }\n    });\n  }\n\n","sourceOld":"  public void testBasics() throws Exception {\n    final Random r = new Random(random().nextLong());\n    doTest(new Failure() {\n      @Override\n      public void eval(MockDirectoryWrapper dir) throws IOException {\n        if (r.nextInt(3000) == 0) {\n          StackTraceElement stack[] = Thread.currentThread().getStackTrace();\n          boolean ok = false;\n          for (int i = 0; i < stack.length; i++) {\n            if (stack[i].getClassName().equals(IndexWriter.class.getName())) {\n              ok = true;\n            }\n          }\n          if (ok) {\n            throw new OutOfMemoryError(\"Fake OutOfMemoryError\");\n          }\n        }\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"30310b71978c10ec44d08c346837a2f4bfe7dfed":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"5c00b79f9ef0eddb49044fff3fd0e5208efff795":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d14ffaac9c4a4a2c750bf0cd956506802561e062"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":["5c00b79f9ef0eddb49044fff3fd0e5208efff795","d14ffaac9c4a4a2c750bf0cd956506802561e062"],"c48871ed951104729f5e17a8ee1091b43fa18980":["a87ce200bba7d88024e2f1c4012212072ce8a5ae"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13","ad2a673349939e48652bf304cccf673c3412198f"],"a87ce200bba7d88024e2f1c4012212072ce8a5ae":["30310b71978c10ec44d08c346837a2f4bfe7dfed"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ad2a673349939e48652bf304cccf673c3412198f":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c48871ed951104729f5e17a8ee1091b43fa18980"],"d14ffaac9c4a4a2c750bf0cd956506802561e062":["5c00b79f9ef0eddb49044fff3fd0e5208efff795"]},"commit2Childs":{"30310b71978c10ec44d08c346837a2f4bfe7dfed":["a87ce200bba7d88024e2f1c4012212072ce8a5ae"],"5c00b79f9ef0eddb49044fff3fd0e5208efff795":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","d14ffaac9c4a4a2c750bf0cd956506802561e062"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["402ad3ddc9da7b70da1b167667a60ece6a1381fb","ad2a673349939e48652bf304cccf673c3412198f"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":[],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["30310b71978c10ec44d08c346837a2f4bfe7dfed"],"c48871ed951104729f5e17a8ee1091b43fa18980":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a87ce200bba7d88024e2f1c4012212072ce8a5ae":["c48871ed951104729f5e17a8ee1091b43fa18980"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5c00b79f9ef0eddb49044fff3fd0e5208efff795"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"ad2a673349939e48652bf304cccf673c3412198f":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"d14ffaac9c4a4a2c750bf0cd956506802561e062":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","c6f080a2ab37c464dd98db173f6cbf10dc74f211"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}