{"path":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,String[],int,int,int,boolean).mjava","commits":[{"id":"7f6c85ffa816c86be877aa7a5029a5daa1336e7f","date":1259617761,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,String[],int,int,int,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.\n   *  \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param hyphenator\n   *          the hyphenation pattern tree to use for hyphenation\n   * @param dictionary\n   *          the word dictionary to match against\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,\n      HyphenationTree hyphenator, String[] dictionary, int minWordSize,\n      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    this(input, hyphenator, makeDictionary(dictionary), minWordSize,\n        minSubwordSize, maxSubwordSize, onlyLongestMatch);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,String[],int,int,int,boolean).mjava","pathOld":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter#HyphenationCompoundWordTokenFilter(Version,TokenStream,HyphenationTree,String[],int,int,int,boolean).mjava","sourceNew":"  /**\n   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.\n   *  \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param hyphenator\n   *          the hyphenation pattern tree to use for hyphenation\n   * @param dictionary\n   *          the word dictionary to match against\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,\n      HyphenationTree hyphenator, String[] dictionary, int minWordSize,\n      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    this(input, hyphenator, makeDictionary(dictionary), minWordSize,\n        minSubwordSize, maxSubwordSize, onlyLongestMatch);\n  }\n\n","sourceOld":"  /**\n   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.\n   *  \n   * @param matchVersion\n   *          Lucene version to enable correct Unicode 4.0 behavior in the\n   *          dictionaries if Version > 3.0. See <a\n   *          href=\"CompoundWordTokenFilterBase#version\"\n   *          >CompoundWordTokenFilterBase</a> for details.\n   * @param input\n   *          the {@link TokenStream} to process\n   * @param hyphenator\n   *          the hyphenation pattern tree to use for hyphenation\n   * @param dictionary\n   *          the word dictionary to match against\n   * @param minWordSize\n   *          only words longer than this get processed\n   * @param minSubwordSize\n   *          only subwords longer than this get to the output stream\n   * @param maxSubwordSize\n   *          only subwords shorter than this get to the output stream\n   * @param onlyLongestMatch\n   *          Add only the longest matching subword to the stream\n   */\n  public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,\n      HyphenationTree hyphenator, String[] dictionary, int minWordSize,\n      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {\n    this(input, hyphenator, makeDictionary(dictionary), minWordSize,\n        minSubwordSize, maxSubwordSize, onlyLongestMatch);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7f6c85ffa816c86be877aa7a5029a5daa1336e7f"],"7f6c85ffa816c86be877aa7a5029a5daa1336e7f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7f6c85ffa816c86be877aa7a5029a5daa1336e7f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7f6c85ffa816c86be877aa7a5029a5daa1336e7f":["9454a6510e2db155fb01faa5c049b06ece95fab9"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}