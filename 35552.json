{"path":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#putCacheEntry(CacheEntry[K,V]).mjava","commits":[{"id":"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83","date":1568645407,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#putCacheEntry(CacheEntry[K,V]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Visible for testing to create synthetic cache entries.\n   * @lucene.internal\n   */\n  public V putCacheEntry(CacheEntry<K, V> e) {\n    stats.accessCounter.incrementAndGet();\n    // initialize oldestEntry\n    oldestEntry.updateAndGet(x -> x > e.lastAccessed  || x == 0 ? e.lastAccessed : x);\n    CacheEntry<K, V> oldCacheEntry = map.put(e.key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n      ramBytes.addAndGet(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      currentSize = stats.size.get();\n      ramBytes.addAndGet(-oldCacheEntry.ramBytesUsed());\n      ramBytes.addAndGet(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n    long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n    if ((currentSize > upperWaterMark || (evictByIdleTime && oldestEntry.get() < idleCutoff)) && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"87f0484c38f986062889ed50f3bf3bd462848c26","date":1570108628,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#putCacheEntry(CacheEntry[K,V]).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#putCacheEntry(CacheEntry[K,V]).mjava","sourceNew":"  /**\n   * Visible for testing to create synthetic cache entries.\n   * @lucene.internal\n   */\n  public V putCacheEntry(CacheEntry<K, V> e) {\n    stats.accessCounter.increment();\n    // initialize oldestEntry\n    oldestEntry.updateAndGet(x -> x > e.lastAccessed  || x == 0 ? e.lastAccessed : x);\n    CacheEntry<K, V> oldCacheEntry = map.put(e.key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      stats.size.increment();\n      currentSize = stats.size.intValue();\n      ramBytes.add(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      currentSize = stats.size.intValue();\n      ramBytes.add(-oldCacheEntry.ramBytesUsed());\n      ramBytes.add(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n    long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n    if ((currentSize > upperWaterMark || (evictByIdleTime && oldestEntry.get() < idleCutoff)) && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  /**\n   * Visible for testing to create synthetic cache entries.\n   * @lucene.internal\n   */\n  public V putCacheEntry(CacheEntry<K, V> e) {\n    stats.accessCounter.incrementAndGet();\n    // initialize oldestEntry\n    oldestEntry.updateAndGet(x -> x > e.lastAccessed  || x == 0 ? e.lastAccessed : x);\n    CacheEntry<K, V> oldCacheEntry = map.put(e.key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n      ramBytes.addAndGet(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      currentSize = stats.size.get();\n      ramBytes.addAndGet(-oldCacheEntry.ramBytesUsed());\n      ramBytes.addAndGet(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n    long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n    if ((currentSize > upperWaterMark || (evictByIdleTime && oldestEntry.get() < idleCutoff)) && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":3,"author":"jimczi","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#putCacheEntry(CacheEntry[K,V]).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#putCacheEntry(CacheEntry[K,V]).mjava","sourceNew":"  /**\n   * Visible for testing to create synthetic cache entries.\n   * @lucene.internal\n   */\n  public V putCacheEntry(CacheEntry<K, V> e) {\n    stats.accessCounter.increment();\n    // initialize oldestEntry\n    oldestEntry.updateAndGet(x -> x > e.lastAccessed  || x == 0 ? e.lastAccessed : x);\n    CacheEntry<K, V> oldCacheEntry = map.put(e.key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      stats.size.increment();\n      currentSize = stats.size.intValue();\n      ramBytes.add(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      currentSize = stats.size.intValue();\n      ramBytes.add(-oldCacheEntry.ramBytesUsed());\n      ramBytes.add(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n    long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n    if ((currentSize > upperWaterMark || (evictByIdleTime && oldestEntry.get() < idleCutoff)) && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  /**\n   * Visible for testing to create synthetic cache entries.\n   * @lucene.internal\n   */\n  public V putCacheEntry(CacheEntry<K, V> e) {\n    stats.accessCounter.incrementAndGet();\n    // initialize oldestEntry\n    oldestEntry.updateAndGet(x -> x > e.lastAccessed  || x == 0 ? e.lastAccessed : x);\n    CacheEntry<K, V> oldCacheEntry = map.put(e.key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n      ramBytes.addAndGet(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      currentSize = stats.size.get();\n      ramBytes.addAndGet(-oldCacheEntry.ramBytesUsed());\n      ramBytes.addAndGet(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n    long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n    if ((currentSize > upperWaterMark || (evictByIdleTime && oldestEntry.get() < idleCutoff)) && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bfa27be7bde9d711ce2b418fadc555654849383f","date":1573652589,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#putCacheEntry(CacheEntry[K,V]).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#putCacheEntry(CacheEntry[K,V]).mjava","sourceNew":"  /**\n   * Visible for testing to create synthetic cache entries.\n   * @lucene.internal\n   */\n  public V putCacheEntry(CacheEntry<K, V> e) {\n    stats.accessCounter.increment();\n    // initialize oldestEntry\n    oldestEntry.updateAndGet(x -> x > e.lastAccessed  || x == 0 ? e.lastAccessed : x);\n    CacheEntry<K, V> oldCacheEntry = map.put(e.key, e);\n    if (oldCacheEntry == null) {\n      stats.size.increment();\n      ramBytes.add(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      ramBytes.add(-oldCacheEntry.ramBytesUsed());\n      ramBytes.add(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n    maybeMarkAndSweep();\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  /**\n   * Visible for testing to create synthetic cache entries.\n   * @lucene.internal\n   */\n  public V putCacheEntry(CacheEntry<K, V> e) {\n    stats.accessCounter.increment();\n    // initialize oldestEntry\n    oldestEntry.updateAndGet(x -> x > e.lastAccessed  || x == 0 ? e.lastAccessed : x);\n    CacheEntry<K, V> oldCacheEntry = map.put(e.key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      stats.size.increment();\n      currentSize = stats.size.intValue();\n      ramBytes.add(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      currentSize = stats.size.intValue();\n      ramBytes.add(-oldCacheEntry.ramBytesUsed());\n      ramBytes.add(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n    long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n    if ((currentSize > upperWaterMark || (evictByIdleTime && oldestEntry.get() < idleCutoff)) && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null) {\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d7d3943904804560937e6239effeebda0f920e4","date":1573762904,"type":4,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#putCacheEntry(CacheEntry[K,V]).mjava","sourceNew":null,"sourceOld":"  /**\n   * Visible for testing to create synthetic cache entries.\n   * @lucene.internal\n   */\n  public V putCacheEntry(CacheEntry<K, V> e) {\n    stats.accessCounter.increment();\n    // initialize oldestEntry\n    oldestEntry.updateAndGet(x -> x > e.lastAccessed  || x == 0 ? e.lastAccessed : x);\n    CacheEntry<K, V> oldCacheEntry = map.put(e.key, e);\n    if (oldCacheEntry == null) {\n      stats.size.increment();\n      ramBytes.add(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      ramBytes.add(-oldCacheEntry.ramBytesUsed());\n      ramBytes.add(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n    maybeMarkAndSweep();\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bfa27be7bde9d711ce2b418fadc555654849383f":["87f0484c38f986062889ed50f3bf3bd462848c26"],"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4d7d3943904804560937e6239effeebda0f920e4":["bfa27be7bde9d711ce2b418fadc555654849383f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"87f0484c38f986062889ed50f3bf3bd462848c26":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4d7d3943904804560937e6239effeebda0f920e4"],"b0b597c65628ca9e73913a07e81691f8229bae35":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83","87f0484c38f986062889ed50f3bf3bd462848c26"]},"commit2Childs":{"bfa27be7bde9d711ce2b418fadc555654849383f":["4d7d3943904804560937e6239effeebda0f920e4"],"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83":["87f0484c38f986062889ed50f3bf3bd462848c26","b0b597c65628ca9e73913a07e81691f8229bae35"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83"],"4d7d3943904804560937e6239effeebda0f920e4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"87f0484c38f986062889ed50f3bf3bd462848c26":["bfa27be7bde9d711ce2b418fadc555654849383f","b0b597c65628ca9e73913a07e81691f8229bae35"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}