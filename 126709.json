{"path":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","commits":[{"id":"0984ad47974c2d5d354519ddb2aa8358973a6271","date":1330868053,"type":0,"author":"Christian Moen","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","pathOld":"/dev/null","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", offsetAtt.startOffset() <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + offsetAtt.endOffset() + \" vs finalOffset=\" + finalOffset.intValue(),\n                     offsetAtt.endOffset() <= finalOffset.intValue());\n        }\n      }\n      if (posIncrAtt != null) {\n        assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e","1fe9452de26a70442324c5bdc5a5a333e55f07db"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":0,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","pathOld":"/dev/null","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", offsetAtt.startOffset() <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + offsetAtt.endOffset() + \" vs finalOffset=\" + finalOffset.intValue(),\n                     offsetAtt.endOffset() <= finalOffset.intValue());\n        }\n      }\n      if (posIncrAtt != null) {\n        assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54c9be9a3aac8e0bab09abb249165f90a6758f01","date":1331903190,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", offsetAtt.startOffset() <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + offsetAtt.endOffset() + \" vs finalOffset=\" + finalOffset.intValue(),\n                     offsetAtt.endOffset() <= finalOffset.intValue());\n        }\n      }\n      if (posIncrAtt != null) {\n        if (i == 0) {\n          assertTrue(\"first posIncrement must be >= 1\", posIncrAtt.getPositionIncrement() >= 1);\n        } else {\n          assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n        }\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", offsetAtt.startOffset() <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + offsetAtt.endOffset() + \" vs finalOffset=\" + finalOffset.intValue(),\n                     offsetAtt.endOffset() <= finalOffset.intValue());\n        }\n      }\n      if (posIncrAtt != null) {\n        assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c46b5eed1428b2cecc6851b67142702486279f89","date":1332284557,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", offsetAtt.startOffset() <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + offsetAtt.endOffset() + \" vs finalOffset=\" + finalOffset.intValue(),\n                     offsetAtt.endOffset() <= finalOffset.intValue());\n        }\n      }\n      if (posIncrAtt != null) {\n        if (i == 0) {\n          assertTrue(\"first posIncrement must be >= 1\", posIncrAtt.getPositionIncrement() >= 1);\n        } else {\n          assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n        }\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null) {\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    }\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", offsetAtt.startOffset() <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + offsetAtt.endOffset() + \" vs finalOffset=\" + finalOffset.intValue(),\n                     offsetAtt.endOffset() <= finalOffset.intValue());\n        }\n      }\n      if (posIncrAtt != null) {\n        if (i == 0) {\n          assertTrue(\"first posIncrement must be >= 1\", posIncrAtt.getPositionIncrement() >= 1);\n        } else {\n          assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n        }\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null)\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f106f36fed7af3f5d4b31c051a3dd1b157913054","date":1332724926,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset, got startOffset=\" + offsetAtt.startOffset() + \",endOffset=\" + offsetAtt.endOffset(), \n            offsetAtt.endOffset() >= offsetAtt.startOffset());\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", offsetAtt.startOffset() <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + offsetAtt.endOffset() + \" vs finalOffset=\" + finalOffset.intValue(),\n                     offsetAtt.endOffset() <= finalOffset.intValue());\n        }\n      }\n      if (posIncrAtt != null) {\n        if (i == 0) {\n          assertTrue(\"first posIncrement must be >= 1\", posIncrAtt.getPositionIncrement() >= 1);\n        } else {\n          assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n        }\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null) {\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    }\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset\", offsetAtt.endOffset() >= offsetAtt.startOffset());\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", offsetAtt.startOffset() <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + offsetAtt.endOffset() + \" vs finalOffset=\" + finalOffset.intValue(),\n                     offsetAtt.endOffset() <= finalOffset.intValue());\n        }\n      }\n      if (posIncrAtt != null) {\n        if (i == 0) {\n          assertTrue(\"first posIncrement must be >= 1\", posIncrAtt.getPositionIncrement() >= 1);\n        } else {\n          assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n        }\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null) {\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    }\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":["1fe9452de26a70442324c5bdc5a5a333e55f07db"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1fe9452de26a70442324c5bdc5a5a333e55f07db","date":1333912637,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    // Maps position to the start/end offset:\n    final Map<Integer,Integer> posToStartOffset = new HashMap<Integer,Integer>();\n    final Map<Integer,Integer> posToEndOffset = new HashMap<Integer,Integer>();\n\n    ts.reset();\n    int pos = -1;\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        final int startOffset = offsetAtt.startOffset();\n        final int endOffset = offsetAtt.endOffset();\n        assertTrue(\"startOffset must be >= 0\", startOffset >= 0);\n        assertTrue(\"endOffset must be >= 0\", endOffset >= 0);\n        assertTrue(\"endOffset must be >= startOffset, got startOffset=\" + startOffset + \",endOffset=\" + endOffset, \n            endOffset >= startOffset);\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", startOffset <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + endOffset + \" vs finalOffset=\" + finalOffset.intValue(),\n                     endOffset <= finalOffset.intValue());\n        }\n\n        if (posLengthAtt != null && posIncrAtt != null) {\n          // Validate offset consistency in the graph, ie\n          // all tokens leaving from a certain pos have the\n          // same startOffset, and all tokens arriving to a\n          // certain pos have the same endOffset:\n          final int posInc = posIncrAtt.getPositionIncrement();\n          pos += posInc;\n\n          final int posLength = posLengthAtt.getPositionLength();\n\n          if (!posToStartOffset.containsKey(pos)) {\n            // First time we've seen a token leaving from this position:\n            posToStartOffset.put(pos, startOffset);\n            //System.out.println(\"  + s \" + pos + \" -> \" + startOffset);\n          } else {\n            // We've seen a token leaving from this position\n            // before; verify the startOffset is the same:\n            //System.out.println(\"  + vs \" + pos + \" -> \" + startOffset);\n            assertEquals(posToStartOffset.get(pos).intValue(), startOffset);\n          }\n\n          final int endPos = pos + posLength;\n\n          if (!posToEndOffset.containsKey(endPos)) {\n            // First time we've seen a token arriving to this position:\n            posToEndOffset.put(endPos, endOffset);\n            //System.out.println(\"  + e \" + endPos + \" -> \" + endOffset);\n          } else {\n            // We've seen a token arriving to this position\n            // before; verify the endOffset is the same:\n            //System.out.println(\"  + ve \" + endPos + \" -> \" + endOffset);\n            assertEquals(posToEndOffset.get(endPos).intValue(), endOffset);\n          }\n        }\n      }\n      if (posIncrAtt != null) {\n        if (i == 0) {\n          assertTrue(\"first posIncrement must be >= 1\", posIncrAtt.getPositionIncrement() >= 1);\n        } else {\n          assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n        }\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null) {\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    }\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        assertTrue(\"startOffset must be >= 0\", offsetAtt.startOffset() >= 0);\n        assertTrue(\"endOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n        assertTrue(\"endOffset must be >= startOffset, got startOffset=\" + offsetAtt.startOffset() + \",endOffset=\" + offsetAtt.endOffset(), \n            offsetAtt.endOffset() >= offsetAtt.startOffset());\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", offsetAtt.startOffset() <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + offsetAtt.endOffset() + \" vs finalOffset=\" + finalOffset.intValue(),\n                     offsetAtt.endOffset() <= finalOffset.intValue());\n        }\n      }\n      if (posIncrAtt != null) {\n        if (i == 0) {\n          assertTrue(\"first posIncrement must be >= 1\", posIncrAtt.getPositionIncrement() >= 1);\n        } else {\n          assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n        }\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null) {\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    }\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","bugFix":["0984ad47974c2d5d354519ddb2aa8358973a6271","f106f36fed7af3f5d4b31c051a3dd1b157913054"],"bugIntro":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"aa380b0ac7fa6c578259afbb8eaa19927570010d","date":1333998347,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    // Maps position to the start/end offset:\n    final Map<Integer,Integer> posToStartOffset = new HashMap<Integer,Integer>();\n    final Map<Integer,Integer> posToEndOffset = new HashMap<Integer,Integer>();\n\n    ts.reset();\n    int pos = -1;\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        final int startOffset = offsetAtt.startOffset();\n        final int endOffset = offsetAtt.endOffset();\n        assertTrue(\"startOffset must be >= 0\", startOffset >= 0);\n        assertTrue(\"endOffset must be >= 0\", endOffset >= 0);\n        assertTrue(\"endOffset must be >= startOffset, got startOffset=\" + startOffset + \",endOffset=\" + endOffset, \n            endOffset >= startOffset);\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", startOffset <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + endOffset + \" vs finalOffset=\" + finalOffset.intValue(),\n                     endOffset <= finalOffset.intValue());\n        }\n\n        if (posLengthAtt != null && posIncrAtt != null) {\n          // Validate offset consistency in the graph, ie\n          // all tokens leaving from a certain pos have the\n          // same startOffset, and all tokens arriving to a\n          // certain pos have the same endOffset:\n          final int posInc = posIncrAtt.getPositionIncrement();\n          pos += posInc;\n\n          final int posLength = posLengthAtt.getPositionLength();\n\n          if (!posToStartOffset.containsKey(pos)) {\n            // First time we've seen a token leaving from this position:\n            posToStartOffset.put(pos, startOffset);\n            //System.out.println(\"  + s \" + pos + \" -> \" + startOffset);\n          } else {\n            // We've seen a token leaving from this position\n            // before; verify the startOffset is the same:\n            //System.out.println(\"  + vs \" + pos + \" -> \" + startOffset);\n            assertEquals(posToStartOffset.get(pos).intValue(), startOffset);\n          }\n\n          final int endPos = pos + posLength;\n\n          if (!posToEndOffset.containsKey(endPos)) {\n            // First time we've seen a token arriving to this position:\n            posToEndOffset.put(endPos, endOffset);\n            //System.out.println(\"  + e \" + endPos + \" -> \" + endOffset);\n          } else {\n            // We've seen a token arriving to this position\n            // before; verify the endOffset is the same:\n            //System.out.println(\"  + ve \" + endPos + \" -> \" + endOffset);\n            assertEquals(posToEndOffset.get(endPos).intValue(), endOffset);\n          }\n        }\n      }\n      if (posIncrAtt != null) {\n        if (i == 0) {\n          assertTrue(\"first posIncrement must be >= 1\", posIncrAtt.getPositionIncrement() >= 1);\n        } else {\n          assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n        }\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected (expected count=\" + output.length + \")\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null) {\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    }\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    // Maps position to the start/end offset:\n    final Map<Integer,Integer> posToStartOffset = new HashMap<Integer,Integer>();\n    final Map<Integer,Integer> posToEndOffset = new HashMap<Integer,Integer>();\n\n    ts.reset();\n    int pos = -1;\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        final int startOffset = offsetAtt.startOffset();\n        final int endOffset = offsetAtt.endOffset();\n        assertTrue(\"startOffset must be >= 0\", startOffset >= 0);\n        assertTrue(\"endOffset must be >= 0\", endOffset >= 0);\n        assertTrue(\"endOffset must be >= startOffset, got startOffset=\" + startOffset + \",endOffset=\" + endOffset, \n            endOffset >= startOffset);\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", startOffset <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + endOffset + \" vs finalOffset=\" + finalOffset.intValue(),\n                     endOffset <= finalOffset.intValue());\n        }\n\n        if (posLengthAtt != null && posIncrAtt != null) {\n          // Validate offset consistency in the graph, ie\n          // all tokens leaving from a certain pos have the\n          // same startOffset, and all tokens arriving to a\n          // certain pos have the same endOffset:\n          final int posInc = posIncrAtt.getPositionIncrement();\n          pos += posInc;\n\n          final int posLength = posLengthAtt.getPositionLength();\n\n          if (!posToStartOffset.containsKey(pos)) {\n            // First time we've seen a token leaving from this position:\n            posToStartOffset.put(pos, startOffset);\n            //System.out.println(\"  + s \" + pos + \" -> \" + startOffset);\n          } else {\n            // We've seen a token leaving from this position\n            // before; verify the startOffset is the same:\n            //System.out.println(\"  + vs \" + pos + \" -> \" + startOffset);\n            assertEquals(posToStartOffset.get(pos).intValue(), startOffset);\n          }\n\n          final int endPos = pos + posLength;\n\n          if (!posToEndOffset.containsKey(endPos)) {\n            // First time we've seen a token arriving to this position:\n            posToEndOffset.put(endPos, endOffset);\n            //System.out.println(\"  + e \" + endPos + \" -> \" + endOffset);\n          } else {\n            // We've seen a token arriving to this position\n            // before; verify the endOffset is the same:\n            //System.out.println(\"  + ve \" + endPos + \" -> \" + endOffset);\n            assertEquals(posToEndOffset.get(endPos).intValue(), endOffset);\n          }\n        }\n      }\n      if (posIncrAtt != null) {\n        if (i == 0) {\n          assertTrue(\"first posIncrement must be >= 1\", posIncrAtt.getPositionIncrement() >= 1);\n        } else {\n          assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n        }\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null) {\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    }\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"888c2d6bca1edd8d9293631d6e1d188b036e0f05","date":1334076894,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertTokenStreamContents(ts, output, startOffsets, endOffsets, types, posIncrements, posLengths, finalOffset, true);\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    // Maps position to the start/end offset:\n    final Map<Integer,Integer> posToStartOffset = new HashMap<Integer,Integer>();\n    final Map<Integer,Integer> posToEndOffset = new HashMap<Integer,Integer>();\n\n    ts.reset();\n    int pos = -1;\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        final int startOffset = offsetAtt.startOffset();\n        final int endOffset = offsetAtt.endOffset();\n        assertTrue(\"startOffset must be >= 0\", startOffset >= 0);\n        assertTrue(\"endOffset must be >= 0\", endOffset >= 0);\n        assertTrue(\"endOffset must be >= startOffset, got startOffset=\" + startOffset + \",endOffset=\" + endOffset, \n            endOffset >= startOffset);\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", startOffset <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + endOffset + \" vs finalOffset=\" + finalOffset.intValue(),\n                     endOffset <= finalOffset.intValue());\n        }\n\n        if (posLengthAtt != null && posIncrAtt != null) {\n          // Validate offset consistency in the graph, ie\n          // all tokens leaving from a certain pos have the\n          // same startOffset, and all tokens arriving to a\n          // certain pos have the same endOffset:\n          final int posInc = posIncrAtt.getPositionIncrement();\n          pos += posInc;\n\n          final int posLength = posLengthAtt.getPositionLength();\n\n          if (!posToStartOffset.containsKey(pos)) {\n            // First time we've seen a token leaving from this position:\n            posToStartOffset.put(pos, startOffset);\n            //System.out.println(\"  + s \" + pos + \" -> \" + startOffset);\n          } else {\n            // We've seen a token leaving from this position\n            // before; verify the startOffset is the same:\n            //System.out.println(\"  + vs \" + pos + \" -> \" + startOffset);\n            assertEquals(posToStartOffset.get(pos).intValue(), startOffset);\n          }\n\n          final int endPos = pos + posLength;\n\n          if (!posToEndOffset.containsKey(endPos)) {\n            // First time we've seen a token arriving to this position:\n            posToEndOffset.put(endPos, endOffset);\n            //System.out.println(\"  + e \" + endPos + \" -> \" + endOffset);\n          } else {\n            // We've seen a token arriving to this position\n            // before; verify the endOffset is the same:\n            //System.out.println(\"  + ve \" + endPos + \" -> \" + endOffset);\n            assertEquals(posToEndOffset.get(endPos).intValue(), endOffset);\n          }\n        }\n      }\n      if (posIncrAtt != null) {\n        if (i == 0) {\n          assertTrue(\"first posIncrement must be >= 1\", posIncrAtt.getPositionIncrement() >= 1);\n        } else {\n          assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n        }\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected (expected count=\" + output.length + \")\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null) {\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    }\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e","date":1334174049,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[],int[],Integer).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertTokenStreamContents(ts, output, startOffsets, endOffsets, types, posIncrements, posLengths, finalOffset, true);\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], Integer finalOffset) throws IOException {\n    assertNotNull(output);\n    CheckClearAttributesAttribute checkClearAtt = ts.addAttribute(CheckClearAttributesAttribute.class);\n    \n    assertTrue(\"has no CharTermAttribute\", ts.hasAttribute(CharTermAttribute.class));\n    CharTermAttribute termAtt = ts.getAttribute(CharTermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null || finalOffset != null) {\n      assertTrue(\"has no OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has no TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has no PositionIncrementAttribute\", ts.hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);\n    }\n\n    PositionLengthAttribute posLengthAtt = null;\n    if (posLengths != null) {\n      assertTrue(\"has no PositionLengthAttribute\", ts.hasAttribute(PositionLengthAttribute.class));\n      posLengthAtt = ts.getAttribute(PositionLengthAttribute.class);\n    }\n    \n    // Maps position to the start/end offset:\n    final Map<Integer,Integer> posToStartOffset = new HashMap<Integer,Integer>();\n    final Map<Integer,Integer> posToEndOffset = new HashMap<Integer,Integer>();\n\n    ts.reset();\n    int pos = -1;\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also assign bogus values\n      ts.clearAttributes();\n      termAtt.setEmpty().append(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724,24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n      \n      checkClearAtt.getAndResetClearCalled(); // reset it, because we called clearAttribute() before\n      assertTrue(\"token \"+i+\" does not exist\", ts.incrementToken());\n      assertTrue(\"clearAttributes() was not called correctly in TokenStream chain\", checkClearAtt.getAndResetClearCalled());\n      \n      assertEquals(\"term \"+i, output[i], termAtt.toString());\n      if (startOffsets != null)\n        assertEquals(\"startOffset \"+i, startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null)\n        assertEquals(\"endOffset \"+i, endOffsets[i], offsetAtt.endOffset());\n      if (types != null)\n        assertEquals(\"type \"+i, types[i], typeAtt.type());\n      if (posIncrements != null)\n        assertEquals(\"posIncrement \"+i, posIncrements[i], posIncrAtt.getPositionIncrement());\n      if (posLengths != null)\n        assertEquals(\"posLength \"+i, posLengths[i], posLengthAtt.getPositionLength());\n      \n      // we can enforce some basic things about a few attributes even if the caller doesn't check:\n      if (offsetAtt != null) {\n        final int startOffset = offsetAtt.startOffset();\n        final int endOffset = offsetAtt.endOffset();\n        assertTrue(\"startOffset must be >= 0\", startOffset >= 0);\n        assertTrue(\"endOffset must be >= 0\", endOffset >= 0);\n        assertTrue(\"endOffset must be >= startOffset, got startOffset=\" + startOffset + \",endOffset=\" + endOffset, \n            endOffset >= startOffset);\n        if (finalOffset != null) {\n          assertTrue(\"startOffset must be <= finalOffset\", startOffset <= finalOffset.intValue());\n          assertTrue(\"endOffset must be <= finalOffset: got endOffset=\" + endOffset + \" vs finalOffset=\" + finalOffset.intValue(),\n                     endOffset <= finalOffset.intValue());\n        }\n\n        if (posLengthAtt != null && posIncrAtt != null) {\n          // Validate offset consistency in the graph, ie\n          // all tokens leaving from a certain pos have the\n          // same startOffset, and all tokens arriving to a\n          // certain pos have the same endOffset:\n          final int posInc = posIncrAtt.getPositionIncrement();\n          pos += posInc;\n\n          final int posLength = posLengthAtt.getPositionLength();\n\n          if (!posToStartOffset.containsKey(pos)) {\n            // First time we've seen a token leaving from this position:\n            posToStartOffset.put(pos, startOffset);\n            //System.out.println(\"  + s \" + pos + \" -> \" + startOffset);\n          } else {\n            // We've seen a token leaving from this position\n            // before; verify the startOffset is the same:\n            //System.out.println(\"  + vs \" + pos + \" -> \" + startOffset);\n            assertEquals(posToStartOffset.get(pos).intValue(), startOffset);\n          }\n\n          final int endPos = pos + posLength;\n\n          if (!posToEndOffset.containsKey(endPos)) {\n            // First time we've seen a token arriving to this position:\n            posToEndOffset.put(endPos, endOffset);\n            //System.out.println(\"  + e \" + endPos + \" -> \" + endOffset);\n          } else {\n            // We've seen a token arriving to this position\n            // before; verify the endOffset is the same:\n            //System.out.println(\"  + ve \" + endPos + \" -> \" + endOffset);\n            assertEquals(posToEndOffset.get(endPos).intValue(), endOffset);\n          }\n        }\n      }\n      if (posIncrAtt != null) {\n        if (i == 0) {\n          assertTrue(\"first posIncrement must be >= 1\", posIncrAtt.getPositionIncrement() >= 1);\n        } else {\n          assertTrue(\"posIncrement must be >= 0\", posIncrAtt.getPositionIncrement() >= 0);\n        }\n      }\n      if (posLengthAtt != null) {\n        assertTrue(\"posLength must be >= 1\", posLengthAtt.getPositionLength() >= 1);\n      }\n    }\n    assertFalse(\"TokenStream has more tokens than expected\", ts.incrementToken());\n    ts.end();\n    if (finalOffset != null) {\n      assertEquals(\"finalOffset \", finalOffset.intValue(), offsetAtt.endOffset());\n    }\n    if (offsetAtt != null) {\n      assertTrue(\"finalOffset must be >= 0\", offsetAtt.endOffset() >= 0);\n    }\n    ts.close();\n  }\n\n","bugFix":["0984ad47974c2d5d354519ddb2aa8358973a6271","c46b5eed1428b2cecc6851b67142702486279f89","54c9be9a3aac8e0bab09abb249165f90a6758f01","1fe9452de26a70442324c5bdc5a5a333e55f07db"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"888c2d6bca1edd8d9293631d6e1d188b036e0f05":["aa380b0ac7fa6c578259afbb8eaa19927570010d"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0984ad47974c2d5d354519ddb2aa8358973a6271"],"0984ad47974c2d5d354519ddb2aa8358973a6271":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e":["1fe9452de26a70442324c5bdc5a5a333e55f07db","888c2d6bca1edd8d9293631d6e1d188b036e0f05"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"54c9be9a3aac8e0bab09abb249165f90a6758f01":["0984ad47974c2d5d354519ddb2aa8358973a6271"],"1fe9452de26a70442324c5bdc5a5a333e55f07db":["f106f36fed7af3f5d4b31c051a3dd1b157913054"],"f106f36fed7af3f5d4b31c051a3dd1b157913054":["c46b5eed1428b2cecc6851b67142702486279f89"],"c46b5eed1428b2cecc6851b67142702486279f89":["54c9be9a3aac8e0bab09abb249165f90a6758f01"],"aa380b0ac7fa6c578259afbb8eaa19927570010d":["1fe9452de26a70442324c5bdc5a5a333e55f07db"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"]},"commit2Childs":{"888c2d6bca1edd8d9293631d6e1d188b036e0f05":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"0984ad47974c2d5d354519ddb2aa8358973a6271":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","54c9be9a3aac8e0bab09abb249165f90a6758f01"],"ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","0984ad47974c2d5d354519ddb2aa8358973a6271"],"54c9be9a3aac8e0bab09abb249165f90a6758f01":["c46b5eed1428b2cecc6851b67142702486279f89"],"1fe9452de26a70442324c5bdc5a5a333e55f07db":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e","aa380b0ac7fa6c578259afbb8eaa19927570010d"],"f106f36fed7af3f5d4b31c051a3dd1b157913054":["1fe9452de26a70442324c5bdc5a5a333e55f07db"],"c46b5eed1428b2cecc6851b67142702486279f89":["f106f36fed7af3f5d4b31c051a3dd1b157913054"],"aa380b0ac7fa6c578259afbb8eaa19927570010d":["888c2d6bca1edd8d9293631d6e1d188b036e0f05"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}