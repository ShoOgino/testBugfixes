{"path":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","commits":[{"id":"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d","date":1426480823,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1931d98b40b01d5075753b197c2461a5c2652689","date":1471971289,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> fstate = new HashMap<>(1);\n      fstate.put(FACET_REFINE, refinement);\n      String fstateString = JSONUtil.toJSON(fstate);\n      shardsRefineRequest.params.add(FACET_STATE, fstateString);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":["a3584d3db8b472772e3329d9d95d584b68ae997e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a","date":1472163016,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> fstate = new HashMap<>(1);\n      fstate.put(FACET_REFINE, refinement);\n      String fstateString = JSONUtil.toJSON(fstate);\n      shardsRefineRequest.params.add(FACET_STATE, fstateString);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> fstate = new HashMap<>(1);\n      fstate.put(FACET_REFINE, refinement);\n      String fstateString = JSONUtil.toJSON(fstate);\n      shardsRefineRequest.params.add(FACET_STATE, fstateString);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8ec805ca8fedc0166461148c7182f1bcbbd18ee1","date":1489767223,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> fstate = new HashMap<>(1);\n      fstate.put(FACET_REFINE, refinement);\n      String fstateString = JSONUtil.toJSON(fstate);\n      shardsRefineRequest.params.add(FACET_STATE, fstateString);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":["d6ca2e1fb422aea9c41a4c63e72d6108a37291c1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"58b93c361b4f6fe193e84bfd27ea523366eada52","date":1490100167,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo);\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"11ab475c994c79138885cc8a30b2641d929cdc43","date":1490280010,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> fstate = new HashMap<>(1);\n      fstate.put(FACET_REFINE, refinement);\n      String fstateString = JSONUtil.toJSON(fstate);\n      shardsRefineRequest.params.add(FACET_STATE, fstateString);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8908009aaa8e9318b455c1c22b83e0e87738228a","date":1490280013,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo);\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6ca2e1fb422aea9c41a4c63e72d6108a37291c1","date":1497545589,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo, -1);\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo);\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":["8ec805ca8fedc0166461148c7182f1bcbbd18ee1"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo, -1);\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo);\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo, -1);\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo);\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f1d005dd5ef5744d35de478e9702fc8c8d3cf4a9","date":1520265828,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n\n      // String finfoStr = JSONUtil.toJSON(finfo, -1);  // this doesn't handle formatting of Date objects the way we want\n      CharArr out = new CharArr();\n      JSONWriter jsonWriter = new JSONWriter(out, -1) {\n        @Override\n        public void handleUnknownClass(Object o) {\n          // handle date formatting correctly\n          if (o instanceof Date) {\n            String s = Instant.ofEpochMilli(((Date)o).getTime()).toString();\n            writeString(s);\n            return;\n          }\n          super.handleUnknownClass(o);\n        }\n      };\n      jsonWriter.write(finfo);\n      String finfoStr = out.toString();\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n      String finfoStr = JSONUtil.toJSON(finfo, -1);\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":["15b321aed72eecb043f237c490b9afd4e52c25be"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"15b321aed72eecb043f237c490b9afd4e52c25be","date":1525894978,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n\n      // String finfoStr = JSONUtil.toJSON(finfo, -1);  // this doesn't handle formatting of Date objects the way we want\n      CharArr out = new CharArr();\n      JSONWriter jsonWriter = new JSONWriter(out, -1) {\n        @Override\n        public void handleUnknownClass(Object o) {\n          // handle date formatting correctly\n          if (o instanceof Date) {\n            String s = ((Date)o).toInstant().toString();\n            writeString(s);\n            return;\n          }\n          super.handleUnknownClass(o);\n        }\n      };\n      jsonWriter.write(finfo);\n      String finfoStr = out.toString();\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n\n      // String finfoStr = JSONUtil.toJSON(finfo, -1);  // this doesn't handle formatting of Date objects the way we want\n      CharArr out = new CharArr();\n      JSONWriter jsonWriter = new JSONWriter(out, -1) {\n        @Override\n        public void handleUnknownClass(Object o) {\n          // handle date formatting correctly\n          if (o instanceof Date) {\n            String s = Instant.ofEpochMilli(((Date)o).getTime()).toString();\n            writeString(s);\n            return;\n          }\n          super.handleUnknownClass(o);\n        }\n      };\n      jsonWriter.write(finfo);\n      String finfoStr = out.toString();\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":["f1d005dd5ef5744d35de478e9702fc8c8d3cf4a9"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3584d3db8b472772e3329d9d95d584b68ae997e","date":1551710517,"type":3,"author":"Mikhail Khludnev","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if ((facetState.mcontext==null) ||facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n\n      // String finfoStr = JSONUtil.toJSON(finfo, -1);  // this doesn't handle formatting of Date objects the way we want\n      CharArr out = new CharArr();\n      JSONWriter jsonWriter = new JSONWriter(out, -1) {\n        @Override\n        public void handleUnknownClass(Object o) {\n          // handle date formatting correctly\n          if (o instanceof Date) {\n            String s = ((Date)o).toInstant().toString();\n            writeString(s);\n            return;\n          }\n          super.handleUnknownClass(o);\n        }\n      };\n      jsonWriter.write(finfo);\n      String finfoStr = out.toString();\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if (facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n\n      // String finfoStr = JSONUtil.toJSON(finfo, -1);  // this doesn't handle formatting of Date objects the way we want\n      CharArr out = new CharArr();\n      JSONWriter jsonWriter = new JSONWriter(out, -1) {\n        @Override\n        public void handleUnknownClass(Object o) {\n          // handle date formatting correctly\n          if (o instanceof Date) {\n            String s = ((Date)o).toInstant().toString();\n            writeString(s);\n            return;\n          }\n          super.handleUnknownClass(o);\n        }\n      };\n      jsonWriter.write(finfo);\n      String finfoStr = out.toString();\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":["1931d98b40b01d5075753b197c2461a5c2652689"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56a9893014b284af4d1af451e6c02e7ffdf5b6e","date":1590065972,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetModule#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if ((facetState.mcontext == null) || facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String, Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ((sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS | ShardRequest.PURPOSE_REFINE_FACETS | ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard)) {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[]{shard};\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String, Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n\n      // String finfoStr = JSONUtil.toJSON(finfo, -1);  // this doesn't handle formatting of Date objects the way we want\n      CharArr out = new CharArr();\n      JSONWriter jsonWriter = new JSONWriter(out, -1) {\n        @Override\n        public void handleUnknownClass(Object o) {\n          // handle date formatting correctly\n          if (o instanceof Date) {\n            String s = ((Date) o).toInstant().toString();\n            writeString(s);\n            return;\n          }\n          super.handleUnknownClass(o);\n        }\n      };\n      jsonWriter.write(finfo);\n      String finfoStr = out.toString();\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    FacetComponentState facetState = getFacetComponentState(rb);\n    if (facetState == null) return ResponseBuilder.STAGE_DONE;\n\n    if (rb.stage != ResponseBuilder.STAGE_GET_FIELDS) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Check if there are any refinements possible\n    if ((facetState.mcontext==null) ||facetState.mcontext.getSubsWithRefinement(facetState.facetRequest).isEmpty()) {\n      clearFaceting(rb.outgoing);\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    // Overlap facet refinement requests (those shards that we need a count\n    // for particular facet values from), where possible, with\n    // the requests to get fields (because we know that is the\n    // only other required phase).\n    // We do this in distributedProcess so we can look at all of the\n    // requests in the outgoing queue at once.\n\n    assert rb.shards.length == facetState.mcontext.numShards;\n    for (String shard : rb.shards) {\n      facetState.mcontext.setShard(shard);\n\n      // shard-specific refinement\n      Map<String,Object> refinement = facetState.merger.getRefinement(facetState.mcontext);\n      if (refinement == null) continue;\n\n      boolean newRequest = false;\n      ShardRequest shardsRefineRequest = null;\n\n      // try to find a request that is already going out to that shard.\n      // If nshards becomes too great, we may want to move to hashing for\n      // better scalability.\n      for (ShardRequest sreq : rb.outgoing) {\n        if ( (sreq.purpose & (ShardRequest.PURPOSE_GET_FIELDS|ShardRequest.PURPOSE_REFINE_FACETS|ShardRequest.PURPOSE_REFINE_PIVOT_FACETS)) != 0\n            && sreq.shards != null\n            && sreq.shards.length == 1\n            && sreq.shards[0].equals(shard))\n        {\n          shardsRefineRequest = sreq;\n          break;\n        }\n      }\n\n      if (shardsRefineRequest == null) {\n        // we didn't find any other suitable requests going out to that shard,\n        // so create one ourselves.\n        newRequest = true;\n        shardsRefineRequest = new ShardRequest();\n        shardsRefineRequest.shards = new String[] { shard };\n        shardsRefineRequest.params = new ModifiableSolrParams(rb.req.getParams());\n        // don't request any documents\n        shardsRefineRequest.params.remove(CommonParams.START);\n        shardsRefineRequest.params.set(CommonParams.ROWS, \"0\");\n        shardsRefineRequest.params.set(FacetParams.FACET, false);\n      }\n\n      shardsRefineRequest.purpose |= PURPOSE_REFINE_JSON_FACETS;\n\n      Map<String,Object> finfo = new HashMap<>(1);\n      finfo.put(FACET_REFINE, refinement);\n\n      // String finfoStr = JSONUtil.toJSON(finfo, -1);  // this doesn't handle formatting of Date objects the way we want\n      CharArr out = new CharArr();\n      JSONWriter jsonWriter = new JSONWriter(out, -1) {\n        @Override\n        public void handleUnknownClass(Object o) {\n          // handle date formatting correctly\n          if (o instanceof Date) {\n            String s = ((Date)o).toInstant().toString();\n            writeString(s);\n            return;\n          }\n          super.handleUnknownClass(o);\n        }\n      };\n      jsonWriter.write(finfo);\n      String finfoStr = out.toString();\n      // System.err.println(\"##################### REFINE=\" + finfoStr);\n      shardsRefineRequest.params.add(FACET_INFO, finfoStr);\n\n      if (newRequest) {\n        rb.addRequest(this, shardsRefineRequest);\n      }\n    }\n\n    // clearFaceting(rb.outgoing);\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"58b93c361b4f6fe193e84bfd27ea523366eada52":["8ec805ca8fedc0166461148c7182f1bcbbd18ee1"],"a3584d3db8b472772e3329d9d95d584b68ae997e":["15b321aed72eecb043f237c490b9afd4e52c25be"],"f1d005dd5ef5744d35de478e9702fc8c8d3cf4a9":["28288370235ed02234a64753cdbf0c6ec096304a"],"1931d98b40b01d5075753b197c2461a5c2652689":["ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"8ec805ca8fedc0166461148c7182f1bcbbd18ee1":["e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"8908009aaa8e9318b455c1c22b83e0e87738228a":["11ab475c994c79138885cc8a30b2641d929cdc43"],"15b321aed72eecb043f237c490b9afd4e52c25be":["f1d005dd5ef5744d35de478e9702fc8c8d3cf4a9"],"28288370235ed02234a64753cdbf0c6ec096304a":["58b93c361b4f6fe193e84bfd27ea523366eada52","d6ca2e1fb422aea9c41a4c63e72d6108a37291c1"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d","e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"d6ca2e1fb422aea9c41a4c63e72d6108a37291c1":["58b93c361b4f6fe193e84bfd27ea523366eada52"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"a56a9893014b284af4d1af451e6c02e7ffdf5b6e":["a3584d3db8b472772e3329d9d95d584b68ae997e"],"11ab475c994c79138885cc8a30b2641d929cdc43":["e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a":["ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d","1931d98b40b01d5075753b197c2461a5c2652689"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["8908009aaa8e9318b455c1c22b83e0e87738228a","d6ca2e1fb422aea9c41a4c63e72d6108a37291c1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a56a9893014b284af4d1af451e6c02e7ffdf5b6e"]},"commit2Childs":{"58b93c361b4f6fe193e84bfd27ea523366eada52":["28288370235ed02234a64753cdbf0c6ec096304a","d6ca2e1fb422aea9c41a4c63e72d6108a37291c1"],"a3584d3db8b472772e3329d9d95d584b68ae997e":["a56a9893014b284af4d1af451e6c02e7ffdf5b6e"],"f1d005dd5ef5744d35de478e9702fc8c8d3cf4a9":["15b321aed72eecb043f237c490b9afd4e52c25be"],"1931d98b40b01d5075753b197c2461a5c2652689":["e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"8ec805ca8fedc0166461148c7182f1bcbbd18ee1":["58b93c361b4f6fe193e84bfd27ea523366eada52"],"8908009aaa8e9318b455c1c22b83e0e87738228a":["2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"15b321aed72eecb043f237c490b9afd4e52c25be":["a3584d3db8b472772e3329d9d95d584b68ae997e"],"28288370235ed02234a64753cdbf0c6ec096304a":["f1d005dd5ef5744d35de478e9702fc8c8d3cf4a9"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d6ca2e1fb422aea9c41a4c63e72d6108a37291c1":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"a56a9893014b284af4d1af451e6c02e7ffdf5b6e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"11ab475c994c79138885cc8a30b2641d929cdc43":["8908009aaa8e9318b455c1c22b83e0e87738228a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d":["1931d98b40b01d5075753b197c2461a5c2652689","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a":["8ec805ca8fedc0166461148c7182f1bcbbd18ee1","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","11ab475c994c79138885cc8a30b2641d929cdc43"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}