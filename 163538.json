{"path":"lucene/contrib/demo/src/java/org/apache/lucene/demo/FileDocument#Document(File).mjava","commits":[{"id":"790c3f61c9b891d66d919c5d10db9fa5216eb0f1","date":1274818604,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/FileDocument#Document(File).mjava","pathOld":"lucene/src/demo/org/apache/lucene/demo/FileDocument#Document(File).mjava","sourceNew":"  /** Makes a document for a File.\n    <p>\n    The document has three fields:\n    <ul>\n    <li><code>path</code>--containing the pathname of the file, as a stored,\n    untokenized field;\n    <li><code>modified</code>--containing the last modified date of the file as\n    a field as created by <a\n    href=\"lucene.document.DateTools.html\">DateTools</a>; and\n    <li><code>contents</code>--containing the full contents of the file, as a\n    Reader field;\n    */\n  public static Document Document(File f)\n       throws java.io.FileNotFoundException {\n\t \n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the path of the file as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  Use \n    // a field that is indexed (i.e. searchable), but don't tokenize the field\n    // into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n    // so that the text of the file is tokenized and indexed, but not stored.\n    // Note that FileReader expects the file to be in the system's default encoding.\n    // If that's not the case searching for special characters will fail.\n    doc.add(new Field(\"contents\", new FileReader(f)));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  /** Makes a document for a File.\n    <p>\n    The document has three fields:\n    <ul>\n    <li><code>path</code>--containing the pathname of the file, as a stored,\n    untokenized field;\n    <li><code>modified</code>--containing the last modified date of the file as\n    a field as created by <a\n    href=\"lucene.document.DateTools.html\">DateTools</a>; and\n    <li><code>contents</code>--containing the full contents of the file, as a\n    Reader field;\n    */\n  public static Document Document(File f)\n       throws java.io.FileNotFoundException {\n\t \n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the path of the file as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  Use \n    // a field that is indexed (i.e. searchable), but don't tokenize the field\n    // into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n    // so that the text of the file is tokenized and indexed, but not stored.\n    // Note that FileReader expects the file to be in the system's default encoding.\n    // If that's not the case searching for special characters will fail.\n    doc.add(new Field(\"contents\", new FileReader(f)));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb38e04906cc704c95b1bb9cdc7a960017b0cc25","date":1288942385,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/FileDocument#Document(File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/FileDocument#Document(File).mjava","sourceNew":"  /** Makes a document for a File.\n    <p>\n    The document has three fields:\n    <ul>\n    <li><code>path</code>--containing the pathname of the file, as a stored,\n    untokenized field;\n    <li><code>modified</code>--containing the last modified date of the file as\n    a field as created by <a\n    href=\"lucene.document.DateTools.html\">DateTools</a>; and\n    <li><code>contents</code>--containing the full contents of the file, as a\n    Reader field;\n    */\n  public static Document Document(File f)\n       throws java.io.IOException {\n\t \n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the path of the file as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  Use \n    // a field that is indexed (i.e. searchable), but don't tokenize the field\n    // into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n    // so that the text of the file is tokenized and indexed, but not stored.\n    // Note that FileReader expects the file to be in UTF-8 encoding.\n    // If that's not the case searching for special characters will fail.\n    doc.add(new Field(\"contents\", new InputStreamReader(new FileInputStream(f), \"UTF-8\")));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  /** Makes a document for a File.\n    <p>\n    The document has three fields:\n    <ul>\n    <li><code>path</code>--containing the pathname of the file, as a stored,\n    untokenized field;\n    <li><code>modified</code>--containing the last modified date of the file as\n    a field as created by <a\n    href=\"lucene.document.DateTools.html\">DateTools</a>; and\n    <li><code>contents</code>--containing the full contents of the file, as a\n    Reader field;\n    */\n  public static Document Document(File f)\n       throws java.io.FileNotFoundException {\n\t \n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the path of the file as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  Use \n    // a field that is indexed (i.e. searchable), but don't tokenize the field\n    // into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n    // so that the text of the file is tokenized and indexed, but not stored.\n    // Note that FileReader expects the file to be in the system's default encoding.\n    // If that's not the case searching for special characters will fail.\n    doc.add(new Field(\"contents\", new FileReader(f)));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":["91109046a59c58ee0ee5d0d2767b08d1f30d6702","8fe73f6848cbfa49743e37b86b3e184dfc15a8cc"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/FileDocument#Document(File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/FileDocument#Document(File).mjava","sourceNew":"  /** Makes a document for a File.\n    <p>\n    The document has three fields:\n    <ul>\n    <li><code>path</code>--containing the pathname of the file, as a stored,\n    untokenized field;\n    <li><code>modified</code>--containing the last modified date of the file as\n    a field as created by <a\n    href=\"lucene.document.DateTools.html\">DateTools</a>; and\n    <li><code>contents</code>--containing the full contents of the file, as a\n    Reader field;\n    */\n  public static Document Document(File f)\n       throws java.io.IOException {\n\t \n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the path of the file as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  Use \n    // a field that is indexed (i.e. searchable), but don't tokenize the field\n    // into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n    // so that the text of the file is tokenized and indexed, but not stored.\n    // Note that FileReader expects the file to be in UTF-8 encoding.\n    // If that's not the case searching for special characters will fail.\n    doc.add(new Field(\"contents\", new InputStreamReader(new FileInputStream(f), \"UTF-8\")));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  /** Makes a document for a File.\n    <p>\n    The document has three fields:\n    <ul>\n    <li><code>path</code>--containing the pathname of the file, as a stored,\n    untokenized field;\n    <li><code>modified</code>--containing the last modified date of the file as\n    a field as created by <a\n    href=\"lucene.document.DateTools.html\">DateTools</a>; and\n    <li><code>contents</code>--containing the full contents of the file, as a\n    Reader field;\n    */\n  public static Document Document(File f)\n       throws java.io.FileNotFoundException {\n\t \n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the path of the file as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  Use \n    // a field that is indexed (i.e. searchable), but don't tokenize the field\n    // into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n    // so that the text of the file is tokenized and indexed, but not stored.\n    // Note that FileReader expects the file to be in the system's default encoding.\n    // If that's not the case searching for special characters will fail.\n    doc.add(new Field(\"contents\", new FileReader(f)));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/demo/src/java/org/apache/lucene/demo/FileDocument#Document(File).mjava","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/FileDocument#Document(File).mjava","sourceNew":"  /** Makes a document for a File.\n    <p>\n    The document has three fields:\n    <ul>\n    <li><code>path</code>--containing the pathname of the file, as a stored,\n    untokenized field;\n    <li><code>modified</code>--containing the last modified date of the file as\n    a field as created by <a\n    href=\"lucene.document.DateTools.html\">DateTools</a>; and\n    <li><code>contents</code>--containing the full contents of the file, as a\n    Reader field;\n    */\n  public static Document Document(File f)\n       throws java.io.IOException {\n\t \n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the path of the file as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  Use \n    // a field that is indexed (i.e. searchable), but don't tokenize the field\n    // into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n    // so that the text of the file is tokenized and indexed, but not stored.\n    // Note that FileReader expects the file to be in UTF-8 encoding.\n    // If that's not the case searching for special characters will fail.\n    doc.add(new Field(\"contents\", new InputStreamReader(new FileInputStream(f), \"UTF-8\")));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  /** Makes a document for a File.\n    <p>\n    The document has three fields:\n    <ul>\n    <li><code>path</code>--containing the pathname of the file, as a stored,\n    untokenized field;\n    <li><code>modified</code>--containing the last modified date of the file as\n    a field as created by <a\n    href=\"lucene.document.DateTools.html\">DateTools</a>; and\n    <li><code>contents</code>--containing the full contents of the file, as a\n    Reader field;\n    */\n  public static Document Document(File f)\n       throws java.io.FileNotFoundException {\n\t \n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the path of the file as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  Use \n    // a field that is indexed (i.e. searchable), but don't tokenize the field\n    // into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n    // so that the text of the file is tokenized and indexed, but not stored.\n    // Note that FileReader expects the file to be in the system's default encoding.\n    // If that's not the case searching for special characters will fail.\n    doc.add(new Field(\"contents\", new FileReader(f)));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81ea17596392ebd5d12741eb9e3b2516258b9413","date":1298090976,"type":4,"author":"Steven Rowe","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/FileDocument#Document(File).mjava","sourceNew":null,"sourceOld":"  /** Makes a document for a File.\n    <p>\n    The document has three fields:\n    <ul>\n    <li><code>path</code>--containing the pathname of the file, as a stored,\n    untokenized field;\n    <li><code>modified</code>--containing the last modified date of the file as\n    a field as created by <a\n    href=\"lucene.document.DateTools.html\">DateTools</a>; and\n    <li><code>contents</code>--containing the full contents of the file, as a\n    Reader field;\n    */\n  public static Document Document(File f)\n       throws java.io.IOException {\n\t \n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the path of the file as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  Use \n    // a field that is indexed (i.e. searchable), but don't tokenize the field\n    // into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n    // so that the text of the file is tokenized and indexed, but not stored.\n    // Note that FileReader expects the file to be in UTF-8 encoding.\n    // If that's not the case searching for special characters will fail.\n    doc.add(new Field(\"contents\", new InputStreamReader(new FileInputStream(f), \"UTF-8\")));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/FileDocument#Document(File).mjava","sourceNew":null,"sourceOld":"  /** Makes a document for a File.\n    <p>\n    The document has three fields:\n    <ul>\n    <li><code>path</code>--containing the pathname of the file, as a stored,\n    untokenized field;\n    <li><code>modified</code>--containing the last modified date of the file as\n    a field as created by <a\n    href=\"lucene.document.DateTools.html\">DateTools</a>; and\n    <li><code>contents</code>--containing the full contents of the file, as a\n    Reader field;\n    */\n  public static Document Document(File f)\n       throws java.io.IOException {\n\t \n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the path of the file as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  Use \n    // a field that is indexed (i.e. searchable), but don't tokenize the field\n    // into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n    // so that the text of the file is tokenized and indexed, but not stored.\n    // Note that FileReader expects the file to be in UTF-8 encoding.\n    // If that's not the case searching for special characters will fail.\n    doc.add(new Field(\"contents\", new InputStreamReader(new FileInputStream(f), \"UTF-8\")));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/demo/src/java/org/apache/lucene/demo/FileDocument#Document(File).mjava","sourceNew":null,"sourceOld":"  /** Makes a document for a File.\n    <p>\n    The document has three fields:\n    <ul>\n    <li><code>path</code>--containing the pathname of the file, as a stored,\n    untokenized field;\n    <li><code>modified</code>--containing the last modified date of the file as\n    a field as created by <a\n    href=\"lucene.document.DateTools.html\">DateTools</a>; and\n    <li><code>contents</code>--containing the full contents of the file, as a\n    Reader field;\n    */\n  public static Document Document(File f)\n       throws java.io.IOException {\n\t \n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the path of the file as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  Use \n    // a field that is indexed (i.e. searchable), but don't tokenize the field\n    // into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the contents of the file to a field named \"contents\".  Specify a Reader,\n    // so that the text of the file is tokenized and indexed, but not stored.\n    // Note that FileReader expects the file to be in UTF-8 encoding.\n    // If that's not the case searching for special characters will fail.\n    doc.add(new Field(\"contents\", new InputStreamReader(new FileInputStream(f), \"UTF-8\")));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f1bdbf92da222965b46c0a942c3857ba56e5c638":["85a883878c0af761245ab048babc63d099f835f3","81ea17596392ebd5d12741eb9e3b2516258b9413"],"81ea17596392ebd5d12741eb9e3b2516258b9413":["fb38e04906cc704c95b1bb9cdc7a960017b0cc25"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"85a883878c0af761245ab048babc63d099f835f3":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1","fb38e04906cc704c95b1bb9cdc7a960017b0cc25"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1","fb38e04906cc704c95b1bb9cdc7a960017b0cc25"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","81ea17596392ebd5d12741eb9e3b2516258b9413"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["81ea17596392ebd5d12741eb9e3b2516258b9413"],"fb38e04906cc704c95b1bb9cdc7a960017b0cc25":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"f1bdbf92da222965b46c0a942c3857ba56e5c638":[],"81ea17596392ebd5d12741eb9e3b2516258b9413":["f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"85a883878c0af761245ab048babc63d099f835f3":["f1bdbf92da222965b46c0a942c3857ba56e5c638"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"fb38e04906cc704c95b1bb9cdc7a960017b0cc25":["81ea17596392ebd5d12741eb9e3b2516258b9413","85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","fb38e04906cc704c95b1bb9cdc7a960017b0cc25"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}