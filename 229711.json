{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","commits":[{"id":"889901f1b564e80868c57d5f3743f4ddbb4ce44a","date":1375181138,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<TermFreq> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new TermFreq(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    \n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(new MockAnalyzer(random()));\n    analyzingSuggester.setPreservePositionIncrements(random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<TermFreqPayload> keysAndPayloads = new ArrayList<>();\n      for (TermFreq termFreq : keys) {\n        keysAndPayloads.add(new TermFreqPayload(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new TermFreqPayloadArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new TermFreqArrayIterator(keys));  \n    }\n    \n    for (TermFreq termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    lineFile.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":0,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<TermFreq> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new TermFreq(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    \n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(new MockAnalyzer(random()));\n    analyzingSuggester.setPreservePositionIncrements(random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<TermFreqPayload> keysAndPayloads = new ArrayList<>();\n      for (TermFreq termFreq : keys) {\n        keysAndPayloads.add(new TermFreqPayload(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new TermFreqPayloadArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new TermFreqArrayIterator(keys));  \n    }\n    \n    for (TermFreq termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    lineFile.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ada2f7352a7f964fe49bccd13227c4ec38563d39","date":1381659982,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","sourceNew":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<TermFreqPayload> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new TermFreqPayload(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    \n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(new MockAnalyzer(random()));\n    analyzingSuggester.setPreservePositionIncrements(random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<TermFreqPayload> keysAndPayloads = new ArrayList<>();\n      for (TermFreqPayload termFreq : keys) {\n        keysAndPayloads.add(new TermFreqPayload(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new TermFreqPayloadArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new TermFreqPayloadArrayIterator(keys));  \n    }\n    \n    for (TermFreqPayload termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    lineFile.close();\n  }\n\n","sourceOld":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<TermFreq> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new TermFreq(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    \n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(new MockAnalyzer(random()));\n    analyzingSuggester.setPreservePositionIncrements(random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<TermFreqPayload> keysAndPayloads = new ArrayList<>();\n      for (TermFreq termFreq : keys) {\n        keysAndPayloads.add(new TermFreqPayload(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new TermFreqPayloadArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new TermFreqArrayIterator(keys));  \n    }\n    \n    for (TermFreq termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    lineFile.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41aee74b5f91a096e3fd950f4a336bc763f0e7a7","date":1381772070,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","sourceNew":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    \n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(new MockAnalyzer(random()));\n    analyzingSuggester.setPreservePositionIncrements(random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    lineFile.close();\n  }\n\n","sourceOld":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<TermFreqPayload> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new TermFreqPayload(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    \n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(new MockAnalyzer(random()));\n    analyzingSuggester.setPreservePositionIncrements(random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<TermFreqPayload> keysAndPayloads = new ArrayList<>();\n      for (TermFreqPayload termFreq : keys) {\n        keysAndPayloads.add(new TermFreqPayload(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new TermFreqPayloadArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new TermFreqPayloadArrayIterator(keys));  \n    }\n    \n    for (TermFreqPayload termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    lineFile.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4e0095ef720d1b8e7406847147af69f19af3ab6","date":1383131477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","sourceNew":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(new MockAnalyzer(random()), new MockAnalyzer(random()),\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    lineFile.close();\n  }\n\n","sourceOld":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    \n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(new MockAnalyzer(random()));\n    analyzingSuggester.setPreservePositionIncrements(random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    lineFile.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","sourceNew":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    Analyzer indexAnalyzer = new MockAnalyzer(random());\n    Analyzer queryAnalyzer = new MockAnalyzer(random());\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(indexAnalyzer, queryAnalyzer,\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    IOUtils.close(lineFile, indexAnalyzer, queryAnalyzer);\n  }\n\n","sourceOld":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(new MockAnalyzer(random()), new MockAnalyzer(random()),\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    lineFile.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","sourceNew":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    Analyzer indexAnalyzer = new MockAnalyzer(random());\n    Analyzer queryAnalyzer = new MockAnalyzer(random());\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(indexAnalyzer, queryAnalyzer,\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    IOUtils.close(lineFile, indexAnalyzer, queryAnalyzer);\n  }\n\n","sourceOld":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(new MockAnalyzer(random()), new MockAnalyzer(random()),\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    lineFile.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"867e3d9153fb761456b54a9dcce566e1545c5ef6","date":1444903098,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","sourceNew":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    Analyzer indexAnalyzer = new MockAnalyzer(random());\n    Analyzer queryAnalyzer = new MockAnalyzer(random());\n    Directory tempDir = getDirectory();\n\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(tempDir, \"suggest\", indexAnalyzer, queryAnalyzer,\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    IOUtils.close(lineFile, indexAnalyzer, queryAnalyzer, tempDir);\n  }\n\n","sourceOld":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    Analyzer indexAnalyzer = new MockAnalyzer(random());\n    Analyzer queryAnalyzer = new MockAnalyzer(random());\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(indexAnalyzer, queryAnalyzer,\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    IOUtils.close(lineFile, indexAnalyzer, queryAnalyzer);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b38ea7a4ab33863f70e24bc63632e650d8e2c521","date":1502089951,"type":3,"author":"Jim Ferenczi","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","sourceNew":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      int maxLen = Math.min(title.length(), 500);\n      String prefix = title.substring(0, maxLen);\n      keys.add(new Input(prefix, randomWeight));\n      if (!mapping.containsKey(prefix) || mapping.get(prefix) < randomWeight) {\n        mapping.put(prefix, Long.valueOf(randomWeight));\n      }\n    }\n    Analyzer indexAnalyzer = new MockAnalyzer(random());\n    Analyzer queryAnalyzer = new MockAnalyzer(random());\n    Directory tempDir = getDirectory();\n\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(tempDir, \"suggest\", indexAnalyzer, queryAnalyzer,\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    IOUtils.close(lineFile, indexAnalyzer, queryAnalyzer, tempDir);\n  }\n\n","sourceOld":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    Analyzer indexAnalyzer = new MockAnalyzer(random());\n    Analyzer queryAnalyzer = new MockAnalyzer(random());\n    Directory tempDir = getDirectory();\n\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(tempDir, \"suggest\", indexAnalyzer, queryAnalyzer,\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    IOUtils.close(lineFile, indexAnalyzer, queryAnalyzer, tempDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"566112f6115904d848cbf09462ebd8bf1304257b","date":1502103699,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","sourceNew":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      int maxLen = Math.min(title.length(), 500);\n      String prefix = title.substring(0, maxLen);\n      keys.add(new Input(prefix, randomWeight));\n      if (!mapping.containsKey(prefix) || mapping.get(prefix) < randomWeight) {\n        mapping.put(prefix, Long.valueOf(randomWeight));\n      }\n    }\n    Analyzer indexAnalyzer = new MockAnalyzer(random());\n    Analyzer queryAnalyzer = new MockAnalyzer(random());\n    Directory tempDir = getDirectory();\n\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(tempDir, \"suggest\", indexAnalyzer, queryAnalyzer,\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    IOUtils.close(lineFile, indexAnalyzer, queryAnalyzer, tempDir);\n  }\n\n","sourceOld":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    Analyzer indexAnalyzer = new MockAnalyzer(random());\n    Analyzer queryAnalyzer = new MockAnalyzer(random());\n    Directory tempDir = getDirectory();\n\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(tempDir, \"suggest\", indexAnalyzer, queryAnalyzer,\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    IOUtils.close(lineFile, indexAnalyzer, queryAnalyzer, tempDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#testRandomRealisticKeys().mjava","sourceNew":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      int maxLen = Math.min(title.length(), 500);\n      String prefix = title.substring(0, maxLen);\n      keys.add(new Input(prefix, randomWeight));\n      if (!mapping.containsKey(prefix) || mapping.get(prefix) < randomWeight) {\n        mapping.put(prefix, Long.valueOf(randomWeight));\n      }\n    }\n    Analyzer indexAnalyzer = new MockAnalyzer(random());\n    Analyzer queryAnalyzer = new MockAnalyzer(random());\n    Directory tempDir = getDirectory();\n\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(tempDir, \"suggest\", indexAnalyzer, queryAnalyzer,\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    IOUtils.close(lineFile, indexAnalyzer, queryAnalyzer, tempDir);\n  }\n\n","sourceOld":"  public void testRandomRealisticKeys() throws IOException {\n    LineFileDocs lineFile = new LineFileDocs(random());\n    Map<String, Long> mapping = new HashMap<>();\n    List<Input> keys = new ArrayList<>();\n    \n    int howMany = atLeast(100); // this might bring up duplicates\n    for (int i = 0; i < howMany; i++) {\n      Document nextDoc = lineFile.nextDoc();\n      String title = nextDoc.getField(\"title\").stringValue();\n      int randomWeight = random().nextInt(100);\n      keys.add(new Input(title, randomWeight));\n      if (!mapping.containsKey(title) || mapping.get(title) < randomWeight) {\n          mapping.put(title, Long.valueOf(randomWeight));\n      }\n    }\n    Analyzer indexAnalyzer = new MockAnalyzer(random());\n    Analyzer queryAnalyzer = new MockAnalyzer(random());\n    Directory tempDir = getDirectory();\n\n    AnalyzingSuggester analyzingSuggester = new AnalyzingSuggester(tempDir, \"suggest\", indexAnalyzer, queryAnalyzer,\n        AnalyzingSuggester.EXACT_FIRST | AnalyzingSuggester.PRESERVE_SEP, 256, -1, random().nextBoolean());\n    boolean doPayloads = random().nextBoolean();\n    if (doPayloads) {\n      List<Input> keysAndPayloads = new ArrayList<>();\n      for (Input termFreq : keys) {\n        keysAndPayloads.add(new Input(termFreq.term, termFreq.v, new BytesRef(Long.toString(termFreq.v))));\n      }\n      analyzingSuggester.build(new InputArrayIterator(keysAndPayloads));\n    } else {\n      analyzingSuggester.build(new InputArrayIterator(keys));  \n    }\n    \n    for (Input termFreq : keys) {\n      List<LookupResult> lookup = analyzingSuggester.lookup(termFreq.term.utf8ToString(), false, keys.size());\n      for (LookupResult lookupResult : lookup) {\n        assertEquals(mapping.get(lookupResult.key), Long.valueOf(lookupResult.value));\n        if (doPayloads) {\n          assertEquals(lookupResult.payload.utf8ToString(), Long.toString(lookupResult.value));\n        } else {\n          assertNull(lookupResult.payload);\n        }\n      }\n    }\n    \n    IOUtils.close(lineFile, indexAnalyzer, queryAnalyzer, tempDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["d4e0095ef720d1b8e7406847147af69f19af3ab6","a56958d7f71a28824f20031ffbb2e13502a0274e"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["867e3d9153fb761456b54a9dcce566e1545c5ef6","566112f6115904d848cbf09462ebd8bf1304257b"],"566112f6115904d848cbf09462ebd8bf1304257b":["867e3d9153fb761456b54a9dcce566e1545c5ef6","b38ea7a4ab33863f70e24bc63632e650d8e2c521"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b38ea7a4ab33863f70e24bc63632e650d8e2c521":["867e3d9153fb761456b54a9dcce566e1545c5ef6"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"889901f1b564e80868c57d5f3743f4ddbb4ce44a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["d4e0095ef720d1b8e7406847147af69f19af3ab6"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["a56958d7f71a28824f20031ffbb2e13502a0274e"],"d4e0095ef720d1b8e7406847147af69f19af3ab6":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["566112f6115904d848cbf09462ebd8bf1304257b"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["889901f1b564e80868c57d5f3743f4ddbb4ce44a"]},"commit2Childs":{"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["d4e0095ef720d1b8e7406847147af69f19af3ab6"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"566112f6115904d848cbf09462ebd8bf1304257b":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b38ea7a4ab33863f70e24bc63632e650d8e2c521":["566112f6115904d848cbf09462ebd8bf1304257b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","889901f1b564e80868c57d5f3743f4ddbb4ce44a"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"889901f1b564e80868c57d5f3743f4ddbb4ce44a":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","867e3d9153fb761456b54a9dcce566e1545c5ef6"],"d4e0095ef720d1b8e7406847147af69f19af3ab6":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","566112f6115904d848cbf09462ebd8bf1304257b","b38ea7a4ab33863f70e24bc63632e650d8e2c521"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}