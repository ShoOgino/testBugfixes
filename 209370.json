{"path":"solr/test-framework/src/java/org/apache/solr/util/SolrSecurityManager#checkRead(String).mjava","commits":[{"id":"cf4186ad2efcdebf9859a7b14723a280571c6587","date":1575575603,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"solr/test-framework/src/java/org/apache/solr/util/SolrSecurityManager#checkRead(String).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/util/TestSecurityManager#checkRead(String).mjava","sourceNew":"  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage FileUtil code\n   */\n  @Override\n  public void checkRead(String file) {\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop \"createPermissionsDiagnosisString\" method doesn't handle securityexception and fails completely.\n      // it insists on climbing up full directory tree!\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.hdfs.MiniDFSCluster\".equals(element.getClassName()) &&\n          \"createPermissionsDiagnosisString\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canRead\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canRead\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkRead(file);\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage FileUtil code\n   */\n  @Override\n  public void checkRead(String file) {\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop \"createPermissionsDiagnosisString\" method doesn't handle securityexception and fails completely.\n      // it insists on climbing up full directory tree!\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.hdfs.MiniDFSCluster\".equals(element.getClassName()) &&\n          \"createPermissionsDiagnosisString\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canRead\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canRead\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkRead(file);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c173aec5dba4a880e26706e8ca1ec9e67b74ed5","date":1575629849,"type":1,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/test-framework/src/java/org/apache/solr/util/SolrSecurityManager#checkRead(String).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/util/TestSecurityManager#checkRead(String).mjava","sourceNew":"  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage FileUtil code\n   */\n  @Override\n  public void checkRead(String file) {\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop \"createPermissionsDiagnosisString\" method doesn't handle securityexception and fails completely.\n      // it insists on climbing up full directory tree!\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.hdfs.MiniDFSCluster\".equals(element.getClassName()) &&\n          \"createPermissionsDiagnosisString\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canRead\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canRead\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkRead(file);\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage FileUtil code\n   */\n  @Override\n  public void checkRead(String file) {\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop \"createPermissionsDiagnosisString\" method doesn't handle securityexception and fails completely.\n      // it insists on climbing up full directory tree!\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.hdfs.MiniDFSCluster\".equals(element.getClassName()) &&\n          \"createPermissionsDiagnosisString\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canRead\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canRead\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkRead(file);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bdf107cf16be0f22504ae184fed81596665a244","date":1576012524,"type":4,"author":"Kevin Risden","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/test-framework/src/java/org/apache/solr/util/SolrSecurityManager#checkRead(String).mjava","sourceNew":null,"sourceOld":"  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage FileUtil code\n   */\n  @Override\n  public void checkRead(String file) {\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop \"createPermissionsDiagnosisString\" method doesn't handle securityexception and fails completely.\n      // it insists on climbing up full directory tree!\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.hdfs.MiniDFSCluster\".equals(element.getClassName()) &&\n          \"createPermissionsDiagnosisString\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canRead\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canRead\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkRead(file);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a229cb50768e988c50a2106bdae3a92154f428bf","date":1576051038,"type":4,"author":"Dawid Weiss","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/test-framework/src/java/org/apache/solr/util/SolrSecurityManager#checkRead(String).mjava","sourceNew":null,"sourceOld":"  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage FileUtil code\n   */\n  @Override\n  public void checkRead(String file) {\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop \"createPermissionsDiagnosisString\" method doesn't handle securityexception and fails completely.\n      // it insists on climbing up full directory tree!\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.hdfs.MiniDFSCluster\".equals(element.getClassName()) &&\n          \"createPermissionsDiagnosisString\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canRead\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily read, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canRead\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkRead(file);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a229cb50768e988c50a2106bdae3a92154f428bf":["2c173aec5dba4a880e26706e8ca1ec9e67b74ed5","6bdf107cf16be0f22504ae184fed81596665a244"],"cf4186ad2efcdebf9859a7b14723a280571c6587":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6bdf107cf16be0f22504ae184fed81596665a244":["cf4186ad2efcdebf9859a7b14723a280571c6587"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2c173aec5dba4a880e26706e8ca1ec9e67b74ed5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","cf4186ad2efcdebf9859a7b14723a280571c6587"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6bdf107cf16be0f22504ae184fed81596665a244"]},"commit2Childs":{"a229cb50768e988c50a2106bdae3a92154f428bf":[],"cf4186ad2efcdebf9859a7b14723a280571c6587":["6bdf107cf16be0f22504ae184fed81596665a244","2c173aec5dba4a880e26706e8ca1ec9e67b74ed5"],"2c173aec5dba4a880e26706e8ca1ec9e67b74ed5":["a229cb50768e988c50a2106bdae3a92154f428bf"],"6bdf107cf16be0f22504ae184fed81596665a244":["a229cb50768e988c50a2106bdae3a92154f428bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cf4186ad2efcdebf9859a7b14723a280571c6587","2c173aec5dba4a880e26706e8ca1ec9e67b74ed5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a229cb50768e988c50a2106bdae3a92154f428bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}