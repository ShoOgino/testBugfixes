{"path":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","commits":[{"id":"1816753738ff1f27f11b38030e83c0ded050b7a4","date":1380106089,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"/dev/null","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<String, List<Integer>>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2e73db80cda3387e197641256d964f8c1c3992c7","date":1380978036,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<String, List<Integer>>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<String, List<Integer>>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bc841231667f1f315bae6799c068f9aad6543967","date":1381415189,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<String, List<Integer>>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    waitForRecoveriesToFinish(collectionName, false);\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<String, List<Integer>>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9d5abf772262a05c74afddcadc95c4bdab07f1f","date":1381747682,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<String, List<Integer>>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null, null);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    waitForRecoveriesToFinish(collectionName, false);\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<String, List<Integer>>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    waitForRecoveriesToFinish(collectionName, false);\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null, null);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    waitForRecoveriesToFinish(collectionName, false);\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<String, List<Integer>>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null, null);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    waitForRecoveriesToFinish(collectionName, false);\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c7856260bc28f285ae7bfefa99b28db4dca6daf","date":1395253500,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null, null);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    waitForRecoveriesToFinish(collectionName, false);\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    collectionClient.shutdown();\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null, null);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    waitForRecoveriesToFinish(collectionName, false);\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bafca15d8e408346a67f4282ad1143b88023893b","date":1420034748,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    CloudSolrClient client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrClient collectionClient = new HttpSolrClient(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null, null);\n        break;\n      } catch (HttpSolrClient.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    waitForRecoveriesToFinish(collectionName, false);\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    collectionClient.shutdown();\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    CloudSolrServer client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrServer collectionClient = new HttpSolrServer(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null, null);\n        break;\n      } catch (HttpSolrServer.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    waitForRecoveriesToFinish(collectionName, false);\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    collectionClient.shutdown();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cc3b13b430571c2e169f98fe38e1e7666f88522d","date":1422446157,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = new HttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    CloudSolrClient client = null;\n    String shard_fld = \"shard_s\";\n    try {\n      client = createCloudClient(null);\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    } finally {\n      if (client != null) client.shutdown();\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    HttpSolrClient collectionClient = new HttpSolrClient(url);\n\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n    Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n\n    for (int i = 100; i <= 200; i++) {\n      String shardKey = \"\" + (char)('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n      collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n      int idx = getHashRangeIdx(router, ranges, shardKey);\n      if (idx != -1)  {\n        docCounts[idx]++;\n      }\n    }\n\n    for (int i = 0; i < docCounts.length; i++) {\n      int docCount = docCounts[i];\n      log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n    }\n\n    collectionClient.commit();\n\n    for (int i = 0; i < 3; i++) {\n      try {\n        splitShard(collectionName, SHARD1, null, null);\n        break;\n      } catch (HttpSolrClient.RemoteSolrException e) {\n        if (e.code() != 500) {\n          throw e;\n        }\n        log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n        if (i == 2) {\n          fail(\"SPLITSHARD was not successful even after three tries\");\n        }\n      }\n    }\n\n    waitForRecoveriesToFinish(collectionName, false);\n\n    assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n    assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    collectionClient.shutdown();\n  }\n\n","bugFix":null,"bugIntro":["344b0840364d990b29b97467bfcc766ff8325d11"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"234afba21d42e6c527535c6aa11baba09a4771f3","date":1432825127,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = new HttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = new HttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b693a83132c9e45afcd564fd65a25b60ed80388b","date":1436882146,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = new HttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = ZkNodeProps.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = new HttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088","date":1460069869,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = new HttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b","date":1460110033,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = new HttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"344b0840364d990b29b97467bfcc766ff8325d11","date":1501574100,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getSlice(collectionName, SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6146c07c0dee1ae1e42926167acd127fed5ef59d","date":1516129420,"type":5,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByRouteFieldTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          OverseerCollectionMessageHandler.NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":4,"author":"Karl Wright","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByRouteFieldTest().mjava","sourceNew":null,"sourceOld":"  public void splitByRouteFieldTest() throws Exception  {\n    log.info(\"Starting testSplitWithRouteField\");\n    String collectionName = \"routeFieldColl\";\n    int numShards = 4;\n    int replicationFactor = 2;\n    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()\n        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;\n\n    HashMap<String, List<Integer>> collectionInfos = new HashMap<>();\n    String shard_fld = \"shard_s\";\n    try (CloudSolrClient client = createCloudClient(null)) {\n      Map<String, Object> props = Utils.makeMap(\n          REPLICATION_FACTOR, replicationFactor,\n          MAX_SHARDS_PER_NODE, maxShardsPerNode,\n          NUM_SLICES, numShards,\n          \"router.field\", shard_fld);\n\n      createCollection(collectionInfos, collectionName,props,client);\n    }\n\n    List<Integer> list = collectionInfos.get(collectionName);\n    checkForCollection(collectionName, list, null);\n\n    waitForRecoveriesToFinish(false);\n\n    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);\n\n    try (HttpSolrClient collectionClient = getHttpSolrClient(url)) {\n\n      ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n      final DocRouter router = clusterState.getCollection(collectionName).getRouter();\n      Slice shard1 = clusterState.getCollection(collectionName).getSlice(SHARD1);\n      DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n      final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n      final int[] docCounts = new int[ranges.size()];\n\n      for (int i = 100; i <= 200; i++) {\n        String shardKey = \"\" + (char) ('a' + (i % 26)); // See comment in ShardRoutingTest for hash distribution\n\n        collectionClient.add(getDoc(id, i, \"n_ti\", i, shard_fld, shardKey));\n        int idx = getHashRangeIdx(router, ranges, shardKey);\n        if (idx != -1) {\n          docCounts[idx]++;\n        }\n      }\n\n      for (int i = 0; i < docCounts.length; i++) {\n        int docCount = docCounts[i];\n        log.info(\"Shard {} docCount = {}\", \"shard1_\" + i, docCount);\n      }\n\n      collectionClient.commit();\n\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(collectionName, SHARD1, null, null);\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500) {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n\n      waitForRecoveriesToFinish(collectionName, false);\n\n      assertEquals(docCounts[0], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_0\")).getResults().getNumFound());\n      assertEquals(docCounts[1], collectionClient.query(new SolrQuery(\"*:*\").setParam(\"shards\", \"shard1_1\")).getResults().getNumFound());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["d9d5abf772262a05c74afddcadc95c4bdab07f1f"],"1816753738ff1f27f11b38030e83c0ded050b7a4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b94236357aaa22b76c10629851fe4e376e0cea82":["344b0840364d990b29b97467bfcc766ff8325d11","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"344b0840364d990b29b97467bfcc766ff8325d11":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088":["b693a83132c9e45afcd564fd65a25b60ed80388b"],"b693a83132c9e45afcd564fd65a25b60ed80388b":["234afba21d42e6c527535c6aa11baba09a4771f3"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["344b0840364d990b29b97467bfcc766ff8325d11"],"bafca15d8e408346a67f4282ad1143b88023893b":["4c7856260bc28f285ae7bfefa99b28db4dca6daf"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b","344b0840364d990b29b97467bfcc766ff8325d11"],"234afba21d42e6c527535c6aa11baba09a4771f3":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"4c7856260bc28f285ae7bfefa99b28db4dca6daf":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"bc841231667f1f315bae6799c068f9aad6543967":["2e73db80cda3387e197641256d964f8c1c3992c7"],"2e73db80cda3387e197641256d964f8c1c3992c7":["1816753738ff1f27f11b38030e83c0ded050b7a4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d9d5abf772262a05c74afddcadc95c4bdab07f1f":["bc841231667f1f315bae6799c068f9aad6543967"],"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b":["b693a83132c9e45afcd564fd65a25b60ed80388b","e3c94a8b8bf47db4f968d9ae510ec8bbe1372088"],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["bafca15d8e408346a67f4282ad1143b88023893b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b94236357aaa22b76c10629851fe4e376e0cea82"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["4c7856260bc28f285ae7bfefa99b28db4dca6daf"],"1816753738ff1f27f11b38030e83c0ded050b7a4":["2e73db80cda3387e197641256d964f8c1c3992c7"],"b94236357aaa22b76c10629851fe4e376e0cea82":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"344b0840364d990b29b97467bfcc766ff8325d11":["b94236357aaa22b76c10629851fe4e376e0cea82","6146c07c0dee1ae1e42926167acd127fed5ef59d","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b94236357aaa22b76c10629851fe4e376e0cea82"],"b693a83132c9e45afcd564fd65a25b60ed80388b":["e3c94a8b8bf47db4f968d9ae510ec8bbe1372088","5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"bafca15d8e408346a67f4282ad1143b88023893b":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"234afba21d42e6c527535c6aa11baba09a4771f3":["b693a83132c9e45afcd564fd65a25b60ed80388b"],"4c7856260bc28f285ae7bfefa99b28db4dca6daf":["bafca15d8e408346a67f4282ad1143b88023893b"],"bc841231667f1f315bae6799c068f9aad6543967":["d9d5abf772262a05c74afddcadc95c4bdab07f1f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1816753738ff1f27f11b38030e83c0ded050b7a4"],"2e73db80cda3387e197641256d964f8c1c3992c7":["bc841231667f1f315bae6799c068f9aad6543967"],"d9d5abf772262a05c74afddcadc95c4bdab07f1f":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b":["344b0840364d990b29b97467bfcc766ff8325d11","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["234afba21d42e6c527535c6aa11baba09a4771f3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}