{"path":"src/test/org/apache/solr/HighlighterTest#testTermVecHighlight().mjava","commits":[{"id":"1aa2b803ab70ac42b322d648a4f0bf8fdcb7456d","date":1152816469,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/test/org/apache/solr/HighlighterTest#testTermVecHighlight().mjava","pathOld":"/dev/null","sourceNew":"  public void testTermVecHighlight() {\n\n    // do summarization using term vectors\n    HashMap args = new HashMap();\n    args.put(\"highlight\", \"true\");\n    args.put(\"highlightFields\", \"tv_text\");\n    args.put(\"maxSnippets\", \"2\");\n    TestHarness.LocalRequestFactory sumLRF = h.getRequestFactory(\n      \"standard\",0,200,args);\n    \n    assertU(adoc(\"tv_text\", \"a long days night this should be a piece of text which is is is is is is is is is is is is is is is is is is is is is is is is isis is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is sufficiently lengthly to produce multiple fragments which are not concatenated at all--we want two disjoint long fragments.\", \n                 \"id\", \"1\"));\n    assertU(commit());\n    assertU(optimize());\n    assertQ(\"Basic summarization\",\n            sumLRF.makeRequest(\"tv_text:long\"),\n            \"//lst[@name='highlighting']/lst[@name='1']\",\n            \"//lst[@name='1']/arr[@name='tv_text']/str[.='a <em>long</em> days night this should be a piece of text which']\",\n            \"//arr[@name='tv_text']/str[.=' <em>long</em> fragments']\"\n            );\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"af09a11446184597ca824554260a98704507f8a7","date":1157138567,"type":3,"author":"Mike Klaas","isMerge":false,"pathNew":"src/test/org/apache/solr/HighlighterTest#testTermVecHighlight().mjava","pathOld":"src/test/org/apache/solr/HighlighterTest#testTermVecHighlight().mjava","sourceNew":"  public void testTermVecHighlight() {\n\n    // do summarization using term vectors\n    HashMap<String,String> args = new HashMap<String,String>();\n    args.put(\"hl\", \"true\");\n    args.put(\"hl.fl\", \"tv_text\");\n    args.put(\"hl.snippets\", \"2\");\n    TestHarness.LocalRequestFactory sumLRF = h.getRequestFactory(\n      \"standard\",0,200,args);\n    \n    assertU(adoc(\"tv_text\", \"a long days night this should be a piece of text which is is is is is is is is is is is is is is is is is is is is is is is is isis is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is sufficiently lengthly to produce multiple fragments which are not concatenated at all--we want two disjoint long fragments.\", \n                 \"id\", \"1\"));\n    assertU(commit());\n    assertU(optimize());\n    assertQ(\"Basic summarization\",\n            sumLRF.makeRequest(\"tv_text:long\"),\n            \"//lst[@name='highlighting']/lst[@name='1']\",\n            \"//lst[@name='1']/arr[@name='tv_text']/str[.='a <em>long</em> days night this should be a piece of text which']\",\n            \"//arr[@name='tv_text']/str[.=' <em>long</em> fragments']\"\n            );\n  }\n\n","sourceOld":"  public void testTermVecHighlight() {\n\n    // do summarization using term vectors\n    HashMap args = new HashMap();\n    args.put(\"highlight\", \"true\");\n    args.put(\"highlightFields\", \"tv_text\");\n    args.put(\"maxSnippets\", \"2\");\n    TestHarness.LocalRequestFactory sumLRF = h.getRequestFactory(\n      \"standard\",0,200,args);\n    \n    assertU(adoc(\"tv_text\", \"a long days night this should be a piece of text which is is is is is is is is is is is is is is is is is is is is is is is is isis is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is sufficiently lengthly to produce multiple fragments which are not concatenated at all--we want two disjoint long fragments.\", \n                 \"id\", \"1\"));\n    assertU(commit());\n    assertU(optimize());\n    assertQ(\"Basic summarization\",\n            sumLRF.makeRequest(\"tv_text:long\"),\n            \"//lst[@name='highlighting']/lst[@name='1']\",\n            \"//lst[@name='1']/arr[@name='tv_text']/str[.='a <em>long</em> days night this should be a piece of text which']\",\n            \"//arr[@name='tv_text']/str[.=' <em>long</em> fragments']\"\n            );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0b845edb872ec943a6446ed152345ddc4bea9549","date":1157761602,"type":3,"author":"Mike Klaas","isMerge":false,"pathNew":"src/test/org/apache/solr/HighlighterTest#testTermVecHighlight().mjava","pathOld":"src/test/org/apache/solr/HighlighterTest#testTermVecHighlight().mjava","sourceNew":"  public void testTermVecHighlight() {\n\n    // do summarization using term vectors\n    HashMap<String,String> args = new HashMap<String,String>();\n    args.put(\"hl\", \"true\");\n    args.put(\"hl.fl\", \"tv_text\");\n    args.put(\"hl.snippets\", \"2\");\n    TestHarness.LocalRequestFactory sumLRF = h.getRequestFactory(\n      \"standard\",0,200,args);\n    \n    assertU(adoc(\"tv_text\", \"a long days night this should be a piece of text which is is is is is is is is is is is is is is is is is is is is is is is is isis is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is sufficiently lengthly to produce multiple fragments which are not concatenated at all--we want two disjoint long fragments.\", \n                 \"id\", \"1\"));\n    assertU(commit());\n    assertU(optimize());\n    assertQ(\"Basic summarization\",\n            sumLRF.makeRequest(\"tv_text:long\"),\n            \"//lst[@name='highlighting']/lst[@name='1']\",\n            \"//lst[@name='1']/arr[@name='tv_text']/str[.='a <em>long</em> days night this should be a piece of text which']\",\n            \"//arr[@name='tv_text']/str[.=' <em>long</em> fragments.']\"\n            );\n  }\n\n","sourceOld":"  public void testTermVecHighlight() {\n\n    // do summarization using term vectors\n    HashMap<String,String> args = new HashMap<String,String>();\n    args.put(\"hl\", \"true\");\n    args.put(\"hl.fl\", \"tv_text\");\n    args.put(\"hl.snippets\", \"2\");\n    TestHarness.LocalRequestFactory sumLRF = h.getRequestFactory(\n      \"standard\",0,200,args);\n    \n    assertU(adoc(\"tv_text\", \"a long days night this should be a piece of text which is is is is is is is is is is is is is is is is is is is is is is is is isis is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is sufficiently lengthly to produce multiple fragments which are not concatenated at all--we want two disjoint long fragments.\", \n                 \"id\", \"1\"));\n    assertU(commit());\n    assertU(optimize());\n    assertQ(\"Basic summarization\",\n            sumLRF.makeRequest(\"tv_text:long\"),\n            \"//lst[@name='highlighting']/lst[@name='1']\",\n            \"//lst[@name='1']/arr[@name='tv_text']/str[.='a <em>long</em> days night this should be a piece of text which']\",\n            \"//arr[@name='tv_text']/str[.=' <em>long</em> fragments']\"\n            );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"218fde9d650f817f30726670473f41b564398acd","date":1181882189,"type":5,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/test/org/apache/solr/highlight/HighlighterTest#testTermVecHighlight().mjava","pathOld":"src/test/org/apache/solr/HighlighterTest#testTermVecHighlight().mjava","sourceNew":"  public void testTermVecHighlight() {\n\n    // do summarization using term vectors\n    HashMap<String,String> args = new HashMap<String,String>();\n    args.put(\"hl\", \"true\");\n    args.put(\"hl.fl\", \"tv_text\");\n    args.put(\"hl.snippets\", \"2\");\n    TestHarness.LocalRequestFactory sumLRF = h.getRequestFactory(\n      \"standard\",0,200,args);\n    \n    assertU(adoc(\"tv_text\", \"a long days night this should be a piece of text which is is is is is is is is is is is is is is is is is is is is is is is is isis is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is sufficiently lengthly to produce multiple fragments which are not concatenated at all--we want two disjoint long fragments.\", \n                 \"id\", \"1\"));\n    assertU(commit());\n    assertU(optimize());\n    assertQ(\"Basic summarization\",\n            sumLRF.makeRequest(\"tv_text:long\"),\n            \"//lst[@name='highlighting']/lst[@name='1']\",\n            \"//lst[@name='1']/arr[@name='tv_text']/str[.='a <em>long</em> days night this should be a piece of text which']\",\n            \"//arr[@name='tv_text']/str[.=' <em>long</em> fragments.']\"\n            );\n  }\n\n","sourceOld":"  public void testTermVecHighlight() {\n\n    // do summarization using term vectors\n    HashMap<String,String> args = new HashMap<String,String>();\n    args.put(\"hl\", \"true\");\n    args.put(\"hl.fl\", \"tv_text\");\n    args.put(\"hl.snippets\", \"2\");\n    TestHarness.LocalRequestFactory sumLRF = h.getRequestFactory(\n      \"standard\",0,200,args);\n    \n    assertU(adoc(\"tv_text\", \"a long days night this should be a piece of text which is is is is is is is is is is is is is is is is is is is is is is is is isis is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is sufficiently lengthly to produce multiple fragments which are not concatenated at all--we want two disjoint long fragments.\", \n                 \"id\", \"1\"));\n    assertU(commit());\n    assertU(optimize());\n    assertQ(\"Basic summarization\",\n            sumLRF.makeRequest(\"tv_text:long\"),\n            \"//lst[@name='highlighting']/lst[@name='1']\",\n            \"//lst[@name='1']/arr[@name='tv_text']/str[.='a <em>long</em> days night this should be a piece of text which']\",\n            \"//arr[@name='tv_text']/str[.=' <em>long</em> fragments.']\"\n            );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"218fde9d650f817f30726670473f41b564398acd":["0b845edb872ec943a6446ed152345ddc4bea9549"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"0b845edb872ec943a6446ed152345ddc4bea9549":["af09a11446184597ca824554260a98704507f8a7"],"af09a11446184597ca824554260a98704507f8a7":["1aa2b803ab70ac42b322d648a4f0bf8fdcb7456d"],"1aa2b803ab70ac42b322d648a4f0bf8fdcb7456d":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"218fde9d650f817f30726670473f41b564398acd":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["1aa2b803ab70ac42b322d648a4f0bf8fdcb7456d"],"0b845edb872ec943a6446ed152345ddc4bea9549":["218fde9d650f817f30726670473f41b564398acd"],"af09a11446184597ca824554260a98704507f8a7":["0b845edb872ec943a6446ed152345ddc4bea9549"],"1aa2b803ab70ac42b322d648a4f0bf8fdcb7456d":["af09a11446184597ca824554260a98704507f8a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["218fde9d650f817f30726670473f41b564398acd","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}