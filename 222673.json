{"path":"lucene/src/test/org/apache/lucene/index/codecs/perfield/TestPerFieldPostingsFormat#testChangeCodecAndMerge().mjava","commits":[{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/perfield/TestPerFieldPostingsFormat#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    PostingsFormat origContentCodec = PostingsFormat.forName(\"MockSep\");\n    PostingsFormat newContentCodec = PostingsFormat.forName(\"Lucene40\");\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/perfield/TestPerFieldPostingsFormat#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/perfield/TestPerFieldPostingsFormat#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    PostingsFormat origContentCodec = PostingsFormat.forName(\"MockSep\");\n    PostingsFormat newContentCodec = PostingsFormat.forName(\"Lucene40\");\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/codecs/perfield/TestPerFieldPostingsFormat#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/perfield/TestPerFieldPostingsFormat#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.forceMerge(1);\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["7b91922b55d15444d554721b352861d028eb8278"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7b91922b55d15444d554721b352861d028eb8278"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}