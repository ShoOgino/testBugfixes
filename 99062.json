{"path":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","commits":[{"id":"3a2591037a85ef083e6588e0b846a5a34ff9b5a3","date":1326403130,"type":0,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Removes items from the cache to bring the size down\n   * to an acceptable value ('acceptableWaterMark').\n   * <p/>\n   * It is done in two stages. In the first stage, least recently used items are evicted.\n   * If, after the first stage, the cache size is still greater than 'acceptableSize'\n   * config parameter, the second stage takes over.\n   * <p/>\n   * The second stage is more intensive and tries to bring down the cache size\n   * to the 'lowerWaterMark' config parameter.\n   */\n  private void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount;     // volatile write to make isCleaning visible\n\n      int sz = stats.size.get();\n\n      int wantToRemove = sz - lowerWaterMark;\n\n      TreeSet<CacheEntry> tree = new TreeSet<CacheEntry>();\n\n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads\n        ce.hitsCopy = ce.hits.get();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.set(ce.hitsCopy >>> 1);\n        }\n\n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          // If the hits are not equal, we can remove before adding\n          // which is slightly faster\n          if (ce.hitsCopy < tree.first().hitsCopy) {\n            tree.remove(tree.first());\n            tree.add(ce);\n          } else if (ce.hitsCopy == tree.first().hitsCopy) {\n            tree.add(ce);\n            tree.remove(tree.first());\n          }\n        }\n      }\n\n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n    } finally {\n      isCleaning = false;  // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["2bb583c6ee51389f2d0a7def839c425969b85fee"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","sourceNew":"  /**\n   * Removes items from the cache to bring the size down\n   * to an acceptable value ('acceptableWaterMark').\n   * <p/>\n   * It is done in two stages. In the first stage, least recently used items are evicted.\n   * If, after the first stage, the cache size is still greater than 'acceptableSize'\n   * config parameter, the second stage takes over.\n   * <p/>\n   * The second stage is more intensive and tries to bring down the cache size\n   * to the 'lowerWaterMark' config parameter.\n   */\n  private void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount;     // volatile write to make isCleaning visible\n\n      int sz = stats.size.get();\n\n      int wantToRemove = sz - lowerWaterMark;\n\n      TreeSet<CacheEntry> tree = new TreeSet<>();\n\n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads\n        ce.hitsCopy = ce.hits.get();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.set(ce.hitsCopy >>> 1);\n        }\n\n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          // If the hits are not equal, we can remove before adding\n          // which is slightly faster\n          if (ce.hitsCopy < tree.first().hitsCopy) {\n            tree.remove(tree.first());\n            tree.add(ce);\n          } else if (ce.hitsCopy == tree.first().hitsCopy) {\n            tree.add(ce);\n            tree.remove(tree.first());\n          }\n        }\n      }\n\n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n    } finally {\n      isCleaning = false;  // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Removes items from the cache to bring the size down\n   * to an acceptable value ('acceptableWaterMark').\n   * <p/>\n   * It is done in two stages. In the first stage, least recently used items are evicted.\n   * If, after the first stage, the cache size is still greater than 'acceptableSize'\n   * config parameter, the second stage takes over.\n   * <p/>\n   * The second stage is more intensive and tries to bring down the cache size\n   * to the 'lowerWaterMark' config parameter.\n   */\n  private void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount;     // volatile write to make isCleaning visible\n\n      int sz = stats.size.get();\n\n      int wantToRemove = sz - lowerWaterMark;\n\n      TreeSet<CacheEntry> tree = new TreeSet<CacheEntry>();\n\n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads\n        ce.hitsCopy = ce.hits.get();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.set(ce.hitsCopy >>> 1);\n        }\n\n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          // If the hits are not equal, we can remove before adding\n          // which is slightly faster\n          if (ce.hitsCopy < tree.first().hitsCopy) {\n            tree.remove(tree.first());\n            tree.add(ce);\n          } else if (ce.hitsCopy == tree.first().hitsCopy) {\n            tree.add(ce);\n            tree.remove(tree.first());\n          }\n        }\n      }\n\n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n    } finally {\n      isCleaning = false;  // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":["2bb583c6ee51389f2d0a7def839c425969b85fee"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2bb583c6ee51389f2d0a7def839c425969b85fee","date":1432473604,"type":3,"author":"Shawn Heisey","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","sourceNew":"  /**\n   * Removes items from the cache to bring the size down to the lowerWaterMark.\n   */\n  private void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount; // volatile write to make isCleaning visible\n      \n      int sz = stats.size.get();\n      if (sz <= upperWaterMark) {\n        /* SOLR-7585: Even though we acquired a lock, multiple threads might detect a need for calling this method.\n         * Locking keeps these from executing at the same time, so they run sequentially.  The second and subsequent\n         * sequential runs of this method don't need to be done, since there are no elements to remove.\n        */\n        return;\n      }\n      \n      int wantToRemove = sz - lowerWaterMark;\n      \n      TreeSet<CacheEntry<K, V>> tree = new TreeSet<>();\n      \n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads.  Primitive types are faster than the atomic get().\n        ce.hitsCopy = ce.hits.get();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.set(ce.hitsCopy >>> 1);\n        }\n        \n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          /*\n           * SOLR-7585: Before doing this part, make sure the TreeSet actually has an element, since the first() method\n           * fails with NoSuchElementException if the set is empty.  If that test passes, check hits. This test may\n           * never actually fail due to the upperWaterMark check above, but we'll do it anyway.\n           */\n          if (tree.size() > 0) {\n            /* If hits are not equal, we can remove before adding which is slightly faster. I can no longer remember\n             * why removing first is faster, but I vaguely remember being sure about it!\n             */\n            if (ce.hitsCopy < tree.first().hitsCopy) {\n              tree.remove(tree.first());\n              tree.add(ce);\n            } else if (ce.hitsCopy == tree.first().hitsCopy) {\n              tree.add(ce);\n              tree.remove(tree.first());\n            }\n          }\n        }\n      }\n      \n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n    } finally {\n      isCleaning = false; // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Removes items from the cache to bring the size down\n   * to an acceptable value ('acceptableWaterMark').\n   * <p/>\n   * It is done in two stages. In the first stage, least recently used items are evicted.\n   * If, after the first stage, the cache size is still greater than 'acceptableSize'\n   * config parameter, the second stage takes over.\n   * <p/>\n   * The second stage is more intensive and tries to bring down the cache size\n   * to the 'lowerWaterMark' config parameter.\n   */\n  private void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount;     // volatile write to make isCleaning visible\n\n      int sz = stats.size.get();\n\n      int wantToRemove = sz - lowerWaterMark;\n\n      TreeSet<CacheEntry> tree = new TreeSet<>();\n\n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads\n        ce.hitsCopy = ce.hits.get();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.set(ce.hitsCopy >>> 1);\n        }\n\n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          // If the hits are not equal, we can remove before adding\n          // which is slightly faster\n          if (ce.hitsCopy < tree.first().hitsCopy) {\n            tree.remove(tree.first());\n            tree.add(ce);\n          } else if (ce.hitsCopy == tree.first().hitsCopy) {\n            tree.add(ce);\n            tree.remove(tree.first());\n          }\n        }\n      }\n\n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n    } finally {\n      isCleaning = false;  // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","bugFix":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","3a2591037a85ef083e6588e0b846a5a34ff9b5a3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83","date":1568645407,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","sourceNew":"  /**\n   * Removes items from the cache to bring the size down to the lowerWaterMark.\n   * <p>Visible for unit testing.</p>\n   * @lucene.internal\n   */\n  public void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount; // volatile write to make isCleaning visible\n      \n      int sz = stats.size.get();\n      boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n      long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n      if (sz <= upperWaterMark && (evictByIdleTime && oldestEntry.get() > idleCutoff)) {\n        /* SOLR-7585: Even though we acquired a lock, multiple threads might detect a need for calling this method.\n         * Locking keeps these from executing at the same time, so they run sequentially.  The second and subsequent\n         * sequential runs of this method don't need to be done, since there are no elements to remove.\n        */\n        return;\n      }\n\n      // first evict by idleTime - it's less costly to do an additional pass over the\n      // map than to manage the outdated entries in a TreeSet\n      if (evictByIdleTime) {\n        long currentOldestEntry = Long.MAX_VALUE;\n        Iterator<Map.Entry<Object, CacheEntry<K, V>>> iterator = map.entrySet().iterator();\n        while (iterator.hasNext()) {\n          Map.Entry<Object, CacheEntry<K, V>> entry = iterator.next();\n          entry.getValue().lastAccessedCopy = entry.getValue().lastAccessed;\n          if (entry.getValue().lastAccessedCopy < idleCutoff) {\n            iterator.remove();\n            postRemoveEntry(entry.getValue());\n            stats.evictionIdleCounter.incrementAndGet();\n          } else {\n            if (entry.getValue().lastAccessedCopy < currentOldestEntry) {\n              currentOldestEntry = entry.getValue().lastAccessedCopy;\n            }\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n        // refresh size and maybe return\n        sz = stats.size.get();\n        if (sz <= upperWaterMark) {\n          return;\n        }\n      }\n      int wantToRemove = sz - lowerWaterMark;\n\n      TreeSet<CacheEntry<K, V>> tree = new TreeSet<>();\n\n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads.  Primitive types are faster than the atomic get().\n        ce.hitsCopy = ce.hits.get();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.set(ce.hitsCopy >>> 1);\n        }\n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          /*\n           * SOLR-7585: Before doing this part, make sure the TreeSet actually has an element, since the first() method\n           * fails with NoSuchElementException if the set is empty.  If that test passes, check hits. This test may\n           * never actually fail due to the upperWaterMark check above, but we'll do it anyway.\n           */\n          if (tree.size() > 0) {\n            /* If hits are not equal, we can remove before adding which is slightly faster. I can no longer remember\n             * why removing first is faster, but I vaguely remember being sure about it!\n             */\n            if (ce.hitsCopy < tree.first().hitsCopy) {\n              tree.remove(tree.first());\n              tree.add(ce);\n            } else if (ce.hitsCopy == tree.first().hitsCopy) {\n              tree.add(ce);\n              tree.remove(tree.first());\n            }\n          }\n        }\n      }\n      \n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n      if (evictByIdleTime) {\n        // do a full pass because we don't what is the max. age of remaining items\n        long currentOldestEntry = Long.MAX_VALUE;\n        for (CacheEntry<K, V> e : map.values()) {\n          if (e.lastAccessedCopy < currentOldestEntry) {\n            currentOldestEntry = e.lastAccessedCopy;\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n      }\n    } finally {\n      isCleaning = false; // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Removes items from the cache to bring the size down to the lowerWaterMark.\n   */\n  private void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount; // volatile write to make isCleaning visible\n      \n      int sz = stats.size.get();\n      if (sz <= upperWaterMark) {\n        /* SOLR-7585: Even though we acquired a lock, multiple threads might detect a need for calling this method.\n         * Locking keeps these from executing at the same time, so they run sequentially.  The second and subsequent\n         * sequential runs of this method don't need to be done, since there are no elements to remove.\n        */\n        return;\n      }\n      \n      int wantToRemove = sz - lowerWaterMark;\n      \n      TreeSet<CacheEntry<K, V>> tree = new TreeSet<>();\n      \n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads.  Primitive types are faster than the atomic get().\n        ce.hitsCopy = ce.hits.get();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.set(ce.hitsCopy >>> 1);\n        }\n        \n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          /*\n           * SOLR-7585: Before doing this part, make sure the TreeSet actually has an element, since the first() method\n           * fails with NoSuchElementException if the set is empty.  If that test passes, check hits. This test may\n           * never actually fail due to the upperWaterMark check above, but we'll do it anyway.\n           */\n          if (tree.size() > 0) {\n            /* If hits are not equal, we can remove before adding which is slightly faster. I can no longer remember\n             * why removing first is faster, but I vaguely remember being sure about it!\n             */\n            if (ce.hitsCopy < tree.first().hitsCopy) {\n              tree.remove(tree.first());\n              tree.add(ce);\n            } else if (ce.hitsCopy == tree.first().hitsCopy) {\n              tree.add(ce);\n              tree.remove(tree.first());\n            }\n          }\n        }\n      }\n      \n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n    } finally {\n      isCleaning = false; // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"87f0484c38f986062889ed50f3bf3bd462848c26","date":1570108628,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","sourceNew":"  /**\n   * Removes items from the cache to bring the size down to the lowerWaterMark.\n   * <p>Visible for unit testing.</p>\n   * @lucene.internal\n   */\n  public void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount; // volatile write to make isCleaning visible\n      \n      int sz = stats.size.intValue();\n      boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n      long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n      if (sz <= upperWaterMark && (evictByIdleTime && oldestEntry.get() > idleCutoff)) {\n        /* SOLR-7585: Even though we acquired a lock, multiple threads might detect a need for calling this method.\n         * Locking keeps these from executing at the same time, so they run sequentially.  The second and subsequent\n         * sequential runs of this method don't need to be done, since there are no elements to remove.\n        */\n        return;\n      }\n\n      // first evict by idleTime - it's less costly to do an additional pass over the\n      // map than to manage the outdated entries in a TreeSet\n      if (evictByIdleTime) {\n        long currentOldestEntry = Long.MAX_VALUE;\n        Iterator<Map.Entry<Object, CacheEntry<K, V>>> iterator = map.entrySet().iterator();\n        while (iterator.hasNext()) {\n          Map.Entry<Object, CacheEntry<K, V>> entry = iterator.next();\n          entry.getValue().lastAccessedCopy = entry.getValue().lastAccessed;\n          if (entry.getValue().lastAccessedCopy < idleCutoff) {\n            iterator.remove();\n            postRemoveEntry(entry.getValue());\n            stats.evictionIdleCounter.increment();\n          } else {\n            if (entry.getValue().lastAccessedCopy < currentOldestEntry) {\n              currentOldestEntry = entry.getValue().lastAccessedCopy;\n            }\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n        // refresh size and maybe return\n        sz = stats.size.intValue();\n        if (sz <= upperWaterMark) {\n          return;\n        }\n      }\n      int wantToRemove = sz - lowerWaterMark;\n\n      TreeSet<CacheEntry<K, V>> tree = new TreeSet<>();\n\n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads.  Primitive types are faster than the atomic get().\n        ce.hitsCopy = ce.hits.longValue();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.reset();\n          ce.hits.add(ce.hitsCopy >>> 1);\n        }\n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          /*\n           * SOLR-7585: Before doing this part, make sure the TreeSet actually has an element, since the first() method\n           * fails with NoSuchElementException if the set is empty.  If that test passes, check hits. This test may\n           * never actually fail due to the upperWaterMark check above, but we'll do it anyway.\n           */\n          if (tree.size() > 0) {\n            /* If hits are not equal, we can remove before adding which is slightly faster. I can no longer remember\n             * why removing first is faster, but I vaguely remember being sure about it!\n             */\n            if (ce.hitsCopy < tree.first().hitsCopy) {\n              tree.remove(tree.first());\n              tree.add(ce);\n            } else if (ce.hitsCopy == tree.first().hitsCopy) {\n              tree.add(ce);\n              tree.remove(tree.first());\n            }\n          }\n        }\n      }\n      \n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n      if (evictByIdleTime) {\n        // do a full pass because we don't what is the max. age of remaining items\n        long currentOldestEntry = Long.MAX_VALUE;\n        for (CacheEntry<K, V> e : map.values()) {\n          if (e.lastAccessedCopy < currentOldestEntry) {\n            currentOldestEntry = e.lastAccessedCopy;\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n      }\n    } finally {\n      isCleaning = false; // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Removes items from the cache to bring the size down to the lowerWaterMark.\n   * <p>Visible for unit testing.</p>\n   * @lucene.internal\n   */\n  public void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount; // volatile write to make isCleaning visible\n      \n      int sz = stats.size.get();\n      boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n      long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n      if (sz <= upperWaterMark && (evictByIdleTime && oldestEntry.get() > idleCutoff)) {\n        /* SOLR-7585: Even though we acquired a lock, multiple threads might detect a need for calling this method.\n         * Locking keeps these from executing at the same time, so they run sequentially.  The second and subsequent\n         * sequential runs of this method don't need to be done, since there are no elements to remove.\n        */\n        return;\n      }\n\n      // first evict by idleTime - it's less costly to do an additional pass over the\n      // map than to manage the outdated entries in a TreeSet\n      if (evictByIdleTime) {\n        long currentOldestEntry = Long.MAX_VALUE;\n        Iterator<Map.Entry<Object, CacheEntry<K, V>>> iterator = map.entrySet().iterator();\n        while (iterator.hasNext()) {\n          Map.Entry<Object, CacheEntry<K, V>> entry = iterator.next();\n          entry.getValue().lastAccessedCopy = entry.getValue().lastAccessed;\n          if (entry.getValue().lastAccessedCopy < idleCutoff) {\n            iterator.remove();\n            postRemoveEntry(entry.getValue());\n            stats.evictionIdleCounter.incrementAndGet();\n          } else {\n            if (entry.getValue().lastAccessedCopy < currentOldestEntry) {\n              currentOldestEntry = entry.getValue().lastAccessedCopy;\n            }\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n        // refresh size and maybe return\n        sz = stats.size.get();\n        if (sz <= upperWaterMark) {\n          return;\n        }\n      }\n      int wantToRemove = sz - lowerWaterMark;\n\n      TreeSet<CacheEntry<K, V>> tree = new TreeSet<>();\n\n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads.  Primitive types are faster than the atomic get().\n        ce.hitsCopy = ce.hits.get();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.set(ce.hitsCopy >>> 1);\n        }\n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          /*\n           * SOLR-7585: Before doing this part, make sure the TreeSet actually has an element, since the first() method\n           * fails with NoSuchElementException if the set is empty.  If that test passes, check hits. This test may\n           * never actually fail due to the upperWaterMark check above, but we'll do it anyway.\n           */\n          if (tree.size() > 0) {\n            /* If hits are not equal, we can remove before adding which is slightly faster. I can no longer remember\n             * why removing first is faster, but I vaguely remember being sure about it!\n             */\n            if (ce.hitsCopy < tree.first().hitsCopy) {\n              tree.remove(tree.first());\n              tree.add(ce);\n            } else if (ce.hitsCopy == tree.first().hitsCopy) {\n              tree.add(ce);\n              tree.remove(tree.first());\n            }\n          }\n        }\n      }\n      \n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n      if (evictByIdleTime) {\n        // do a full pass because we don't what is the max. age of remaining items\n        long currentOldestEntry = Long.MAX_VALUE;\n        for (CacheEntry<K, V> e : map.values()) {\n          if (e.lastAccessedCopy < currentOldestEntry) {\n            currentOldestEntry = e.lastAccessedCopy;\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n      }\n    } finally {\n      isCleaning = false; // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":3,"author":"jimczi","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","sourceNew":"  /**\n   * Removes items from the cache to bring the size down to the lowerWaterMark.\n   * <p>Visible for unit testing.</p>\n   * @lucene.internal\n   */\n  public void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount; // volatile write to make isCleaning visible\n      \n      int sz = stats.size.intValue();\n      boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n      long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n      if (sz <= upperWaterMark && (evictByIdleTime && oldestEntry.get() > idleCutoff)) {\n        /* SOLR-7585: Even though we acquired a lock, multiple threads might detect a need for calling this method.\n         * Locking keeps these from executing at the same time, so they run sequentially.  The second and subsequent\n         * sequential runs of this method don't need to be done, since there are no elements to remove.\n        */\n        return;\n      }\n\n      // first evict by idleTime - it's less costly to do an additional pass over the\n      // map than to manage the outdated entries in a TreeSet\n      if (evictByIdleTime) {\n        long currentOldestEntry = Long.MAX_VALUE;\n        Iterator<Map.Entry<Object, CacheEntry<K, V>>> iterator = map.entrySet().iterator();\n        while (iterator.hasNext()) {\n          Map.Entry<Object, CacheEntry<K, V>> entry = iterator.next();\n          entry.getValue().lastAccessedCopy = entry.getValue().lastAccessed;\n          if (entry.getValue().lastAccessedCopy < idleCutoff) {\n            iterator.remove();\n            postRemoveEntry(entry.getValue());\n            stats.evictionIdleCounter.increment();\n          } else {\n            if (entry.getValue().lastAccessedCopy < currentOldestEntry) {\n              currentOldestEntry = entry.getValue().lastAccessedCopy;\n            }\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n        // refresh size and maybe return\n        sz = stats.size.intValue();\n        if (sz <= upperWaterMark) {\n          return;\n        }\n      }\n      int wantToRemove = sz - lowerWaterMark;\n\n      TreeSet<CacheEntry<K, V>> tree = new TreeSet<>();\n\n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads.  Primitive types are faster than the atomic get().\n        ce.hitsCopy = ce.hits.longValue();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.reset();\n          ce.hits.add(ce.hitsCopy >>> 1);\n        }\n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          /*\n           * SOLR-7585: Before doing this part, make sure the TreeSet actually has an element, since the first() method\n           * fails with NoSuchElementException if the set is empty.  If that test passes, check hits. This test may\n           * never actually fail due to the upperWaterMark check above, but we'll do it anyway.\n           */\n          if (tree.size() > 0) {\n            /* If hits are not equal, we can remove before adding which is slightly faster. I can no longer remember\n             * why removing first is faster, but I vaguely remember being sure about it!\n             */\n            if (ce.hitsCopy < tree.first().hitsCopy) {\n              tree.remove(tree.first());\n              tree.add(ce);\n            } else if (ce.hitsCopy == tree.first().hitsCopy) {\n              tree.add(ce);\n              tree.remove(tree.first());\n            }\n          }\n        }\n      }\n      \n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n      if (evictByIdleTime) {\n        // do a full pass because we don't what is the max. age of remaining items\n        long currentOldestEntry = Long.MAX_VALUE;\n        for (CacheEntry<K, V> e : map.values()) {\n          if (e.lastAccessedCopy < currentOldestEntry) {\n            currentOldestEntry = e.lastAccessedCopy;\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n      }\n    } finally {\n      isCleaning = false; // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","sourceOld":"  /**\n   * Removes items from the cache to bring the size down to the lowerWaterMark.\n   * <p>Visible for unit testing.</p>\n   * @lucene.internal\n   */\n  public void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount; // volatile write to make isCleaning visible\n      \n      int sz = stats.size.get();\n      boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n      long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n      if (sz <= upperWaterMark && (evictByIdleTime && oldestEntry.get() > idleCutoff)) {\n        /* SOLR-7585: Even though we acquired a lock, multiple threads might detect a need for calling this method.\n         * Locking keeps these from executing at the same time, so they run sequentially.  The second and subsequent\n         * sequential runs of this method don't need to be done, since there are no elements to remove.\n        */\n        return;\n      }\n\n      // first evict by idleTime - it's less costly to do an additional pass over the\n      // map than to manage the outdated entries in a TreeSet\n      if (evictByIdleTime) {\n        long currentOldestEntry = Long.MAX_VALUE;\n        Iterator<Map.Entry<Object, CacheEntry<K, V>>> iterator = map.entrySet().iterator();\n        while (iterator.hasNext()) {\n          Map.Entry<Object, CacheEntry<K, V>> entry = iterator.next();\n          entry.getValue().lastAccessedCopy = entry.getValue().lastAccessed;\n          if (entry.getValue().lastAccessedCopy < idleCutoff) {\n            iterator.remove();\n            postRemoveEntry(entry.getValue());\n            stats.evictionIdleCounter.incrementAndGet();\n          } else {\n            if (entry.getValue().lastAccessedCopy < currentOldestEntry) {\n              currentOldestEntry = entry.getValue().lastAccessedCopy;\n            }\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n        // refresh size and maybe return\n        sz = stats.size.get();\n        if (sz <= upperWaterMark) {\n          return;\n        }\n      }\n      int wantToRemove = sz - lowerWaterMark;\n\n      TreeSet<CacheEntry<K, V>> tree = new TreeSet<>();\n\n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads.  Primitive types are faster than the atomic get().\n        ce.hitsCopy = ce.hits.get();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.set(ce.hitsCopy >>> 1);\n        }\n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          /*\n           * SOLR-7585: Before doing this part, make sure the TreeSet actually has an element, since the first() method\n           * fails with NoSuchElementException if the set is empty.  If that test passes, check hits. This test may\n           * never actually fail due to the upperWaterMark check above, but we'll do it anyway.\n           */\n          if (tree.size() > 0) {\n            /* If hits are not equal, we can remove before adding which is slightly faster. I can no longer remember\n             * why removing first is faster, but I vaguely remember being sure about it!\n             */\n            if (ce.hitsCopy < tree.first().hitsCopy) {\n              tree.remove(tree.first());\n              tree.add(ce);\n            } else if (ce.hitsCopy == tree.first().hitsCopy) {\n              tree.add(ce);\n              tree.remove(tree.first());\n            }\n          }\n        }\n      }\n      \n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n      if (evictByIdleTime) {\n        // do a full pass because we don't what is the max. age of remaining items\n        long currentOldestEntry = Long.MAX_VALUE;\n        for (CacheEntry<K, V> e : map.values()) {\n          if (e.lastAccessedCopy < currentOldestEntry) {\n            currentOldestEntry = e.lastAccessedCopy;\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n      }\n    } finally {\n      isCleaning = false; // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d7d3943904804560937e6239effeebda0f920e4","date":1573762904,"type":4,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLFUCache#markAndSweep().mjava","sourceNew":null,"sourceOld":"  /**\n   * Removes items from the cache to bring the size down to the lowerWaterMark.\n   * <p>Visible for unit testing.</p>\n   * @lucene.internal\n   */\n  public void markAndSweep() {\n    if (!markAndSweepLock.tryLock()) return;\n    try {\n      long lowHitCount = this.lowHitCount;\n      isCleaning = true;\n      this.lowHitCount = lowHitCount; // volatile write to make isCleaning visible\n      \n      int sz = stats.size.intValue();\n      boolean evictByIdleTime = maxIdleTimeNs != Long.MAX_VALUE;\n      long idleCutoff = evictByIdleTime ? timeSource.getEpochTimeNs() - maxIdleTimeNs : -1L;\n      if (sz <= upperWaterMark && (evictByIdleTime && oldestEntry.get() > idleCutoff)) {\n        /* SOLR-7585: Even though we acquired a lock, multiple threads might detect a need for calling this method.\n         * Locking keeps these from executing at the same time, so they run sequentially.  The second and subsequent\n         * sequential runs of this method don't need to be done, since there are no elements to remove.\n        */\n        return;\n      }\n\n      // first evict by idleTime - it's less costly to do an additional pass over the\n      // map than to manage the outdated entries in a TreeSet\n      if (evictByIdleTime) {\n        long currentOldestEntry = Long.MAX_VALUE;\n        Iterator<Map.Entry<Object, CacheEntry<K, V>>> iterator = map.entrySet().iterator();\n        while (iterator.hasNext()) {\n          Map.Entry<Object, CacheEntry<K, V>> entry = iterator.next();\n          entry.getValue().lastAccessedCopy = entry.getValue().lastAccessed;\n          if (entry.getValue().lastAccessedCopy < idleCutoff) {\n            iterator.remove();\n            postRemoveEntry(entry.getValue());\n            stats.evictionIdleCounter.increment();\n          } else {\n            if (entry.getValue().lastAccessedCopy < currentOldestEntry) {\n              currentOldestEntry = entry.getValue().lastAccessedCopy;\n            }\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n        // refresh size and maybe return\n        sz = stats.size.intValue();\n        if (sz <= upperWaterMark) {\n          return;\n        }\n      }\n      int wantToRemove = sz - lowerWaterMark;\n\n      TreeSet<CacheEntry<K, V>> tree = new TreeSet<>();\n\n      for (CacheEntry<K, V> ce : map.values()) {\n        // set hitsCopy to avoid later Atomic reads.  Primitive types are faster than the atomic get().\n        ce.hitsCopy = ce.hits.longValue();\n        ce.lastAccessedCopy = ce.lastAccessed;\n        if (timeDecay) {\n          ce.hits.reset();\n          ce.hits.add(ce.hitsCopy >>> 1);\n        }\n        if (tree.size() < wantToRemove) {\n          tree.add(ce);\n        } else {\n          /*\n           * SOLR-7585: Before doing this part, make sure the TreeSet actually has an element, since the first() method\n           * fails with NoSuchElementException if the set is empty.  If that test passes, check hits. This test may\n           * never actually fail due to the upperWaterMark check above, but we'll do it anyway.\n           */\n          if (tree.size() > 0) {\n            /* If hits are not equal, we can remove before adding which is slightly faster. I can no longer remember\n             * why removing first is faster, but I vaguely remember being sure about it!\n             */\n            if (ce.hitsCopy < tree.first().hitsCopy) {\n              tree.remove(tree.first());\n              tree.add(ce);\n            } else if (ce.hitsCopy == tree.first().hitsCopy) {\n              tree.add(ce);\n              tree.remove(tree.first());\n            }\n          }\n        }\n      }\n      \n      for (CacheEntry<K, V> e : tree) {\n        evictEntry(e.key);\n      }\n      if (evictByIdleTime) {\n        // do a full pass because we don't what is the max. age of remaining items\n        long currentOldestEntry = Long.MAX_VALUE;\n        for (CacheEntry<K, V> e : map.values()) {\n          if (e.lastAccessedCopy < currentOldestEntry) {\n            currentOldestEntry = e.lastAccessedCopy;\n          }\n        }\n        if (currentOldestEntry != Long.MAX_VALUE) {\n          oldestEntry.set(currentOldestEntry);\n        }\n      }\n    } finally {\n      isCleaning = false; // set before markAndSweep.unlock() for visibility\n      markAndSweepLock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2bb583c6ee51389f2d0a7def839c425969b85fee":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["3a2591037a85ef083e6588e0b846a5a34ff9b5a3"],"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83":["2bb583c6ee51389f2d0a7def839c425969b85fee"],"4d7d3943904804560937e6239effeebda0f920e4":["87f0484c38f986062889ed50f3bf3bd462848c26"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"87f0484c38f986062889ed50f3bf3bd462848c26":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83"],"3a2591037a85ef083e6588e0b846a5a34ff9b5a3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4d7d3943904804560937e6239effeebda0f920e4"],"b0b597c65628ca9e73913a07e81691f8229bae35":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83","87f0484c38f986062889ed50f3bf3bd462848c26"]},"commit2Childs":{"2bb583c6ee51389f2d0a7def839c425969b85fee":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["2bb583c6ee51389f2d0a7def839c425969b85fee"],"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83":["87f0484c38f986062889ed50f3bf3bd462848c26","b0b597c65628ca9e73913a07e81691f8229bae35"],"4d7d3943904804560937e6239effeebda0f920e4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a2591037a85ef083e6588e0b846a5a34ff9b5a3"],"87f0484c38f986062889ed50f3bf3bd462848c26":["4d7d3943904804560937e6239effeebda0f920e4","b0b597c65628ca9e73913a07e81691f8229bae35"],"3a2591037a85ef083e6588e0b846a5a34ff9b5a3":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}