{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,String,int,int,String,String).mjava","commits":[{"id":"09dfa411e0e1bbfad83c3e6629cf1fe24a7aed89","date":1567784912,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,String,int,int,String,String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * @param blockDecoder Optional block decoder, may be null if none.\n   *                     It can be used for decompression or decryption.\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state, BlockDecoder blockDecoder,\n                                     String codecName, int versionStart, int versionCurrent, String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos);\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, blockDecoder, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"42f6185d883389450f593fb00103d2e89a0b8336","date":1577705030,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,String,int,int,String,String).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,String,int,int,String,String).mjava","sourceNew":"  /**\n   * @param blockDecoder Optional block decoder, may be null if none.\n   *                     It can be used for decompression or decryption.\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state, BlockDecoder blockDecoder,\n                                     String codecName, int versionStart, int versionCurrent, String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos, state.segmentInfo.maxDoc());\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, blockDecoder, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","sourceOld":"  /**\n   * @param blockDecoder Optional block decoder, may be null if none.\n   *                     It can be used for decompression or decryption.\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state, BlockDecoder blockDecoder,\n                                     String codecName, int versionStart, int versionCurrent, String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos);\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, blockDecoder, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"62e478fa10594a2ef9d1ddf7d195020300453c4e","date":1577783287,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,String,int,int,String,String).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,String,int,int,String,String).mjava","sourceNew":"  /**\n   * @param blockDecoder Optional block decoder, may be null if none.\n   *                     It can be used for decompression or decryption.\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state, BlockDecoder blockDecoder,\n                                     String codecName, int versionStart, int versionCurrent, String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos, state.segmentInfo.maxDoc());\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, blockDecoder, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","sourceOld":"  /**\n   * @param blockDecoder Optional block decoder, may be null if none.\n   *                     It can be used for decompression or decryption.\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state, BlockDecoder blockDecoder,\n                                     String codecName, int versionStart, int versionCurrent, String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos);\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, blockDecoder, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d28da8a459f5f0c930da7185c56d0c25edd3fbd1","date":1577783695,"type":5,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,FieldMetadata.Serializer,String,int,int,String,String).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,String,int,int,String,String).mjava","sourceNew":"  /**\n   * @param blockDecoder Optional block decoder, may be null if none.\n   *                     It can be used for decompression or decryption.\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state,\n                                    BlockDecoder blockDecoder, FieldMetadata.Serializer fieldMetadataReader,\n                                     String codecName, int versionStart, int versionCurrent,\n                                    String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos, fieldMetadataReader, state.segmentInfo.maxDoc());\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, blockDecoder, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","sourceOld":"  /**\n   * @param blockDecoder Optional block decoder, may be null if none.\n   *                     It can be used for decompression or decryption.\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state, BlockDecoder blockDecoder,\n                                     String codecName, int versionStart, int versionCurrent, String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos, state.segmentInfo.maxDoc());\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, blockDecoder, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c606b777c4250f3f3f6f66d659c7c4c403679b71","date":1577958559,"type":5,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,FieldMetadata.Serializer,String,int,int,String,String).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/uniformsplit/UniformSplitTermsReader#UniformSplitTermsReader(PostingsReaderBase,SegmentReadState,BlockDecoder,String,int,int,String,String).mjava","sourceNew":"  /**\n   * @param blockDecoder Optional block decoder, may be null if none.\n   *                     It can be used for decompression or decryption.\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state,\n                                    BlockDecoder blockDecoder, FieldMetadata.Serializer fieldMetadataReader,\n                                     String codecName, int versionStart, int versionCurrent,\n                                    String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos, fieldMetadataReader, state.segmentInfo.maxDoc());\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, blockDecoder, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","sourceOld":"  /**\n   * @param blockDecoder Optional block decoder, may be null if none.\n   *                     It can be used for decompression or decryption.\n   */\n  protected UniformSplitTermsReader(PostingsReaderBase postingsReader, SegmentReadState state, BlockDecoder blockDecoder,\n                                     String codecName, int versionStart, int versionCurrent, String termsBlocksExtension, String dictionaryExtension) throws IOException {\n     IndexInput dictionaryInput = null;\n     IndexInput blockInput = null;\n     boolean success = false;\n     try {\n       this.postingsReader = postingsReader;\n       String segmentName = state.segmentInfo.name;\n       String termsName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, termsBlocksExtension);\n       blockInput = state.directory.openInput(termsName, state.context);\n\n       int version = CodecUtil.checkIndexHeader(blockInput, codecName, versionStart,\n           versionCurrent, state.segmentInfo.getId(), state.segmentSuffix);\n       String indexName = IndexFileNames.segmentFileName(segmentName, state.segmentSuffix, dictionaryExtension);\n       dictionaryInput = state.directory.openInput(indexName, state.context);\n\n       CodecUtil.checkIndexHeader(dictionaryInput, codecName, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n       CodecUtil.checksumEntireFile(dictionaryInput);\n\n       postingsReader.init(blockInput, state);\n       CodecUtil.retrieveChecksum(blockInput);\n\n       seekFieldsMetadata(blockInput);\n       Collection<FieldMetadata> fieldMetadataCollection = parseFieldsMetadata(blockInput, state.fieldInfos, state.segmentInfo.maxDoc());\n\n       fieldToTermsMap = new HashMap<>();\n       this.blockInput = blockInput;\n       this.dictionaryInput = dictionaryInput;\n\n       fillFieldMap(postingsReader, blockDecoder, dictionaryInput, blockInput, fieldMetadataCollection, state.fieldInfos);\n\n       List<String> fieldNames = new ArrayList<>(fieldToTermsMap.keySet());\n       Collections.sort(fieldNames);\n       sortedFieldNames = Collections.unmodifiableList(fieldNames);\n\n       success = true;\n     } finally {\n       if (!success) {\n         IOUtils.closeWhileHandlingException(blockInput, dictionaryInput);\n       }\n     }\n   }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c606b777c4250f3f3f6f66d659c7c4c403679b71":["62e478fa10594a2ef9d1ddf7d195020300453c4e","d28da8a459f5f0c930da7185c56d0c25edd3fbd1"],"42f6185d883389450f593fb00103d2e89a0b8336":["09dfa411e0e1bbfad83c3e6629cf1fe24a7aed89"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"09dfa411e0e1bbfad83c3e6629cf1fe24a7aed89":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"62e478fa10594a2ef9d1ddf7d195020300453c4e":["09dfa411e0e1bbfad83c3e6629cf1fe24a7aed89","42f6185d883389450f593fb00103d2e89a0b8336"],"d28da8a459f5f0c930da7185c56d0c25edd3fbd1":["42f6185d883389450f593fb00103d2e89a0b8336"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d28da8a459f5f0c930da7185c56d0c25edd3fbd1"]},"commit2Childs":{"c606b777c4250f3f3f6f66d659c7c4c403679b71":[],"42f6185d883389450f593fb00103d2e89a0b8336":["62e478fa10594a2ef9d1ddf7d195020300453c4e","d28da8a459f5f0c930da7185c56d0c25edd3fbd1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["09dfa411e0e1bbfad83c3e6629cf1fe24a7aed89"],"09dfa411e0e1bbfad83c3e6629cf1fe24a7aed89":["42f6185d883389450f593fb00103d2e89a0b8336","62e478fa10594a2ef9d1ddf7d195020300453c4e"],"62e478fa10594a2ef9d1ddf7d195020300453c4e":["c606b777c4250f3f3f6f66d659c7c4c403679b71"],"d28da8a459f5f0c930da7185c56d0c25edd3fbd1":["c606b777c4250f3f3f6f66d659c7c4c403679b71","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c606b777c4250f3f3f6f66d659c7c4c403679b71","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}