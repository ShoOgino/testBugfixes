{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(boolean[]).mjava","commits":[{"id":"ddaef9c801f985de924507f0cceea9786b55ac1f","date":1481326890,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(boolean[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private long prepareCommitInternal(boolean[] doMaybeMerge) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          doMaybeMerge[0] = true;\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9856095f7afb5a607bf5e65077615ed91273508c","date":1481837697,"type":1,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(boolean[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(MergePolicy).mjava","sourceNew":"  private long prepareCommitInternal(boolean[] doMaybeMerge) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          doMaybeMerge[0] = true;\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal(MergePolicy mergePolicy) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          maybeMerge(mergePolicy, MergeTrigger.FULL_FLUSH, UNBOUNDED_MAX_MERGE_SEGMENTS);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(boolean[]).mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false, false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal(boolean[] doMaybeMerge) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          doMaybeMerge[0] = true;\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["15e716649e2bd79a98b5e68c464154ea4c44677a","15e716649e2bd79a98b5e68c464154ea4c44677a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":5,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(boolean[]).mjava","sourceNew":"  private long prepareCommitInternal() throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anyChanges = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anyChanges = true;\n              seqNo = -seqNo;\n            }\n            if (anyChanges == false) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n\n            // cannot pass triggerMerges=true here else it can lead to deadlock:\n            processEvents(false, false);\n            \n            flushSuccess = true;\n\n            applyAllDeletesAndUpdates();\n\n            synchronized(this) {\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anyChanges) {\n          maybeMerge.set(true);\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private long prepareCommitInternal(boolean[] doMaybeMerge) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          doMaybeMerge[0] = true;\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":4,"author":"Karl Wright","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareCommitInternal(boolean[]).mjava","sourceNew":null,"sourceOld":"  private long prepareCommitInternal(boolean[] doMaybeMerge) throws IOException {\n    startCommitTime = System.nanoTime();\n    synchronized(commitLock) {\n      ensureOpen(false);\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"prepareCommit: flush\");\n        infoStream.message(\"IW\", \"  index before flush \" + segString());\n      }\n\n      if (tragedy != null) {\n        throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot commit\", tragedy);\n      }\n\n      if (pendingCommit != null) {\n        throw new IllegalStateException(\"prepareCommit was already called with no corresponding call to commit\");\n      }\n\n      doBeforeFlush();\n      testPoint(\"startDoFlush\");\n      SegmentInfos toCommit = null;\n      boolean anySegmentsFlushed = false;\n      long seqNo;\n\n      // This is copied from doFlush, except it's modified to\n      // clone & incRef the flushed SegmentInfos inside the\n      // sync block:\n\n      try {\n\n        synchronized (fullFlushLock) {\n          boolean flushSuccess = false;\n          boolean success = false;\n          try {\n            seqNo = docWriter.flushAllThreads();\n            if (seqNo < 0) {\n              anySegmentsFlushed = true;\n              seqNo = -seqNo;\n            }\n            if (!anySegmentsFlushed) {\n              // prevent double increment since docWriter#doFlush increments the flushcount\n              // if we flushed anything.\n              flushCount.incrementAndGet();\n            }\n            processEvents(false, true);\n            flushSuccess = true;\n\n            synchronized(this) {\n              maybeApplyDeletes(true);\n\n              readerPool.commit(segmentInfos);\n\n              if (changeCount.get() != lastCommitChangeCount) {\n                // There are changes to commit, so we will write a new segments_N in startCommit.\n                // The act of committing is itself an NRT-visible change (an NRT reader that was\n                // just opened before this should see it on reopen) so we increment changeCount\n                // and segments version so a future NRT reopen will see the change:\n                changeCount.incrementAndGet();\n                segmentInfos.changed();\n              }\n\n              if (commitUserData != null) {\n                Map<String,String> userData = new HashMap<>();\n                for(Map.Entry<String,String> ent : commitUserData) {\n                  userData.put(ent.getKey(), ent.getValue());\n                }\n                segmentInfos.setUserData(userData, false);\n              }\n\n              // Must clone the segmentInfos while we still\n              // hold fullFlushLock and while sync'd so that\n              // no partial changes (eg a delete w/o\n              // corresponding add from an updateDocument) can\n              // sneak into the commit point:\n              toCommit = segmentInfos.clone();\n\n              pendingCommitChangeCount = changeCount.get();\n\n              // This protects the segmentInfos we are now going\n              // to commit.  This is important in case, eg, while\n              // we are trying to sync all referenced files, a\n              // merge completes which would otherwise have\n              // removed the files we are now syncing.    \n              filesToCommit = toCommit.files(false); \n              deleter.incRef(filesToCommit);\n            }\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"hit exception during prepareCommit\");\n              }\n            }\n            // Done: finish the full flush!\n            docWriter.finishFullFlush(this, flushSuccess);\n            doAfterFlush();\n          }\n        }\n      } catch (AbortingException | VirtualMachineError tragedy) {\n        tragicEvent(tragedy, \"prepareCommit\");\n\n        // dead code but javac disagrees:\n        seqNo = -1;\n      }\n     \n      boolean success = false;\n      try {\n        if (anySegmentsFlushed) {\n          doMaybeMerge[0] = true;\n        }\n        startCommit(toCommit);\n        success = true;\n        if (pendingCommit == null) {\n          return -1;\n        } else {\n          return seqNo;\n        }\n      } finally {\n        if (!success) {\n          synchronized (this) {\n            if (filesToCommit != null) {\n              deleter.decRefWhileHandlingException(filesToCommit);\n              filesToCommit = null;\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["ddaef9c801f985de924507f0cceea9786b55ac1f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9856095f7afb5a607bf5e65077615ed91273508c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ddaef9c801f985de924507f0cceea9786b55ac1f"],"ddaef9c801f985de924507f0cceea9786b55ac1f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["ddaef9c801f985de924507f0cceea9786b55ac1f","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"28288370235ed02234a64753cdbf0c6ec096304a":["ddaef9c801f985de924507f0cceea9786b55ac1f","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["28288370235ed02234a64753cdbf0c6ec096304a"]},"commit2Childs":{"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9856095f7afb5a607bf5e65077615ed91273508c","ddaef9c801f985de924507f0cceea9786b55ac1f"],"9856095f7afb5a607bf5e65077615ed91273508c":[],"ddaef9c801f985de924507f0cceea9786b55ac1f":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","9856095f7afb5a607bf5e65077615ed91273508c","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"28288370235ed02234a64753cdbf0c6ec096304a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9856095f7afb5a607bf5e65077615ed91273508c","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}