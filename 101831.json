{"path":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(segment, flushState.numDocs, directory, false, flushState.codec, fieldInfos.asReadOnly());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + (newSegment.getHasVectors() ? \"vectors\" : \"no vectors\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(segment, flushState.numDocs, directory, false, flushState.codec, fieldInfos.asReadOnly());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + (newSegment.getHasVectors() ? \"vectors\" : \"no vectors\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2dee33619431ada2a7a07f5fe2dbd94bac6a460","date":1337274029,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     SegmentInfo.NO, -1, segment, false, null, false, 0,\n                                                     flushState.fieldInfos.hasProx(), flushState.codec,\n                                                     null,\n                                                     flushState.fieldInfos.hasVectors(),\n                                                     flushState.fieldInfos.hasDocValues(),\n                                                     flushState.fieldInfos.hasNorms(),\n                                                     flushState.fieldInfos.hasFreq());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (newSegment.getHasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (newSegment.getHasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (newSegment.getHasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (newSegment.getHasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (newSegment.getHasProx() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(segment, flushState.numDocs, directory, false, flushState.codec, fieldInfos.asReadOnly());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + (newSegment.getHasVectors() ? \"vectors\" : \"no vectors\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fc834f3412d287003cc04691da380b69ab983239","date":1337276089,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     SegmentInfo.NO, -1, segment, false, null, false, 0,\n                                                     flushState.fieldInfos.hasProx(), flushState.codec,\n                                                     null,\n                                                     flushState.fieldInfos.hasVectors());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     SegmentInfo.NO, -1, segment, false, null, false, 0,\n                                                     flushState.fieldInfos.hasProx(), flushState.codec,\n                                                     null,\n                                                     flushState.fieldInfos.hasVectors(),\n                                                     flushState.fieldInfos.hasDocValues(),\n                                                     flushState.fieldInfos.hasNorms(),\n                                                     flushState.fieldInfos.hasFreq());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (newSegment.getHasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (newSegment.getHasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (newSegment.getHasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (newSegment.getHasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (newSegment.getHasProx() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4a8b14bc4241c302311422d5c6f7627f8febb86e","date":1337291675,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     SegmentInfo.NO, -1, segment, false, null, false, 0,\n                                                     flushState.fieldInfos.hasProx(), flushState.codec,\n                                                     null);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     SegmentInfo.NO, -1, segment, false, null, false, 0,\n                                                     flushState.fieldInfos.hasProx(), flushState.codec,\n                                                     null,\n                                                     flushState.fieldInfos.hasVectors());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dc97c61094c5498702b29cc2e8309beac50c23dc","date":1337293692,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     SegmentInfo.NO, -1, segment, false, null, false, 0,\n                                                     flushState.codec,\n                                                     null);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     SegmentInfo.NO, -1, segment, false, null, false, 0,\n                                                     flushState.fieldInfos.hasProx(), flushState.codec,\n                                                     null);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a851824c09818632c94eba41e60ef5e72e323c8e","date":1337355760,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     SegmentInfo.NO, -1, segment, false, null, false, 0,\n                                                     flushState.codec,\n                                                     null);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     SegmentInfo.NO, -1, segment, false, null, false, 0,\n                                                     flushState.codec,\n                                                     null);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4356000e349e38c9fb48034695b7c309abd54557","date":1337460341,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     0, segment, false, null, false, 0,\n                                                     flushState.codec,\n                                                     null);\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, flushState.fieldInfos, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     SegmentInfo.NO, -1, segment, false, null, false, 0,\n                                                     flushState.codec,\n                                                     null);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"352763be0465236f8e2ac188aa1b761cb3e1c9ee","date":1337516554,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     -1, segment, false, null, false, 0,\n                                                     flushState.codec,\n                                                     null);\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, flushState.fieldInfos, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     0, segment, false, null, false, 0,\n                                                     flushState.codec,\n                                                     null);\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, flushState.fieldInfos, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1494abe5dc85557ec2e2772f87660d48f831c3a5","date":1337614370,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directoryOrig, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     -1, segment, false, null, false, 0,\n                                                     flushState.codec,\n                                                     null);\n      newSegment.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, flushState.fieldInfos, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directory, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     -1, segment, false, null, false, 0,\n                                                     flushState.codec,\n                                                     null);\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, flushState.fieldInfos, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directoryOrig, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     -1, segment, false, null, false,\n                                                     flushState.codec,\n                                                     null);\n      newSegment.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(new SegmentInfoPerCommit(newSegment, 0, -1L), flushState.fieldInfos,\n                                segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directoryOrig, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     -1, segment, false, null, false, 0,\n                                                     flushState.codec,\n                                                     null);\n      newSegment.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, flushState.fieldInfos, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"63caed6eb28209e181e97822c4c8fdf808884c3b","date":1337712793,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directoryOrig, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     -1, segment, false, null, false,\n                                                     flushState.codec,\n                                                     null, null);\n      newSegment.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(new SegmentInfoPerCommit(newSegment, 0, -1L), flushState.fieldInfos,\n                                segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directoryOrig, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     -1, segment, false, null, false,\n                                                     flushState.codec,\n                                                     null);\n      newSegment.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(new SegmentInfoPerCommit(newSegment, 0, -1L), flushState.fieldInfos,\n                                segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"129c6e8ac0c0d9a110ba29e4b5f1889374f30076","date":1337725510,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.docCount = flushState.numDocs;\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfo.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(new SegmentInfoPerCommit(segmentInfo, 0, -1L), flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(directoryOrig, Constants.LUCENE_MAIN_VERSION, segment, flushState.numDocs,\n                                                     -1, segment, false, null, false,\n                                                     flushState.codec,\n                                                     null, null);\n      newSegment.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(new SegmentInfoPerCommit(newSegment, 0, -1L), flushState.fieldInfos,\n                                segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["f241b963c5bcd6c2293a928059dd2d64988a6042"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"662f233ff219b7c334eb6c65cd68cc71b27a4ffe","date":1337732885,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      // nocommit use setter and make this a SetOnce:\n      segmentInfo.docCount = flushState.numDocs;\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfo.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(new SegmentInfoPerCommit(segmentInfo, 0, -1L), flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.docCount = flushState.numDocs;\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfo.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(new SegmentInfoPerCommit(segmentInfo, 0, -1L), flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb5728b83dbb3e002cdd22adfe6caf103a96ef15","date":1337791289,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      // nocommit use setter and make this a SetOnce:\n      segmentInfo.docCount = flushState.numDocs;\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      // nocommit use setter and make this a SetOnce:\n      segmentInfo.docCount = flushState.numDocs;\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfo.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(new SegmentInfoPerCommit(segmentInfo, 0, -1L), flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"203d7d3cb7712e10ef33009a63247ae40c302d7a","date":1337798111,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      // nocommit use setter and make this a SetOnce:\n      segmentInfo.setDocCount(flushState.numDocs);\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      // nocommit use setter and make this a SetOnce:\n      segmentInfo.docCount = flushState.numDocs;\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0cadbbc3b8df99c8c7acd19da62f6b35eb126c85","date":1337798576,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      // nocommit use setter and make this a SetOnce:\n      segmentInfo.setDocCount(flushState.numDocs);\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      // nocommit use setter and make this a SetOnce:\n      segmentInfo.setDocCount(flushState.numDocs);\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"16cbef32b882ec68df422af3f08845ec82620335","date":1337802266,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      // nocommit use setter and make this a SetOnce:\n      segmentInfo.setDocCount(flushState.numDocs);\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    flushState = new SegmentWriteState(infoStream, directory, segment, fieldInfos,\n        numDocsInRAM, writer.getConfig().getTermIndexInterval(),\n        codec, pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentName + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      final SegmentInfo newSegment = new SegmentInfo(segment, flushState.numDocs, directory, false, flushState.codec, fieldInfos.asReadOnly());\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.numDocs - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" + (newSegment.getHasVectors() ? \"vectors\" : \"no vectors\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + newSegment.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + newSegment.getCodec());\n      }\n      flushedDocCount += flushState.numDocs;\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = newSegment.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + newSegment + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n      doAfterFlush();\n      success = true;\n\n      return new FlushedSegment(newSegment, segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n    } finally {\n      if (!success) {\n        if (segment != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segment);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f241b963c5bcd6c2293a928059dd2d64988a6042","date":1340296137,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":["129c6e8ac0c0d9a110ba29e4b5f1889374f30076","58c6bbc222f074c844e736e6fb23647e3db9cfe3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","6c18273ea5b3974d2f30117f46f1ae416c28f727"],"bugIntro":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7","date":1349855720,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          synchronized(parent.indexWriter) {\n            parent.indexWriter.deleter.refresh(segmentInfo.name);\n          }\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b47dabfbaff6449eedcd4321017ab2f73dfa06ab","date":1360797548,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b41f996b22bd5518650f897d050088ff808ec03","date":1360969107,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfo.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        writer.getConfig().getTermIndexInterval(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7af110b00ea8df9429309d83e38e0533d82e144f","date":1376924768,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"31d4861802ca404d78ca1d15f4550eec415b9199","date":1376947894,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice == null : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = parent.flushControl.netBytes() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      flushedDocCount += flushState.segmentInfo.getDocCount();\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n        pendingDeletes = new BufferedDeletes();\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushedDocCount / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      doAfterFlush();\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        if (segmentInfo != null) {\n          writer.flushFailed(segmentInfo);\n        }\n        abort();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e072d0b1fc19e0533d8ce432eed245196bca6fde","date":1379265112,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty() && pendingDeletes.numericUpdates.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty()) {\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingDeletes, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingDeletes.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingDeletes.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingDeletes.docIDs.size();\n      pendingDeletes.bytesUsed.addAndGet(-pendingDeletes.docIDs.size() * BufferedDeletes.BYTES_PER_DEL_DOCID);\n      pendingDeletes.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingDeletes.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentInfoPerCommit segmentInfoPerCommit = new SegmentInfoPerCommit(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedDeletes segmentDeletes;\n      if (pendingDeletes.queries.isEmpty() && pendingDeletes.numericUpdates.isEmpty()) {\n        pendingDeletes.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingDeletes;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["0567bdc5c86c94ced64201187cfcef2417d76dda"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<String>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"06805da26538ed636bd89b10c2699cc3834032ae","date":1395132972,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c8af5691e81e91ce5976783599376e8cd55f9ca","date":1400666525,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0567bdc5c86c94ced64201187cfcef2417d76dda","date":1400678298,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","bugFix":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a656b32c3aa151037a8c52e9b134acc3cbf482bc","date":1400688195,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7605579001505896d48b07160075a5c8b8e128e","date":1400758727,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : (flushState.segmentInfo.getDocCount() - flushState.delCountOnFlush)) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9299079153fd7895bf3cf6835cf7019af2ba89b3","date":1417813477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw new AbortingException(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborting) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    boolean success = false;\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      success = true;\n\n      return fs;\n    } finally {\n      if (!success) {\n        abort(filesToDelete);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d2879042d8cb5738afcc7dc5f8f11f9d3006642","date":1418137170,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw new AbortingException(th);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"20c85e7e94bb746322f26163ea038a38c73887e6","date":1421315713,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize(includes docstores)=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b0267c69e2456a3477a1ad785723f2135da3117e","date":1425317087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b06445ae1731e049327712db0454e5643ca9b7fe","date":1425329139,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setDocCount(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.getDocCount() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1786be6a11f9cf5e48ce84869d1bb71e9c02f966","date":1448381196,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"86a0a50d2d14aaee1e635bbec914468551f7f9a2","date":1482234306,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":["86c34ea6a885f625f2e464756450d45b72653ef3","c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7","f241b963c5bcd6c2293a928059dd2d64988a6042"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","date":1482251961,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n\n    try {\n      consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n                                             sortMap);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n      \n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":null,"bugIntro":["fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n                                             sortMap);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n      \n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n                                             sortMap);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n      \n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.docIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.docIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.docIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.docIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.docIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      pendingUpdates.terms.clear();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.queries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef","date":1512420564,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n                                             sortMap);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n                                             sortMap);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n      \n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":["f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"845b760a99e5f369fcd0a5d723a87b8def6a3f56","date":1521117993,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n          sortMap);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\");\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException, AbortingException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n                           (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n                           (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" + \n                           (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" + \n                           (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" + \n                           (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes()/1024./1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name + \n                \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n                \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n                \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n                                             segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n                                             sortMap);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0)/1000000.0) + \" msec\");\n      }\n\n      return fs;\n    } catch (Throwable th) {\n      abort();\n      throw AbortingException.wrap(th);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7","date":1524496660,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush(DocumentsWriter.FlushNotifications).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#flush().mjava","sourceNew":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush(DocumentsWriter.FlushNotifications flushNotifications) throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n          sortMap);\n      sealFlushedSegment(fs, sortMap, flushNotifications);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\", flushNotifications);\n    }\n  }\n\n","sourceOld":"  /** Flush all pending docs to a new segment */\n  FlushedSegment flush() throws IOException {\n    assert numDocsInRAM > 0;\n    assert deleteSlice.isEmpty() : \"all deletes must be applied in prepareFlush\";\n    segmentInfo.setMaxDoc(numDocsInRAM);\n    final SegmentWriteState flushState = new SegmentWriteState(infoStream, directory, segmentInfo, fieldInfos.finish(),\n        pendingUpdates, new IOContext(new FlushInfo(numDocsInRAM, bytesUsed())));\n    final double startMBUsed = bytesUsed() / 1024. / 1024.;\n\n    // Apply delete-by-docID now (delete-byDocID only\n    // happens when an exception is hit processing that\n    // doc, eg if analyzer has some problem w/ the text):\n    if (pendingUpdates.deleteDocIDs.size() > 0) {\n      flushState.liveDocs = codec.liveDocsFormat().newLiveDocs(numDocsInRAM);\n      for(int delDocID : pendingUpdates.deleteDocIDs) {\n        flushState.liveDocs.clear(delDocID);\n      }\n      flushState.delCountOnFlush = pendingUpdates.deleteDocIDs.size();\n      pendingUpdates.bytesUsed.addAndGet(-pendingUpdates.deleteDocIDs.size() * BufferedUpdates.BYTES_PER_DEL_DOCID);\n      pendingUpdates.deleteDocIDs.clear();\n    }\n\n    if (aborted) {\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush: skip because aborting is set\");\n      }\n      return null;\n    }\n\n    long t0 = System.nanoTime();\n\n    if (infoStream.isEnabled(\"DWPT\")) {\n      infoStream.message(\"DWPT\", \"flush postings as segment \" + flushState.segmentInfo.name + \" numDocs=\" + numDocsInRAM);\n    }\n    final Sorter.DocMap sortMap;\n    try {\n      sortMap = consumer.flush(flushState);\n      // We clear this here because we already resolved them (private to this segment) when writing postings:\n      pendingUpdates.clearDeleteTerms();\n      segmentInfo.setFiles(new HashSet<>(directory.getCreatedFiles()));\n\n      final SegmentCommitInfo segmentInfoPerCommit = new SegmentCommitInfo(segmentInfo, 0, -1L, -1L, -1L);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"new segment has \" + (flushState.liveDocs == null ? 0 : flushState.delCountOnFlush) + \" deleted docs\");\n        infoStream.message(\"DWPT\", \"new segment has \" +\n            (flushState.fieldInfos.hasVectors() ? \"vectors\" : \"no vectors\") + \"; \" +\n            (flushState.fieldInfos.hasNorms() ? \"norms\" : \"no norms\") + \"; \" +\n            (flushState.fieldInfos.hasDocValues() ? \"docValues\" : \"no docValues\") + \"; \" +\n            (flushState.fieldInfos.hasProx() ? \"prox\" : \"no prox\") + \"; \" +\n            (flushState.fieldInfos.hasFreq() ? \"freqs\" : \"no freqs\"));\n        infoStream.message(\"DWPT\", \"flushedFiles=\" + segmentInfoPerCommit.files());\n        infoStream.message(\"DWPT\", \"flushed codec=\" + codec);\n      }\n\n      final BufferedUpdates segmentDeletes;\n      if (pendingUpdates.deleteQueries.isEmpty() && pendingUpdates.numericUpdates.isEmpty() && pendingUpdates.binaryUpdates.isEmpty()) {\n        pendingUpdates.clear();\n        segmentDeletes = null;\n      } else {\n        segmentDeletes = pendingUpdates;\n      }\n\n      if (infoStream.isEnabled(\"DWPT\")) {\n        final double newSegmentSize = segmentInfoPerCommit.sizeInBytes() / 1024. / 1024.;\n        infoStream.message(\"DWPT\", \"flushed: segment=\" + segmentInfo.name +\n            \" ramUsed=\" + nf.format(startMBUsed) + \" MB\" +\n            \" newFlushedSize=\" + nf.format(newSegmentSize) + \" MB\" +\n            \" docs/MB=\" + nf.format(flushState.segmentInfo.maxDoc() / newSegmentSize));\n      }\n\n      assert segmentInfo != null;\n\n      FlushedSegment fs = new FlushedSegment(infoStream, segmentInfoPerCommit, flushState.fieldInfos,\n          segmentDeletes, flushState.liveDocs, flushState.delCountOnFlush,\n          sortMap);\n      sealFlushedSegment(fs, sortMap);\n      if (infoStream.isEnabled(\"DWPT\")) {\n        infoStream.message(\"DWPT\", \"flush time \" + ((System.nanoTime() - t0) / 1000000.0) + \" msec\");\n      }\n      return fs;\n    } catch (Throwable t) {\n      onAbortingException(t);\n      throw t;\n    } finally {\n      maybeAbort(\"flush\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["fc834f3412d287003cc04691da380b69ab983239"],"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7":["845b760a99e5f369fcd0a5d723a87b8def6a3f56"],"f241b963c5bcd6c2293a928059dd2d64988a6042":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"63caed6eb28209e181e97822c4c8fdf808884c3b":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"16cbef32b882ec68df422af3f08845ec82620335":["0cadbbc3b8df99c8c7acd19da62f6b35eb126c85"],"06805da26538ed636bd89b10c2699cc3834032ae":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"20c85e7e94bb746322f26163ea038a38c73887e6":["9d2879042d8cb5738afcc7dc5f8f11f9d3006642"],"7c8af5691e81e91ce5976783599376e8cd55f9ca":["06805da26538ed636bd89b10c2699cc3834032ae"],"129c6e8ac0c0d9a110ba29e4b5f1889374f30076":["63caed6eb28209e181e97822c4c8fdf808884c3b"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":["1786be6a11f9cf5e48ce84869d1bb71e9c02f966","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"3b41f996b22bd5518650f897d050088ff808ec03":["c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7","b47dabfbaff6449eedcd4321017ab2f73dfa06ab"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["fb5728b83dbb3e002cdd22adfe6caf103a96ef15"],"fb5728b83dbb3e002cdd22adfe6caf103a96ef15":["662f233ff219b7c334eb6c65cd68cc71b27a4ffe"],"a45bec74b98f6fc05f52770cfb425739e6563960":["b47dabfbaff6449eedcd4321017ab2f73dfa06ab"],"b0267c69e2456a3477a1ad785723f2135da3117e":["20c85e7e94bb746322f26163ea038a38c73887e6"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["86a0a50d2d14aaee1e635bbec914468551f7f9a2","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9d2879042d8cb5738afcc7dc5f8f11f9d3006642":["9299079153fd7895bf3cf6835cf7019af2ba89b3"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","f241b963c5bcd6c2293a928059dd2d64988a6042"],"a656b32c3aa151037a8c52e9b134acc3cbf482bc":["06805da26538ed636bd89b10c2699cc3834032ae","0567bdc5c86c94ced64201187cfcef2417d76dda"],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["0567bdc5c86c94ced64201187cfcef2417d76dda"],"845b760a99e5f369fcd0a5d723a87b8def6a3f56":["fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"7af110b00ea8df9429309d83e38e0533d82e144f":["a45bec74b98f6fc05f52770cfb425739e6563960"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"a851824c09818632c94eba41e60ef5e72e323c8e":["dc97c61094c5498702b29cc2e8309beac50c23dc"],"b7605579001505896d48b07160075a5c8b8e128e":["06805da26538ed636bd89b10c2699cc3834032ae","0567bdc5c86c94ced64201187cfcef2417d76dda"],"1494abe5dc85557ec2e2772f87660d48f831c3a5":["352763be0465236f8e2ac188aa1b761cb3e1c9ee"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["20c85e7e94bb746322f26163ea038a38c73887e6","b0267c69e2456a3477a1ad785723f2135da3117e"],"4356000e349e38c9fb48034695b7c309abd54557":["a851824c09818632c94eba41e60ef5e72e323c8e"],"b06445ae1731e049327712db0454e5643ca9b7fe":["20c85e7e94bb746322f26163ea038a38c73887e6","b0267c69e2456a3477a1ad785723f2135da3117e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["b47dabfbaff6449eedcd4321017ab2f73dfa06ab"],"b47dabfbaff6449eedcd4321017ab2f73dfa06ab":["c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7"],"e072d0b1fc19e0533d8ce432eed245196bca6fde":["7af110b00ea8df9429309d83e38e0533d82e144f"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"1786be6a11f9cf5e48ce84869d1bb71e9c02f966":["b0267c69e2456a3477a1ad785723f2135da3117e"],"352763be0465236f8e2ac188aa1b761cb3e1c9ee":["4356000e349e38c9fb48034695b7c309abd54557"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","7af110b00ea8df9429309d83e38e0533d82e144f"],"31d4861802ca404d78ca1d15f4550eec415b9199":["a45bec74b98f6fc05f52770cfb425739e6563960","7af110b00ea8df9429309d83e38e0533d82e144f"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["1494abe5dc85557ec2e2772f87660d48f831c3a5"],"0567bdc5c86c94ced64201187cfcef2417d76dda":["7c8af5691e81e91ce5976783599376e8cd55f9ca"],"dc97c61094c5498702b29cc2e8309beac50c23dc":["4a8b14bc4241c302311422d5c6f7627f8febb86e"],"c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7":["f241b963c5bcd6c2293a928059dd2d64988a6042"],"fc834f3412d287003cc04691da380b69ab983239":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460"],"28288370235ed02234a64753cdbf0c6ec096304a":["86a0a50d2d14aaee1e635bbec914468551f7f9a2","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","16cbef32b882ec68df422af3f08845ec82620335"],"fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef":["28288370235ed02234a64753cdbf0c6ec096304a"],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["1786be6a11f9cf5e48ce84869d1bb71e9c02f966"],"0cadbbc3b8df99c8c7acd19da62f6b35eb126c85":["203d7d3cb7712e10ef33009a63247ae40c302d7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["86a2e8a56b368d37ef3ba7180541fa317d6fd6c7"],"662f233ff219b7c334eb6c65cd68cc71b27a4ffe":["129c6e8ac0c0d9a110ba29e4b5f1889374f30076"]},"commit2Childs":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["dc97c61094c5498702b29cc2e8309beac50c23dc"],"86a2e8a56b368d37ef3ba7180541fa317d6fd6c7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f241b963c5bcd6c2293a928059dd2d64988a6042":["fe33227f6805edab2036cbb80645cc4e2d1fa424","c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"63caed6eb28209e181e97822c4c8fdf808884c3b":["129c6e8ac0c0d9a110ba29e4b5f1889374f30076"],"16cbef32b882ec68df422af3f08845ec82620335":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"06805da26538ed636bd89b10c2699cc3834032ae":["7c8af5691e81e91ce5976783599376e8cd55f9ca","a656b32c3aa151037a8c52e9b134acc3cbf482bc","b7605579001505896d48b07160075a5c8b8e128e"],"20c85e7e94bb746322f26163ea038a38c73887e6":["b0267c69e2456a3477a1ad785723f2135da3117e","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe"],"7c8af5691e81e91ce5976783599376e8cd55f9ca":["0567bdc5c86c94ced64201187cfcef2417d76dda"],"129c6e8ac0c0d9a110ba29e4b5f1889374f30076":["662f233ff219b7c334eb6c65cd68cc71b27a4ffe"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":[],"3b41f996b22bd5518650f897d050088ff808ec03":[],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["0cadbbc3b8df99c8c7acd19da62f6b35eb126c85"],"fb5728b83dbb3e002cdd22adfe6caf103a96ef15":["203d7d3cb7712e10ef33009a63247ae40c302d7a"],"a45bec74b98f6fc05f52770cfb425739e6563960":["7af110b00ea8df9429309d83e38e0533d82e144f","31d4861802ca404d78ca1d15f4550eec415b9199"],"b0267c69e2456a3477a1ad785723f2135da3117e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","1786be6a11f9cf5e48ce84869d1bb71e9c02f966"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["fc834f3412d287003cc04691da380b69ab983239"],"9d2879042d8cb5738afcc7dc5f8f11f9d3006642":["20c85e7e94bb746322f26163ea038a38c73887e6"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a656b32c3aa151037a8c52e9b134acc3cbf482bc":[],"9299079153fd7895bf3cf6835cf7019af2ba89b3":["9d2879042d8cb5738afcc7dc5f8f11f9d3006642"],"845b760a99e5f369fcd0a5d723a87b8def6a3f56":["86a2e8a56b368d37ef3ba7180541fa317d6fd6c7"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"7af110b00ea8df9429309d83e38e0533d82e144f":["e072d0b1fc19e0533d8ce432eed245196bca6fde","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"a851824c09818632c94eba41e60ef5e72e323c8e":["4356000e349e38c9fb48034695b7c309abd54557"],"b7605579001505896d48b07160075a5c8b8e128e":[],"1494abe5dc85557ec2e2772f87660d48f831c3a5":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"4356000e349e38c9fb48034695b7c309abd54557":["352763be0465236f8e2ac188aa1b761cb3e1c9ee"],"b06445ae1731e049327712db0454e5643ca9b7fe":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576"],"b47dabfbaff6449eedcd4321017ab2f73dfa06ab":["3b41f996b22bd5518650f897d050088ff808ec03","a45bec74b98f6fc05f52770cfb425739e6563960","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"e072d0b1fc19e0533d8ce432eed245196bca6fde":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["06805da26538ed636bd89b10c2699cc3834032ae"],"1786be6a11f9cf5e48ce84869d1bb71e9c02f966":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"352763be0465236f8e2ac188aa1b761cb3e1c9ee":["1494abe5dc85557ec2e2772f87660d48f831c3a5"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"31d4861802ca404d78ca1d15f4550eec415b9199":[],"9d153abcf92dc5329d98571a8c3035df9bd80648":["63caed6eb28209e181e97822c4c8fdf808884c3b"],"0567bdc5c86c94ced64201187cfcef2417d76dda":["a656b32c3aa151037a8c52e9b134acc3cbf482bc","9299079153fd7895bf3cf6835cf7019af2ba89b3","b7605579001505896d48b07160075a5c8b8e128e"],"dc97c61094c5498702b29cc2e8309beac50c23dc":["a851824c09818632c94eba41e60ef5e72e323c8e"],"c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7":["3b41f996b22bd5518650f897d050088ff808ec03","b47dabfbaff6449eedcd4321017ab2f73dfa06ab"],"fc834f3412d287003cc04691da380b69ab983239":["4a8b14bc4241c302311422d5c6f7627f8febb86e"],"28288370235ed02234a64753cdbf0c6ec096304a":["fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["f241b963c5bcd6c2293a928059dd2d64988a6042","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef":["845b760a99e5f369fcd0a5d723a87b8def6a3f56"],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","f4363cd33f6eff7fb4753574a441e2d18c1022a4","28288370235ed02234a64753cdbf0c6ec096304a"],"0cadbbc3b8df99c8c7acd19da62f6b35eb126c85":["16cbef32b882ec68df422af3f08845ec82620335"],"662f233ff219b7c334eb6c65cd68cc71b27a4ffe":["fb5728b83dbb3e002cdd22adfe6caf103a96ef15"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","3b41f996b22bd5518650f897d050088ff808ec03","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","fe33227f6805edab2036cbb80645cc4e2d1fa424","a656b32c3aa151037a8c52e9b134acc3cbf482bc","b7605579001505896d48b07160075a5c8b8e128e","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}