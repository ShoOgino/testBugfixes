{"path":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedSetAroundBlockSize().mjava","commits":[{"id":"084884d4602f4d1c7411eab29e897e349ce62675","date":1475571034,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"/dev/null","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1967bed916cc89da82a1c2085f27976da6d08cbd","date":1475588750,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"/dev/null","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"/dev/null","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"409da428f28953cf35fddd5c9ff5c7e4f5439863","date":1547556145,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedSetAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput buffer = new ByteBuffersDataOutput();\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        buffer.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          buffer.writeVInt(ref.length);\n          buffer.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      ByteBuffersDataInput in = buffer.toDataInput();\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        out.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          out.writeVInt(ref.length);\n          out.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"03e17b020972a0d6e8d6823f545571a66646a167","date":1547847724,"type":5,"author":"Toke Eskildsen","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedSetAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput buffer = new ByteBuffersDataOutput();\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        buffer.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          buffer.writeVInt(ref.length);\n          buffer.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      ByteBuffersDataInput in = buffer.toDataInput();\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput buffer = new ByteBuffersDataOutput();\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        buffer.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          buffer.writeVInt(ref.length);\n          buffer.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      ByteBuffersDataInput in = buffer.toDataInput();\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c89f1ef80a9432f4eabaeda9a1e135cd72e60836","date":1547972642,"type":5,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedSetAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedSetAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput buffer = new ByteBuffersDataOutput();\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        buffer.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          buffer.writeVInt(ref.length);\n          buffer.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      ByteBuffersDataInput in = buffer.toDataInput();\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedSetAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput buffer = new ByteBuffersDataOutput();\n      Document doc = new Document();\n      SortedSetDocValuesField field1 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field1);\n      SortedSetDocValuesField field2 = new SortedSetDocValuesField(\"sset\", new BytesRef());\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        BytesRef s1 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        BytesRef s2 = new BytesRef(TestUtil.randomSimpleString(random(), 2));\n        field1.setBytesValue(s1);\n        field2.setBytesValue(s2);\n        w.addDocument(doc);\n        Set<BytesRef> set = new TreeSet<>(Arrays.asList(s1, s2));\n        buffer.writeVInt(set.size());\n        for (BytesRef ref : set) {\n          buffer.writeVInt(ref.length);\n          buffer.writeBytes(ref.bytes, ref.offset, ref.length);\n        }\n      }\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedSetDocValues values = sr.getSortedSetDocValues(\"sset\");\n      assertNotNull(values);\n      ByteBuffersDataInput in = buffer.toDataInput();\n      BytesRefBuilder b = new BytesRefBuilder();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        final int numValues = in.readVInt();\n\n        for (int j = 0; j < numValues; ++j) {\n          b.setLength(in.readVInt());\n          b.grow(b.length());\n          in.readBytes(b.bytes(), 0, b.length());\n          assertEquals(b.get(), values.lookupOrd(values.nextOrd()));\n        }\n\n        assertEquals(SortedSetDocValues.NO_MORE_ORDS, values.nextOrd());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"03e17b020972a0d6e8d6823f545571a66646a167":["409da428f28953cf35fddd5c9ff5c7e4f5439863"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["1967bed916cc89da82a1c2085f27976da6d08cbd"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":["409da428f28953cf35fddd5c9ff5c7e4f5439863","03e17b020972a0d6e8d6823f545571a66646a167"],"1967bed916cc89da82a1c2085f27976da6d08cbd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","084884d4602f4d1c7411eab29e897e349ce62675"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1967bed916cc89da82a1c2085f27976da6d08cbd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["03e17b020972a0d6e8d6823f545571a66646a167"],"084884d4602f4d1c7411eab29e897e349ce62675":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"03e17b020972a0d6e8d6823f545571a66646a167":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["03e17b020972a0d6e8d6823f545571a66646a167","c89f1ef80a9432f4eabaeda9a1e135cd72e60836"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":[],"1967bed916cc89da82a1c2085f27976da6d08cbd":["409da428f28953cf35fddd5c9ff5c7e4f5439863","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1967bed916cc89da82a1c2085f27976da6d08cbd","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","084884d4602f4d1c7411eab29e897e349ce62675"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"084884d4602f4d1c7411eab29e897e349ce62675":["1967bed916cc89da82a1c2085f27976da6d08cbd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}