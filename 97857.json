{"path":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","commits":[{"id":"761333d77c7f29123c00c93b107b743f32f012e6","date":1411986072,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsAndPositionsEnumStart().mjava","sourceNew":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true,  random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      DocsAndPositionsEnum disi = reader.termPositionsEnum(new Term(\"foo\", \"bar\"));\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.docsAndPositions(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","sourceOld":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true,  random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      DocsAndPositionsEnum disi = reader.termPositionsEnum(new Term(\"foo\", \"bar\"));\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.docsAndPositions(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d9a47902d6207303f5ed3e7aaca62ca33433af66","date":1412435312,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsAndPositionsEnumStart().mjava","sourceNew":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true,  random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      DocsAndPositionsEnum disi = reader.termPositionsEnum(new Term(\"foo\", \"bar\"));\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.docsAndPositions(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","sourceOld":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true,  random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      DocsAndPositionsEnum disi = reader.termPositionsEnum(new Term(\"foo\", \"bar\"));\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.docsAndPositions(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb","date":1420550360,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","sourceNew":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      DocsAndPositionsEnum disi = reader.termPositionsEnum(new Term(\"foo\", \"bar\"));\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.docsAndPositions(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","sourceOld":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true,  random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      DocsAndPositionsEnum disi = reader.termPositionsEnum(new Term(\"foo\", \"bar\"));\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.docsAndPositions(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","sourceNew":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      PostingsEnum disi = reader.termDocsEnum(new Term(\"foo\", \"bar\"), PostingsEnum.FLAG_ALL);\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.postings(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","sourceOld":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      DocsAndPositionsEnum disi = reader.termPositionsEnum(new Term(\"foo\", \"bar\"));\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.docsAndPositions(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","sourceNew":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      PostingsEnum disi = reader.postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.postings(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","sourceOld":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      PostingsEnum disi = reader.termDocsEnum(new Term(\"foo\", \"bar\"), PostingsEnum.FLAG_ALL);\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.postings(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb04834a792874aacf8d8b111a39603c23fbd777","date":1428406678,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","sourceNew":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      TestUtil.checkReader(reader);\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      PostingsEnum disi = reader.postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.postings(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","sourceOld":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      PostingsEnum disi = reader.postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.postings(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","sourceNew":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      TestUtil.checkReader(reader);\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      PostingsEnum disi = reader.postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator();\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.postings(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","sourceOld":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      TestUtil.checkReader(reader);\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      PostingsEnum disi = reader.postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator(null);\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.postings(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","sourceNew":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      TestUtil.checkReader(reader);\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      PostingsEnum disi = reader.postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator();\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.postings(disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","sourceOld":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      TestUtil.checkReader(reader);\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      PostingsEnum disi = reader.postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator();\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.postings(null, disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d77dafd89756a5161d244985903e3487ca109182","date":1548679743,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstDirectory#testDocsAndPositionsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsAndPositionsEnumStart().mjava","sourceNew":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      TestUtil.checkReader(reader);\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      PostingsEnum disi = reader.postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator();\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.postings(disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","sourceOld":"  public void testDocsAndPositionsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    int numIters = atLeast(3);\n    MemoryIndex memory = new MemoryIndex(true, false, random().nextInt(50) * 1024 * 1024);\n    for (int i = 0; i < numIters; i++) { // check reuse\n      memory.addField(\"foo\", \"bar\", analyzer);\n      LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n      TestUtil.checkReader(reader);\n      assertEquals(1, reader.terms(\"foo\").getSumTotalTermFreq());\n      PostingsEnum disi = reader.postings(new Term(\"foo\", \"bar\"), PostingsEnum.ALL);\n      int docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      assertEquals(0, disi.nextPosition());\n      assertEquals(0, disi.startOffset());\n      assertEquals(3, disi.endOffset());\n      \n      // now reuse and check again\n      TermsEnum te = reader.terms(\"foo\").iterator();\n      assertTrue(te.seekExact(new BytesRef(\"bar\")));\n      disi = te.postings(disi);\n      docid = disi.docID();\n      assertEquals(-1, docid);\n      assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n      reader.close();\n      memory.reset();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["bb04834a792874aacf8d8b111a39603c23fbd777"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"bb04834a792874aacf8d8b111a39603c23fbd777":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d77dafd89756a5161d244985903e3487ca109182":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb":["761333d77c7f29123c00c93b107b743f32f012e6"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","761333d77c7f29123c00c93b107b743f32f012e6"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb"],"761333d77c7f29123c00c93b107b743f32f012e6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d77dafd89756a5161d244985903e3487ca109182"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["d77dafd89756a5161d244985903e3487ca109182"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["bb04834a792874aacf8d8b111a39603c23fbd777"],"bb04834a792874aacf8d8b111a39603c23fbd777":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d9a47902d6207303f5ed3e7aaca62ca33433af66","761333d77c7f29123c00c93b107b743f32f012e6"],"d77dafd89756a5161d244985903e3487ca109182":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb":["51f5280f31484820499077f41fcdfe92d527d9dc"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":[],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"761333d77c7f29123c00c93b107b743f32f012e6":["e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb","d9a47902d6207303f5ed3e7aaca62ca33433af66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d9a47902d6207303f5ed3e7aaca62ca33433af66","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}