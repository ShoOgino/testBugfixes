{"path":"lucene/backwards/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/backwards/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","pathOld":"backwards/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","sourceNew":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    assertTrue(reader != null);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = (TermVectorEntry) iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = (TermVectorEntry) iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Iterator iterator = map.entrySet().iterator(); iterator.hasNext();) {\n      Map.Entry entry = (Map.Entry) iterator.next();\n      SortedSet sortedSet = (SortedSet) entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (Iterator inner = sortedSet.iterator(); inner.hasNext();) {\n        TermVectorEntry tve = (TermVectorEntry) inner.next();\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Iterator iterator = map.entrySet().iterator(); iterator.hasNext();) {\n      Map.Entry entry = (Map.Entry) iterator.next();\n      SortedSet sortedSet = (SortedSet) entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (Iterator inner = sortedSet.iterator(); inner.hasNext();) {\n        TermVectorEntry tve = (TermVectorEntry) inner.next();\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n\n  }\n\n","sourceOld":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    assertTrue(reader != null);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = (TermVectorEntry) iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = (TermVectorEntry) iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Iterator iterator = map.entrySet().iterator(); iterator.hasNext();) {\n      Map.Entry entry = (Map.Entry) iterator.next();\n      SortedSet sortedSet = (SortedSet) entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (Iterator inner = sortedSet.iterator(); inner.hasNext();) {\n        TermVectorEntry tve = (TermVectorEntry) inner.next();\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Iterator iterator = map.entrySet().iterator(); iterator.hasNext();) {\n      Map.Entry entry = (Map.Entry) iterator.next();\n      SortedSet sortedSet = (SortedSet) entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (Iterator inner = sortedSet.iterator(); inner.hasNext();) {\n        TermVectorEntry tve = (TermVectorEntry) inner.next();\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6","date":1272983566,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backwards/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","sourceNew":null,"sourceOld":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    assertTrue(reader != null);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = (TermVectorEntry) iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = (TermVectorEntry) iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Iterator iterator = map.entrySet().iterator(); iterator.hasNext();) {\n      Map.Entry entry = (Map.Entry) iterator.next();\n      SortedSet sortedSet = (SortedSet) entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (Iterator inner = sortedSet.iterator(); inner.hasNext();) {\n        TermVectorEntry tve = (TermVectorEntry) inner.next();\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Iterator iterator = map.entrySet().iterator(); iterator.hasNext();) {\n      Map.Entry entry = (Map.Entry) iterator.next();\n      SortedSet sortedSet = (SortedSet) entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (Iterator inner = sortedSet.iterator(); inner.hasNext();) {\n        TermVectorEntry tve = (TermVectorEntry) inner.next();\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}