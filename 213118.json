{"path":"contrib/extraction/src/main/java/org/apache/solr/handler/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","commits":[{"id":"868e0ed16bb29556f95c00e989da33ab5c9dfe56","date":1228568666,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/extraction/src/main/java/org/apache/solr/handler/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        XMLSerializer serializer = null;\n        if (extractOnly == true) {\n          writer = new StringWriter();\n          serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n\n        }\n      } catch (Exception e) {\n        //TODO: handle here with an option to not fail and just log the exception\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["623193e0f05f138bdb5a54e0d149ab4ce4bf51f5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"46dfcd540005e76a7db876d494ac74e82c476523","date":1229095104,"type":5,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/extraction/src/main/java/org/apache/solr/handler/extraction/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","pathOld":"contrib/extraction/src/main/java/org/apache/solr/handler/ExtractingDocumentLoader#load(SolrQueryRequest,SolrQueryResponse,ContentStream).mjava","sourceNew":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        XMLSerializer serializer = null;\n        if (extractOnly == true) {\n          writer = new StringWriter();\n          serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n\n        }\n      } catch (Exception e) {\n        //TODO: handle here with an option to not fail and just log the exception\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","sourceOld":"  /**\n   * @param req\n   * @param stream\n   * @throws java.io.IOException\n   */\n  public void load(SolrQueryRequest req, SolrQueryResponse rsp, ContentStream stream) throws IOException {\n    errHeader = \"ExtractingDocumentLoader: \" + stream.getSourceInfo();\n    Parser parser = null;\n    String streamType = req.getParams().get(ExtractingParams.STREAM_TYPE, null);\n    if (streamType != null) {\n      //Cache?  Parsers are lightweight to construct and thread-safe, so I'm told\n      parser = config.getParser(streamType.trim().toLowerCase());\n    } else {\n      parser = autoDetectParser;\n    }\n    if (parser != null) {\n      Metadata metadata = new Metadata();\n      metadata.add(ExtractingMetadataConstants.STREAM_NAME, stream.getName());\n      metadata.add(ExtractingMetadataConstants.STREAM_SOURCE_INFO, stream.getSourceInfo());\n      metadata.add(ExtractingMetadataConstants.STREAM_SIZE, String.valueOf(stream.getSize()));\n      metadata.add(ExtractingMetadataConstants.STREAM_CONTENT_TYPE, stream.getContentType());\n\n      // If you specify the resource name (the filename, roughly) with this parameter,\n      // then Tika can make use of it in guessing the appropriate MIME type:\n      String resourceName = req.getParams().get(ExtractingParams.RESOURCE_NAME, null);\n      if (resourceName != null) {\n        metadata.add(Metadata.RESOURCE_NAME_KEY, resourceName);\n      }\n\n      SolrContentHandler handler = factory.createSolrContentHandler(metadata, params, schema);\n      InputStream inputStream = null;\n      try {\n        inputStream = stream.getStream();\n        String xpathExpr = params.get(ExtractingParams.XPATH_EXPRESSION);\n        boolean extractOnly = params.getBool(ExtractingParams.EXTRACT_ONLY, false);\n        ContentHandler parsingHandler = handler;\n\n        StringWriter writer = null;\n        XMLSerializer serializer = null;\n        if (extractOnly == true) {\n          writer = new StringWriter();\n          serializer = new XMLSerializer(writer, new OutputFormat(\"XML\", \"UTF-8\", true));\n          if (xpathExpr != null) {\n            Matcher matcher =\n                    PARSER.parse(xpathExpr);\n            serializer.startDocument();//The MatchingContentHandler does not invoke startDocument.  See http://tika.markmail.org/message/kknu3hw7argwiqin\n            parsingHandler = new MatchingContentHandler(serializer, matcher);\n          } else {\n            parsingHandler = serializer;\n          }\n        } else if (xpathExpr != null) {\n          Matcher matcher =\n                  PARSER.parse(xpathExpr);\n          parsingHandler = new MatchingContentHandler(handler, matcher);\n        } //else leave it as is\n\n        //potentially use a wrapper handler for parsing, but we still need the SolrContentHandler for getting the document.\n        parser.parse(inputStream, parsingHandler, metadata);\n        if (extractOnly == false) {\n          addDoc(handler);\n        } else {\n          //serializer is not null, so we need to call endDoc on it if using xpath\n          if (xpathExpr != null){\n            serializer.endDocument();\n          }\n          rsp.add(stream.getName(), writer.toString());\n          writer.close();\n\n        }\n      } catch (Exception e) {\n        //TODO: handle here with an option to not fail and just log the exception\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n\n      } finally {\n        IOUtils.closeQuietly(inputStream);\n      }\n    } else {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Stream type of \" + streamType + \" didn't match any known parsers.  Please supply the \" + ExtractingParams.STREAM_TYPE + \" parameter.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"868e0ed16bb29556f95c00e989da33ab5c9dfe56":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"46dfcd540005e76a7db876d494ac74e82c476523":["868e0ed16bb29556f95c00e989da33ab5c9dfe56"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["868e0ed16bb29556f95c00e989da33ab5c9dfe56"],"868e0ed16bb29556f95c00e989da33ab5c9dfe56":["46dfcd540005e76a7db876d494ac74e82c476523"],"46dfcd540005e76a7db876d494ac74e82c476523":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["46dfcd540005e76a7db876d494ac74e82c476523","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}