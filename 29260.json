{"path":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/CompactLabelToOrdinal#open(Path,float,int).mjava","commits":[{"id":"f4abec28b874149a7223e32cc7a01704c27790de","date":1410644789,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/CompactLabelToOrdinal#open(Path,float,int).mjava","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/CompactLabelToOrdinal#open(File,float,int).mjava","sourceNew":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(Path)} command.\n   */\n  static CompactLabelToOrdinal open(Path file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          Files.newInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // identical code to CategoryPath.hashFromSerialized. since we need to\n        // advance offset, we cannot call the method directly. perhaps if we\n        // could pass a mutable Integer or something...\n        int length = (short) l2o.labelRepository.charAt(offset++);\n        int hash = length;\n        if (length != 0) {\n          for (int i = 0; i < length; i++) {\n            int len = (short) l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + l2o.labelRepository.subSequence(offset, offset + len).hashCode();\n            offset += len;\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","sourceOld":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(File)} command.\n   */\n  static CompactLabelToOrdinal open(File file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          new FileInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // identical code to CategoryPath.hashFromSerialized. since we need to\n        // advance offset, we cannot call the method directly. perhaps if we\n        // could pass a mutable Integer or something...\n        int length = (short) l2o.labelRepository.charAt(offset++);\n        int hash = length;\n        if (length != 0) {\n          for (int i = 0; i < length; i++) {\n            int len = (short) l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + l2o.labelRepository.subSequence(offset, offset + len).hashCode();\n            offset += len;\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2ae0982c0457fa3cfe0cda93a327c573fbe6f874","date":1507039114,"type":4,"author":"Mike McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/CompactLabelToOrdinal#open(Path,float,int).mjava","sourceNew":null,"sourceOld":"  /**\n   * Opens the file and reloads the CompactLabelToOrdinal. The file it expects\n   * is generated from the {@link #flush(Path)} command.\n   */\n  static CompactLabelToOrdinal open(Path file, float loadFactor,\n                                    int numHashArrays) throws IOException {\n    /**\n     * Part of the file is the labelRepository, which needs to be rehashed\n     * and label offsets re-added to the object. I am unsure as to why we\n     * can't just store these off in the file as well, but in keeping with\n     * the spirit of the original code, I did it this way. (ssuppe)\n     */\n    CompactLabelToOrdinal l2o = new CompactLabelToOrdinal();\n    l2o.loadFactor = loadFactor;\n    l2o.hashArrays = new HashArray[numHashArrays];\n\n    DataInputStream dis = null;\n    try {\n      dis = new DataInputStream(new BufferedInputStream(\n          Files.newInputStream(file)));\n\n      // TaxiReader needs to load the \"counter\" or occupancy (L2O) to know\n      // the next unique facet. we used to load the delimiter too, but\n      // never used it.\n      l2o.counter = dis.readInt();\n\n      l2o.capacity = determineCapacity((int) Math.pow(2,\n          l2o.hashArrays.length), l2o.counter);\n      l2o.init();\n\n      // now read the chars\n      l2o.labelRepository = CharBlockArray.open(dis);\n\n      l2o.collisionMap = new CollisionMap(l2o.labelRepository);\n\n      // Calculate hash on the fly based on how CategoryPath hashes\n      // itself. Maybe in the future we can call some static based methods\n      // in CategoryPath so that this doesn't break again? I don't like\n      // having code in two different places...\n      int cid = 0;\n      // Skip the initial offset, it's the CategoryPath(0,0), which isn't\n      // a hashed value.\n      int offset = 1;\n      int lastStartOffset = offset;\n      // This loop really relies on a well-formed input (assumes pretty blindly\n      // that array offsets will work).  Since the initial file is machine \n      // generated, I think this should be OK.\n      while (offset < l2o.labelRepository.length()) {\n        // identical code to CategoryPath.hashFromSerialized. since we need to\n        // advance offset, we cannot call the method directly. perhaps if we\n        // could pass a mutable Integer or something...\n        int length = (short) l2o.labelRepository.charAt(offset++);\n        int hash = length;\n        if (length != 0) {\n          for (int i = 0; i < length; i++) {\n            int len = (short) l2o.labelRepository.charAt(offset++);\n            hash = hash * 31 + l2o.labelRepository.subSequence(offset, offset + len).hashCode();\n            offset += len;\n          }\n        }\n        // Now that we've hashed the components of the label, do the\n        // final part of the hash algorithm.\n        hash = hash ^ ((hash >>> 20) ^ (hash >>> 12));\n        hash = hash ^ (hash >>> 7) ^ (hash >>> 4);\n        // Add the label, and let's keep going\n        l2o.addLabelOffset(hash, cid, lastStartOffset);\n        cid++;\n        lastStartOffset = offset;\n      }\n\n    } catch (ClassNotFoundException cnfe) {\n      throw new IOException(\"Invalid file format. Cannot deserialize.\");\n    } finally {\n      if (dis != null) {\n        dis.close();\n      }\n    }\n\n    l2o.threshold = (int) (l2o.loadFactor * l2o.capacity);\n    return l2o;\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2ae0982c0457fa3cfe0cda93a327c573fbe6f874":["f4abec28b874149a7223e32cc7a01704c27790de"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f4abec28b874149a7223e32cc7a01704c27790de":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2ae0982c0457fa3cfe0cda93a327c573fbe6f874"]},"commit2Childs":{"2ae0982c0457fa3cfe0cda93a327c573fbe6f874":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f4abec28b874149a7223e32cc7a01704c27790de"],"f4abec28b874149a7223e32cc7a01704c27790de":["2ae0982c0457fa3cfe0cda93a327c573fbe6f874"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}