{"path":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    LowerCaseTokenizer stream = new LowerCaseTokenizer(LuceneTestCase.TEST_VERSION_CURRENT, arg1);\n    stream.addAttribute(TermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    LowerCaseTokenizer stream = new LowerCaseTokenizer(LuceneTestCase.TEST_VERSION_CURRENT, arg1);\n    stream.addAttribute(TermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7f8e68717c68517265937c911e1ce9f25750247","date":1274071103,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(TermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    LowerCaseTokenizer stream = new LowerCaseTokenizer(LuceneTestCase.TEST_VERSION_CURRENT, arg1);\n    stream.addAttribute(TermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7347509fad0711ac30cb15a746e9a3830a38ebd","date":1275388513,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(CharTermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(TermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4","date":1305207152,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(CharTermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    try {\n      stream.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(CharTermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(CharTermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    try {\n      stream.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(CharTermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(CharTermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    try {\n      stream.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(CharTermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4525255e5565a6468896c2e5a3d10956439f7e5c","date":1314334747,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(CharTermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(CharTermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    try {\n      stream.reset();\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"53ae89cd75b0acbdfb8890710c6742f3fb80e65d","date":1315806626,"type":5,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#createComponents(String,Reader).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymAnalyzer[HighlighterTest]#tokenStream(String,Reader).mjava","sourceNew":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStreamComponents createComponents(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(CharTermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new TokenStreamComponents(stream, new SynonymTokenizer(stream, synonyms));\n  }\n\n","sourceOld":"  /*\n   * (non-Javadoc)\n   * \n   * @see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n   *      java.io.Reader)\n   */\n  @Override\n  public TokenStream tokenStream(String arg0, Reader arg1) {\n    Tokenizer stream = new MockTokenizer(arg1, MockTokenizer.SIMPLE, true);\n    stream.addAttribute(CharTermAttribute.class);\n    stream.addAttribute(PositionIncrementAttribute.class);\n    stream.addAttribute(OffsetAttribute.class);\n    return new SynonymTokenizer(stream, synonyms);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a7347509fad0711ac30cb15a746e9a3830a38ebd","e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4525255e5565a6468896c2e5a3d10956439f7e5c":["e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["a7347509fad0711ac30cb15a746e9a3830a38ebd","e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"c7f8e68717c68517265937c911e1ce9f25750247":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["c7f8e68717c68517265937c911e1ce9f25750247"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["53ae89cd75b0acbdfb8890710c6742f3fb80e65d"],"53ae89cd75b0acbdfb8890710c6742f3fb80e65d":["4525255e5565a6468896c2e5a3d10956439f7e5c"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4":["a3776dccca01c11e7046323cfad46a3b4a471233","4525255e5565a6468896c2e5a3d10956439f7e5c","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"4525255e5565a6468896c2e5a3d10956439f7e5c":["53ae89cd75b0acbdfb8890710c6742f3fb80e65d"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"c7f8e68717c68517265937c911e1ce9f25750247":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["c7f8e68717c68517265937c911e1ce9f25750247"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"53ae89cd75b0acbdfb8890710c6742f3fb80e65d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}