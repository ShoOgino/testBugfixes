{"path":"src/java/org/apache/solr/analysis/CharStreamAwareCJKTokenizer#next(Token).mjava","commits":[{"id":"00c1e7284eb0e728903446dd05972acc9905dd53","date":1226627781,"type":0,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"src/java/org/apache/solr/analysis/CharStreamAwareCJKTokenizer#next(Token).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Returns the next token in the stream, or null at EOS.\n     * See http://java.sun.com/j2se/1.3/docs/api/java/lang/Character.UnicodeBlock.html\n     * for detail.\n     *\n     * @param reusableToken a reusable token\n     * @return Token\n     *\n     * @throws java.io.IOException - throw IOException when read error <br>\n     *         happened in the InputStream\n     *\n     */\n    public final Token next(final Token reusableToken) throws java.io.IOException {\n        /** how many character(s) has been stored in buffer */\n        assert reusableToken != null;\n        int length = 0;\n\n        /** the position used to create Token */\n        int start = offset;\n\n        while (true) {\n            /** current character */\n            char c;\n\n            /** unicode block of current character for detail */\n            Character.UnicodeBlock ub;\n\n            offset++;\n\n            if (bufferIndex >= dataLen) {\n                dataLen = input.read(ioBuffer);\n                bufferIndex = 0;\n            }\n\n            if (dataLen == -1) {\n                if (length > 0) {\n                    if (preIsTokened == true) {\n                        length = 0;\n                        preIsTokened = false;\n                    }\n\n                    break;\n                } else {\n                    return null;\n                }\n            } else {\n                //get current character\n                c = ioBuffer[bufferIndex++];\n\n                //get the UnicodeBlock of the current character\n                ub = Character.UnicodeBlock.of(c);\n            }\n\n            //if the current character is ASCII or Extend ASCII\n            if ((ub == Character.UnicodeBlock.BASIC_LATIN)\n                    || (ub == Character.UnicodeBlock.HALFWIDTH_AND_FULLWIDTH_FORMS)\n               ) {\n                if (ub == Character.UnicodeBlock.HALFWIDTH_AND_FULLWIDTH_FORMS) {\n                    // convert  HALFWIDTH_AND_FULLWIDTH_FORMS to BASIC_LATIN\n                    int i = (int) c;\n                    i = i - 65248;\n                    c = (char) i;\n                }\n\n                // if the current character is a letter or \"_\" \"+\" \"#\"\n                if (Character.isLetterOrDigit(c)\n                        || ((c == '_') || (c == '+') || (c == '#'))\n                   ) {\n                    if (length == 0) {\n                        // \"javaC1C2C3C4linux\" <br>\n                        //      ^--: the current character begin to token the ASCII\n                        // letter\n                        start = offset - 1;\n                    } else if (tokenType == DOUBLE_TOKEN_TYPE) {\n                        // \"javaC1C2C3C4linux\" <br>\n                        //              ^--: the previous non-ASCII\n                        // : the current character\n                        offset--;\n                        bufferIndex--;\n\n                        if (preIsTokened == true) {\n                            // there is only one non-ASCII has been stored\n                            length = 0;\n                            preIsTokened = false;\n                            break;\n                        } else {\n                            break;\n                        }\n                    }\n\n                    // store the LowerCase(c) in the buffer\n                    buffer[length++] = Character.toLowerCase(c);\n                    tokenType = SINGLE_TOKEN_TYPE;\n\n                    // break the procedure if buffer overflowed!\n                    if (length == MAX_WORD_LEN) {\n                        break;\n                    }\n                } else if (length > 0) {\n                    if (preIsTokened == true) {\n                        length = 0;\n                        preIsTokened = false;\n                    } else {\n                        break;\n                    }\n                }\n            } else {\n                // non-ASCII letter, e.g.\"C1C2C3C4\"\n                if (Character.isLetter(c)) {\n                    if (length == 0) {\n                        start = offset - 1;\n                        buffer[length++] = c;\n                        tokenType = DOUBLE_TOKEN_TYPE;\n                    } else {\n                      if (tokenType == SINGLE_TOKEN_TYPE) {\n                            offset--;\n                            bufferIndex--;\n\n                            //return the previous ASCII characters\n                            break;\n                        } else {\n                            buffer[length++] = c;\n                            tokenType = DOUBLE_TOKEN_TYPE;\n\n                            if (length == 2) {\n                                offset--;\n                                bufferIndex--;\n                                preIsTokened = true;\n\n                                break;\n                            }\n                        }\n                    }\n                } else if (length > 0) {\n                    if (preIsTokened == true) {\n                        // empty the buffer\n                        length = 0;\n                        preIsTokened = false;\n                    } else {\n                        break;\n                    }\n                }\n            }\n        }\n\n        if (length > 0) {\n            // Because of \"CharStream aware\" tokenizer, using correctOffset() to\n            // correct start/end offsets\n            return reusableToken.reinit\n                (buffer, 0, length,\n                \t((CharStream)input).correctOffset( start ),\n                \t((CharStream)input).correctOffset( start+length ),\n                \tTOKEN_TYPE_NAMES[tokenType]);\n        } else if (dataLen != -1) {\n            // Don't return an empty string - recurse to get the next token\n            return next(reusableToken);\n        } else {\n          return null;\n        }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e77721aaf23393f6ea7926045ae6f8efea0ce8e","date":1247678464,"type":4,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/solr/analysis/CharStreamAwareCJKTokenizer#next(Token).mjava","sourceNew":null,"sourceOld":"    /**\n     * Returns the next token in the stream, or null at EOS.\n     * See http://java.sun.com/j2se/1.3/docs/api/java/lang/Character.UnicodeBlock.html\n     * for detail.\n     *\n     * @param reusableToken a reusable token\n     * @return Token\n     *\n     * @throws java.io.IOException - throw IOException when read error <br>\n     *         happened in the InputStream\n     *\n     */\n    public final Token next(final Token reusableToken) throws java.io.IOException {\n        /** how many character(s) has been stored in buffer */\n        assert reusableToken != null;\n        int length = 0;\n\n        /** the position used to create Token */\n        int start = offset;\n\n        while (true) {\n            /** current character */\n            char c;\n\n            /** unicode block of current character for detail */\n            Character.UnicodeBlock ub;\n\n            offset++;\n\n            if (bufferIndex >= dataLen) {\n                dataLen = input.read(ioBuffer);\n                bufferIndex = 0;\n            }\n\n            if (dataLen == -1) {\n                if (length > 0) {\n                    if (preIsTokened == true) {\n                        length = 0;\n                        preIsTokened = false;\n                    }\n\n                    break;\n                } else {\n                    return null;\n                }\n            } else {\n                //get current character\n                c = ioBuffer[bufferIndex++];\n\n                //get the UnicodeBlock of the current character\n                ub = Character.UnicodeBlock.of(c);\n            }\n\n            //if the current character is ASCII or Extend ASCII\n            if ((ub == Character.UnicodeBlock.BASIC_LATIN)\n                    || (ub == Character.UnicodeBlock.HALFWIDTH_AND_FULLWIDTH_FORMS)\n               ) {\n                if (ub == Character.UnicodeBlock.HALFWIDTH_AND_FULLWIDTH_FORMS) {\n                    // convert  HALFWIDTH_AND_FULLWIDTH_FORMS to BASIC_LATIN\n                    int i = (int) c;\n                    i = i - 65248;\n                    c = (char) i;\n                }\n\n                // if the current character is a letter or \"_\" \"+\" \"#\"\n                if (Character.isLetterOrDigit(c)\n                        || ((c == '_') || (c == '+') || (c == '#'))\n                   ) {\n                    if (length == 0) {\n                        // \"javaC1C2C3C4linux\" <br>\n                        //      ^--: the current character begin to token the ASCII\n                        // letter\n                        start = offset - 1;\n                    } else if (tokenType == DOUBLE_TOKEN_TYPE) {\n                        // \"javaC1C2C3C4linux\" <br>\n                        //              ^--: the previous non-ASCII\n                        // : the current character\n                        offset--;\n                        bufferIndex--;\n\n                        if (preIsTokened == true) {\n                            // there is only one non-ASCII has been stored\n                            length = 0;\n                            preIsTokened = false;\n                            break;\n                        } else {\n                            break;\n                        }\n                    }\n\n                    // store the LowerCase(c) in the buffer\n                    buffer[length++] = Character.toLowerCase(c);\n                    tokenType = SINGLE_TOKEN_TYPE;\n\n                    // break the procedure if buffer overflowed!\n                    if (length == MAX_WORD_LEN) {\n                        break;\n                    }\n                } else if (length > 0) {\n                    if (preIsTokened == true) {\n                        length = 0;\n                        preIsTokened = false;\n                    } else {\n                        break;\n                    }\n                }\n            } else {\n                // non-ASCII letter, e.g.\"C1C2C3C4\"\n                if (Character.isLetter(c)) {\n                    if (length == 0) {\n                        start = offset - 1;\n                        buffer[length++] = c;\n                        tokenType = DOUBLE_TOKEN_TYPE;\n                    } else {\n                      if (tokenType == SINGLE_TOKEN_TYPE) {\n                            offset--;\n                            bufferIndex--;\n\n                            //return the previous ASCII characters\n                            break;\n                        } else {\n                            buffer[length++] = c;\n                            tokenType = DOUBLE_TOKEN_TYPE;\n\n                            if (length == 2) {\n                                offset--;\n                                bufferIndex--;\n                                preIsTokened = true;\n\n                                break;\n                            }\n                        }\n                    }\n                } else if (length > 0) {\n                    if (preIsTokened == true) {\n                        // empty the buffer\n                        length = 0;\n                        preIsTokened = false;\n                    } else {\n                        break;\n                    }\n                }\n            }\n        }\n\n        if (length > 0) {\n            // Because of \"CharStream aware\" tokenizer, using correctOffset() to\n            // correct start/end offsets\n            return reusableToken.reinit\n                (buffer, 0, length,\n                \t((CharStream)input).correctOffset( start ),\n                \t((CharStream)input).correctOffset( start+length ),\n                \tTOKEN_TYPE_NAMES[tokenType]);\n        } else if (dataLen != -1) {\n            // Don't return an empty string - recurse to get the next token\n            return next(reusableToken);\n        } else {\n          return null;\n        }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1e77721aaf23393f6ea7926045ae6f8efea0ce8e":["00c1e7284eb0e728903446dd05972acc9905dd53"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"00c1e7284eb0e728903446dd05972acc9905dd53":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"1e77721aaf23393f6ea7926045ae6f8efea0ce8e":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["00c1e7284eb0e728903446dd05972acc9905dd53"],"00c1e7284eb0e728903446dd05972acc9905dd53":["1e77721aaf23393f6ea7926045ae6f8efea0ce8e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["1e77721aaf23393f6ea7926045ae6f8efea0ce8e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}