{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/temp/TempBlockTermsWriter.TermsWriter#flushBlock().mjava","commits":[{"id":"6d01ed6d1df51191983f4dd157aedf5f4650e2b3","date":1376572546,"type":0,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/temp/TempBlockTermsWriter.TermsWriter#flushBlock().mjava","pathOld":"/dev/null","sourceNew":"    private void flushBlock() throws IOException {\n      //System.out.println(\"BTW.flushBlock seg=\" + segment + \" pendingCount=\" + pendingCount + \" fp=\" + out.getFilePointer());\n\n      // First pass: compute common prefix for all terms\n      // in the block, against term before first term in\n      // this block:\n      int commonPrefix = sharedPrefix(lastPrevTerm, pendingTerms[0].term);\n      for(int termCount=1;termCount<pendingCount;termCount++) {\n        commonPrefix = Math.min(commonPrefix,\n                                sharedPrefix(lastPrevTerm,\n                                             pendingTerms[termCount].term));\n      }        \n\n      out.writeVInt(pendingCount);\n      out.writeVInt(commonPrefix);\n\n      // 2nd pass: write suffixes, as separate byte[] blob\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final int suffix = pendingTerms[termCount].term.length - commonPrefix;\n        // TODO: cutover to better intblock codec, instead\n        // of interleaving here:\n        bytesWriter.writeVInt(suffix);\n        bytesWriter.writeBytes(pendingTerms[termCount].term.bytes, commonPrefix, suffix);\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // 3rd pass: write the freqs as byte[] blob\n      // TODO: cutover to better intblock codec.  simple64?\n      // write prefix, suffix first:\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final TermStats stats = pendingTerms[termCount].stats;\n        assert stats != null;\n        bytesWriter.writeVInt(stats.docFreq);\n        if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n          bytesWriter.writeVLong(stats.totalTermFreq-stats.docFreq);\n        }\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // 4th pass: write the metadata \n      long[] lastLongs = new long[longsSize];\n      Arrays.fill(lastLongs, 0);\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final long[] longs = pendingTerms[termCount].longs;\n        final byte[] bytes = pendingTerms[termCount].bytes;\n        for (int i = 0; i < longsSize; i++) {\n          bytesWriter.writeVLong(longs[i] - lastLongs[i]);\n        }\n        lastLongs = longs;\n        bytesWriter.writeBytes(bytes, 0, bytes.length);\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      lastPrevTerm.copyBytes(pendingTerms[pendingCount-1].term);\n      pendingCount = 0;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"abfc4a4873131874a50c6f6e3deb59a743ee1f44","date":1376737165,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/temp/TempBlockTermsWriter.TermsWriter#flushBlock().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/temp/TempBlockTermsWriter.TermsWriter#flushBlock().mjava","sourceNew":"    private void flushBlock() throws IOException {\n      //System.out.println(\"BTW.flushBlock seg=\" + segment + \" pendingCount=\" + pendingCount + \" fp=\" + out.getFilePointer());\n\n      // First pass: compute common prefix for all terms\n      // in the block, against term before first term in\n      // this block:\n      int commonPrefix = sharedPrefix(lastPrevTerm, pendingTerms[0].term);\n      for(int termCount=1;termCount<pendingCount;termCount++) {\n        commonPrefix = Math.min(commonPrefix,\n                                sharedPrefix(lastPrevTerm,\n                                             pendingTerms[termCount].term));\n      }        \n\n      out.writeVInt(pendingCount);\n      out.writeVInt(commonPrefix);\n\n      // 2nd pass: write suffixes, as separate byte[] blob\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final int suffix = pendingTerms[termCount].term.length - commonPrefix;\n        // TODO: cutover to better intblock codec, instead\n        // of interleaving here:\n        bytesWriter.writeVInt(suffix);\n        bytesWriter.writeBytes(pendingTerms[termCount].term.bytes, commonPrefix, suffix);\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // 3rd pass: write the freqs as byte[] blob\n      // TODO: cutover to better intblock codec.  simple64?\n      // write prefix, suffix first:\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final BlockTermState state = pendingTerms[termCount].state;\n        assert state != null;\n        bytesWriter.writeVInt(state.docFreq);\n        if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n          bytesWriter.writeVLong(state.totalTermFreq-state.docFreq);\n        }\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // 4th pass: write the metadata \n      long[] longs = new long[longsSize];\n      boolean absolute = true;\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final BlockTermState state = pendingTerms[termCount].state;\n        postingsWriter.encodeTerm(longs, bufferWriter, fieldInfo, state, absolute);\n        for (int i = 0; i < longsSize; i++) {\n          bytesWriter.writeVLong(longs[i]);\n        }\n        bufferWriter.writeTo(bytesWriter);\n        bufferWriter.reset();\n        absolute = false;\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      lastPrevTerm.copyBytes(pendingTerms[pendingCount-1].term);\n      pendingCount = 0;\n    }\n\n","sourceOld":"    private void flushBlock() throws IOException {\n      //System.out.println(\"BTW.flushBlock seg=\" + segment + \" pendingCount=\" + pendingCount + \" fp=\" + out.getFilePointer());\n\n      // First pass: compute common prefix for all terms\n      // in the block, against term before first term in\n      // this block:\n      int commonPrefix = sharedPrefix(lastPrevTerm, pendingTerms[0].term);\n      for(int termCount=1;termCount<pendingCount;termCount++) {\n        commonPrefix = Math.min(commonPrefix,\n                                sharedPrefix(lastPrevTerm,\n                                             pendingTerms[termCount].term));\n      }        \n\n      out.writeVInt(pendingCount);\n      out.writeVInt(commonPrefix);\n\n      // 2nd pass: write suffixes, as separate byte[] blob\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final int suffix = pendingTerms[termCount].term.length - commonPrefix;\n        // TODO: cutover to better intblock codec, instead\n        // of interleaving here:\n        bytesWriter.writeVInt(suffix);\n        bytesWriter.writeBytes(pendingTerms[termCount].term.bytes, commonPrefix, suffix);\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // 3rd pass: write the freqs as byte[] blob\n      // TODO: cutover to better intblock codec.  simple64?\n      // write prefix, suffix first:\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final TermStats stats = pendingTerms[termCount].stats;\n        assert stats != null;\n        bytesWriter.writeVInt(stats.docFreq);\n        if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n          bytesWriter.writeVLong(stats.totalTermFreq-stats.docFreq);\n        }\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // 4th pass: write the metadata \n      long[] lastLongs = new long[longsSize];\n      Arrays.fill(lastLongs, 0);\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final long[] longs = pendingTerms[termCount].longs;\n        final byte[] bytes = pendingTerms[termCount].bytes;\n        for (int i = 0; i < longsSize; i++) {\n          bytesWriter.writeVLong(longs[i] - lastLongs[i]);\n        }\n        lastLongs = longs;\n        bytesWriter.writeBytes(bytes, 0, bytes.length);\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      lastPrevTerm.copyBytes(pendingTerms[pendingCount-1].term);\n      pendingCount = 0;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e6904bcc97d8afa27bd72ee29ac01e525e327ad4","date":1377958787,"type":4,"author":"Han Jiang","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/temp/TempBlockTermsWriter.TermsWriter#flushBlock().mjava","sourceNew":null,"sourceOld":"    private void flushBlock() throws IOException {\n      //System.out.println(\"BTW.flushBlock seg=\" + segment + \" pendingCount=\" + pendingCount + \" fp=\" + out.getFilePointer());\n\n      // First pass: compute common prefix for all terms\n      // in the block, against term before first term in\n      // this block:\n      int commonPrefix = sharedPrefix(lastPrevTerm, pendingTerms[0].term);\n      for(int termCount=1;termCount<pendingCount;termCount++) {\n        commonPrefix = Math.min(commonPrefix,\n                                sharedPrefix(lastPrevTerm,\n                                             pendingTerms[termCount].term));\n      }        \n\n      out.writeVInt(pendingCount);\n      out.writeVInt(commonPrefix);\n\n      // 2nd pass: write suffixes, as separate byte[] blob\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final int suffix = pendingTerms[termCount].term.length - commonPrefix;\n        // TODO: cutover to better intblock codec, instead\n        // of interleaving here:\n        bytesWriter.writeVInt(suffix);\n        bytesWriter.writeBytes(pendingTerms[termCount].term.bytes, commonPrefix, suffix);\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // 3rd pass: write the freqs as byte[] blob\n      // TODO: cutover to better intblock codec.  simple64?\n      // write prefix, suffix first:\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final BlockTermState state = pendingTerms[termCount].state;\n        assert state != null;\n        bytesWriter.writeVInt(state.docFreq);\n        if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n          bytesWriter.writeVLong(state.totalTermFreq-state.docFreq);\n        }\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // 4th pass: write the metadata \n      long[] longs = new long[longsSize];\n      boolean absolute = true;\n      for(int termCount=0;termCount<pendingCount;termCount++) {\n        final BlockTermState state = pendingTerms[termCount].state;\n        postingsWriter.encodeTerm(longs, bufferWriter, fieldInfo, state, absolute);\n        for (int i = 0; i < longsSize; i++) {\n          bytesWriter.writeVLong(longs[i]);\n        }\n        bufferWriter.writeTo(bytesWriter);\n        bufferWriter.reset();\n        absolute = false;\n      }\n      out.writeVInt((int) bytesWriter.getFilePointer());\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      lastPrevTerm.copyBytes(pendingTerms[pendingCount-1].term);\n      pendingCount = 0;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"abfc4a4873131874a50c6f6e3deb59a743ee1f44":["6d01ed6d1df51191983f4dd157aedf5f4650e2b3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e6904bcc97d8afa27bd72ee29ac01e525e327ad4":["abfc4a4873131874a50c6f6e3deb59a743ee1f44"],"6d01ed6d1df51191983f4dd157aedf5f4650e2b3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"abfc4a4873131874a50c6f6e3deb59a743ee1f44":["e6904bcc97d8afa27bd72ee29ac01e525e327ad4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6d01ed6d1df51191983f4dd157aedf5f4650e2b3","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e6904bcc97d8afa27bd72ee29ac01e525e327ad4":[],"6d01ed6d1df51191983f4dd157aedf5f4650e2b3":["abfc4a4873131874a50c6f6e3deb59a743ee1f44"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e6904bcc97d8afa27bd72ee29ac01e525e327ad4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}