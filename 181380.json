{"path":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","commits":[{"id":"cf0b1b21012d341c80a1f3975cf88823f0fe95a9","date":1316016056,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/solrj/src/java/org/apache/solr/common/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<K,V>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<K,V>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<K,V>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"310f3f20b324aca4933c1fc4261b19bfe3bc3322","date":1428729280,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invokation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually aquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ca83400a04ed1cbfa09560d2e7184f93f5d75363","date":1428921124,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc69baf14413994ccde897681e5ce1d393cf7156","date":1468245555,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc0fbfa191179ae7a0081ee1cf7da0464bcd8078","date":1469530061,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.incrementAndGet();\n    } else {\n      stats.nonLivePutCounter.incrementAndGet();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread() {\n          @Override\n          public void run() {\n            markAndSweep();\n          }\n        }.start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c5044c9bb1518e7a13c1c5385a21325ae343056","date":1479187798,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n      if (ramUpperWatermark != Long.MAX_VALUE)  {\n        ramBytes.addAndGet(e.ramBytesUsed() + LRUCache.HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n      }\n    } else {\n      currentSize = stats.size.get();\n      if (ramUpperWatermark != Long.MAX_VALUE)  {\n        if (oldCacheEntry.value instanceof Accountable) {\n          ramBytes.addAndGet(-((Accountable)oldCacheEntry.value).ramBytesUsed());\n        } else  {\n          ramBytes.addAndGet(-LRUCache.DEFAULT_RAM_BYTES_USED);\n        }\n        if (val instanceof Accountable) {\n          ramBytes.addAndGet(((Accountable)val).ramBytesUsed());\n        } else  {\n          ramBytes.addAndGet(LRUCache.DEFAULT_RAM_BYTES_USED);\n        }\n      }\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if ((currentSize > upperWaterMark || ramBytes.get() > ramUpperWatermark) && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"21019aa828c8c9b0153877543a8b3f200bf2ca19","date":1479224450,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n      if (ramUpperWatermark != Long.MAX_VALUE)  {\n        ramBytes.addAndGet(e.ramBytesUsed() + LRUCache.HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n      }\n    } else {\n      currentSize = stats.size.get();\n      if (ramUpperWatermark != Long.MAX_VALUE)  {\n        if (oldCacheEntry.value instanceof Accountable) {\n          ramBytes.addAndGet(-((Accountable)oldCacheEntry.value).ramBytesUsed());\n        } else  {\n          ramBytes.addAndGet(-LRUCache.DEFAULT_RAM_BYTES_USED);\n        }\n        if (val instanceof Accountable) {\n          ramBytes.addAndGet(((Accountable)val).ramBytesUsed());\n        } else  {\n          ramBytes.addAndGet(LRUCache.DEFAULT_RAM_BYTES_USED);\n        }\n      }\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if ((currentSize > upperWaterMark || ramBytes.get() > ramUpperWatermark) && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n    } else {\n      currentSize = stats.size.get();\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if (currentSize > upperWaterMark && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a71ca10e7131e1f01868c80d228f26a855e79dd0","date":1562166223,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n      ramBytes.addAndGet(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      currentSize = stats.size.get();\n      ramBytes.addAndGet(-oldCacheEntry.ramBytesUsed());\n      ramBytes.addAndGet(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if ((currentSize > upperWaterMark || ramBytes.get() > ramUpperWatermark) && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n      if (ramUpperWatermark != Long.MAX_VALUE)  {\n        ramBytes.addAndGet(e.ramBytesUsed() + LRUCache.HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n      }\n    } else {\n      currentSize = stats.size.get();\n      if (ramUpperWatermark != Long.MAX_VALUE)  {\n        if (oldCacheEntry.value instanceof Accountable) {\n          ramBytes.addAndGet(-((Accountable)oldCacheEntry.value).ramBytesUsed());\n        } else  {\n          ramBytes.addAndGet(-LRUCache.DEFAULT_RAM_BYTES_USED);\n        }\n        if (val instanceof Accountable) {\n          ramBytes.addAndGet(((Accountable)val).ramBytesUsed());\n        } else  {\n          ramBytes.addAndGet(LRUCache.DEFAULT_RAM_BYTES_USED);\n        }\n      }\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if ((currentSize > upperWaterMark || ramBytes.get() > ramUpperWatermark) && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83","date":1568645407,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ConcurrentLRUCache#put(K,V).mjava","sourceNew":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K, V> e = new CacheEntry<>(key, val, timeSource.getEpochTimeNs(), stats.accessCounter.incrementAndGet());\n    return putCacheEntry(e);\n  }\n\n","sourceOld":"  @Override\n  public V put(K key, V val) {\n    if (val == null) return null;\n    CacheEntry<K,V> e = new CacheEntry<>(key, val, stats.accessCounter.incrementAndGet());\n    CacheEntry<K,V> oldCacheEntry = map.put(key, e);\n    int currentSize;\n    if (oldCacheEntry == null) {\n      currentSize = stats.size.incrementAndGet();\n      ramBytes.addAndGet(e.ramBytesUsed() + HASHTABLE_RAM_BYTES_PER_ENTRY); // added key + value + entry\n    } else {\n      currentSize = stats.size.get();\n      ramBytes.addAndGet(-oldCacheEntry.ramBytesUsed());\n      ramBytes.addAndGet(e.ramBytesUsed());\n    }\n    if (islive) {\n      stats.putCounter.increment();\n    } else {\n      stats.nonLivePutCounter.increment();\n    }\n\n    // Check if we need to clear out old entries from the cache.\n    // isCleaning variable is checked instead of markAndSweepLock.isLocked()\n    // for performance because every put invocation will check until\n    // the size is back to an acceptable level.\n    //\n    // There is a race between the check and the call to markAndSweep, but\n    // it's unimportant because markAndSweep actually acquires the lock or returns if it can't.\n    //\n    // Thread safety note: isCleaning read is piggybacked (comes after) other volatile reads\n    // in this method.\n    if ((currentSize > upperWaterMark || ramBytes.get() > ramUpperWatermark) && !isCleaning) {\n      if (newThreadForCleanup) {\n        new Thread(this::markAndSweep).start();\n      } else if (cleanupThread != null){\n        cleanupThread.wakeThread();\n      } else {\n        markAndSweep();\n      }\n    }\n    return oldCacheEntry == null ? null : oldCacheEntry.value;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"cf0b1b21012d341c80a1f3975cf88823f0fe95a9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["cf0b1b21012d341c80a1f3975cf88823f0fe95a9"],"ca83400a04ed1cbfa09560d2e7184f93f5d75363":["310f3f20b324aca4933c1fc4261b19bfe3bc3322"],"21019aa828c8c9b0153877543a8b3f200bf2ca19":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","7c5044c9bb1518e7a13c1c5385a21325ae343056"],"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83":["a71ca10e7131e1f01868c80d228f26a855e79dd0"],"a71ca10e7131e1f01868c80d228f26a855e79dd0":["7c5044c9bb1518e7a13c1c5385a21325ae343056"],"bc0fbfa191179ae7a0081ee1cf7da0464bcd8078":["cc69baf14413994ccde897681e5ce1d393cf7156"],"cc69baf14413994ccde897681e5ce1d393cf7156":["ca83400a04ed1cbfa09560d2e7184f93f5d75363"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["ca83400a04ed1cbfa09560d2e7184f93f5d75363","bc0fbfa191179ae7a0081ee1cf7da0464bcd8078"],"7c5044c9bb1518e7a13c1c5385a21325ae343056":["bc0fbfa191179ae7a0081ee1cf7da0464bcd8078"],"310f3f20b324aca4933c1fc4261b19bfe3bc3322":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["cc69baf14413994ccde897681e5ce1d393cf7156","bc0fbfa191179ae7a0081ee1cf7da0464bcd8078"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83"]},"commit2Childs":{"cf0b1b21012d341c80a1f3975cf88823f0fe95a9":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["310f3f20b324aca4933c1fc4261b19bfe3bc3322"],"ca83400a04ed1cbfa09560d2e7184f93f5d75363":["cc69baf14413994ccde897681e5ce1d393cf7156","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"21019aa828c8c9b0153877543a8b3f200bf2ca19":[],"fbd58791ecf2b92d8917c2f4aab0e50965ec6a83":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a71ca10e7131e1f01868c80d228f26a855e79dd0":["fbd58791ecf2b92d8917c2f4aab0e50965ec6a83"],"bc0fbfa191179ae7a0081ee1cf7da0464bcd8078":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","7c5044c9bb1518e7a13c1c5385a21325ae343056","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"cc69baf14413994ccde897681e5ce1d393cf7156":["bc0fbfa191179ae7a0081ee1cf7da0464bcd8078","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["21019aa828c8c9b0153877543a8b3f200bf2ca19"],"7c5044c9bb1518e7a13c1c5385a21325ae343056":["21019aa828c8c9b0153877543a8b3f200bf2ca19","a71ca10e7131e1f01868c80d228f26a855e79dd0"],"310f3f20b324aca4933c1fc4261b19bfe3bc3322":["ca83400a04ed1cbfa09560d2e7184f93f5d75363"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cf0b1b21012d341c80a1f3975cf88823f0fe95a9"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["21019aa828c8c9b0153877543a8b3f200bf2ca19","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}