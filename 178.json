{"path":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","pathOld":"modules/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","sourceNew":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","sourceOld":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b07bc5b253e2373a655fc734d650af4ac46c8614","date":1386093923,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","sourceNew":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(new StringReader(input), new DefaultICUTokenizerConfig(false));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","sourceOld":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","sourceNew":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(new StringReader(input), new DefaultICUTokenizerConfig(false));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","sourceOld":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","sourceNew":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(new DefaultICUTokenizerConfig(false));\n    tokenizer.setReader(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","sourceOld":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(new StringReader(input), new DefaultICUTokenizerConfig(false));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75","date":1399205975,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","sourceNew":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(newAttributeFactory(), new DefaultICUTokenizerConfig(false));\n    tokenizer.setReader(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","sourceOld":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(new DefaultICUTokenizerConfig(false));\n    tokenizer.setReader(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","bugFix":null,"bugIntro":["b34acf30a377e146cfc8f7da3ec9a01e944403e1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b34acf30a377e146cfc8f7da3ec9a01e944403e1","date":1469718024,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","sourceNew":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(newAttributeFactory(), new DefaultICUTokenizerConfig(false, true));\n    tokenizer.setReader(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","sourceOld":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(newAttributeFactory(), new DefaultICUTokenizerConfig(false));\n    tokenizer.setReader(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","bugFix":["923f36bb0db6f793cf62dbb68723ae3bfbaf1d75"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","sourceNew":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(newAttributeFactory(), new DefaultICUTokenizerConfig(false, true));\n    tokenizer.setReader(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","sourceOld":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(newAttributeFactory(), new DefaultICUTokenizerConfig(false));\n    tokenizer.setReader(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","pathOld":"lucene/analysis/icu/src/test/org/apache/lucene/analysis/icu/segmentation/TestICUTokenizer#testHugeDoc().mjava","sourceNew":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(newAttributeFactory(), new DefaultICUTokenizerConfig(false, true));\n    tokenizer.setReader(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","sourceOld":"  public void testHugeDoc() throws IOException {\n    StringBuilder sb = new StringBuilder();\n    char whitespace[] = new char[4094];\n    Arrays.fill(whitespace, ' ');\n    sb.append(whitespace);\n    sb.append(\"testing 1234\");\n    String input = sb.toString();\n    ICUTokenizer tokenizer = new ICUTokenizer(newAttributeFactory(), new DefaultICUTokenizerConfig(false));\n    tokenizer.setReader(new StringReader(input));\n    assertTokenStreamContents(tokenizer, new String[] { \"testing\", \"1234\" });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b34acf30a377e146cfc8f7da3ec9a01e944403e1":["923f36bb0db6f793cf62dbb68723ae3bfbaf1d75"],"b07bc5b253e2373a655fc734d650af4ac46c8614":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["b07bc5b253e2373a655fc734d650af4ac46c8614"],"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["b89678825b68eccaf09e6ab71675fc0b0af1e099","b07bc5b253e2373a655fc734d650af4ac46c8614"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["923f36bb0db6f793cf62dbb68723ae3bfbaf1d75","b34acf30a377e146cfc8f7da3ec9a01e944403e1"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["923f36bb0db6f793cf62dbb68723ae3bfbaf1d75","b34acf30a377e146cfc8f7da3ec9a01e944403e1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b34acf30a377e146cfc8f7da3ec9a01e944403e1"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["b07bc5b253e2373a655fc734d650af4ac46c8614","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"b34acf30a377e146cfc8f7da3ec9a01e944403e1":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b07bc5b253e2373a655fc734d650af4ac46c8614":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["923f36bb0db6f793cf62dbb68723ae3bfbaf1d75"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"923f36bb0db6f793cf62dbb68723ae3bfbaf1d75":["b34acf30a377e146cfc8f7da3ec9a01e944403e1","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}