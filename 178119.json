{"path":"lucene/backwards/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/backwards/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"backwards/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final TermAttribute termAtt = addAttribute(TermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator tokens = Arrays.asList(new String[]{\"a\",\"b\",\"c\"}).iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!tokens.hasNext()) return false;\n        clearAttributes();\n        termAtt.setTermBuffer((String) tokens.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final TermAttribute termAtt = addAttribute(TermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator tokens = Arrays.asList(new String[]{\"a\",\"b\",\"c\"}).iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!tokens.hasNext()) return false;\n        clearAttributes();\n        termAtt.setTermBuffer((String) tokens.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6","date":1272983566,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backwards/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":null,"sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final TermAttribute termAtt = addAttribute(TermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n      \n      final Iterator tokens = Arrays.asList(new String[]{\"a\",\"b\",\"c\"}).iterator();\n      boolean first = true;\n      \n      @Override\n      public boolean incrementToken() {\n        if (!tokens.hasNext()) return false;\n        clearAttributes();\n        termAtt.setTermBuffer((String) tokens.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    MockRAMDirectory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    Document doc = new Document();\n    doc.add(new Field(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexSearcher s = new IndexSearcher(dir, false);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    TermPositions tps = s.getIndexReader().termPositions(new Term(\"field\", \"a\"));\n    assertTrue(tps.next());\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    assertTrue(_TestUtil.checkIndex(dir));\n    s.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["90eca6fcb6635ca73ea4fdbe2f57d2033b66d3b6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}