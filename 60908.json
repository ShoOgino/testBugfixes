{"path":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","commits":[{"id":"44fcbde6fb2ac44ee3b45e013e54a42911e689ff","date":1292065621,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"/dev/null","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false, false);\n    assertTrue(writer.bufferedDeletes.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["631ea3d1607299c59f33edef140ffc19a81f07a0"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad1eb108f4291bd5b4672bac446eb48bf97d321f","date":1292343856,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false, false);\n    assertTrue(writer.bufferedDeletes.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false, false);\n    assertTrue(writer.bufferedDeletes.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletes.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false, false);\n    assertTrue(writer.bufferedDeletes.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"/dev/null","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletes.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"/dev/null","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletes.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"14975dba6846360ff627c6797726fa4899a3413d","date":1295174738,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletes.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, true);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletes.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c19f985e36a65cc969e8e564fe337a0d41512075","date":1296330536,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletes.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletes.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, true);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletes.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletes.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, true);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, true);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, true);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5f411c79281946a184efeab34a673deffc25edcb","date":1303995312,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, true);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, true);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fcef5771aee556e6c886946095ae4485a392526b","date":1304005192,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, true);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"786a4d25ca958a1f315a9d6a74f0441fdafcd522","date":1305734256,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT,\n        new MockAnalyzer());\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    \n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n    \n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means \n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n    \n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n    \n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n    \n    assertEquals(2, writer.segmentInfos.size());\n    \n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n    \n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n    \n    Term id3 = new Term(\"id\", Integer.toString(3));\n    \n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n    \n    assertTrue(writer.numRamDocs() > 0);\n    \n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n    \n    SegmentInfo info0 = writer.segmentInfos.get(0);\n    SegmentInfo info1 = writer.segmentInfos.get(1);\n    \n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n    \n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n    \n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n    \n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n    \n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n    \n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getLiveDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getLiveDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getLiveDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getDeletedDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"00743482822ec0841b0344a37944b666e6a0228d","date":1313588663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getLiveDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getLiveDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getLiveDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    writer.setInfoStream(VERBOSE ? System.out : null);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getLiveDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerSegmentDeletes#testDeletes1().mjava","sourceNew":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getLiveDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletes1() throws Exception {\n    //IndexWriter.debug2 = System.out;\n    Directory dir = new MockDirectoryWrapper(new Random(random.nextLong()), new RAMDirectory());\n    IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random));\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    iwc.setMaxBufferedDocs(5000);\n    iwc.setRAMBufferSizeMB(100);\n    RangeMergePolicy fsmp = new RangeMergePolicy(false);\n    iwc.setMergePolicy(fsmp);\n    IndexWriter writer = new IndexWriter(dir, iwc);\n    for (int x = 0; x < 5; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"1\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit1\");\n    writer.commit();\n    assertEquals(1, writer.segmentInfos.size());\n    for (int x = 5; x < 10; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"2\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    //System.out.println(\"commit2\");\n    writer.commit();\n    assertEquals(2, writer.segmentInfos.size());\n\n    for (int x = 10; x < 15; x++) {\n      writer.addDocument(DocHelper.createDocument(x, \"3\", 2));\n      //System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    writer.deleteDocuments(new Term(\"id\", \"11\"));\n\n    // flushing without applying deletes means\n    // there will still be deletes in the segment infos\n    writer.flush(false, false);\n    assertTrue(writer.bufferedDeletesStream.any());\n\n    // get reader flushes pending deletes\n    // so there should not be anymore\n    IndexReader r1 = writer.getReader();\n    assertFalse(writer.bufferedDeletesStream.any());\n    r1.close();\n\n    // delete id:2 from the first segment\n    // merge segments 0 and 1\n    // which should apply the delete id:2\n    writer.deleteDocuments(new Term(\"id\", \"2\"));\n    writer.flush(false, false);\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    writer.maybeMerge();\n\n    assertEquals(2, writer.segmentInfos.size());\n\n    // id:2 shouldn't exist anymore because\n    // it's been applied in the merge and now it's gone\n    IndexReader r2 = writer.getReader();\n    int[] id2docs = toDocsArray(new Term(\"id\", \"2\"), null, r2);\n    assertTrue(id2docs == null);\n    r2.close();\n\n    /**\n    // added docs are in the ram buffer\n    for (int x = 15; x < 20; x++) {\n      writer.addDocument(TestIndexWriterReader.createDocument(x, \"4\", 2));\n      System.out.println(\"numRamDocs(\" + x + \")\" + writer.numRamDocs());\n    }\n    assertTrue(writer.numRamDocs() > 0);\n    // delete from the ram buffer\n    writer.deleteDocuments(new Term(\"id\", Integer.toString(13)));\n\n    Term id3 = new Term(\"id\", Integer.toString(3));\n\n    // delete from the 1st segment\n    writer.deleteDocuments(id3);\n\n    assertTrue(writer.numRamDocs() > 0);\n\n    //System.out\n    //    .println(\"segdels1:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    // we cause a merge to happen\n    fsmp.doMerge = true;\n    fsmp.start = 0;\n    fsmp.length = 2;\n    System.out.println(\"maybeMerge \"+writer.segmentInfos);\n\n    SegmentInfo info0 = writer.segmentInfos.info(0);\n    SegmentInfo info1 = writer.segmentInfos.info(1);\n\n    writer.maybeMerge();\n    System.out.println(\"maybeMerge after \"+writer.segmentInfos);\n    // there should be docs in RAM\n    assertTrue(writer.numRamDocs() > 0);\n\n    // assert we've merged the 1 and 2 segments\n    // and still have a segment leftover == 2\n    assertEquals(2, writer.segmentInfos.size());\n    assertFalse(segThere(info0, writer.segmentInfos));\n    assertFalse(segThere(info1, writer.segmentInfos));\n\n    //System.out.println(\"segdels2:\" + writer.docWriter.deletesToString());\n\n    //assertTrue(writer.docWriter.segmentDeletes.size() > 0);\n\n    IndexReader r = writer.getReader();\n    IndexReader r1 = r.getSequentialSubReaders()[0];\n    printDelDocs(r1.getLiveDocs());\n    int[] docs = toDocsArray(id3, null, r);\n    System.out.println(\"id3 docs:\"+Arrays.toString(docs));\n    // there shouldn't be any docs for id:3\n    assertTrue(docs == null);\n    r.close();\n\n    part2(writer, fsmp);\n    **/\n    // System.out.println(\"segdels2:\"+writer.docWriter.segmentDeletes.toString());\n    //System.out.println(\"close\");\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"ad1eb108f4291bd5b4672bac446eb48bf97d321f":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["06584e6e98d592b34e1329b384182f368d2025e8"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["786a4d25ca958a1f315a9d6a74f0441fdafcd522"],"00743482822ec0841b0344a37944b666e6a0228d":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"fcef5771aee556e6c886946095ae4485a392526b":["5f411c79281946a184efeab34a673deffc25edcb"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"c19f985e36a65cc969e8e564fe337a0d41512075":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["c19f985e36a65cc969e8e564fe337a0d41512075"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","c19f985e36a65cc969e8e564fe337a0d41512075"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["ad1eb108f4291bd5b4672bac446eb48bf97d321f"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["14975dba6846360ff627c6797726fa4899a3413d","c19f985e36a65cc969e8e564fe337a0d41512075"],"5f411c79281946a184efeab34a673deffc25edcb":["962d04139994fce5193143ef35615499a9a96d78"],"06584e6e98d592b34e1329b384182f368d2025e8":["00743482822ec0841b0344a37944b666e6a0228d"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["f2c5f0cb44df114db4228c8f77861714b5cabaea","fcef5771aee556e6c886946095ae4485a392526b"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["786a4d25ca958a1f315a9d6a74f0441fdafcd522","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["a3776dccca01c11e7046323cfad46a3b4a471233","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"786a4d25ca958a1f315a9d6a74f0441fdafcd522":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["135621f3a0670a9394eb563224a3b76cc4dddc0f","786a4d25ca958a1f315a9d6a74f0441fdafcd522"],"a3776dccca01c11e7046323cfad46a3b4a471233":["c19f985e36a65cc969e8e564fe337a0d41512075","786a4d25ca958a1f315a9d6a74f0441fdafcd522"],"14975dba6846360ff627c6797726fa4899a3413d":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"ad1eb108f4291bd5b4672bac446eb48bf97d321f":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["ad1eb108f4291bd5b4672bac446eb48bf97d321f"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["00743482822ec0841b0344a37944b666e6a0228d","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"00743482822ec0841b0344a37944b666e6a0228d":["06584e6e98d592b34e1329b384182f368d2025e8"],"fcef5771aee556e6c886946095ae4485a392526b":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["14975dba6846360ff627c6797726fa4899a3413d"],"c19f985e36a65cc969e8e564fe337a0d41512075":["f2c5f0cb44df114db4228c8f77861714b5cabaea","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","a3776dccca01c11e7046323cfad46a3b4a471233"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["b3e06be49006ecac364d39d12b9c9f74882f9b9f","962d04139994fce5193143ef35615499a9a96d78"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","c19f985e36a65cc969e8e564fe337a0d41512075","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"5f411c79281946a184efeab34a673deffc25edcb":["fcef5771aee556e6c886946095ae4485a392526b"],"06584e6e98d592b34e1329b384182f368d2025e8":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["c3a8a449466c1ff7ce2274fe73dab487256964b4"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["135621f3a0670a9394eb563224a3b76cc4dddc0f","786a4d25ca958a1f315a9d6a74f0441fdafcd522"],"962d04139994fce5193143ef35615499a9a96d78":["5f411c79281946a184efeab34a673deffc25edcb"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"786a4d25ca958a1f315a9d6a74f0441fdafcd522":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","d083e83f225b11e5fdd900e83d26ddb385b6955c","c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":[],"a3776dccca01c11e7046323cfad46a3b4a471233":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"14975dba6846360ff627c6797726fa4899a3413d":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","c3a8a449466c1ff7ce2274fe73dab487256964b4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}