{"path":"lucene/src/test-framework/java/org/apache/lucene/index/codecs/mockrandom/MockRandomPostingsFormat#fieldsProducer(SegmentReadState).mjava","commits":[{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/index/codecs/mockrandom/MockRandomPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/index/codecs/mockrandom/MockRandomCodec#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n\n    final String seedFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, SEED_EXT);\n    final IndexInput in = state.dir.openInput(seedFileName, state.context);\n    final long seed = in.readLong();\n    if (LuceneTestCase.VERBOSE) {\n      System.out.println(\"MockRandomCodec: reading from seg=\" + state.segmentInfo.name + \" formatID=\" + state.segmentSuffix + \" seed=\" + seed);\n    }\n    in.close();\n\n    final Random random = new Random(seed);\n    \n    int readBufferSize = _TestUtil.nextInt(random, 1, 4096);\n    if (LuceneTestCase.VERBOSE) {\n      System.out.println(\"MockRandomCodec: readBufferSize=\" + readBufferSize);\n    }\n\n    PostingsReaderBase postingsReader;\n\n    if (random.nextBoolean()) {\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Sep postings\");\n      }\n      postingsReader = new SepPostingsReader(state.dir, state.segmentInfo,\n                                             state.context, new MockIntStreamFactory(random), state.segmentSuffix);\n    } else {\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Standard postings\");\n      }\n      postingsReader = new Lucene40PostingsReader(state.dir, state.segmentInfo, state.context, state.segmentSuffix);\n    }\n\n    if (random.nextBoolean()) {\n      final int totTFCutoff = _TestUtil.nextInt(random, 1, 20);\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading pulsing postings with totTFCutoff=\" + totTFCutoff);\n      }\n      postingsReader = new PulsingPostingsReader(postingsReader);\n    }\n\n    final FieldsProducer fields;\n\n    if (random.nextBoolean()) {\n      // Use BlockTree terms dict\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading BlockTree terms dict\");\n      }\n\n      boolean success = false;\n      try {\n        fields = new BlockTreeTermsReader(state.dir,\n                                          state.fieldInfos,\n                                          state.segmentInfo.name,\n                                          postingsReader,\n                                          state.context,\n                                          state.segmentSuffix,\n                                          state.termsIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          postingsReader.close();\n        }\n      }\n    } else {\n\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Block terms dict\");\n      }\n      final TermsIndexReaderBase indexReader;\n      boolean success = false;\n      try {\n        final boolean doFixedGap = random.nextBoolean();\n\n        // randomness diverges from writer, here:\n        if (state.termsIndexDivisor != -1) {\n          state.termsIndexDivisor = _TestUtil.nextInt(random, 1, 10);\n        }\n\n        if (doFixedGap) {\n          // if termsIndexDivisor is set to -1, we should not touch it. It means a\n          // test explicitly instructed not to load the terms index.\n          if (LuceneTestCase.VERBOSE) {\n            System.out.println(\"MockRandomCodec: fixed-gap terms index (divisor=\" + state.termsIndexDivisor + \")\");\n          }\n          indexReader = new FixedGapTermsIndexReader(state.dir,\n                                                     state.fieldInfos,\n                                                     state.segmentInfo.name,\n                                                     state.termsIndexDivisor,\n                                                     BytesRef.getUTF8SortedAsUnicodeComparator(),\n                                                     state.segmentSuffix, state.context);\n        } else {\n          final int n2 = random.nextInt(3);\n          if (n2 == 1) {\n            random.nextInt();\n          } else if (n2 == 2) {\n            random.nextLong();\n          }\n          if (LuceneTestCase.VERBOSE) {\n            System.out.println(\"MockRandomCodec: variable-gap terms index (divisor=\" + state.termsIndexDivisor + \")\");\n          }\n          indexReader = new VariableGapTermsIndexReader(state.dir,\n                                                        state.fieldInfos,\n                                                        state.segmentInfo.name,\n                                                        state.termsIndexDivisor,\n                                                        state.segmentSuffix, state.context);\n\n        }\n\n        success = true;\n      } finally {\n        if (!success) {\n          postingsReader.close();\n        }\n      }\n\n      final int termsCacheSize = _TestUtil.nextInt(random, 1, 1024);\n\n      success = false;\n      try {\n        fields = new BlockTermsReader(indexReader,\n                                      state.dir,\n                                      state.fieldInfos,\n                                      state.segmentInfo.name,\n                                      postingsReader,\n                                      state.context,\n                                      termsCacheSize,\n                                      state.segmentSuffix);\n        success = true;\n      } finally {\n        if (!success) {\n          try {\n            postingsReader.close();\n          } finally {\n            indexReader.close();\n          }\n        }\n      }\n    }\n\n    return fields;\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n\n    final String seedFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.codecId, SEED_EXT);\n    final IndexInput in = state.dir.openInput(seedFileName, state.context);\n    final long seed = in.readLong();\n    if (LuceneTestCase.VERBOSE) {\n      System.out.println(\"MockRandomCodec: reading from seg=\" + state.segmentInfo.name + \" codecID=\" + state.codecId + \" seed=\" + seed);\n    }\n    in.close();\n\n    final Random random = new Random(seed);\n    \n    int readBufferSize = _TestUtil.nextInt(random, 1, 4096);\n    if (LuceneTestCase.VERBOSE) {\n      System.out.println(\"MockRandomCodec: readBufferSize=\" + readBufferSize);\n    }\n\n    PostingsReaderBase postingsReader;\n\n    if (random.nextBoolean()) {\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Sep postings\");\n      }\n      postingsReader = new SepPostingsReader(state.dir, state.segmentInfo,\n                                             state.context, new MockIntStreamFactory(random), state.codecId);\n    } else {\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Standard postings\");\n      }\n      postingsReader = new StandardPostingsReader(state.dir, state.segmentInfo, state.context, state.codecId);\n    }\n\n    if (random.nextBoolean()) {\n      final int totTFCutoff = _TestUtil.nextInt(random, 1, 20);\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading pulsing postings with totTFCutoff=\" + totTFCutoff);\n      }\n      postingsReader = new PulsingPostingsReader(postingsReader);\n    }\n\n    final FieldsProducer fields;\n\n    if (random.nextBoolean()) {\n      // Use BlockTree terms dict\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading BlockTree terms dict\");\n      }\n\n      boolean success = false;\n      try {\n        fields = new BlockTreeTermsReader(state.dir,\n                                          state.fieldInfos,\n                                          state.segmentInfo.name,\n                                          postingsReader,\n                                          state.context,\n                                          state.codecId,\n                                          state.termsIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          postingsReader.close();\n        }\n      }\n    } else {\n\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Block terms dict\");\n      }\n      final TermsIndexReaderBase indexReader;\n      boolean success = false;\n      try {\n        final boolean doFixedGap = random.nextBoolean();\n\n        // randomness diverges from writer, here:\n        if (state.termsIndexDivisor != -1) {\n          state.termsIndexDivisor = _TestUtil.nextInt(random, 1, 10);\n        }\n\n        if (doFixedGap) {\n          // if termsIndexDivisor is set to -1, we should not touch it. It means a\n          // test explicitly instructed not to load the terms index.\n          if (LuceneTestCase.VERBOSE) {\n            System.out.println(\"MockRandomCodec: fixed-gap terms index (divisor=\" + state.termsIndexDivisor + \")\");\n          }\n          indexReader = new FixedGapTermsIndexReader(state.dir,\n                                                     state.fieldInfos,\n                                                     state.segmentInfo.name,\n                                                     state.termsIndexDivisor,\n                                                     BytesRef.getUTF8SortedAsUnicodeComparator(),\n                                                     state.codecId, state.context);\n        } else {\n          final int n2 = random.nextInt(3);\n          if (n2 == 1) {\n            random.nextInt();\n          } else if (n2 == 2) {\n            random.nextLong();\n          }\n          if (LuceneTestCase.VERBOSE) {\n            System.out.println(\"MockRandomCodec: variable-gap terms index (divisor=\" + state.termsIndexDivisor + \")\");\n          }\n          indexReader = new VariableGapTermsIndexReader(state.dir,\n                                                        state.fieldInfos,\n                                                        state.segmentInfo.name,\n                                                        state.termsIndexDivisor,\n                                                        state.codecId, state.context);\n\n        }\n\n        success = true;\n      } finally {\n        if (!success) {\n          postingsReader.close();\n        }\n      }\n\n      final int termsCacheSize = _TestUtil.nextInt(random, 1, 1024);\n\n      success = false;\n      try {\n        fields = new BlockTermsReader(indexReader,\n                                      state.dir,\n                                      state.fieldInfos,\n                                      state.segmentInfo.name,\n                                      postingsReader,\n                                      state.context,\n                                      termsCacheSize,\n                                      state.codecId);\n        success = true;\n      } finally {\n        if (!success) {\n          try {\n            postingsReader.close();\n          } finally {\n            indexReader.close();\n          }\n        }\n      }\n    }\n\n    return fields;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/codecs/mockrandom/MockRandomPostingsFormat#fieldsProducer(SegmentReadState).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/index/codecs/mockrandom/MockRandomPostingsFormat#fieldsProducer(SegmentReadState).mjava","sourceNew":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n\n    final String seedFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, SEED_EXT);\n    final IndexInput in = state.dir.openInput(seedFileName, state.context);\n    final long seed = in.readLong();\n    if (LuceneTestCase.VERBOSE) {\n      System.out.println(\"MockRandomCodec: reading from seg=\" + state.segmentInfo.name + \" formatID=\" + state.segmentSuffix + \" seed=\" + seed);\n    }\n    in.close();\n\n    final Random random = new Random(seed);\n    \n    int readBufferSize = _TestUtil.nextInt(random, 1, 4096);\n    if (LuceneTestCase.VERBOSE) {\n      System.out.println(\"MockRandomCodec: readBufferSize=\" + readBufferSize);\n    }\n\n    PostingsReaderBase postingsReader;\n\n    if (random.nextBoolean()) {\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Sep postings\");\n      }\n      postingsReader = new SepPostingsReader(state.dir, state.segmentInfo,\n                                             state.context, new MockIntStreamFactory(random), state.segmentSuffix);\n    } else {\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Standard postings\");\n      }\n      postingsReader = new Lucene40PostingsReader(state.dir, state.segmentInfo, state.context, state.segmentSuffix);\n    }\n\n    if (random.nextBoolean()) {\n      final int totTFCutoff = _TestUtil.nextInt(random, 1, 20);\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading pulsing postings with totTFCutoff=\" + totTFCutoff);\n      }\n      postingsReader = new PulsingPostingsReader(postingsReader);\n    }\n\n    final FieldsProducer fields;\n\n    if (random.nextBoolean()) {\n      // Use BlockTree terms dict\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading BlockTree terms dict\");\n      }\n\n      boolean success = false;\n      try {\n        fields = new BlockTreeTermsReader(state.dir,\n                                          state.fieldInfos,\n                                          state.segmentInfo.name,\n                                          postingsReader,\n                                          state.context,\n                                          state.segmentSuffix,\n                                          state.termsIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          postingsReader.close();\n        }\n      }\n    } else {\n\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Block terms dict\");\n      }\n      final TermsIndexReaderBase indexReader;\n      boolean success = false;\n      try {\n        final boolean doFixedGap = random.nextBoolean();\n\n        // randomness diverges from writer, here:\n        if (state.termsIndexDivisor != -1) {\n          state.termsIndexDivisor = _TestUtil.nextInt(random, 1, 10);\n        }\n\n        if (doFixedGap) {\n          // if termsIndexDivisor is set to -1, we should not touch it. It means a\n          // test explicitly instructed not to load the terms index.\n          if (LuceneTestCase.VERBOSE) {\n            System.out.println(\"MockRandomCodec: fixed-gap terms index (divisor=\" + state.termsIndexDivisor + \")\");\n          }\n          indexReader = new FixedGapTermsIndexReader(state.dir,\n                                                     state.fieldInfos,\n                                                     state.segmentInfo.name,\n                                                     state.termsIndexDivisor,\n                                                     BytesRef.getUTF8SortedAsUnicodeComparator(),\n                                                     state.segmentSuffix, state.context);\n        } else {\n          final int n2 = random.nextInt(3);\n          if (n2 == 1) {\n            random.nextInt();\n          } else if (n2 == 2) {\n            random.nextLong();\n          }\n          if (LuceneTestCase.VERBOSE) {\n            System.out.println(\"MockRandomCodec: variable-gap terms index (divisor=\" + state.termsIndexDivisor + \")\");\n          }\n          indexReader = new VariableGapTermsIndexReader(state.dir,\n                                                        state.fieldInfos,\n                                                        state.segmentInfo.name,\n                                                        state.termsIndexDivisor,\n                                                        state.segmentSuffix, state.context);\n\n        }\n\n        success = true;\n      } finally {\n        if (!success) {\n          postingsReader.close();\n        }\n      }\n\n      final int termsCacheSize = _TestUtil.nextInt(random, 1, 1024);\n\n      success = false;\n      try {\n        fields = new BlockTermsReader(indexReader,\n                                      state.dir,\n                                      state.fieldInfos,\n                                      state.segmentInfo.name,\n                                      postingsReader,\n                                      state.context,\n                                      termsCacheSize,\n                                      state.segmentSuffix);\n        success = true;\n      } finally {\n        if (!success) {\n          try {\n            postingsReader.close();\n          } finally {\n            indexReader.close();\n          }\n        }\n      }\n    }\n\n    return fields;\n  }\n\n","sourceOld":"  @Override\n  public FieldsProducer fieldsProducer(SegmentReadState state) throws IOException {\n\n    final String seedFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, SEED_EXT);\n    final IndexInput in = state.dir.openInput(seedFileName, state.context);\n    final long seed = in.readLong();\n    if (LuceneTestCase.VERBOSE) {\n      System.out.println(\"MockRandomCodec: reading from seg=\" + state.segmentInfo.name + \" formatID=\" + state.segmentSuffix + \" seed=\" + seed);\n    }\n    in.close();\n\n    final Random random = new Random(seed);\n    \n    int readBufferSize = _TestUtil.nextInt(random, 1, 4096);\n    if (LuceneTestCase.VERBOSE) {\n      System.out.println(\"MockRandomCodec: readBufferSize=\" + readBufferSize);\n    }\n\n    PostingsReaderBase postingsReader;\n\n    if (random.nextBoolean()) {\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Sep postings\");\n      }\n      postingsReader = new SepPostingsReader(state.dir, state.segmentInfo,\n                                             state.context, new MockIntStreamFactory(random), state.segmentSuffix);\n    } else {\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Standard postings\");\n      }\n      postingsReader = new Lucene40PostingsReader(state.dir, state.segmentInfo, state.context, state.segmentSuffix);\n    }\n\n    if (random.nextBoolean()) {\n      final int totTFCutoff = _TestUtil.nextInt(random, 1, 20);\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading pulsing postings with totTFCutoff=\" + totTFCutoff);\n      }\n      postingsReader = new PulsingPostingsReader(postingsReader);\n    }\n\n    final FieldsProducer fields;\n\n    if (random.nextBoolean()) {\n      // Use BlockTree terms dict\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading BlockTree terms dict\");\n      }\n\n      boolean success = false;\n      try {\n        fields = new BlockTreeTermsReader(state.dir,\n                                          state.fieldInfos,\n                                          state.segmentInfo.name,\n                                          postingsReader,\n                                          state.context,\n                                          state.segmentSuffix,\n                                          state.termsIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          postingsReader.close();\n        }\n      }\n    } else {\n\n      if (LuceneTestCase.VERBOSE) {\n        System.out.println(\"MockRandomCodec: reading Block terms dict\");\n      }\n      final TermsIndexReaderBase indexReader;\n      boolean success = false;\n      try {\n        final boolean doFixedGap = random.nextBoolean();\n\n        // randomness diverges from writer, here:\n        if (state.termsIndexDivisor != -1) {\n          state.termsIndexDivisor = _TestUtil.nextInt(random, 1, 10);\n        }\n\n        if (doFixedGap) {\n          // if termsIndexDivisor is set to -1, we should not touch it. It means a\n          // test explicitly instructed not to load the terms index.\n          if (LuceneTestCase.VERBOSE) {\n            System.out.println(\"MockRandomCodec: fixed-gap terms index (divisor=\" + state.termsIndexDivisor + \")\");\n          }\n          indexReader = new FixedGapTermsIndexReader(state.dir,\n                                                     state.fieldInfos,\n                                                     state.segmentInfo.name,\n                                                     state.termsIndexDivisor,\n                                                     BytesRef.getUTF8SortedAsUnicodeComparator(),\n                                                     state.segmentSuffix, state.context);\n        } else {\n          final int n2 = random.nextInt(3);\n          if (n2 == 1) {\n            random.nextInt();\n          } else if (n2 == 2) {\n            random.nextLong();\n          }\n          if (LuceneTestCase.VERBOSE) {\n            System.out.println(\"MockRandomCodec: variable-gap terms index (divisor=\" + state.termsIndexDivisor + \")\");\n          }\n          indexReader = new VariableGapTermsIndexReader(state.dir,\n                                                        state.fieldInfos,\n                                                        state.segmentInfo.name,\n                                                        state.termsIndexDivisor,\n                                                        state.segmentSuffix, state.context);\n\n        }\n\n        success = true;\n      } finally {\n        if (!success) {\n          postingsReader.close();\n        }\n      }\n\n      final int termsCacheSize = _TestUtil.nextInt(random, 1, 1024);\n\n      success = false;\n      try {\n        fields = new BlockTermsReader(indexReader,\n                                      state.dir,\n                                      state.fieldInfos,\n                                      state.segmentInfo.name,\n                                      postingsReader,\n                                      state.context,\n                                      termsCacheSize,\n                                      state.segmentSuffix);\n        success = true;\n      } finally {\n        if (!success) {\n          try {\n            postingsReader.close();\n          } finally {\n            indexReader.close();\n          }\n        }\n      }\n    }\n\n    return fields;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["7b91922b55d15444d554721b352861d028eb8278"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7b91922b55d15444d554721b352861d028eb8278"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}