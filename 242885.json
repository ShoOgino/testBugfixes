{"path":"backwards/src/test/org/apache/lucene/search/TestPositionIncrement#testSetPosition().mjava","commits":[{"id":"480d01e5b0ef8efb136d51670fec297ae5ae2c9c","date":1268821447,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"backwards/src/test/org/apache/lucene/search/TestPositionIncrement#testSetPosition().mjava","pathOld":"/dev/null","sourceNew":"  public void testSetPosition() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new TokenStream() {\n          private final String[] TOKENS = {\"1\", \"2\", \"3\", \"4\", \"5\"};\n          private final int[] INCREMENTS = {0, 2, 1, 0, 1};\n          private int i = 0;\n\n          PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          TermAttribute termAtt = addAttribute(TermAttribute.class);\n          OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          \n          @Override\n          public boolean incrementToken() {\n            if (i == TOKENS.length)\n              return false;\n            termAtt.setTermBuffer(TOKENS[i]);\n            offsetAtt.setOffset(i,i);\n            posIncrAtt.setPositionIncrement(INCREMENTS[i]);\n            i++;\n            return true;\n          }\n        };\n      }\n    };\n    Directory store = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(store, analyzer, true,\n                                         IndexWriter.MaxFieldLength.LIMITED);\n    Document d = new Document();\n    d.add(new Field(\"field\", \"bogus\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(d);\n    writer.optimize();\n    writer.close();\n    \n\n    IndexSearcher searcher = new IndexSearcher(store, true);\n    \n    TermPositions pos = searcher.getIndexReader().termPositions(new Term(\"field\", \"1\"));\n    pos.next();\n    // first token should be at position 0\n    assertEquals(0, pos.nextPosition());\n    \n    pos = searcher.getIndexReader().termPositions(new Term(\"field\", \"2\"));\n    pos.next();\n    // second token should be at position 2\n    assertEquals(2, pos.nextPosition());\n    \n    PhraseQuery q;\n    ScoreDoc[] hits;\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"1\"));\n    q.add(new Term(\"field\", \"2\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // same as previous, just specify positions explicitely.\n    q = new PhraseQuery(); \n    q.add(new Term(\"field\", \"1\"),0);\n    q.add(new Term(\"field\", \"2\"),1);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // specifying correct positions should find the phrase.\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"1\"),0);\n    q.add(new Term(\"field\", \"2\"),2);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"2\"));\n    q.add(new Term(\"field\", \"3\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"));\n    q.add(new Term(\"field\", \"4\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // phrase query would find it when correct positions are specified. \n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"),0);\n    q.add(new Term(\"field\", \"4\"),0);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    // phrase query should fail for non existing searched term \n    // even if there exist another searched terms in the same searched position. \n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"),0);\n    q.add(new Term(\"field\", \"9\"),0);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // multi-phrase query should succed for non existing searched term\n    // because there exist another searched terms in the same searched position. \n    MultiPhraseQuery mq = new MultiPhraseQuery();\n    mq.add(new Term[]{new Term(\"field\", \"3\"),new Term(\"field\", \"9\")},0);\n    hits = searcher.search(mq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"2\"));\n    q.add(new Term(\"field\", \"4\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"));\n    q.add(new Term(\"field\", \"5\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"4\"));\n    q.add(new Term(\"field\", \"5\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"2\"));\n    q.add(new Term(\"field\", \"5\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // should not find \"1 2\" because there is a gap of 1 in the index\n    QueryParser qp = new QueryParser(Version.LUCENE_CURRENT, \"field\",\n                                     new StopWhitespaceAnalyzer(false));\n    q = (PhraseQuery) qp.parse(\"\\\"1 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // omitted stop word cannot help because stop filter swallows the increments. \n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // query parser alone won't help, because stop filter swallows the increments. \n    qp.setEnablePositionIncrements(true);\n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // stop filter alone won't help, because query parser swallows the increments. \n    qp.setEnablePositionIncrements(false);\n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n      \n    // when both qp qnd stopFilter propagate increments, we should find the doc.\n    qp = new QueryParser(Version.LUCENE_CURRENT, \"field\",\n                         new StopWhitespaceAnalyzer(true));\n    qp.setEnablePositionIncrements(true);\n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/backwards/src/test/org/apache/lucene/search/TestPositionIncrement#testSetPosition().mjava","pathOld":"backwards/src/test/org/apache/lucene/search/TestPositionIncrement#testSetPosition().mjava","sourceNew":"  public void testSetPosition() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new TokenStream() {\n          private final String[] TOKENS = {\"1\", \"2\", \"3\", \"4\", \"5\"};\n          private final int[] INCREMENTS = {0, 2, 1, 0, 1};\n          private int i = 0;\n\n          PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          TermAttribute termAtt = addAttribute(TermAttribute.class);\n          OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          \n          @Override\n          public boolean incrementToken() {\n            if (i == TOKENS.length)\n              return false;\n            termAtt.setTermBuffer(TOKENS[i]);\n            offsetAtt.setOffset(i,i);\n            posIncrAtt.setPositionIncrement(INCREMENTS[i]);\n            i++;\n            return true;\n          }\n        };\n      }\n    };\n    Directory store = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(store, analyzer, true,\n                                         IndexWriter.MaxFieldLength.LIMITED);\n    Document d = new Document();\n    d.add(new Field(\"field\", \"bogus\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(d);\n    writer.optimize();\n    writer.close();\n    \n\n    IndexSearcher searcher = new IndexSearcher(store, true);\n    \n    TermPositions pos = searcher.getIndexReader().termPositions(new Term(\"field\", \"1\"));\n    pos.next();\n    // first token should be at position 0\n    assertEquals(0, pos.nextPosition());\n    \n    pos = searcher.getIndexReader().termPositions(new Term(\"field\", \"2\"));\n    pos.next();\n    // second token should be at position 2\n    assertEquals(2, pos.nextPosition());\n    \n    PhraseQuery q;\n    ScoreDoc[] hits;\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"1\"));\n    q.add(new Term(\"field\", \"2\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // same as previous, just specify positions explicitely.\n    q = new PhraseQuery(); \n    q.add(new Term(\"field\", \"1\"),0);\n    q.add(new Term(\"field\", \"2\"),1);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // specifying correct positions should find the phrase.\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"1\"),0);\n    q.add(new Term(\"field\", \"2\"),2);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"2\"));\n    q.add(new Term(\"field\", \"3\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"));\n    q.add(new Term(\"field\", \"4\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // phrase query would find it when correct positions are specified. \n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"),0);\n    q.add(new Term(\"field\", \"4\"),0);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    // phrase query should fail for non existing searched term \n    // even if there exist another searched terms in the same searched position. \n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"),0);\n    q.add(new Term(\"field\", \"9\"),0);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // multi-phrase query should succed for non existing searched term\n    // because there exist another searched terms in the same searched position. \n    MultiPhraseQuery mq = new MultiPhraseQuery();\n    mq.add(new Term[]{new Term(\"field\", \"3\"),new Term(\"field\", \"9\")},0);\n    hits = searcher.search(mq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"2\"));\n    q.add(new Term(\"field\", \"4\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"));\n    q.add(new Term(\"field\", \"5\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"4\"));\n    q.add(new Term(\"field\", \"5\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"2\"));\n    q.add(new Term(\"field\", \"5\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // should not find \"1 2\" because there is a gap of 1 in the index\n    QueryParser qp = new QueryParser(Version.LUCENE_CURRENT, \"field\",\n                                     new StopWhitespaceAnalyzer(false));\n    q = (PhraseQuery) qp.parse(\"\\\"1 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // omitted stop word cannot help because stop filter swallows the increments. \n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // query parser alone won't help, because stop filter swallows the increments. \n    qp.setEnablePositionIncrements(true);\n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // stop filter alone won't help, because query parser swallows the increments. \n    qp.setEnablePositionIncrements(false);\n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n      \n    // when both qp qnd stopFilter propagate increments, we should find the doc.\n    qp = new QueryParser(Version.LUCENE_CURRENT, \"field\",\n                         new StopWhitespaceAnalyzer(true));\n    qp.setEnablePositionIncrements(true);\n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n  }\n\n","sourceOld":"  public void testSetPosition() throws Exception {\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new TokenStream() {\n          private final String[] TOKENS = {\"1\", \"2\", \"3\", \"4\", \"5\"};\n          private final int[] INCREMENTS = {0, 2, 1, 0, 1};\n          private int i = 0;\n\n          PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n          TermAttribute termAtt = addAttribute(TermAttribute.class);\n          OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n          \n          @Override\n          public boolean incrementToken() {\n            if (i == TOKENS.length)\n              return false;\n            termAtt.setTermBuffer(TOKENS[i]);\n            offsetAtt.setOffset(i,i);\n            posIncrAtt.setPositionIncrement(INCREMENTS[i]);\n            i++;\n            return true;\n          }\n        };\n      }\n    };\n    Directory store = new MockRAMDirectory();\n    IndexWriter writer = new IndexWriter(store, analyzer, true,\n                                         IndexWriter.MaxFieldLength.LIMITED);\n    Document d = new Document();\n    d.add(new Field(\"field\", \"bogus\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(d);\n    writer.optimize();\n    writer.close();\n    \n\n    IndexSearcher searcher = new IndexSearcher(store, true);\n    \n    TermPositions pos = searcher.getIndexReader().termPositions(new Term(\"field\", \"1\"));\n    pos.next();\n    // first token should be at position 0\n    assertEquals(0, pos.nextPosition());\n    \n    pos = searcher.getIndexReader().termPositions(new Term(\"field\", \"2\"));\n    pos.next();\n    // second token should be at position 2\n    assertEquals(2, pos.nextPosition());\n    \n    PhraseQuery q;\n    ScoreDoc[] hits;\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"1\"));\n    q.add(new Term(\"field\", \"2\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // same as previous, just specify positions explicitely.\n    q = new PhraseQuery(); \n    q.add(new Term(\"field\", \"1\"),0);\n    q.add(new Term(\"field\", \"2\"),1);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // specifying correct positions should find the phrase.\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"1\"),0);\n    q.add(new Term(\"field\", \"2\"),2);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"2\"));\n    q.add(new Term(\"field\", \"3\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"));\n    q.add(new Term(\"field\", \"4\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // phrase query would find it when correct positions are specified. \n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"),0);\n    q.add(new Term(\"field\", \"4\"),0);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    // phrase query should fail for non existing searched term \n    // even if there exist another searched terms in the same searched position. \n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"),0);\n    q.add(new Term(\"field\", \"9\"),0);\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // multi-phrase query should succed for non existing searched term\n    // because there exist another searched terms in the same searched position. \n    MultiPhraseQuery mq = new MultiPhraseQuery();\n    mq.add(new Term[]{new Term(\"field\", \"3\"),new Term(\"field\", \"9\")},0);\n    hits = searcher.search(mq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"2\"));\n    q.add(new Term(\"field\", \"4\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"3\"));\n    q.add(new Term(\"field\", \"5\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"4\"));\n    q.add(new Term(\"field\", \"5\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    q = new PhraseQuery();\n    q.add(new Term(\"field\", \"2\"));\n    q.add(new Term(\"field\", \"5\"));\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // should not find \"1 2\" because there is a gap of 1 in the index\n    QueryParser qp = new QueryParser(Version.LUCENE_CURRENT, \"field\",\n                                     new StopWhitespaceAnalyzer(false));\n    q = (PhraseQuery) qp.parse(\"\\\"1 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // omitted stop word cannot help because stop filter swallows the increments. \n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // query parser alone won't help, because stop filter swallows the increments. \n    qp.setEnablePositionIncrements(true);\n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n\n    // stop filter alone won't help, because query parser swallows the increments. \n    qp.setEnablePositionIncrements(false);\n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(0, hits.length);\n      \n    // when both qp qnd stopFilter propagate increments, we should find the doc.\n    qp = new QueryParser(Version.LUCENE_CURRENT, \"field\",\n                         new StopWhitespaceAnalyzer(true));\n    qp.setEnablePositionIncrements(true);\n    q = (PhraseQuery) qp.parse(\"\\\"1 stop 2\\\"\");\n    hits = searcher.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"480d01e5b0ef8efb136d51670fec297ae5ae2c9c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["480d01e5b0ef8efb136d51670fec297ae5ae2c9c"]},"commit2Childs":{"480d01e5b0ef8efb136d51670fec297ae5ae2c9c":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["480d01e5b0ef8efb136d51670fec297ae5ae2c9c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}