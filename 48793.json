{"path":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","commits":[{"id":"b1405362241b561f5590ff4a87d5d6e173bcd9cf","date":1190107634,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","pathOld":"/dev/null","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n\n      if (infoStream != null) {\n        if (merge.isAborted())\n          message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      }\n\n      assert merge.increfDone;\n      decrefMergeSegments(merge);\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    boolean success = false;\n\n    int start;\n\n    try {\n      SegmentInfos sourceSegmentsClone = merge.segmentsClone;\n      SegmentInfos sourceSegments = merge.segments;\n      final int numSegments = segmentInfos.size();\n\n      start = ensureContiguousMerge(merge);\n      if (infoStream != null)\n        message(\"commitMerge \" + merge.segString(directory));\n\n      // Carefully merge deletes that occurred after we\n      // started merging:\n\n      BitVector deletes = null;\n      int docUpto = 0;\n\n      final int numSegmentsToMerge = sourceSegments.size();\n      for(int i=0;i<numSegmentsToMerge;i++) {\n        final SegmentInfo previousInfo = sourceSegmentsClone.info(i);\n        final SegmentInfo currentInfo = sourceSegments.info(i);\n\n        assert currentInfo.docCount == previousInfo.docCount;\n\n        final int docCount = currentInfo.docCount;\n\n        if (previousInfo.hasDeletions()) {\n\n          // There were deletes on this segment when the merge\n          // started.  The merge has collapsed away those\n          // deletes, but, if new deletes were flushed since\n          // the merge started, we must now carefully keep any\n          // newly flushed deletes but mapping them to the new\n          // docIDs.\n\n          assert currentInfo.hasDeletions();\n\n          // Load deletes present @ start of merge, for this segment:\n          BitVector previousDeletes = new BitVector(previousInfo.dir, previousInfo.getDelFileName());\n\n          if (!currentInfo.getDelFileName().equals(previousInfo.getDelFileName())) {\n            // This means this segment has had new deletes\n            // committed since we started the merge, so we\n            // must merge them:\n            if (deletes == null)\n              deletes = new BitVector(merge.info.docCount);\n\n            BitVector currentDeletes = new BitVector(currentInfo.dir, currentInfo.getDelFileName());\n            for(int j=0;j<docCount;j++) {\n              if (previousDeletes.get(j))\n                assert currentDeletes.get(j);\n              else {\n                if (currentDeletes.get(j))\n                  deletes.set(docUpto);\n                docUpto++;\n              }\n            }\n          } else\n            docUpto += docCount - previousDeletes.count();\n        \n        } else if (currentInfo.hasDeletions()) {\n          // This segment had no deletes before but now it\n          // does:\n          if (deletes == null)\n            deletes = new BitVector(merge.info.docCount);\n          BitVector currentDeletes = new BitVector(directory, currentInfo.getDelFileName());\n\n          for(int j=0;j<docCount;j++) {\n            if (currentDeletes.get(j))\n              deletes.set(docUpto);\n            docUpto++;\n          }\n            \n        } else\n          // No deletes before or after\n          docUpto += currentInfo.docCount;\n      }\n\n      if (deletes != null) {\n        merge.info.advanceDelGen();\n        deletes.write(directory, merge.info.getDelFileName());\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream != null)\n          message(\"hit exception creating merged deletes file\");\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    success = false;\n    SegmentInfos rollback = null;\n    try {\n      rollback = (SegmentInfos) segmentInfos.clone();\n      segmentInfos.subList(start, start + merge.segments.size()).clear();\n      segmentInfos.add(start, merge.info);\n      checkpoint();\n      success = true;\n    } finally {\n      if (!success && rollback != null) {\n        if (infoStream != null)\n          message(\"hit exception when checkpointing after merge\");\n        segmentInfos.clear();\n        segmentInfos.addAll(rollback);\n        deletePartialSegmentsFile();\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    deleter.checkpoint(segmentInfos, autoCommit);\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["346d5897e4c4e77ed5dbd31f7730ff30973d5971","d9d40c43a41eb2ee87c78ef5d4db212c8ec7c29c","c0716ddfa41d3662d014c42086a700ad78fc5dcb","8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5","c619aff1490fbcbfb8aee81049da5e5120a986d6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6a1f29c9b1051488fd5fa7d56c98db5f4388408","date":1196281221,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n\n      if (infoStream != null) {\n        if (merge.isAborted())\n          message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      }\n\n      assert merge.increfDone;\n      decrefMergeSegments(merge);\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    boolean success = false;\n\n    int start;\n\n    try {\n      SegmentInfos sourceSegmentsClone = merge.segmentsClone;\n      SegmentInfos sourceSegments = merge.segments;\n\n      start = ensureContiguousMerge(merge);\n      if (infoStream != null)\n        message(\"commitMerge \" + merge.segString(directory));\n\n      // Carefully merge deletes that occurred after we\n      // started merging:\n\n      BitVector deletes = null;\n      int docUpto = 0;\n\n      final int numSegmentsToMerge = sourceSegments.size();\n      for(int i=0;i<numSegmentsToMerge;i++) {\n        final SegmentInfo previousInfo = sourceSegmentsClone.info(i);\n        final SegmentInfo currentInfo = sourceSegments.info(i);\n\n        assert currentInfo.docCount == previousInfo.docCount;\n\n        final int docCount = currentInfo.docCount;\n\n        if (previousInfo.hasDeletions()) {\n\n          // There were deletes on this segment when the merge\n          // started.  The merge has collapsed away those\n          // deletes, but, if new deletes were flushed since\n          // the merge started, we must now carefully keep any\n          // newly flushed deletes but mapping them to the new\n          // docIDs.\n\n          assert currentInfo.hasDeletions();\n\n          // Load deletes present @ start of merge, for this segment:\n          BitVector previousDeletes = new BitVector(previousInfo.dir, previousInfo.getDelFileName());\n\n          if (!currentInfo.getDelFileName().equals(previousInfo.getDelFileName())) {\n            // This means this segment has had new deletes\n            // committed since we started the merge, so we\n            // must merge them:\n            if (deletes == null)\n              deletes = new BitVector(merge.info.docCount);\n\n            BitVector currentDeletes = new BitVector(currentInfo.dir, currentInfo.getDelFileName());\n            for(int j=0;j<docCount;j++) {\n              if (previousDeletes.get(j))\n                assert currentDeletes.get(j);\n              else {\n                if (currentDeletes.get(j))\n                  deletes.set(docUpto);\n                docUpto++;\n              }\n            }\n          } else\n            docUpto += docCount - previousDeletes.count();\n        \n        } else if (currentInfo.hasDeletions()) {\n          // This segment had no deletes before but now it\n          // does:\n          if (deletes == null)\n            deletes = new BitVector(merge.info.docCount);\n          BitVector currentDeletes = new BitVector(directory, currentInfo.getDelFileName());\n\n          for(int j=0;j<docCount;j++) {\n            if (currentDeletes.get(j))\n              deletes.set(docUpto);\n            docUpto++;\n          }\n            \n        } else\n          // No deletes before or after\n          docUpto += currentInfo.docCount;\n      }\n\n      if (deletes != null) {\n        merge.info.advanceDelGen();\n        deletes.write(directory, merge.info.getDelFileName());\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream != null)\n          message(\"hit exception creating merged deletes file\");\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    success = false;\n    SegmentInfos rollback = null;\n    try {\n      rollback = (SegmentInfos) segmentInfos.clone();\n      segmentInfos.subList(start, start + merge.segments.size()).clear();\n      segmentInfos.add(start, merge.info);\n      checkpoint();\n      success = true;\n    } finally {\n      if (!success && rollback != null) {\n        if (infoStream != null)\n          message(\"hit exception when checkpointing after merge\");\n        segmentInfos.clear();\n        segmentInfos.addAll(rollback);\n        deletePartialSegmentsFile();\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    deleter.checkpoint(segmentInfos, autoCommit);\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n\n      if (infoStream != null) {\n        if (merge.isAborted())\n          message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      }\n\n      assert merge.increfDone;\n      decrefMergeSegments(merge);\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    boolean success = false;\n\n    int start;\n\n    try {\n      SegmentInfos sourceSegmentsClone = merge.segmentsClone;\n      SegmentInfos sourceSegments = merge.segments;\n      final int numSegments = segmentInfos.size();\n\n      start = ensureContiguousMerge(merge);\n      if (infoStream != null)\n        message(\"commitMerge \" + merge.segString(directory));\n\n      // Carefully merge deletes that occurred after we\n      // started merging:\n\n      BitVector deletes = null;\n      int docUpto = 0;\n\n      final int numSegmentsToMerge = sourceSegments.size();\n      for(int i=0;i<numSegmentsToMerge;i++) {\n        final SegmentInfo previousInfo = sourceSegmentsClone.info(i);\n        final SegmentInfo currentInfo = sourceSegments.info(i);\n\n        assert currentInfo.docCount == previousInfo.docCount;\n\n        final int docCount = currentInfo.docCount;\n\n        if (previousInfo.hasDeletions()) {\n\n          // There were deletes on this segment when the merge\n          // started.  The merge has collapsed away those\n          // deletes, but, if new deletes were flushed since\n          // the merge started, we must now carefully keep any\n          // newly flushed deletes but mapping them to the new\n          // docIDs.\n\n          assert currentInfo.hasDeletions();\n\n          // Load deletes present @ start of merge, for this segment:\n          BitVector previousDeletes = new BitVector(previousInfo.dir, previousInfo.getDelFileName());\n\n          if (!currentInfo.getDelFileName().equals(previousInfo.getDelFileName())) {\n            // This means this segment has had new deletes\n            // committed since we started the merge, so we\n            // must merge them:\n            if (deletes == null)\n              deletes = new BitVector(merge.info.docCount);\n\n            BitVector currentDeletes = new BitVector(currentInfo.dir, currentInfo.getDelFileName());\n            for(int j=0;j<docCount;j++) {\n              if (previousDeletes.get(j))\n                assert currentDeletes.get(j);\n              else {\n                if (currentDeletes.get(j))\n                  deletes.set(docUpto);\n                docUpto++;\n              }\n            }\n          } else\n            docUpto += docCount - previousDeletes.count();\n        \n        } else if (currentInfo.hasDeletions()) {\n          // This segment had no deletes before but now it\n          // does:\n          if (deletes == null)\n            deletes = new BitVector(merge.info.docCount);\n          BitVector currentDeletes = new BitVector(directory, currentInfo.getDelFileName());\n\n          for(int j=0;j<docCount;j++) {\n            if (currentDeletes.get(j))\n              deletes.set(docUpto);\n            docUpto++;\n          }\n            \n        } else\n          // No deletes before or after\n          docUpto += currentInfo.docCount;\n      }\n\n      if (deletes != null) {\n        merge.info.advanceDelGen();\n        deletes.write(directory, merge.info.getDelFileName());\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream != null)\n          message(\"hit exception creating merged deletes file\");\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    success = false;\n    SegmentInfos rollback = null;\n    try {\n      rollback = (SegmentInfos) segmentInfos.clone();\n      segmentInfos.subList(start, start + merge.segments.size()).clear();\n      segmentInfos.add(start, merge.info);\n      checkpoint();\n      success = true;\n    } finally {\n      if (!success && rollback != null) {\n        if (infoStream != null)\n          message(\"hit exception when checkpointing after merge\");\n        segmentInfos.clear();\n        segmentInfos.addAll(rollback);\n        deletePartialSegmentsFile();\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    deleter.checkpoint(segmentInfos, autoCommit);\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9d40c43a41eb2ee87c78ef5d4db212c8ec7c29c","date":1196806748,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n\n      assert merge.increfDone;\n      decrefMergeSegments(merge);\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    boolean success = false;\n\n    int start;\n\n    try {\n      SegmentInfos sourceSegmentsClone = merge.segmentsClone;\n      SegmentInfos sourceSegments = merge.segments;\n\n      start = ensureContiguousMerge(merge);\n      if (infoStream != null)\n        message(\"commitMerge \" + merge.segString(directory));\n\n      // Carefully merge deletes that occurred after we\n      // started merging:\n\n      BitVector deletes = null;\n      int docUpto = 0;\n\n      final int numSegmentsToMerge = sourceSegments.size();\n      for(int i=0;i<numSegmentsToMerge;i++) {\n        final SegmentInfo previousInfo = sourceSegmentsClone.info(i);\n        final SegmentInfo currentInfo = sourceSegments.info(i);\n\n        assert currentInfo.docCount == previousInfo.docCount;\n\n        final int docCount = currentInfo.docCount;\n\n        if (previousInfo.hasDeletions()) {\n\n          // There were deletes on this segment when the merge\n          // started.  The merge has collapsed away those\n          // deletes, but, if new deletes were flushed since\n          // the merge started, we must now carefully keep any\n          // newly flushed deletes but mapping them to the new\n          // docIDs.\n\n          assert currentInfo.hasDeletions();\n\n          // Load deletes present @ start of merge, for this segment:\n          BitVector previousDeletes = new BitVector(previousInfo.dir, previousInfo.getDelFileName());\n\n          if (!currentInfo.getDelFileName().equals(previousInfo.getDelFileName())) {\n            // This means this segment has had new deletes\n            // committed since we started the merge, so we\n            // must merge them:\n            if (deletes == null)\n              deletes = new BitVector(merge.info.docCount);\n\n            BitVector currentDeletes = new BitVector(currentInfo.dir, currentInfo.getDelFileName());\n            for(int j=0;j<docCount;j++) {\n              if (previousDeletes.get(j))\n                assert currentDeletes.get(j);\n              else {\n                if (currentDeletes.get(j))\n                  deletes.set(docUpto);\n                docUpto++;\n              }\n            }\n          } else\n            docUpto += docCount - previousDeletes.count();\n        \n        } else if (currentInfo.hasDeletions()) {\n          // This segment had no deletes before but now it\n          // does:\n          if (deletes == null)\n            deletes = new BitVector(merge.info.docCount);\n          BitVector currentDeletes = new BitVector(directory, currentInfo.getDelFileName());\n\n          for(int j=0;j<docCount;j++) {\n            if (currentDeletes.get(j))\n              deletes.set(docUpto);\n            docUpto++;\n          }\n            \n        } else\n          // No deletes before or after\n          docUpto += currentInfo.docCount;\n      }\n\n      if (deletes != null) {\n        merge.info.advanceDelGen();\n        deletes.write(directory, merge.info.getDelFileName());\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream != null)\n          message(\"hit exception creating merged deletes file\");\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    success = false;\n    SegmentInfos rollback = null;\n    try {\n      rollback = (SegmentInfos) segmentInfos.clone();\n      segmentInfos.subList(start, start + merge.segments.size()).clear();\n      segmentInfos.add(start, merge.info);\n      checkpoint();\n      success = true;\n    } finally {\n      if (!success && rollback != null) {\n        if (infoStream != null)\n          message(\"hit exception when checkpointing after merge\");\n        segmentInfos.clear();\n        segmentInfos.addAll(rollback);\n        deletePartialSegmentsFile();\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    deleter.checkpoint(segmentInfos, autoCommit);\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n\n      if (infoStream != null) {\n        if (merge.isAborted())\n          message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      }\n\n      assert merge.increfDone;\n      decrefMergeSegments(merge);\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    boolean success = false;\n\n    int start;\n\n    try {\n      SegmentInfos sourceSegmentsClone = merge.segmentsClone;\n      SegmentInfos sourceSegments = merge.segments;\n\n      start = ensureContiguousMerge(merge);\n      if (infoStream != null)\n        message(\"commitMerge \" + merge.segString(directory));\n\n      // Carefully merge deletes that occurred after we\n      // started merging:\n\n      BitVector deletes = null;\n      int docUpto = 0;\n\n      final int numSegmentsToMerge = sourceSegments.size();\n      for(int i=0;i<numSegmentsToMerge;i++) {\n        final SegmentInfo previousInfo = sourceSegmentsClone.info(i);\n        final SegmentInfo currentInfo = sourceSegments.info(i);\n\n        assert currentInfo.docCount == previousInfo.docCount;\n\n        final int docCount = currentInfo.docCount;\n\n        if (previousInfo.hasDeletions()) {\n\n          // There were deletes on this segment when the merge\n          // started.  The merge has collapsed away those\n          // deletes, but, if new deletes were flushed since\n          // the merge started, we must now carefully keep any\n          // newly flushed deletes but mapping them to the new\n          // docIDs.\n\n          assert currentInfo.hasDeletions();\n\n          // Load deletes present @ start of merge, for this segment:\n          BitVector previousDeletes = new BitVector(previousInfo.dir, previousInfo.getDelFileName());\n\n          if (!currentInfo.getDelFileName().equals(previousInfo.getDelFileName())) {\n            // This means this segment has had new deletes\n            // committed since we started the merge, so we\n            // must merge them:\n            if (deletes == null)\n              deletes = new BitVector(merge.info.docCount);\n\n            BitVector currentDeletes = new BitVector(currentInfo.dir, currentInfo.getDelFileName());\n            for(int j=0;j<docCount;j++) {\n              if (previousDeletes.get(j))\n                assert currentDeletes.get(j);\n              else {\n                if (currentDeletes.get(j))\n                  deletes.set(docUpto);\n                docUpto++;\n              }\n            }\n          } else\n            docUpto += docCount - previousDeletes.count();\n        \n        } else if (currentInfo.hasDeletions()) {\n          // This segment had no deletes before but now it\n          // does:\n          if (deletes == null)\n            deletes = new BitVector(merge.info.docCount);\n          BitVector currentDeletes = new BitVector(directory, currentInfo.getDelFileName());\n\n          for(int j=0;j<docCount;j++) {\n            if (currentDeletes.get(j))\n              deletes.set(docUpto);\n            docUpto++;\n          }\n            \n        } else\n          // No deletes before or after\n          docUpto += currentInfo.docCount;\n      }\n\n      if (deletes != null) {\n        merge.info.advanceDelGen();\n        deletes.write(directory, merge.info.getDelFileName());\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream != null)\n          message(\"hit exception creating merged deletes file\");\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    success = false;\n    SegmentInfos rollback = null;\n    try {\n      rollback = (SegmentInfos) segmentInfos.clone();\n      segmentInfos.subList(start, start + merge.segments.size()).clear();\n      segmentInfos.add(start, merge.info);\n      checkpoint();\n      success = true;\n    } finally {\n      if (!success && rollback != null) {\n        if (infoStream != null)\n          message(\"hit exception when checkpointing after merge\");\n        segmentInfos.clear();\n        segmentInfos.addAll(rollback);\n        deletePartialSegmentsFile();\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    deleter.checkpoint(segmentInfos, autoCommit);\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","bugFix":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"346d5897e4c4e77ed5dbd31f7730ff30973d5971","date":1198317988,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n\n      assert merge.increfDone;\n      decrefMergeSegments(merge);\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    boolean success = false;\n\n    int start;\n\n    try {\n      SegmentInfos sourceSegmentsClone = merge.segmentsClone;\n      SegmentInfos sourceSegments = merge.segments;\n\n      start = ensureContiguousMerge(merge);\n      if (infoStream != null)\n        message(\"commitMerge \" + merge.segString(directory));\n\n      // Carefully merge deletes that occurred after we\n      // started merging:\n\n      BitVector deletes = null;\n      int docUpto = 0;\n\n      final int numSegmentsToMerge = sourceSegments.size();\n      for(int i=0;i<numSegmentsToMerge;i++) {\n        final SegmentInfo previousInfo = sourceSegmentsClone.info(i);\n        final SegmentInfo currentInfo = sourceSegments.info(i);\n\n        assert currentInfo.docCount == previousInfo.docCount;\n\n        final int docCount = currentInfo.docCount;\n\n        if (previousInfo.hasDeletions()) {\n\n          // There were deletes on this segment when the merge\n          // started.  The merge has collapsed away those\n          // deletes, but, if new deletes were flushed since\n          // the merge started, we must now carefully keep any\n          // newly flushed deletes but mapping them to the new\n          // docIDs.\n\n          assert currentInfo.hasDeletions();\n\n          // Load deletes present @ start of merge, for this segment:\n          BitVector previousDeletes = new BitVector(previousInfo.dir, previousInfo.getDelFileName());\n\n          if (!currentInfo.getDelFileName().equals(previousInfo.getDelFileName())) {\n            // This means this segment has had new deletes\n            // committed since we started the merge, so we\n            // must merge them:\n            if (deletes == null)\n              deletes = new BitVector(merge.info.docCount);\n\n            BitVector currentDeletes = new BitVector(currentInfo.dir, currentInfo.getDelFileName());\n            for(int j=0;j<docCount;j++) {\n              if (previousDeletes.get(j))\n                assert currentDeletes.get(j);\n              else {\n                if (currentDeletes.get(j))\n                  deletes.set(docUpto);\n                docUpto++;\n              }\n            }\n          } else\n            docUpto += docCount - previousDeletes.count();\n        \n        } else if (currentInfo.hasDeletions()) {\n          // This segment had no deletes before but now it\n          // does:\n          if (deletes == null)\n            deletes = new BitVector(merge.info.docCount);\n          BitVector currentDeletes = new BitVector(directory, currentInfo.getDelFileName());\n\n          for(int j=0;j<docCount;j++) {\n            if (currentDeletes.get(j))\n              deletes.set(docUpto);\n            docUpto++;\n          }\n\n        } else\n          // No deletes before or after\n          docUpto += currentInfo.docCount;\n\n        merge.checkAborted(directory);\n      }\n\n      if (deletes != null) {\n        merge.info.advanceDelGen();\n        deletes.write(directory, merge.info.getDelFileName());\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream != null)\n          message(\"hit exception creating merged deletes file\");\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    success = false;\n    SegmentInfos rollback = null;\n    try {\n      rollback = (SegmentInfos) segmentInfos.clone();\n      segmentInfos.subList(start, start + merge.segments.size()).clear();\n      segmentInfos.add(start, merge.info);\n      checkpoint();\n      success = true;\n    } finally {\n      if (!success && rollback != null) {\n        if (infoStream != null)\n          message(\"hit exception when checkpointing after merge\");\n        segmentInfos.clear();\n        segmentInfos.addAll(rollback);\n        deletePartialSegmentsFile();\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    deleter.checkpoint(segmentInfos, autoCommit);\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n\n      assert merge.increfDone;\n      decrefMergeSegments(merge);\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    boolean success = false;\n\n    int start;\n\n    try {\n      SegmentInfos sourceSegmentsClone = merge.segmentsClone;\n      SegmentInfos sourceSegments = merge.segments;\n\n      start = ensureContiguousMerge(merge);\n      if (infoStream != null)\n        message(\"commitMerge \" + merge.segString(directory));\n\n      // Carefully merge deletes that occurred after we\n      // started merging:\n\n      BitVector deletes = null;\n      int docUpto = 0;\n\n      final int numSegmentsToMerge = sourceSegments.size();\n      for(int i=0;i<numSegmentsToMerge;i++) {\n        final SegmentInfo previousInfo = sourceSegmentsClone.info(i);\n        final SegmentInfo currentInfo = sourceSegments.info(i);\n\n        assert currentInfo.docCount == previousInfo.docCount;\n\n        final int docCount = currentInfo.docCount;\n\n        if (previousInfo.hasDeletions()) {\n\n          // There were deletes on this segment when the merge\n          // started.  The merge has collapsed away those\n          // deletes, but, if new deletes were flushed since\n          // the merge started, we must now carefully keep any\n          // newly flushed deletes but mapping them to the new\n          // docIDs.\n\n          assert currentInfo.hasDeletions();\n\n          // Load deletes present @ start of merge, for this segment:\n          BitVector previousDeletes = new BitVector(previousInfo.dir, previousInfo.getDelFileName());\n\n          if (!currentInfo.getDelFileName().equals(previousInfo.getDelFileName())) {\n            // This means this segment has had new deletes\n            // committed since we started the merge, so we\n            // must merge them:\n            if (deletes == null)\n              deletes = new BitVector(merge.info.docCount);\n\n            BitVector currentDeletes = new BitVector(currentInfo.dir, currentInfo.getDelFileName());\n            for(int j=0;j<docCount;j++) {\n              if (previousDeletes.get(j))\n                assert currentDeletes.get(j);\n              else {\n                if (currentDeletes.get(j))\n                  deletes.set(docUpto);\n                docUpto++;\n              }\n            }\n          } else\n            docUpto += docCount - previousDeletes.count();\n        \n        } else if (currentInfo.hasDeletions()) {\n          // This segment had no deletes before but now it\n          // does:\n          if (deletes == null)\n            deletes = new BitVector(merge.info.docCount);\n          BitVector currentDeletes = new BitVector(directory, currentInfo.getDelFileName());\n\n          for(int j=0;j<docCount;j++) {\n            if (currentDeletes.get(j))\n              deletes.set(docUpto);\n            docUpto++;\n          }\n            \n        } else\n          // No deletes before or after\n          docUpto += currentInfo.docCount;\n      }\n\n      if (deletes != null) {\n        merge.info.advanceDelGen();\n        deletes.write(directory, merge.info.getDelFileName());\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream != null)\n          message(\"hit exception creating merged deletes file\");\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    success = false;\n    SegmentInfos rollback = null;\n    try {\n      rollback = (SegmentInfos) segmentInfos.clone();\n      segmentInfos.subList(start, start + merge.segments.size()).clear();\n      segmentInfos.add(start, merge.info);\n      checkpoint();\n      success = true;\n    } finally {\n      if (!success && rollback != null) {\n        if (infoStream != null)\n          message(\"hit exception when checkpointing after merge\");\n        segmentInfos.clear();\n        segmentInfos.addAll(rollback);\n        deletePartialSegmentsFile();\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    deleter.checkpoint(segmentInfos, autoCommit);\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","bugFix":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e82780afe6097066eb5befb86e9432f077667e3d","date":1202756169,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory));\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge);\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    segmentInfos.add(start, merge.info);\n    if (lastMergeInfo == null || segmentInfos.indexOf(lastMergeInfo) < start)\n      lastMergeInfo = merge.info;\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    checkpoint();\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n\n      assert merge.increfDone;\n      decrefMergeSegments(merge);\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    boolean success = false;\n\n    int start;\n\n    try {\n      SegmentInfos sourceSegmentsClone = merge.segmentsClone;\n      SegmentInfos sourceSegments = merge.segments;\n\n      start = ensureContiguousMerge(merge);\n      if (infoStream != null)\n        message(\"commitMerge \" + merge.segString(directory));\n\n      // Carefully merge deletes that occurred after we\n      // started merging:\n\n      BitVector deletes = null;\n      int docUpto = 0;\n\n      final int numSegmentsToMerge = sourceSegments.size();\n      for(int i=0;i<numSegmentsToMerge;i++) {\n        final SegmentInfo previousInfo = sourceSegmentsClone.info(i);\n        final SegmentInfo currentInfo = sourceSegments.info(i);\n\n        assert currentInfo.docCount == previousInfo.docCount;\n\n        final int docCount = currentInfo.docCount;\n\n        if (previousInfo.hasDeletions()) {\n\n          // There were deletes on this segment when the merge\n          // started.  The merge has collapsed away those\n          // deletes, but, if new deletes were flushed since\n          // the merge started, we must now carefully keep any\n          // newly flushed deletes but mapping them to the new\n          // docIDs.\n\n          assert currentInfo.hasDeletions();\n\n          // Load deletes present @ start of merge, for this segment:\n          BitVector previousDeletes = new BitVector(previousInfo.dir, previousInfo.getDelFileName());\n\n          if (!currentInfo.getDelFileName().equals(previousInfo.getDelFileName())) {\n            // This means this segment has had new deletes\n            // committed since we started the merge, so we\n            // must merge them:\n            if (deletes == null)\n              deletes = new BitVector(merge.info.docCount);\n\n            BitVector currentDeletes = new BitVector(currentInfo.dir, currentInfo.getDelFileName());\n            for(int j=0;j<docCount;j++) {\n              if (previousDeletes.get(j))\n                assert currentDeletes.get(j);\n              else {\n                if (currentDeletes.get(j))\n                  deletes.set(docUpto);\n                docUpto++;\n              }\n            }\n          } else\n            docUpto += docCount - previousDeletes.count();\n        \n        } else if (currentInfo.hasDeletions()) {\n          // This segment had no deletes before but now it\n          // does:\n          if (deletes == null)\n            deletes = new BitVector(merge.info.docCount);\n          BitVector currentDeletes = new BitVector(directory, currentInfo.getDelFileName());\n\n          for(int j=0;j<docCount;j++) {\n            if (currentDeletes.get(j))\n              deletes.set(docUpto);\n            docUpto++;\n          }\n\n        } else\n          // No deletes before or after\n          docUpto += currentInfo.docCount;\n\n        merge.checkAborted(directory);\n      }\n\n      if (deletes != null) {\n        merge.info.advanceDelGen();\n        deletes.write(directory, merge.info.getDelFileName());\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream != null)\n          message(\"hit exception creating merged deletes file\");\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    success = false;\n    SegmentInfos rollback = null;\n    try {\n      rollback = (SegmentInfos) segmentInfos.clone();\n      segmentInfos.subList(start, start + merge.segments.size()).clear();\n      segmentInfos.add(start, merge.info);\n      checkpoint();\n      success = true;\n    } finally {\n      if (!success && rollback != null) {\n        if (infoStream != null)\n          message(\"hit exception when checkpointing after merge\");\n        segmentInfos.clear();\n        segmentInfos.addAll(rollback);\n        deletePartialSegmentsFile();\n        deleter.refresh(merge.info.name);\n      }\n    }\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    deleter.checkpoint(segmentInfos, autoCommit);\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63","date":1204234542,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    if (hitOOM)\n      return false;\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory));\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge);\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    segmentInfos.add(start, merge.info);\n    if (lastMergeInfo == null || segmentInfos.indexOf(lastMergeInfo) < start)\n      lastMergeInfo = merge.info;\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    checkpoint();\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory));\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge);\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    segmentInfos.add(start, merge.info);\n    if (lastMergeInfo == null || segmentInfos.indexOf(lastMergeInfo) < start)\n      lastMergeInfo = merge.info;\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    checkpoint();\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be","date":1204801324,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentMerger,int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, int mergedDocCount) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM)\n      return false;\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory));\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge);\n\n    docWriter.remapDeletes(segmentInfos, merger.getDocMaps(), merger.getDelCounts(), merge, mergedDocCount);\n      \n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    segmentInfos.add(start, merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    checkpoint();\n\n    decrefMergeSegments(merge);\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    if (hitOOM)\n      return false;\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory));\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if abort() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n\n      deleter.refresh(merge.info.name);\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge);\n\n    // Simple optimization: if the doc store we are using\n    // has been closed and is in now compound format (but\n    // wasn't when we started), then we will switch to the\n    // compound format as well:\n    final String mergeDocStoreSegment = merge.info.getDocStoreSegment(); \n    if (mergeDocStoreSegment != null && !merge.info.getDocStoreIsCompoundFile()) {\n      final int size = segmentInfos.size();\n      for(int i=0;i<size;i++) {\n        final SegmentInfo info = segmentInfos.info(i);\n        final String docStoreSegment = info.getDocStoreSegment();\n        if (docStoreSegment != null &&\n            docStoreSegment.equals(mergeDocStoreSegment) && \n            info.getDocStoreIsCompoundFile()) {\n          merge.info.setDocStoreIsCompoundFile(true);\n          break;\n        }\n      }\n    }\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    segmentInfos.add(start, merge.info);\n    if (lastMergeInfo == null || segmentInfos.indexOf(lastMergeInfo) < start)\n      lastMergeInfo = merge.info;\n\n    if (merge.optimize)\n      segmentsToOptimize.add(merge.info);\n\n    // Must checkpoint before decrefing so any newly\n    // referenced files in the new merge.info are incref'd\n    // first:\n    checkpoint();\n\n    decrefMergeSegments(merge);\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"346d5897e4c4e77ed5dbd31f7730ff30973d5971":["d9d40c43a41eb2ee87c78ef5d4db212c8ec7c29c"],"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63":["e82780afe6097066eb5befb86e9432f077667e3d"],"d9d40c43a41eb2ee87c78ef5d4db212c8ec7c29c":["b6a1f29c9b1051488fd5fa7d56c98db5f4388408"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63"],"e82780afe6097066eb5befb86e9432f077667e3d":["346d5897e4c4e77ed5dbd31f7730ff30973d5971"],"b6a1f29c9b1051488fd5fa7d56c98db5f4388408":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"]},"commit2Childs":{"346d5897e4c4e77ed5dbd31f7730ff30973d5971":["e82780afe6097066eb5befb86e9432f077667e3d"],"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["b6a1f29c9b1051488fd5fa7d56c98db5f4388408"],"01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"d9d40c43a41eb2ee87c78ef5d4db212c8ec7c29c":["346d5897e4c4e77ed5dbd31f7730ff30973d5971"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"e82780afe6097066eb5befb86e9432f077667e3d":["01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b6a1f29c9b1051488fd5fa7d56c98db5f4388408":["d9d40c43a41eb2ee87c78ef5d4db212c8ec7c29c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}