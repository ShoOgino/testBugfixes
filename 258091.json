{"path":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","commits":[{"id":"91109046a59c58ee0ee5d0d2767b08d1f30d6702","date":1000830588,"type":0,"author":"Jason van Zyl","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"/dev/null","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment) throws IOException {\n    mergeSegments(minSegment, true);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e745568eabfe0f163a0eddb52ef01a6a8404656","date":1012321816,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = new SegmentMerger(directory, mergedName);\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += si.docCount;\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n\n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n\t\t\t\t\t    directory));\n    \n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"commit.lock\")) {\n\t  public Object doBody() throws IOException {\n\t    segmentInfos.write(directory);\t  // commit before deleting\n\t    deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n\t    return null;\n\t  }\n\t}.run();\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment) throws IOException {\n    mergeSegments(minSegment, true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8ac4052920fcd27b00a09b0f354a72da109d5d01","date":1049855256,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = new SegmentMerger(directory, mergedName);\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += si.docCount;\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n\n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n\t\t\t\t\t    directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"commit.lock\")) {\n\t  public Object doBody() throws IOException {\n\t    segmentInfos.write(directory);\t  // commit before deleting\n\t    deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n\t    return null;\n\t  }\n\t}.run();\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = new SegmentMerger(directory, mergedName);\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += si.docCount;\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n\n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n\t\t\t\t\t    directory));\n    \n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"commit.lock\")) {\n\t  public Object doBody() throws IOException {\n\t    segmentInfos.write(directory);\t  // commit before deleting\n\t    deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n\t    return null;\n\t  }\n\t}.run();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"693a4c06f749274d170a2e87d4afb2709a810f46","date":1060700703,"type":3,"author":"Scott Ganyo","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = new SegmentMerger(directory, mergedName);\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += si.docCount;\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n\n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n\t\t\t\t\t    directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"commit.lock\"), COMMIT_LOCK_TIMEOUT) {\n\t  public Object doBody() throws IOException {\n\t    segmentInfos.write(directory);\t  // commit before deleting\n\t    deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n\t    return null;\n\t  }\n\t}.run();\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = new SegmentMerger(directory, mergedName);\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += si.docCount;\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n\n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n\t\t\t\t\t    directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"commit.lock\")) {\n\t  public Object doBody() throws IOException {\n\t    segmentInfos.write(directory);\t  // commit before deleting\n\t    deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n\t    return null;\n\t  }\n\t}.run();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cdd9b8e9a06bef873bf7e2c3b6664511a54f6485","date":1063629623,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = new SegmentMerger(directory, mergedName);\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += reader.numDocs();\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n\n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n\t\t\t\t\t    directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"commit.lock\"), COMMIT_LOCK_TIMEOUT) {\n\t  public Object doBody() throws IOException {\n\t    segmentInfos.write(directory);\t  // commit before deleting\n\t    deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n\t    return null;\n\t  }\n\t}.run();\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = new SegmentMerger(directory, mergedName);\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += si.docCount;\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n\n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n\t\t\t\t\t    directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"commit.lock\"), COMMIT_LOCK_TIMEOUT) {\n\t  public Object doBody() throws IOException {\n\t    segmentInfos.write(directory);\t  // commit before deleting\n\t    deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n\t    return null;\n\t  }\n\t}.run();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1","date":1064527311,"type":3,"author":"Dmitry Serebrennikov","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = \n        new SegmentMerger(directory, mergedName, useCompoundFile);\n        \n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n        segmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += reader.numDocs();\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n    \n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"commit.lock\"), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = new SegmentMerger(directory, mergedName);\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += reader.numDocs();\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n\n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n\t\t\t\t\t    directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"commit.lock\"), COMMIT_LOCK_TIMEOUT) {\n\t  public Object doBody() throws IOException {\n\t    segmentInfos.write(directory);\t  // commit before deleting\n\t    deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n\t    return null;\n\t  }\n\t}.run();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"18a2a015b86d022024b2b712bd8b607afccbb881","date":1066054947,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = \n        new SegmentMerger(directory, mergedName, useCompoundFile);\n        \n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n        segmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += reader.numDocs();\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n    \n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"COMMIT_LOCK_NAME\"), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = \n        new SegmentMerger(directory, mergedName, useCompoundFile);\n        \n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n        segmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += reader.numDocs();\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n    \n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"commit.lock\"), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc97c3750bb1acfa4dc8d7289e664ac0210c4f93","date":1066387782,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = \n        new SegmentMerger(directory, mergedName, useCompoundFile);\n        \n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n        segmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += reader.numDocs();\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n    \n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = \n        new SegmentMerger(directory, mergedName, useCompoundFile);\n        \n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n        segmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += reader.numDocs();\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n    \n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(\"COMMIT_LOCK_NAME\"), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7fb6d70db034a5456ae560175dd1b821eea9ff4","date":1066759157,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = \n        new SegmentMerger(directory, mergedName, useCompoundFile);\n        \n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory()==this.directory) || // if we own the directory\n          (reader.directory()==this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += reader.numDocs();\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n    \n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = \n        new SegmentMerger(directory, mergedName, useCompoundFile);\n        \n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      SegmentReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory == this.directory) || // if we own the directory\n          (reader.directory == this.ramDirectory))\n        segmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += reader.numDocs();\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n    \n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a6f7a120a46dc36dbda9d77bf01a0770cf3136e","date":1067090048,"type":3,"author":"Christoph Goller","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = \n        new SegmentMerger(directory, mergedName, useCompoundFile);\n        \n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory()==this.directory) || // if we own the directory\n          (reader.directory()==this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n    }\n    \n    int mergedDocCount = merger.merge();\n    \n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    \n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    int mergedDocCount = 0;\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = \n        new SegmentMerger(directory, mergedName, useCompoundFile);\n        \n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory()==this.directory) || // if we own the directory\n          (reader.directory()==this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n      mergedDocCount += reader.numDocs();\n    }\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    merger.merge();\n    \n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f7961006605708cac1ca5185ead37902442ceff6","date":1078410713,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName, useCompoundFile);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory()==this.directory) || // if we own the directory\n          (reader.directory()==this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = \n        new SegmentMerger(directory, mergedName, useCompoundFile);\n        \n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory()==this.directory) || // if we own the directory\n          (reader.directory()==this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n    }\n    \n    int mergedDocCount = merger.merge();\n    \n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n    \n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f7621c4130b1dcb10f6a36951fc3b95ec4456f99","date":1080243293,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName, useCompoundFile);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName, useCompoundFile);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n\tinfoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory()==this.directory) || // if we own the directory\n          (reader.directory()==this.ramDirectory))\n\tsegmentsToDelete.addElement(reader);\t  // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println();\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);\t\t  // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {\t\t\t  // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);\t  // commit before deleting\n            deleteSegments(segmentsToDelete);\t  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"42a7d0b384f0022c5a29e562b809ebf73991d7e6","date":1082489615,"type":3,"author":"Christoph Goller","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName, useCompoundFile);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n    \n    merger.closeReaders();\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName, useCompoundFile);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc7017b45dd72c4f5934b1062dbd3bc6e9446eb9","date":1086780526,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName, useCompoundFile);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName, useCompoundFile);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n    \n    merger.closeReaders();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79fc67d5cdece593cd3b3b6c7ef195ee2625522c","date":1091970333,"type":3,"author":"Christoph Goller","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    final SegmentMerger merger =\n        new SegmentMerger(directory, mergedName);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            if(useCompoundFile)\n                merger.createCompoundFile();\n            return null;\n          }\n        }.run();\n    }\n\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName, useCompoundFile);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6263f219dcdfc6e861ecffaecf5e1e195f1aaaa7","date":1092245915,"type":3,"author":"Christoph Goller","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    final String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n    \n    if (useCompoundFile) {\n      final Vector filesToDelete = merger.createCompoundFile(mergedName + \".tmp\");\n      synchronized (directory) { // in- & inter-process sync\n        new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            // make compound file visible for SegmentReaders\n            directory.renameFile(mergedName + \".tmp\", mergedName + \".cfs\");\n            // delete now unused files of segment \n            deleteFiles(filesToDelete);   \n            return null;\n          }\n        }.run();\n      }\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    final SegmentMerger merger =\n        new SegmentMerger(directory, mergedName);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(IndexWriter.COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            if(useCompoundFile)\n                merger.createCompoundFile();\n            return null;\n          }\n        }.run();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6e5d88b55f1b57feab6da94a5c635a224539bd2a","date":1095877947,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    final String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = SegmentReader.get(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n    \n    if (useCompoundFile) {\n      final Vector filesToDelete = merger.createCompoundFile(mergedName + \".tmp\");\n      synchronized (directory) { // in- & inter-process sync\n        new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            // make compound file visible for SegmentReaders\n            directory.renameFile(mergedName + \".tmp\", mergedName + \".cfs\");\n            // delete now unused files of segment \n            deleteFiles(filesToDelete);   \n            return null;\n          }\n        }.run();\n      }\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    final String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = new SegmentReader(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n    \n    if (useCompoundFile) {\n      final Vector filesToDelete = merger.createCompoundFile(mergedName + \".tmp\");\n      synchronized (directory) { // in- & inter-process sync\n        new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            // make compound file visible for SegmentReaders\n            directory.renameFile(mergedName + \".tmp\", mergedName + \".cfs\");\n            // delete now unused files of segment \n            deleteFiles(filesToDelete);   \n            return null;\n          }\n        }.run();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3afaca6e0770734b01e3bc663bec3ffa71b6f87b","date":1110394706,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    final String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(this, mergedName);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = SegmentReader.get(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n    \n    if (useCompoundFile) {\n      final Vector filesToDelete = merger.createCompoundFile(mergedName + \".tmp\");\n      synchronized (directory) { // in- & inter-process sync\n        new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            // make compound file visible for SegmentReaders\n            directory.renameFile(mergedName + \".tmp\", mergedName + \".cfs\");\n            // delete now unused files of segment \n            deleteFiles(filesToDelete);   \n            return null;\n          }\n        }.run();\n      }\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    final String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(directory, mergedName);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = SegmentReader.get(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n    \n    if (useCompoundFile) {\n      final Vector filesToDelete = merger.createCompoundFile(mergedName + \".tmp\");\n      synchronized (directory) { // in- & inter-process sync\n        new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            // make compound file visible for SegmentReaders\n            directory.renameFile(mergedName + \".tmp\", mergedName + \".cfs\");\n            // delete now unused files of segment \n            deleteFiles(filesToDelete);   \n            return null;\n          }\n        }.run();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a2ebafe4b791cc3938e53b13379dc7b19ba1f75","date":1110599454,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    final String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = new SegmentMerger(this, mergedName);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = SegmentReader.get(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n    \n    if (useCompoundFile) {\n      final Vector filesToDelete = merger.createCompoundFile(mergedName + \".tmp\");\n      synchronized (directory) { // in- & inter-process sync\n        new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            // make compound file visible for SegmentReaders\n            directory.renameFile(mergedName + \".tmp\", mergedName + \".cfs\");\n            // delete now unused files of segment \n            deleteFiles(filesToDelete);   \n            return null;\n          }\n        }.run();\n      }\n    }\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    final String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger =\n        new SegmentMerger(this, mergedName);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = SegmentReader.get(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n    \n    if (useCompoundFile) {\n      final Vector filesToDelete = merger.createCompoundFile(mergedName + \".tmp\");\n      synchronized (directory) { // in- & inter-process sync\n        new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            // make compound file visible for SegmentReaders\n            directory.renameFile(mergedName + \".tmp\", mergedName + \".cfs\");\n            // delete now unused files of segment \n            deleteFiles(filesToDelete);   \n            return null;\n          }\n        }.run();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db628922a5eb84f4c7e097a23b99c6fcfc46e084","date":1117731958,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    mergeSegments(minSegment, segmentInfos.size());\n  }\n\n","sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    final String mergedName = newSegmentName();\n    if (infoStream != null) infoStream.print(\"merging segments\");\n    SegmentMerger merger = new SegmentMerger(this, mergedName);\n\n    final Vector segmentsToDelete = new Vector();\n    for (int i = minSegment; i < segmentInfos.size(); i++) {\n      SegmentInfo si = segmentInfos.info(i);\n      if (infoStream != null)\n        infoStream.print(\" \" + si.name + \" (\" + si.docCount + \" docs)\");\n      IndexReader reader = SegmentReader.get(si);\n      merger.add(reader);\n      if ((reader.directory() == this.directory) || // if we own the directory\n          (reader.directory() == this.ramDirectory))\n        segmentsToDelete.addElement(reader);   // queue segment for deletion\n    }\n\n    int mergedDocCount = merger.merge();\n\n    if (infoStream != null) {\n      infoStream.println(\" into \"+mergedName+\" (\"+mergedDocCount+\" docs)\");\n    }\n\n    segmentInfos.setSize(minSegment);          // pop old infos & add new\n    segmentInfos.addElement(new SegmentInfo(mergedName, mergedDocCount,\n                                            directory));\n\n    // close readers before we attempt to delete now-obsolete segments\n    merger.closeReaders();\n\n    synchronized (directory) {                 // in- & inter-process sync\n      new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            segmentInfos.write(directory);     // commit before deleting\n            deleteSegments(segmentsToDelete);  // delete now-unused segments\n            return null;\n          }\n        }.run();\n    }\n    \n    if (useCompoundFile) {\n      final Vector filesToDelete = merger.createCompoundFile(mergedName + \".tmp\");\n      synchronized (directory) { // in- & inter-process sync\n        new Lock.With(directory.makeLock(COMMIT_LOCK_NAME), COMMIT_LOCK_TIMEOUT) {\n          public Object doBody() throws IOException {\n            // make compound file visible for SegmentReaders\n            directory.renameFile(mergedName + \".tmp\", mergedName + \".cfs\");\n            // delete now unused files of segment \n            deleteFiles(filesToDelete);   \n            return null;\n          }\n        }.run();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d7052f725a053aa55424f966831826f61b798bf1","date":1158258681,"type":4,"author":"Yonik Seeley","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/index/IndexWriter#mergeSegments(int).mjava","sourceNew":null,"sourceOld":"  /** Pops segments off of segmentInfos stack down to minSegment, merges them,\n    and pushes the merged index onto the top of the segmentInfos stack. */\n  private final void mergeSegments(int minSegment)\n      throws IOException {\n    mergeSegments(minSegment, segmentInfos.size());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d7052f725a053aa55424f966831826f61b798bf1":["db628922a5eb84f4c7e097a23b99c6fcfc46e084"],"18a2a015b86d022024b2b712bd8b607afccbb881":["8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1"],"91109046a59c58ee0ee5d0d2767b08d1f30d6702":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"693a4c06f749274d170a2e87d4afb2709a810f46":["8ac4052920fcd27b00a09b0f354a72da109d5d01"],"e7fb6d70db034a5456ae560175dd1b821eea9ff4":["fc97c3750bb1acfa4dc8d7289e664ac0210c4f93"],"7a2ebafe4b791cc3938e53b13379dc7b19ba1f75":["3afaca6e0770734b01e3bc663bec3ffa71b6f87b"],"db628922a5eb84f4c7e097a23b99c6fcfc46e084":["7a2ebafe4b791cc3938e53b13379dc7b19ba1f75"],"cdd9b8e9a06bef873bf7e2c3b6664511a54f6485":["693a4c06f749274d170a2e87d4afb2709a810f46"],"6263f219dcdfc6e861ecffaecf5e1e195f1aaaa7":["79fc67d5cdece593cd3b3b6c7ef195ee2625522c"],"42a7d0b384f0022c5a29e562b809ebf73991d7e6":["f7621c4130b1dcb10f6a36951fc3b95ec4456f99"],"8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1":["cdd9b8e9a06bef873bf7e2c3b6664511a54f6485"],"fc97c3750bb1acfa4dc8d7289e664ac0210c4f93":["18a2a015b86d022024b2b712bd8b607afccbb881"],"3e745568eabfe0f163a0eddb52ef01a6a8404656":["91109046a59c58ee0ee5d0d2767b08d1f30d6702"],"6a6f7a120a46dc36dbda9d77bf01a0770cf3136e":["e7fb6d70db034a5456ae560175dd1b821eea9ff4"],"8ac4052920fcd27b00a09b0f354a72da109d5d01":["3e745568eabfe0f163a0eddb52ef01a6a8404656"],"f7961006605708cac1ca5185ead37902442ceff6":["6a6f7a120a46dc36dbda9d77bf01a0770cf3136e"],"79fc67d5cdece593cd3b3b6c7ef195ee2625522c":["bc7017b45dd72c4f5934b1062dbd3bc6e9446eb9"],"6e5d88b55f1b57feab6da94a5c635a224539bd2a":["6263f219dcdfc6e861ecffaecf5e1e195f1aaaa7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f7621c4130b1dcb10f6a36951fc3b95ec4456f99":["f7961006605708cac1ca5185ead37902442ceff6"],"bc7017b45dd72c4f5934b1062dbd3bc6e9446eb9":["42a7d0b384f0022c5a29e562b809ebf73991d7e6"],"3afaca6e0770734b01e3bc663bec3ffa71b6f87b":["6e5d88b55f1b57feab6da94a5c635a224539bd2a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d7052f725a053aa55424f966831826f61b798bf1"]},"commit2Childs":{"d7052f725a053aa55424f966831826f61b798bf1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"18a2a015b86d022024b2b712bd8b607afccbb881":["fc97c3750bb1acfa4dc8d7289e664ac0210c4f93"],"91109046a59c58ee0ee5d0d2767b08d1f30d6702":["3e745568eabfe0f163a0eddb52ef01a6a8404656"],"693a4c06f749274d170a2e87d4afb2709a810f46":["cdd9b8e9a06bef873bf7e2c3b6664511a54f6485"],"e7fb6d70db034a5456ae560175dd1b821eea9ff4":["6a6f7a120a46dc36dbda9d77bf01a0770cf3136e"],"7a2ebafe4b791cc3938e53b13379dc7b19ba1f75":["db628922a5eb84f4c7e097a23b99c6fcfc46e084"],"db628922a5eb84f4c7e097a23b99c6fcfc46e084":["d7052f725a053aa55424f966831826f61b798bf1"],"cdd9b8e9a06bef873bf7e2c3b6664511a54f6485":["8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1"],"6263f219dcdfc6e861ecffaecf5e1e195f1aaaa7":["6e5d88b55f1b57feab6da94a5c635a224539bd2a"],"42a7d0b384f0022c5a29e562b809ebf73991d7e6":["bc7017b45dd72c4f5934b1062dbd3bc6e9446eb9"],"8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1":["18a2a015b86d022024b2b712bd8b607afccbb881"],"fc97c3750bb1acfa4dc8d7289e664ac0210c4f93":["e7fb6d70db034a5456ae560175dd1b821eea9ff4"],"3e745568eabfe0f163a0eddb52ef01a6a8404656":["8ac4052920fcd27b00a09b0f354a72da109d5d01"],"6a6f7a120a46dc36dbda9d77bf01a0770cf3136e":["f7961006605708cac1ca5185ead37902442ceff6"],"8ac4052920fcd27b00a09b0f354a72da109d5d01":["693a4c06f749274d170a2e87d4afb2709a810f46"],"f7961006605708cac1ca5185ead37902442ceff6":["f7621c4130b1dcb10f6a36951fc3b95ec4456f99"],"79fc67d5cdece593cd3b3b6c7ef195ee2625522c":["6263f219dcdfc6e861ecffaecf5e1e195f1aaaa7"],"6e5d88b55f1b57feab6da94a5c635a224539bd2a":["3afaca6e0770734b01e3bc663bec3ffa71b6f87b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["91109046a59c58ee0ee5d0d2767b08d1f30d6702"],"f7621c4130b1dcb10f6a36951fc3b95ec4456f99":["42a7d0b384f0022c5a29e562b809ebf73991d7e6"],"bc7017b45dd72c4f5934b1062dbd3bc6e9446eb9":["79fc67d5cdece593cd3b3b6c7ef195ee2625522c"],"3afaca6e0770734b01e3bc663bec3ffa71b6f87b":["7a2ebafe4b791cc3938e53b13379dc7b19ba1f75"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}