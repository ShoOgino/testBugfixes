{"path":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","commits":[{"id":"d26db6980435280d32792a7ddd3e26866ac98ea9","date":1042658704,"type":0,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"/dev/null","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.elementAt(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(searcher.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n      \n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n      \n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n      \n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n     \n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      fieldNormExpl.setValue(Similarity.decodeNorm(reader.norms(field)[doc]));\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n      \n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["9f504eb84bde3aa0d1d67d3b08172306897f39a9","9f504eb84bde3aa0d1d67d3b08172306897f39a9","f8da75c64a26663199511eef8db650621ed89107","f8da75c64a26663199511eef8db650621ed89107"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bbebaf78cc3b33d7a0520f7b9a5cd0324b5065ae","date":1071527173,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.elementAt(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(searcher.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n      \n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n      \n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n      \n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n     \n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n      \n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.elementAt(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(searcher.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n      \n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n      \n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n      \n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n     \n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      fieldNormExpl.setValue(Similarity.decodeNorm(reader.norms(field)[doc]));\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n      \n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"402061809f3a4629ea0c449e33e9f94a9772f3c3","date":1113967712,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.elementAt(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n      \n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n      \n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n      \n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n     \n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n      \n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.elementAt(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(searcher.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n      \n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n      \n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n      \n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n     \n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n      \n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":["f8da75c64a26663199511eef8db650621ed89107","f8da75c64a26663199511eef8db650621ed89107"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"df8dadf22de84eeb1294e70792e292ecf8ded564","date":1130577981,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.elementAt(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.elementAt(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n      \n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n      \n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n      \n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n     \n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n      \n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"19f758d6efad251890e720eb5370329f6ab5b509","date":1217253519,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.elementAt(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"20a9b2ec0ed5b7e0156b6707e34eb285cb86eb7a","date":1240951127,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 0.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"052fac7830290bd38a04cddee1a121ee07656b56","date":1245780702,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader, true, false).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8d6c98c690b593cea727f68742684c979ead1a0a","date":1248688202,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExpl = scorer(reader, true, false).explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe941135bdfc28c81e20b4d21422f8726af34925","date":1250040150,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(Searcher,IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    public Explanation explain(Searcher searcher, IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"231941d2cb96b9752e839c311391096d90470db8","date":1251116803,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(Searcher,IndexReader,int).mjava","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(Searcher searcher, IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8da75c64a26663199511eef8db650621ed89107","date":1251204606,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      docFreqs.append(idfExp.explain());\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \":\" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          docFreqs.append(\" \");\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        docFreqs.append(term.text());\n        docFreqs.append(\"=\");\n        docFreqs.append(reader.docFreq(term));\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \": \" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":["402061809f3a4629ea0c449e33e9f94a9772f3c3","d26db6980435280d32792a7ddd3e26866ac98ea9"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4625cb7ffd7c9caaf2d62b206ba9a382d68da82c","date":1254521470,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuilder docFreqs = new StringBuilder();\n      StringBuilder query = new StringBuilder();\n      query.append('\\\"');\n      docFreqs.append(idfExp.explain());\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \":\" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuffer docFreqs = new StringBuffer();\n      StringBuffer query = new StringBuffer();\n      query.append('\\\"');\n      docFreqs.append(idfExp.explain());\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \":\" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ef82ff03e4016c705811b2658e81471a645c0e49","date":1255900293,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuilder docFreqs = new StringBuilder();\n      StringBuilder query = new StringBuilder();\n      query.append('\\\"');\n      docFreqs.append(idfExp.explain());\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          query.append(\" \");\n        }\n\n        Term term = terms.get(i);\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \":\" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuilder docFreqs = new StringBuilder();\n      StringBuilder query = new StringBuilder();\n      query.append('\\\"');\n      docFreqs.append(idfExp.explain());\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          query.append(\" \");\n        }\n\n        Term term = (Term)terms.get(i);\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \":\" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"486cfd5a3f7481938475c113415d896f7a74a4a9","date":1256682581,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuilder docFreqs = new StringBuilder();\n      StringBuilder query = new StringBuilder();\n      query.append('\\\"');\n      docFreqs.append(idfExp.explain());\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          query.append(\" \");\n        }\n\n        Term term = terms.get(i);\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \":\" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      PhraseScorer scorer = (PhraseScorer) scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExplanation = new Explanation();\n      int d = scorer.advance(doc);\n      float phraseFreq = (d == doc) ? scorer.currentFreq() : 0.0f;\n      tfExplanation.setValue(similarity.tf(phraseFreq));\n      tfExplanation.setDescription(\"tf(phraseFreq=\" + phraseFreq + \")\");\n      \n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuilder docFreqs = new StringBuilder();\n      StringBuilder query = new StringBuilder();\n      query.append('\\\"');\n      docFreqs.append(idfExp.explain());\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          query.append(\" \");\n        }\n\n        Term term = terms.get(i);\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \":\" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      Scorer scorer = scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExpl = scorer.explain(doc);\n      fieldExpl.addDetail(tfExpl);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExpl.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b0eb5b0b5b98c777dad412afbfb347d2c0889327","date":1259094367,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuilder docFreqs = new StringBuilder();\n      StringBuilder query = new StringBuilder();\n      query.append('\\\"');\n      docFreqs.append(idfExp.explain());\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          query.append(\" \");\n        }\n\n        Term term = terms.get(i);\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \":\" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      PhraseScorer scorer = (PhraseScorer) scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExplanation = new Explanation();\n      int d = scorer.advance(doc);\n      float phraseFreq = (d == doc) ? scorer.currentFreq() : 0.0f;\n      tfExplanation.setValue(similarity.tf(phraseFreq));\n      tfExplanation.setDescription(\"tf(phraseFreq=\" + phraseFreq + \")\");\n      \n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuilder docFreqs = new StringBuilder();\n      StringBuilder query = new StringBuilder();\n      query.append('\\\"');\n      docFreqs.append(idfExp.explain());\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          query.append(\" \");\n        }\n\n        Term term = terms.get(i);\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \":\" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      PhraseScorer scorer = (PhraseScorer) scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExplanation = new Explanation();\n      int d = scorer.advance(doc);\n      float phraseFreq = (d == doc) ? scorer.currentFreq() : 0.0f;\n      tfExplanation.setValue(similarity.tf(phraseFreq));\n      tfExplanation.setDescription(\"tf(phraseFreq=\" + phraseFreq + \")\");\n      \n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? Similarity.decodeNorm(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/PhraseQuery.PhraseWeight#explain(IndexReader,int).mjava","sourceNew":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuilder docFreqs = new StringBuilder();\n      StringBuilder query = new StringBuilder();\n      query.append('\\\"');\n      docFreqs.append(idfExp.explain());\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          query.append(\" \");\n        }\n\n        Term term = terms.get(i);\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \":\" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      PhraseScorer scorer = (PhraseScorer) scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExplanation = new Explanation();\n      int d = scorer.advance(doc);\n      float phraseFreq = (d == doc) ? scorer.currentFreq() : 0.0f;\n      tfExplanation.setValue(similarity.tf(phraseFreq));\n      tfExplanation.setDescription(\"tf(phraseFreq=\" + phraseFreq + \")\");\n      \n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      Explanation result = new Explanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      StringBuilder docFreqs = new StringBuilder();\n      StringBuilder query = new StringBuilder();\n      query.append('\\\"');\n      docFreqs.append(idfExp.explain());\n      for (int i = 0; i < terms.size(); i++) {\n        if (i != 0) {\n          query.append(\" \");\n        }\n\n        Term term = terms.get(i);\n\n        query.append(term.text());\n      }\n      query.append('\\\"');\n\n      Explanation idfExpl =\n        new Explanation(idf, \"idf(\" + field + \":\" + docFreqs + \")\");\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(idfExpl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         idfExpl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      Explanation fieldExpl = new Explanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+field+\":\"+query+\" in \"+doc+\n                               \"), product of:\");\n\n      PhraseScorer scorer = (PhraseScorer) scorer(reader, true, false);\n      if (scorer == null) {\n        return new Explanation(0.0f, \"no matching docs\");\n      }\n      Explanation tfExplanation = new Explanation();\n      int d = scorer.advance(doc);\n      float phraseFreq = (d == doc) ? scorer.currentFreq() : 0.0f;\n      tfExplanation.setValue(similarity.tf(phraseFreq));\n      tfExplanation.setDescription(\"tf(phraseFreq=\" + phraseFreq + \")\");\n      \n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(idfExpl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         idfExpl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n\n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"20a9b2ec0ed5b7e0156b6707e34eb285cb86eb7a":["19f758d6efad251890e720eb5370329f6ab5b509"],"231941d2cb96b9752e839c311391096d90470db8":["fe941135bdfc28c81e20b4d21422f8726af34925"],"fe941135bdfc28c81e20b4d21422f8726af34925":["8d6c98c690b593cea727f68742684c979ead1a0a"],"b0eb5b0b5b98c777dad412afbfb347d2c0889327":["486cfd5a3f7481938475c113415d896f7a74a4a9"],"486cfd5a3f7481938475c113415d896f7a74a4a9":["ef82ff03e4016c705811b2658e81471a645c0e49"],"bbebaf78cc3b33d7a0520f7b9a5cd0324b5065ae":["d26db6980435280d32792a7ddd3e26866ac98ea9"],"19f758d6efad251890e720eb5370329f6ab5b509":["df8dadf22de84eeb1294e70792e292ecf8ded564"],"df8dadf22de84eeb1294e70792e292ecf8ded564":["402061809f3a4629ea0c449e33e9f94a9772f3c3"],"402061809f3a4629ea0c449e33e9f94a9772f3c3":["bbebaf78cc3b33d7a0520f7b9a5cd0324b5065ae"],"ef82ff03e4016c705811b2658e81471a645c0e49":["4625cb7ffd7c9caaf2d62b206ba9a382d68da82c"],"f8da75c64a26663199511eef8db650621ed89107":["231941d2cb96b9752e839c311391096d90470db8"],"d26db6980435280d32792a7ddd3e26866ac98ea9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8d6c98c690b593cea727f68742684c979ead1a0a":["052fac7830290bd38a04cddee1a121ee07656b56"],"4625cb7ffd7c9caaf2d62b206ba9a382d68da82c":["f8da75c64a26663199511eef8db650621ed89107"],"052fac7830290bd38a04cddee1a121ee07656b56":["20a9b2ec0ed5b7e0156b6707e34eb285cb86eb7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["b0eb5b0b5b98c777dad412afbfb347d2c0889327"]},"commit2Childs":{"20a9b2ec0ed5b7e0156b6707e34eb285cb86eb7a":["052fac7830290bd38a04cddee1a121ee07656b56"],"231941d2cb96b9752e839c311391096d90470db8":["f8da75c64a26663199511eef8db650621ed89107"],"fe941135bdfc28c81e20b4d21422f8726af34925":["231941d2cb96b9752e839c311391096d90470db8"],"b0eb5b0b5b98c777dad412afbfb347d2c0889327":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"486cfd5a3f7481938475c113415d896f7a74a4a9":["b0eb5b0b5b98c777dad412afbfb347d2c0889327"],"bbebaf78cc3b33d7a0520f7b9a5cd0324b5065ae":["402061809f3a4629ea0c449e33e9f94a9772f3c3"],"19f758d6efad251890e720eb5370329f6ab5b509":["20a9b2ec0ed5b7e0156b6707e34eb285cb86eb7a"],"df8dadf22de84eeb1294e70792e292ecf8ded564":["19f758d6efad251890e720eb5370329f6ab5b509"],"402061809f3a4629ea0c449e33e9f94a9772f3c3":["df8dadf22de84eeb1294e70792e292ecf8ded564"],"ef82ff03e4016c705811b2658e81471a645c0e49":["486cfd5a3f7481938475c113415d896f7a74a4a9"],"d26db6980435280d32792a7ddd3e26866ac98ea9":["bbebaf78cc3b33d7a0520f7b9a5cd0324b5065ae"],"f8da75c64a26663199511eef8db650621ed89107":["4625cb7ffd7c9caaf2d62b206ba9a382d68da82c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d26db6980435280d32792a7ddd3e26866ac98ea9"],"8d6c98c690b593cea727f68742684c979ead1a0a":["fe941135bdfc28c81e20b4d21422f8726af34925"],"4625cb7ffd7c9caaf2d62b206ba9a382d68da82c":["ef82ff03e4016c705811b2658e81471a645c0e49"],"052fac7830290bd38a04cddee1a121ee07656b56":["8d6c98c690b593cea727f68742684c979ead1a0a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}