{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","commits":[{"id":"81cc37e458a3bdbe82fc7b807a5d1a59b06f9191","date":1296158863,"type":0,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"/dev/null","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDiviso, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"MockRandom\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setReaderTermsIndexDivisor(-1);\n    \n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f3256444578be405b4ed2ca10bb2b40153586443","date":1296192335,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDiviso, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"MockRandom\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setReaderTermsIndexDivisor(-1);\n    \n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eb378f8bdee16a26810e086303a4a86b4930ea12","date":1296410797,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"/dev/null","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"/dev/null","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc","date":1308411958,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n    illegalCodecs.add(\"Memory\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","date":1308439813,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n    illegalCodecs.add(\"Memory\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n    illegalCodecs.add(\"Memory\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new TextField(\"f\", \"val\"));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n    illegalCodecs.add(\"Memory\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new Field(\"f\", \"val\", Store.NO, Index.ANALYZED));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    assumeFalse(\"PreFlex codec does not support ReaderTermsIndexDivisor!\", \n        \"Lucene3x\".equals(Codec.getDefault().getName()));\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    \n    // Don't proceed if picked Codec is in the list of illegal ones.\n    final String format = _TestUtil.getPostingsFormat(\"f\");\n    assumeFalse(\"Format: \" + format + \" does not support ReaderTermsIndexDivisor!\",\n        (format.equals(\"SimpleText\") || format.equals(\"Memory\")));\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new TextField(\"f\", \"val\"));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded.\");\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    HashSet<String> illegalCodecs = new HashSet<String>();\n    illegalCodecs.add(\"PreFlex\");\n    illegalCodecs.add(\"SimpleText\");\n    illegalCodecs.add(\"Memory\");\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    // Don't proceed if picked Codec is in the list of illegal ones.\n    if (illegalCodecs.contains(conf.getCodecProvider().getFieldCodec(\"f\"))) return;\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new TextField(\"f\", \"val\"));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded. Codec used \" + conf.getCodecProvider().getFieldCodec(\"f\"));\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    assumeFalse(\"PreFlex codec does not support ReaderTermsIndexDivisor!\", \n        \"Lucene3x\".equals(Codec.getDefault().getName()));\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    \n    // Don't proceed if picked Codec is in the list of illegal ones.\n    final String format = _TestUtil.getPostingsFormat(\"f\");\n    assumeFalse(\"Format: \" + format + \" does not support ReaderTermsIndexDivisor!\",\n        (format.equals(\"SimpleText\") || format.equals(\"Memory\")));\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new TextField(\"f\", \"val\"));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      _TestUtil.docs(random, r, \"f\", new BytesRef(\"val\"), null, null, false);\n      fail(\"should have failed to seek since terms index was not loaded.\");\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    assumeFalse(\"PreFlex codec does not support ReaderTermsIndexDivisor!\", \n        \"Lucene3x\".equals(Codec.getDefault().getName()));\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    \n    // Don't proceed if picked Codec is in the list of illegal ones.\n    final String format = _TestUtil.getPostingsFormat(\"f\");\n    assumeFalse(\"Format: \" + format + \" does not support ReaderTermsIndexDivisor!\",\n        (format.equals(\"SimpleText\") || format.equals(\"Memory\")));\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new TextField(\"f\", \"val\"));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded.\");\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    assumeFalse(\"PreFlex codec does not support ReaderTermsIndexDivisor!\", \n        \"Lucene3x\".equals(Codec.getDefault().getName()));\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    \n    // Don't proceed if picked Codec is in the list of illegal ones.\n    final String format = _TestUtil.getPostingsFormat(\"f\");\n    assumeFalse(\"Format: \" + format + \" does not support ReaderTermsIndexDivisor!\",\n        (format.equals(\"SimpleText\") || format.equals(\"Memory\")));\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new TextField(\"f\", \"val\"));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      _TestUtil.docs(random, r, \"f\", new BytesRef(\"val\"), null, null, false);\n      fail(\"should have failed to seek since terms index was not loaded.\");\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    assumeFalse(\"PreFlex codec does not support ReaderTermsIndexDivisor!\", \n        \"Lucene3x\".equals(Codec.getDefault().getName()));\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    \n    // Don't proceed if picked Codec is in the list of illegal ones.\n    final String format = _TestUtil.getPostingsFormat(\"f\");\n    assumeFalse(\"Format: \" + format + \" does not support ReaderTermsIndexDivisor!\",\n        (format.equals(\"SimpleText\") || format.equals(\"Memory\")));\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new TextField(\"f\", \"val\"));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      r.termDocsEnum(null, \"f\", new BytesRef(\"val\"));\n      fail(\"should have failed to seek since terms index was not loaded.\");\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testNoTermsIndex().mjava","sourceNew":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    assumeFalse(\"PreFlex codec does not support ReaderTermsIndexDivisor!\", \n        \"Lucene3x\".equals(Codec.getDefault().getName()));\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    \n    // Don't proceed if picked Codec is in the list of illegal ones.\n    final String format = _TestUtil.getPostingsFormat(\"f\");\n    assumeFalse(\"Format: \" + format + \" does not support ReaderTermsIndexDivisor!\",\n        (format.equals(\"SimpleText\") || format.equals(\"Memory\")));\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new TextField(\"f\", \"val\"));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      _TestUtil.docs(random, r, \"f\", new BytesRef(\"val\"), null, null, false);\n      fail(\"should have failed to seek since terms index was not loaded.\");\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testNoTermsIndex() throws Exception {\n    // Some Codecs don't honor the ReaderTermsIndexDivisor, so skip the test if\n    // they're picked.\n    assumeFalse(\"PreFlex codec does not support ReaderTermsIndexDivisor!\", \n        \"Lucene3x\".equals(Codec.getDefault().getName()));\n\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setReaderTermsIndexDivisor(-1);\n    \n    // Don't proceed if picked Codec is in the list of illegal ones.\n    final String format = _TestUtil.getPostingsFormat(\"f\");\n    assumeFalse(\"Format: \" + format + \" does not support ReaderTermsIndexDivisor!\",\n        (format.equals(\"SimpleText\") || format.equals(\"Memory\")));\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, conf);\n    Document doc = new Document();\n    doc.add(new TextField(\"f\", \"val\"));\n    w.addDocument(doc);\n    IndexReader r = IndexReader.open(w, true).getSequentialSubReaders()[0];\n    try {\n      _TestUtil.docs(random, r, \"f\", new BytesRef(\"val\"), null, null, false);\n      fail(\"should have failed to seek since terms index was not loaded.\");\n    } catch (IllegalStateException e) {\n      // expected - we didn't load the term index\n    } finally {\n      r.close();\n      w.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["7b91922b55d15444d554721b352861d028eb8278"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"eb378f8bdee16a26810e086303a4a86b4930ea12":["f3256444578be405b4ed2ca10bb2b40153586443"],"7b91922b55d15444d554721b352861d028eb8278":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"81cc37e458a3bdbe82fc7b807a5d1a59b06f9191":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886":["a3776dccca01c11e7046323cfad46a3b4a471233","7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["eb378f8bdee16a26810e086303a4a86b4930ea12"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["7b91922b55d15444d554721b352861d028eb8278","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"a3776dccca01c11e7046323cfad46a3b4a471233":["eb378f8bdee16a26810e086303a4a86b4930ea12","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","eb378f8bdee16a26810e086303a4a86b4930ea12"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f3256444578be405b4ed2ca10bb2b40153586443":["81cc37e458a3bdbe82fc7b807a5d1a59b06f9191"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","eb378f8bdee16a26810e086303a4a86b4930ea12"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc":["f2c5f0cb44df114db4228c8f77861714b5cabaea"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"962d04139994fce5193143ef35615499a9a96d78":[],"eb378f8bdee16a26810e086303a4a86b4930ea12":["f2c5f0cb44df114db4228c8f77861714b5cabaea","a3776dccca01c11e7046323cfad46a3b4a471233","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"7b91922b55d15444d554721b352861d028eb8278":["872cff1d3a554e0cd64014cd97f88d3002b0f491","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"81cc37e458a3bdbe82fc7b807a5d1a59b06f9191":["f3256444578be405b4ed2ca10bb2b40153586443"],"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886":[],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a3776dccca01c11e7046323cfad46a3b4a471233":["d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["81cc37e458a3bdbe82fc7b807a5d1a59b06f9191","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"f3256444578be405b4ed2ca10bb2b40153586443":["eb378f8bdee16a26810e086303a4a86b4930ea12"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7b91922b55d15444d554721b352861d028eb8278"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc":["d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","b65b350ca9588f9fc76ce7d6804160d06c45ff42","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}