{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#writeSomeDocValuesUpdates().mjava","commits":[{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#writeSomeDocValuesUpdates().mjava","pathOld":"/dev/null","sourceNew":"    void writeSomeDocValuesUpdates() throws IOException {\n\n      assert Thread.holdsLock(IndexWriter.this) == false;\n\n      if (writeDocValuesLock.compareAndSet(false, true)) {\n        try {\n\n          LiveIndexWriterConfig config = getConfig();\n          double mb = config.getRAMBufferSizeMB();\n          // If the reader pool is > 50% of our IW buffer, then write the updates:\n          if (mb != IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n            long startNS = System.nanoTime();\n            \n            long ramBytesUsed = ramBytesUsed();\n            if (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                                                       ramBytesUsed/1024./1024., mb));\n              }\n          \n              // Sort by largest ramBytesUsed:\n              PriorityQueue<ReadersAndUpdates> queue = new PriorityQueue<>(readerMap.size(), (a, b) -> Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n              synchronized (this) {\n                for (ReadersAndUpdates rld : readerMap.values()) {\n                  queue.add(rld);\n                }\n              }\n\n              int count = 0;\n              while (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n                ReadersAndUpdates rld = queue.poll();\n                if (rld == null) {\n                  break;\n                }\n\n                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n                // not all of those bytes can be written here:\n                long bytesUsedBefore = rld.ramBytesUsed.get();\n\n                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n                // other threads get a chance to run in between our writes.\n                synchronized (IndexWriter.this) {\n                  rld.writeFieldUpdates(directory, bufferedUpdatesStream.getCompletedDelGen(), infoStream);\n                }\n                long bytesUsedAfter = rld.ramBytesUsed.get();\n                ramBytesUsed -= bytesUsedBefore - bytesUsedAfter;\n                count++;\n              }\n\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n              }\n            }\n          }\n        } finally {\n          writeDocValuesLock.set(false);\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#writeSomeDocValuesUpdates().mjava","pathOld":"/dev/null","sourceNew":"    void writeSomeDocValuesUpdates() throws IOException {\n\n      assert Thread.holdsLock(IndexWriter.this) == false;\n\n      if (writeDocValuesLock.compareAndSet(false, true)) {\n        try {\n\n          LiveIndexWriterConfig config = getConfig();\n          double mb = config.getRAMBufferSizeMB();\n          // If the reader pool is > 50% of our IW buffer, then write the updates:\n          if (mb != IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n            long startNS = System.nanoTime();\n            \n            long ramBytesUsed = ramBytesUsed();\n            if (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                                                       ramBytesUsed/1024./1024., mb));\n              }\n          \n              // Sort by largest ramBytesUsed:\n              PriorityQueue<ReadersAndUpdates> queue = new PriorityQueue<>(readerMap.size(), (a, b) -> Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n              synchronized (this) {\n                for (ReadersAndUpdates rld : readerMap.values()) {\n                  queue.add(rld);\n                }\n              }\n\n              int count = 0;\n              while (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n                ReadersAndUpdates rld = queue.poll();\n                if (rld == null) {\n                  break;\n                }\n\n                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n                // not all of those bytes can be written here:\n                long bytesUsedBefore = rld.ramBytesUsed.get();\n\n                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n                // other threads get a chance to run in between our writes.\n                synchronized (IndexWriter.this) {\n                  rld.writeFieldUpdates(directory, bufferedUpdatesStream.getCompletedDelGen(), infoStream);\n                }\n                long bytesUsedAfter = rld.ramBytesUsed.get();\n                ramBytesUsed -= bytesUsedBefore - bytesUsedAfter;\n                count++;\n              }\n\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n              }\n            }\n          }\n        } finally {\n          writeDocValuesLock.set(false);\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#writeSomeDocValuesUpdates().mjava","pathOld":"/dev/null","sourceNew":"    void writeSomeDocValuesUpdates() throws IOException {\n\n      assert Thread.holdsLock(IndexWriter.this) == false;\n\n      if (writeDocValuesLock.compareAndSet(false, true)) {\n        try {\n\n          LiveIndexWriterConfig config = getConfig();\n          double mb = config.getRAMBufferSizeMB();\n          // If the reader pool is > 50% of our IW buffer, then write the updates:\n          if (mb != IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n            long startNS = System.nanoTime();\n            \n            long ramBytesUsed = ramBytesUsed();\n            if (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                                                       ramBytesUsed/1024./1024., mb));\n              }\n          \n              // Sort by largest ramBytesUsed:\n              PriorityQueue<ReadersAndUpdates> queue = new PriorityQueue<>(readerMap.size(), (a, b) -> Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n              synchronized (this) {\n                for (ReadersAndUpdates rld : readerMap.values()) {\n                  queue.add(rld);\n                }\n              }\n\n              int count = 0;\n              while (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n                ReadersAndUpdates rld = queue.poll();\n                if (rld == null) {\n                  break;\n                }\n\n                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n                // not all of those bytes can be written here:\n                long bytesUsedBefore = rld.ramBytesUsed.get();\n\n                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n                // other threads get a chance to run in between our writes.\n                synchronized (IndexWriter.this) {\n                  rld.writeFieldUpdates(directory, bufferedUpdatesStream.getCompletedDelGen(), infoStream);\n                }\n                long bytesUsedAfter = rld.ramBytesUsed.get();\n                ramBytesUsed -= bytesUsedBefore - bytesUsedAfter;\n                count++;\n              }\n\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n              }\n            }\n          }\n        } finally {\n          writeDocValuesLock.set(false);\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d60c1bb96a28a26d197c36299f7b6c9c5da617a1","date":1522484702,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#writeSomeDocValuesUpdates().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#writeSomeDocValuesUpdates().mjava","sourceNew":"    void writeSomeDocValuesUpdates() throws IOException {\n\n      assert Thread.holdsLock(IndexWriter.this) == false;\n\n      if (writeDocValuesLock.compareAndSet(false, true)) {\n        try {\n\n          LiveIndexWriterConfig config = getConfig();\n          double mb = config.getRAMBufferSizeMB();\n          // If the reader pool is > 50% of our IW buffer, then write the updates:\n          if (mb != IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n            long startNS = System.nanoTime();\n            \n            long ramBytesUsed = ramBytesUsed();\n            if (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                                                       ramBytesUsed/1024./1024., mb));\n              }\n          \n              // Sort by largest ramBytesUsed:\n              PriorityQueue<ReadersAndUpdates> queue = new PriorityQueue<>(readerMap.size(), (a, b) -> Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n              synchronized (this) {\n                for (ReadersAndUpdates rld : readerMap.values()) {\n                  queue.add(rld);\n                }\n              }\n\n              int count = 0;\n              while (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n                ReadersAndUpdates rld = queue.poll();\n                if (rld == null) {\n                  break;\n                }\n\n                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n                // not all of those bytes can be written here:\n                long bytesUsedBefore = rld.ramBytesUsed.get();\n\n                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n                // other threads get a chance to run in between our writes.\n                synchronized (IndexWriter.this) {\n                  if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n                    checkpointNoSIS();\n                  }\n                }\n                long bytesUsedAfter = rld.ramBytesUsed.get();\n                ramBytesUsed -= bytesUsedBefore - bytesUsedAfter;\n                count++;\n              }\n\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n              }\n            }\n          }\n        } finally {\n          writeDocValuesLock.set(false);\n        }\n      }\n    }\n\n","sourceOld":"    void writeSomeDocValuesUpdates() throws IOException {\n\n      assert Thread.holdsLock(IndexWriter.this) == false;\n\n      if (writeDocValuesLock.compareAndSet(false, true)) {\n        try {\n\n          LiveIndexWriterConfig config = getConfig();\n          double mb = config.getRAMBufferSizeMB();\n          // If the reader pool is > 50% of our IW buffer, then write the updates:\n          if (mb != IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n            long startNS = System.nanoTime();\n            \n            long ramBytesUsed = ramBytesUsed();\n            if (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                                                       ramBytesUsed/1024./1024., mb));\n              }\n          \n              // Sort by largest ramBytesUsed:\n              PriorityQueue<ReadersAndUpdates> queue = new PriorityQueue<>(readerMap.size(), (a, b) -> Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n              synchronized (this) {\n                for (ReadersAndUpdates rld : readerMap.values()) {\n                  queue.add(rld);\n                }\n              }\n\n              int count = 0;\n              while (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n                ReadersAndUpdates rld = queue.poll();\n                if (rld == null) {\n                  break;\n                }\n\n                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n                // not all of those bytes can be written here:\n                long bytesUsedBefore = rld.ramBytesUsed.get();\n\n                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n                // other threads get a chance to run in between our writes.\n                synchronized (IndexWriter.this) {\n                  rld.writeFieldUpdates(directory, bufferedUpdatesStream.getCompletedDelGen(), infoStream);\n                }\n                long bytesUsedAfter = rld.ramBytesUsed.get();\n                ramBytesUsed -= bytesUsedBefore - bytesUsedAfter;\n                count++;\n              }\n\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n              }\n            }\n          }\n        } finally {\n          writeDocValuesLock.set(false);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa5e39259dfd4a68287c824d3b7e1bc9097dc895","date":1522505041,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#writeSomeDocValuesUpdates().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#writeSomeDocValuesUpdates().mjava","sourceNew":"    void writeSomeDocValuesUpdates() throws IOException {\n\n      assert Thread.holdsLock(IndexWriter.this) == false;\n\n      if (writeDocValuesLock.compareAndSet(false, true)) {\n        try {\n\n          LiveIndexWriterConfig config = getConfig();\n          double mb = config.getRAMBufferSizeMB();\n          // If the reader pool is > 50% of our IW buffer, then write the updates:\n          if (mb != IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n            long startNS = System.nanoTime();\n            \n            long ramBytesUsed = ramBytesUsed();\n            if (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                                                       ramBytesUsed/1024./1024., mb));\n              }\n          \n              // Sort by largest ramBytesUsed:\n              PriorityQueue<ReadersAndUpdates> queue = new PriorityQueue<>(readerMap.size(), (a, b) -> Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n              synchronized (this) {\n                for (ReadersAndUpdates rld : readerMap.values()) {\n                  queue.add(rld);\n                }\n              }\n\n              int count = 0;\n              while (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n                ReadersAndUpdates rld = queue.poll();\n                if (rld == null) {\n                  break;\n                }\n\n                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n                // not all of those bytes can be written here:\n                long bytesUsedBefore = rld.ramBytesUsed.get();\n\n                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n                // other threads get a chance to run in between our writes.\n                synchronized (IndexWriter.this) {\n                  if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n                    checkpointNoSIS();\n                  }\n                }\n                long bytesUsedAfter = rld.ramBytesUsed.get();\n                ramBytesUsed -= bytesUsedBefore - bytesUsedAfter;\n                count++;\n              }\n\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n              }\n            }\n          }\n        } finally {\n          writeDocValuesLock.set(false);\n        }\n      }\n    }\n\n","sourceOld":"    void writeSomeDocValuesUpdates() throws IOException {\n\n      assert Thread.holdsLock(IndexWriter.this) == false;\n\n      if (writeDocValuesLock.compareAndSet(false, true)) {\n        try {\n\n          LiveIndexWriterConfig config = getConfig();\n          double mb = config.getRAMBufferSizeMB();\n          // If the reader pool is > 50% of our IW buffer, then write the updates:\n          if (mb != IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n            long startNS = System.nanoTime();\n            \n            long ramBytesUsed = ramBytesUsed();\n            if (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                                                       ramBytesUsed/1024./1024., mb));\n              }\n          \n              // Sort by largest ramBytesUsed:\n              PriorityQueue<ReadersAndUpdates> queue = new PriorityQueue<>(readerMap.size(), (a, b) -> Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n              synchronized (this) {\n                for (ReadersAndUpdates rld : readerMap.values()) {\n                  queue.add(rld);\n                }\n              }\n\n              int count = 0;\n              while (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n                ReadersAndUpdates rld = queue.poll();\n                if (rld == null) {\n                  break;\n                }\n\n                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n                // not all of those bytes can be written here:\n                long bytesUsedBefore = rld.ramBytesUsed.get();\n\n                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n                // other threads get a chance to run in between our writes.\n                synchronized (IndexWriter.this) {\n                  rld.writeFieldUpdates(directory, bufferedUpdatesStream.getCompletedDelGen(), infoStream);\n                }\n                long bytesUsedAfter = rld.ramBytesUsed.get();\n                ramBytesUsed -= bytesUsedBefore - bytesUsedAfter;\n                count++;\n              }\n\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n              }\n            }\n          }\n        } finally {\n          writeDocValuesLock.set(false);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1926100d9b67becc9701c54266fee3ba7878a5f0","date":1524472150,"type":4,"author":"Simon Willnauer","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter.ReaderPool#writeSomeDocValuesUpdates().mjava","sourceNew":null,"sourceOld":"    void writeSomeDocValuesUpdates() throws IOException {\n\n      assert Thread.holdsLock(IndexWriter.this) == false;\n\n      if (writeDocValuesLock.compareAndSet(false, true)) {\n        try {\n\n          LiveIndexWriterConfig config = getConfig();\n          double mb = config.getRAMBufferSizeMB();\n          // If the reader pool is > 50% of our IW buffer, then write the updates:\n          if (mb != IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n            long startNS = System.nanoTime();\n            \n            long ramBytesUsed = ramBytesUsed();\n            if (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                                                       ramBytesUsed/1024./1024., mb));\n              }\n          \n              // Sort by largest ramBytesUsed:\n              PriorityQueue<ReadersAndUpdates> queue = new PriorityQueue<>(readerMap.size(), (a, b) -> Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n              synchronized (this) {\n                for (ReadersAndUpdates rld : readerMap.values()) {\n                  queue.add(rld);\n                }\n              }\n\n              int count = 0;\n              while (ramBytesUsed > 0.5 * mb * 1024 * 1024) {\n                ReadersAndUpdates rld = queue.poll();\n                if (rld == null) {\n                  break;\n                }\n\n                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n                // not all of those bytes can be written here:\n                long bytesUsedBefore = rld.ramBytesUsed.get();\n\n                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n                // other threads get a chance to run in between our writes.\n                synchronized (IndexWriter.this) {\n                  if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n                    checkpointNoSIS();\n                  }\n                }\n                long bytesUsedAfter = rld.ramBytesUsed.get();\n                ramBytesUsed -= bytesUsedBefore - bytesUsedAfter;\n                count++;\n              }\n\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n              }\n            }\n          }\n        } finally {\n          writeDocValuesLock.set(false);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"aa5e39259dfd4a68287c824d3b7e1bc9097dc895":["28288370235ed02234a64753cdbf0c6ec096304a","d60c1bb96a28a26d197c36299f7b6c9c5da617a1"],"1926100d9b67becc9701c54266fee3ba7878a5f0":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895"],"d60c1bb96a28a26d197c36299f7b6c9c5da617a1":["28288370235ed02234a64753cdbf0c6ec096304a"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"28288370235ed02234a64753cdbf0c6ec096304a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1926100d9b67becc9701c54266fee3ba7878a5f0"]},"commit2Childs":{"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"aa5e39259dfd4a68287c824d3b7e1bc9097dc895":["1926100d9b67becc9701c54266fee3ba7878a5f0"],"d60c1bb96a28a26d197c36299f7b6c9c5da617a1":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895"],"1926100d9b67becc9701c54266fee3ba7878a5f0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"28288370235ed02234a64753cdbf0c6ec096304a":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895","d60c1bb96a28a26d197c36299f7b6c9c5da617a1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}