{"path":"lucene/core/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(200);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(200);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(),\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random())).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random(), 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(200);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random()) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random(), fieldTerms, reader);\n    doTestSeekDoesNotExist(random(), numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(200);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57ae3024996ccdb3c36c42cb890e1efb37df4ce8","date":1338343651,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(),\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random())).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random(), 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(200);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random()) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random(), fieldTerms, reader);\n    doTestSeekDoesNotExist(random(), numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"]},"commit2Childs":{"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}