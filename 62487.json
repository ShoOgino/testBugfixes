{"path":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","commits":[{"id":"b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c","date":1329188942,"type":0,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"/dev/null","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.getUniqueTermCount()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","sourceOld":null,"bugFix":null,"bugIntro":["8028ab7a24273833d53d35eb160dba5b57283cf5","963375a30a9056a39347c6f920c8b27c4e559212","df0329608a289015ef0887f776679127cbbfe71e","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    InvertedFields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.getUniqueTermCount()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.getUniqueTermCount()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.getUniqueTermCount()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    InvertedFields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.getUniqueTermCount()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","bugFix":null,"bugIntro":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bdb5e42b0cecd8dfb27767a02ada71899bf17917","date":1334100099,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.size()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.getUniqueTermCount()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5a238fc456663f685a9db1ed8d680e348bb45171","date":1334173266,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.size()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.getUniqueTermCount()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e1d3fc16fcae9731e1c7daeb852db4add07352d2","date":1334736427,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.size()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.size()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"963375a30a9056a39347c6f920c8b27c4e559212","date":1346952168,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.size()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.size()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n  //////////////////////// SolrInfoMBeans methods //////////////////////\n\n","bugFix":["b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0ba1867a94c748b12f005cba35453b6d7122e5d8","date":1373802105,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.size()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n        tiq.distinctTerms = new Long(terms.size()).intValue();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"df0329608a289015ef0887f776679127cbbfe71e","date":1375813587,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    final int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (numTerms > 0 && freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","bugFix":["b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","date":1376375609,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    final int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (numTerms > 0 && freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    final int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (numTerms > 0 && freq > tiq.minFreq) {\n        spare.copyUTF8Bytes(text);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    final int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRef spare = new CharsRef();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (numTerms > 0 && freq > tiq.minFreq) {\n        UnicodeUtil.UTF8toUTF16(text, spare);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","bugFix":["b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8028ab7a24273833d53d35eb160dba5b57283cf5","date":1416767720,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    final int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Terms terms = MultiFields.getTerms(req.getSearcher().getIndexReader(), field);\n    if (terms == null) {  // field does not exist\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (numTerms > 0 && freq > tiq.minFreq) {\n        spare.copyUTF8Bytes(text);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    final int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Fields fields = MultiFields.getFields(req.getSearcher().getIndexReader());\n\n    if (fields == null) { // No indexed fields\n      return;\n    }\n\n    Terms terms = fields.terms(field);\n    if (terms == null) {  // No terms in the field.\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (numTerms > 0 && freq > tiq.minFreq) {\n        spare.copyUTF8Bytes(text);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","bugFix":["b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c","e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    final int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Terms terms = MultiFields.getTerms(req.getSearcher().getIndexReader(), field);\n    if (terms == null) {  // field does not exist\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (numTerms > 0 && freq > tiq.minFreq) {\n        spare.copyUTF8Bytes(text);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    final int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Terms terms = MultiFields.getTerms(req.getSearcher().getIndexReader(), field);\n    if (terms == null) {  // field does not exist\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (numTerms > 0 && freq > tiq.minFreq) {\n        spare.copyUTF8Bytes(text);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04e775de416dd2d8067b10db1c8af975a1d5017e","date":1539906554,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler#getDetailedFieldInfo(SolrQueryRequest,String,SimpleOrderedMap[Object]).mjava","sourceNew":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    final int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Terms terms = MultiTerms.getTerms(req.getSearcher().getIndexReader(), field);\n    if (terms == null) {  // field does not exist\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (numTerms > 0 && freq > tiq.minFreq) {\n        spare.copyUTF8Bytes(text);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","sourceOld":"  // Get terribly detailed information about a particular field. This is a very expensive call, use it with caution\n  // especially on large indexes!\n  @SuppressWarnings(\"unchecked\")\n  private static void getDetailedFieldInfo(SolrQueryRequest req, String field, SimpleOrderedMap<Object> fieldMap)\n      throws IOException {\n\n    SolrParams params = req.getParams();\n    final int numTerms = params.getInt( NUMTERMS, DEFAULT_COUNT );\n\n    TopTermQueue tiq = new TopTermQueue(numTerms + 1);  // Something to collect the top N terms in.\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n\n    Terms terms = MultiFields.getTerms(req.getSearcher().getIndexReader(), field);\n    if (terms == null) {  // field does not exist\n      return;\n    }\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef text;\n    int[] buckets = new int[HIST_ARRAY_SIZE];\n    while ((text = termsEnum.next()) != null) {\n      ++tiq.distinctTerms;\n      int freq = termsEnum.docFreq();  // This calculation seems odd, but it gives the same results as it used to.\n      int slot = 32 - Integer.numberOfLeadingZeros(Math.max(0, freq - 1));\n      buckets[slot] = buckets[slot] + 1;\n      if (numTerms > 0 && freq > tiq.minFreq) {\n        spare.copyUTF8Bytes(text);\n        String t = spare.toString();\n\n        tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));\n        if (tiq.size() > numTerms) { // if tiq full\n          tiq.pop(); // remove lowest in tiq\n          tiq.minFreq = tiq.getTopTermInfo().docFreq;\n        }\n      }\n    }\n    tiq.histogram.add(buckets);\n    fieldMap.add(\"distinct\", tiq.distinctTerms);\n\n    // Include top terms\n    fieldMap.add(\"topTerms\", tiq.toNamedList(req.getSearcher().getSchema()));\n\n    // Add a histogram\n    fieldMap.add(\"histogram\", tiq.histogram.toNamedList());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":["37a0f60745e53927c4c876cfe5b5a58170f0646c","df0329608a289015ef0887f776679127cbbfe71e"],"bdb5e42b0cecd8dfb27767a02ada71899bf17917":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["963375a30a9056a39347c6f920c8b27c4e559212","0ba1867a94c748b12f005cba35453b6d7122e5d8"],"5a238fc456663f685a9db1ed8d680e348bb45171":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","bdb5e42b0cecd8dfb27767a02ada71899bf17917"],"df0329608a289015ef0887f776679127cbbfe71e":["0ba1867a94c748b12f005cba35453b6d7122e5d8"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["df0329608a289015ef0887f776679127cbbfe71e"],"b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e1d3fc16fcae9731e1c7daeb852db4add07352d2":["bdb5e42b0cecd8dfb27767a02ada71899bf17917"],"8028ab7a24273833d53d35eb160dba5b57283cf5":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0ba1867a94c748b12f005cba35453b6d7122e5d8":["963375a30a9056a39347c6f920c8b27c4e559212"],"963375a30a9056a39347c6f920c8b27c4e559212":["e1d3fc16fcae9731e1c7daeb852db4add07352d2"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["04e775de416dd2d8067b10db1c8af975a1d5017e"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":[],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["716d18f3a9b0993bc679d7fa7abdc9bfb03411ec"],"bdb5e42b0cecd8dfb27767a02ada71899bf17917":["5a238fc456663f685a9db1ed8d680e348bb45171","e1d3fc16fcae9731e1c7daeb852db4add07352d2"],"5a238fc456663f685a9db1ed8d680e348bb45171":[],"df0329608a289015ef0887f776679127cbbfe71e":["716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"e1d3fc16fcae9731e1c7daeb852db4add07352d2":["963375a30a9056a39347c6f920c8b27c4e559212"],"8028ab7a24273833d53d35eb160dba5b57283cf5":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b6912d3e0a9ef2865124c6822bc9e4cfd3581c6c"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["bdb5e42b0cecd8dfb27767a02ada71899bf17917","5a238fc456663f685a9db1ed8d680e348bb45171"],"963375a30a9056a39347c6f920c8b27c4e559212":["37a0f60745e53927c4c876cfe5b5a58170f0646c","0ba1867a94c748b12f005cba35453b6d7122e5d8"],"0ba1867a94c748b12f005cba35453b6d7122e5d8":["37a0f60745e53927c4c876cfe5b5a58170f0646c","df0329608a289015ef0887f776679127cbbfe71e"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","5a238fc456663f685a9db1ed8d680e348bb45171","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}