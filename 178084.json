{"path":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","commits":[{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad180bd5b1bb2037985ddf0a0e8bfb2c5d587e1e","date":1323363624,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocsWithID(writer, 100, 0);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ad180bd5b1bb2037985ddf0a0e8bfb2c5d587e1e":["7b91922b55d15444d554721b352861d028eb8278"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["7b91922b55d15444d554721b352861d028eb8278","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["7b91922b55d15444d554721b352861d028eb8278","ad180bd5b1bb2037985ddf0a0e8bfb2c5d587e1e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["ad180bd5b1bb2037985ddf0a0e8bfb2c5d587e1e","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"ad180bd5b1bb2037985ddf0a0e8bfb2c5d587e1e":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7b91922b55d15444d554721b352861d028eb8278"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}