{"path":"lucene/src/java/org/apache/lucene/index/codecs/DefaultStoredFieldsReader#DefaultStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","commits":[{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DefaultStoredFieldsReader#DefaultStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/DefaultFieldsReader#DefaultFieldsReader(Directory,String,FieldInfos,IOContext,int,int).mjava","sourceNew":"  public DefaultStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    isOriginal = true;\n    try {\n      fieldInfos = fn;\n\n      cloneableFieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", DefaultStoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", DefaultStoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      cloneableIndexStream = d.openInput(indexStreamFN, context);\n      \n      format = cloneableIndexStream.readInt();\n\n      if (format < DefaultStoredFieldsWriter.FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(cloneableIndexStream, format, DefaultStoredFieldsWriter.FORMAT_MINIMUM, DefaultStoredFieldsWriter.FORMAT_CURRENT);\n      if (format > DefaultStoredFieldsWriter.FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(cloneableIndexStream, format, DefaultStoredFieldsWriter.FORMAT_MINIMUM, DefaultStoredFieldsWriter.FORMAT_CURRENT);\n\n      fieldsStream = (IndexInput) cloneableFieldsStream.clone();\n\n      final long indexSize = cloneableIndexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n\n      indexStream = (IndexInput) cloneableIndexStream.clone();\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public DefaultFieldsReader(Directory d, String segment, FieldInfos fn, IOContext context, int docStoreOffset, int size) throws IOException {\n    boolean success = false;\n    isOriginal = true;\n    try {\n      fieldInfos = fn;\n\n      cloneableFieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", DefaultFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", DefaultFieldsWriter.FIELDS_INDEX_EXTENSION);\n      cloneableIndexStream = d.openInput(indexStreamFN, context);\n      \n      format = cloneableIndexStream.readInt();\n\n      if (format < DefaultFieldsWriter.FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(cloneableIndexStream, format, DefaultFieldsWriter.FORMAT_MINIMUM, DefaultFieldsWriter.FORMAT_CURRENT);\n      if (format > DefaultFieldsWriter.FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(cloneableIndexStream, format, DefaultFieldsWriter.FORMAT_MINIMUM, DefaultFieldsWriter.FORMAT_CURRENT);\n\n      fieldsStream = (IndexInput) cloneableFieldsStream.clone();\n\n      final long indexSize = cloneableIndexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n      }\n\n      indexStream = (IndexInput) cloneableIndexStream.clone();\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DefaultStoredFieldsReader#DefaultStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/DefaultStoredFieldsReader#DefaultStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public DefaultStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", DefaultStoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", DefaultStoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < DefaultStoredFieldsWriter.FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, DefaultStoredFieldsWriter.FORMAT_MINIMUM, DefaultStoredFieldsWriter.FORMAT_CURRENT);\n      if (format > DefaultStoredFieldsWriter.FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, DefaultStoredFieldsWriter.FORMAT_MINIMUM, DefaultStoredFieldsWriter.FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public DefaultStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    isOriginal = true;\n    try {\n      fieldInfos = fn;\n\n      cloneableFieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", DefaultStoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", DefaultStoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      cloneableIndexStream = d.openInput(indexStreamFN, context);\n      \n      format = cloneableIndexStream.readInt();\n\n      if (format < DefaultStoredFieldsWriter.FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(cloneableIndexStream, format, DefaultStoredFieldsWriter.FORMAT_MINIMUM, DefaultStoredFieldsWriter.FORMAT_CURRENT);\n      if (format > DefaultStoredFieldsWriter.FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(cloneableIndexStream, format, DefaultStoredFieldsWriter.FORMAT_MINIMUM, DefaultStoredFieldsWriter.FORMAT_CURRENT);\n\n      fieldsStream = (IndexInput) cloneableFieldsStream.clone();\n\n      final long indexSize = cloneableIndexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n\n      indexStream = (IndexInput) cloneableIndexStream.clone();\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cfd7f00f3dbc4c50d336540f063493fc0f7d830f","date":1322850565,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40StoredFieldsReader#Lucene40StoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/DefaultStoredFieldsReader#DefaultStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene40StoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", Lucene40StoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < Lucene40StoredFieldsWriter.FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n      if (format > Lucene40StoredFieldsWriter.FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, Lucene40StoredFieldsWriter.FORMAT_MINIMUM, Lucene40StoredFieldsWriter.FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public DefaultStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", DefaultStoredFieldsWriter.FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", DefaultStoredFieldsWriter.FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < DefaultStoredFieldsWriter.FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, DefaultStoredFieldsWriter.FORMAT_MINIMUM, DefaultStoredFieldsWriter.FORMAT_CURRENT);\n      if (format > DefaultStoredFieldsWriter.FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, DefaultStoredFieldsWriter.FORMAT_MINIMUM, DefaultStoredFieldsWriter.FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"cfd7f00f3dbc4c50d336540f063493fc0f7d830f":["3cc749c053615f5871f3b95715fe292f34e70a53"],"06584e6e98d592b34e1329b384182f368d2025e8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cc749c053615f5871f3b95715fe292f34e70a53":["06584e6e98d592b34e1329b384182f368d2025e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["cfd7f00f3dbc4c50d336540f063493fc0f7d830f"]},"commit2Childs":{"cfd7f00f3dbc4c50d336540f063493fc0f7d830f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"06584e6e98d592b34e1329b384182f368d2025e8":["3cc749c053615f5871f3b95715fe292f34e70a53"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["06584e6e98d592b34e1329b384182f368d2025e8"],"3cc749c053615f5871f3b95715fe292f34e70a53":["cfd7f00f3dbc4c50d336540f063493fc0f7d830f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}