{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","commits":[{"id":"66b61ab77ab36893d701d693f1b6df2a383bb7b5","date":1364405461,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0;\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (mergedDeletes != null) {\n      if (dropSegment) {\n        mergedDeletes.dropChanges();\n      }\n      readerPool.release(mergedDeletes);\n    }\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0;\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (mergedDeletes != null) {\n      if (dropSegment) {\n        mergedDeletes.dropChanges();\n      }\n      readerPool.release(mergedDeletes);\n    }\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e072d0b1fc19e0533d8ce432eed245196bca6fde","date":1379265112,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0 || mergedDeletes.hasFieldUpdates();\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (mergedDeletes != null) {\n      if (dropSegment) {\n        mergedDeletes.dropChanges();\n      }\n      readerPool.release(mergedDeletes);\n    }\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0;\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (mergedDeletes != null) {\n      if (dropSegment) {\n        mergedDeletes.dropChanges();\n      }\n      readerPool.release(mergedDeletes);\n    }\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"75e4e08ceec867127dcd9913a5ebbc46cf85a28d","date":1379651991,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0 || mergedDeletes.hasFieldUpdates();\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (mergedDeletes != null) {\n      if (dropSegment) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: dropChanges \" + merge.info);\n        mergedDeletes.dropChanges();\n      }\n      readerPool.release(mergedDeletes);\n    }\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0 || mergedDeletes.hasFieldUpdates();\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (mergedDeletes != null) {\n      if (dropSegment) {\n        mergedDeletes.dropChanges();\n      }\n      readerPool.release(mergedDeletes);\n    }\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8da3c22a3b1a00ae6e2664f3ac0d82cfa3a8f666","date":1381263930,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0 || mergedDeletes.hasFieldUpdates();\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedDeletes != null) {\n      if (dropSegment) {\n        mergedDeletes.dropChanges();\n      }\n      // Pass false for assertInfoLive because the merged\n      // segment is not yet live (only below do we commit it\n      // to the segmentInfos):\n      readerPool.release(mergedDeletes, false);\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0 || mergedDeletes.hasFieldUpdates();\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (mergedDeletes != null) {\n      if (dropSegment) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: dropChanges \" + merge.info);\n        mergedDeletes.dropChanges();\n      }\n      readerPool.release(mergedDeletes);\n    }\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":["518db79298f3afbc39f3b6b4fb1fb8d71cae93f2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"92c3afe284adc763569ac804e312451e680313f6","date":1381745540,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0 || mergedDeletes.hasFieldUpdates();\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedDeletes != null) {\n      // Pass false for assertInfoLive because the merged\n      // segment is not yet live (only below do we commit it\n      // to the segmentInfos):\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedDeletes.dropChanges();\n        }\n        readerPool.release(mergedDeletes, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedDeletes.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0 || mergedDeletes.hasFieldUpdates();\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedDeletes != null) {\n      if (dropSegment) {\n        mergedDeletes.dropChanges();\n      }\n      // Pass false for assertInfoLive because the merged\n      // segment is not yet live (only below do we commit it\n      // to the segmentInfos):\n      readerPool.release(mergedDeletes, false);\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"518db79298f3afbc39f3b6b4fb1fb8d71cae93f2","date":1381745605,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0 || mergedDeletes.hasFieldUpdates();\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedDeletes != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedDeletes.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedDeletes, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedDeletes.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0 || mergedDeletes.hasFieldUpdates();\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedDeletes != null) {\n      // Pass false for assertInfoLive because the merged\n      // segment is not yet live (only below do we commit it\n      // to the segmentInfos):\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedDeletes.dropChanges();\n        }\n        readerPool.release(mergedDeletes, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedDeletes.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":["8da3c22a3b1a00ae6e2664f3ac0d82cfa3a8f666"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe","date":1381909398,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedDeletes != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedDeletes.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedDeletes, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedDeletes.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes =  merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    assert mergedDeletes == null || mergedDeletes.getPendingDeleteCount() != 0 || mergedDeletes.hasFieldUpdates();\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedDeletes != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedDeletes.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedDeletes, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedDeletes.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletes(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedDeletes != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedDeletes.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedDeletes, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedDeletes.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a5eff83eba6305c34151d77c8a71495fb0b7808","date":1391866853,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6b7c6630218ed9693cdb8643276513f9f0043f4","date":1406648084,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalDocCount - merge.info.info.getDocCount();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":["fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"949847c0040cd70a68222d526cb0da7bf6cbb3c2","date":1410997182,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalDocCount - merge.info.info.getDocCount();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalDocCount - merge.info.info.getDocCount();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4","date":1414017220,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalDocCount - merge.info.info.getDocCount();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalDocCount - merge.info.info.getDocCount();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5faf65b6692f15cca0f87bf8666c87899afc619f","date":1420468108,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalDocCount - merge.info.info.getDocCount();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalDocCount - merge.info.info.getDocCount();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b0267c69e2456a3477a1ad785723f2135da3117e","date":1425317087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalDocCount - merge.info.info.getDocCount();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":["fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b06445ae1731e049327712db0454e5643ca9b7fe","date":1425329139,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalDocCount - merge.info.info.getDocCount();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.getDocCount() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.getDocCount() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.getDocCount());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.getDocCount() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalDocCount - merge.info.info.getDocCount();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"950882a2bd2a5f9dc16a154871584eaa643d882a","date":1436366563,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      deleter.deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":["fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6bfe104fc023fadc9e709f8d17403d2cc61133fe","date":1454446396,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b470f36a9372c97283360b1304eacbde22df6c0d","date":1454765175,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a207d19eac354d649c3f0e2cce070017c78125e","date":1454776470,"type":3,"author":"Erick Erickson","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    deleter.deletePendingFiles();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b53db710c6b8fb48bb3a2bab4df8d1dfbd7906c","date":1477166077,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"80d0e6d59ae23f4a6f30eaf40bfb40742300287f","date":1477598926,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != -1 && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1ee9437ba5a8297220428d48a6bb823d1fcd57b","date":1489137809,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.rateLimiter.getAbort()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n//    System.out.println(\"[\" + Thread.currentThread().getName() + \"] IW.commitMerge: mergedDeletes=\" + mergedDeletes);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef","date":1512420564,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    assert delDocCount >= 0;\n    pendingNumDocs.addAndGet(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":["b0267c69e2456a3477a1ad785723f2135da3117e","950882a2bd2a5f9dc16a154871584eaa643d882a","d6b7c6630218ed9693cdb8643276513f9f0043f4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"845b760a99e5f369fcd0a5d723a87b8def6a3f56","date":1521117993,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"af02a5a3ff2c1e52a02c0f07ff02c7197e43e59c","date":1521393811,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      checkpoint();\n    } catch (Throwable t) {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      try {\n        checkpoint();\n      } catch (Throwable t1) {\n        t.addSuppressed(t1);\n      }\n      throw t;\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"203e3fcf513c02ee2c07015f2ce277e26dc60907","date":1521404157,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      checkpoint();\n    } catch (Throwable t) {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      try {\n        checkpoint();\n      } catch (Throwable t1) {\n        t.addSuppressed(t1);\n      }\n      throw t;\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    boolean success = false;\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      success = true;\n    } finally {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      if (success) {\n        checkpoint();\n      } else {\n        try {\n          checkpoint();\n        } catch (Throwable t) {\n          // Ignore so we keep throwing original exception.\n        }\n      }\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14d66d86a8b184a86bcaebcf6e15fcef486e0876","date":1521539412,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      checkpoint();\n    } catch (Throwable t) {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      try {\n        checkpoint();\n      } catch (Throwable t1) {\n        t.addSuppressed(t1);\n      }\n      throw t;\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","date":1521731438,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n      checkpoint();\n    } catch (Throwable t) {\n      // Must note the change to segmentInfos so any commits\n      // in-flight don't lose it (IFD will incRef/protect the\n      // new files we created):\n      try {\n        checkpoint();\n      } catch (Throwable t1) {\n        t.addSuppressed(t1);\n      }\n      throw t;\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d60c1bb96a28a26d197c36299f7b6c9c5da617a1","date":1522484702,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && mergedUpdates.isFullyDeleted());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa5e39259dfd4a68287c824d3b7e1bc9097dc895","date":1522505041,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && mergedUpdates.isFullyDeleted());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null &&\n       mergedUpdates.getPendingDeleteCount() == merge.info.info.maxDoc());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5ee0394b8176abd7c90a4be8c05465be1879db79","date":1522842314,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && isFullyDeleted(mergedUpdates));\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted; skipping insert\");\n      }\n    }\n\n    final boolean dropSegment = allDeleted;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && mergedUpdates.isFullyDeleted());\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || keepFullyDeletedSegments || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1926100d9b67becc9701c54266fee3ba7878a5f0","date":1524472150,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && isFullyDeleted(mergedUpdates));\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted; skipping insert\");\n      }\n    }\n\n    final boolean dropSegment = allDeleted;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && isFullyDeleted(mergedUpdates));\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted; skipping insert\");\n      }\n    }\n\n    final boolean dropSegment = allDeleted;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        readerPool.release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe1dc1107e70a3ffaa5d6ce6801458a59923b1b5","date":1583441366,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && isFullyDeleted(mergedUpdates));\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted; skipping insert\");\n      }\n    }\n\n    final boolean dropSegment = allDeleted;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      merge.committed = true;\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && isFullyDeleted(mergedUpdates));\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted; skipping insert\");\n      }\n    }\n\n    final boolean dropSegment = allDeleted;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba192a321314de8edbe20b279eee9c471b16b48b","date":1583706474,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && isFullyDeleted(mergedUpdates));\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted; skipping insert\");\n      }\n    }\n\n    final boolean dropSegment = allDeleted;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && isFullyDeleted(mergedUpdates));\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted; skipping insert\");\n      }\n    }\n\n    final boolean dropSegment = allDeleted;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      merge.committed = true;\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2","date":1588002560,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  @SuppressWarnings(\"try\")\n  private synchronized boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && isFullyDeleted(mergedUpdates));\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted; skipping insert\");\n      }\n    }\n\n    final boolean dropSegment = allDeleted;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @SuppressWarnings(\"try\")\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && isFullyDeleted(mergedUpdates));\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted; skipping insert\");\n      }\n    }\n\n    final boolean dropSegment = allDeleted;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c2a23476693f2bd9a4b44cc3187c429a2e21dac2","date":1593289545,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,MergeState).mjava","sourceNew":"  @SuppressWarnings(\"try\")\n  private synchronized boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n    merge.onMergeComplete();\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && isFullyDeleted(mergedUpdates));\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted; skipping insert\");\n      }\n    }\n\n    final boolean dropSegment = allDeleted;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false, dropSegment);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @SuppressWarnings(\"try\")\n  private synchronized boolean commitMerge(MergePolicy.OneMerge merge, MergeState mergeState) throws IOException {\n\n    testPoint(\"startCommitMerge\");\n\n    if (tragedy.get() != null) {\n      throw new IllegalStateException(\"this writer hit an unrecoverable error; cannot complete merge\", tragedy.get());\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      // In case we opened and pooled a reader for this\n      // segment, drop it now.  This ensures that we close\n      // the reader before trying to delete any of its\n      // files.  This is not a very big deal, since this\n      // reader will never be used by any NRT reader, and\n      // another thread is currently running close(false)\n      // so it will be dropped shortly anyway, but not\n      // doing this  makes  MockDirWrapper angry in\n      // TestNRTThreads (LUCENE-5434):\n      readerPool.drop(merge.info);\n      // Safe: these files must exist:\n      deleteNewFiles(merge.info.files());\n      return false;\n    }\n\n    final ReadersAndUpdates mergedUpdates = merge.info.info.maxDoc() == 0 ? null : commitMergedDeletesAndUpdates(merge, mergeState);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.info.maxDoc() == 0 ||\n      (mergedUpdates != null && isFullyDeleted(mergedUpdates));\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted; skipping insert\");\n      }\n    }\n\n    final boolean dropSegment = allDeleted;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.info.maxDoc() != 0 || dropSegment;\n\n    if (mergedUpdates != null) {\n      boolean success = false;\n      try {\n        if (dropSegment) {\n          mergedUpdates.dropChanges();\n        }\n        // Pass false for assertInfoLive because the merged\n        // segment is not yet live (only below do we commit it\n        // to the segmentInfos):\n        release(mergedUpdates, false);\n        success = true;\n      } finally {\n        if (!success) {\n          mergedUpdates.dropChanges();\n          readerPool.drop(merge.info);\n        }\n      }\n    }\n\n    // Must do this after readerPool.release, in case an\n    // exception is hit e.g. writing the live docs for the\n    // merge segment, in which case we need to abort the\n    // merge:\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n\n    // Now deduct the deleted docs that we just reclaimed from this\n    // merge:\n    int delDocCount;\n    if (dropSegment) {\n      // if we drop the segment we have to reduce the pendingNumDocs by merge.totalMaxDocs since we never drop\n      // the docs when we apply deletes if the segment is currently merged.\n      delDocCount = merge.totalMaxDoc;\n    } else {\n      delDocCount = merge.totalMaxDoc - merge.info.info.maxDoc();\n    }\n    assert delDocCount >= 0;\n    adjustPendingNumDocs(-delDocCount);\n\n    if (dropSegment) {\n      assert !segmentInfos.contains(merge.info);\n      readerPool.drop(merge.info);\n      // Safe: these files must exist\n      deleteNewFiles(merge.info.files());\n    }\n\n    try (Closeable finalizer = this::checkpoint) {\n      // Must close before checkpoint, otherwise IFD won't be\n      // able to delete the held-open files from the merge\n      // readers:\n      closeMergeReaders(merge, false);\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commitMerge: \" + segString());\n    }\n\n    if (merge.maxNumSegments != UNBOUNDED_MAX_MERGE_SEGMENTS && !dropSegment) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ba192a321314de8edbe20b279eee9c471b16b48b":["fe1dc1107e70a3ffaa5d6ce6801458a59923b1b5"],"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["203e3fcf513c02ee2c07015f2ce277e26dc60907","14d66d86a8b184a86bcaebcf6e15fcef486e0876"],"fe1dc1107e70a3ffaa5d6ce6801458a59923b1b5":["1926100d9b67becc9701c54266fee3ba7878a5f0"],"845b760a99e5f369fcd0a5d723a87b8def6a3f56":["fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4":["949847c0040cd70a68222d526cb0da7bf6cbb3c2"],"5a207d19eac354d649c3f0e2cce070017c78125e":["950882a2bd2a5f9dc16a154871584eaa643d882a","b470f36a9372c97283360b1304eacbde22df6c0d"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["c1ee9437ba5a8297220428d48a6bb823d1fcd57b"],"c1ee9437ba5a8297220428d48a6bb823d1fcd57b":["6b53db710c6b8fb48bb3a2bab4df8d1dfbd7906c"],"aa5e39259dfd4a68287c824d3b7e1bc9097dc895":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","d60c1bb96a28a26d197c36299f7b6c9c5da617a1"],"66b61ab77ab36893d701d693f1b6df2a383bb7b5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"af02a5a3ff2c1e52a02c0f07ff02c7197e43e59c":["845b760a99e5f369fcd0a5d723a87b8def6a3f56"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["5faf65b6692f15cca0f87bf8666c87899afc619f","b0267c69e2456a3477a1ad785723f2135da3117e"],"6b53db710c6b8fb48bb3a2bab4df8d1dfbd7906c":["5a207d19eac354d649c3f0e2cce070017c78125e"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["518db79298f3afbc39f3b6b4fb1fb8d71cae93f2"],"b06445ae1731e049327712db0454e5643ca9b7fe":["5faf65b6692f15cca0f87bf8666c87899afc619f","b0267c69e2456a3477a1ad785723f2135da3117e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d6b7c6630218ed9693cdb8643276513f9f0043f4":["2a5eff83eba6305c34151d77c8a71495fb0b7808"],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["950882a2bd2a5f9dc16a154871584eaa643d882a"],"949847c0040cd70a68222d526cb0da7bf6cbb3c2":["d6b7c6630218ed9693cdb8643276513f9f0043f4"],"14d66d86a8b184a86bcaebcf6e15fcef486e0876":["203e3fcf513c02ee2c07015f2ce277e26dc60907"],"8da3c22a3b1a00ae6e2664f3ac0d82cfa3a8f666":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"e072d0b1fc19e0533d8ce432eed245196bca6fde":["66b61ab77ab36893d701d693f1b6df2a383bb7b5"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"5ee0394b8176abd7c90a4be8c05465be1879db79":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895"],"b0267c69e2456a3477a1ad785723f2135da3117e":["5faf65b6692f15cca0f87bf8666c87899afc619f"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["950882a2bd2a5f9dc16a154871584eaa643d882a","b470f36a9372c97283360b1304eacbde22df6c0d"],"203e3fcf513c02ee2c07015f2ce277e26dc60907":["845b760a99e5f369fcd0a5d723a87b8def6a3f56","af02a5a3ff2c1e52a02c0f07ff02c7197e43e59c"],"1926100d9b67becc9701c54266fee3ba7878a5f0":["5ee0394b8176abd7c90a4be8c05465be1879db79"],"518db79298f3afbc39f3b6b4fb1fb8d71cae93f2":["92c3afe284adc763569ac804e312451e680313f6"],"d60c1bb96a28a26d197c36299f7b6c9c5da617a1":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["c1ee9437ba5a8297220428d48a6bb823d1fcd57b","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"28288370235ed02234a64753cdbf0c6ec096304a":["c1ee9437ba5a8297220428d48a6bb823d1fcd57b","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"c2a23476693f2bd9a4b44cc3187c429a2e21dac2":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"],"92c3afe284adc763569ac804e312451e680313f6":["8da3c22a3b1a00ae6e2664f3ac0d82cfa3a8f666"],"b470f36a9372c97283360b1304eacbde22df6c0d":["950882a2bd2a5f9dc16a154871584eaa643d882a","6bfe104fc023fadc9e709f8d17403d2cc61133fe"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["5a207d19eac354d649c3f0e2cce070017c78125e","6b53db710c6b8fb48bb3a2bab4df8d1dfbd7906c"],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["ba192a321314de8edbe20b279eee9c471b16b48b"],"950882a2bd2a5f9dc16a154871584eaa643d882a":["b0267c69e2456a3477a1ad785723f2135da3117e"],"5faf65b6692f15cca0f87bf8666c87899afc619f":["9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4"],"fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef":["28288370235ed02234a64753cdbf0c6ec096304a"],"2a5eff83eba6305c34151d77c8a71495fb0b7808":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c2a23476693f2bd9a4b44cc3187c429a2e21dac2"]},"commit2Childs":{"ba192a321314de8edbe20b279eee9c471b16b48b":["8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2"],"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895","d60c1bb96a28a26d197c36299f7b6c9c5da617a1"],"fe1dc1107e70a3ffaa5d6ce6801458a59923b1b5":["ba192a321314de8edbe20b279eee9c471b16b48b"],"845b760a99e5f369fcd0a5d723a87b8def6a3f56":["af02a5a3ff2c1e52a02c0f07ff02c7197e43e59c","203e3fcf513c02ee2c07015f2ce277e26dc60907"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["2a5eff83eba6305c34151d77c8a71495fb0b7808"],"9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4":["5faf65b6692f15cca0f87bf8666c87899afc619f"],"5a207d19eac354d649c3f0e2cce070017c78125e":["6b53db710c6b8fb48bb3a2bab4df8d1dfbd7906c","80d0e6d59ae23f4a6f30eaf40bfb40742300287f"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"c1ee9437ba5a8297220428d48a6bb823d1fcd57b":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"aa5e39259dfd4a68287c824d3b7e1bc9097dc895":["5ee0394b8176abd7c90a4be8c05465be1879db79"],"66b61ab77ab36893d701d693f1b6df2a383bb7b5":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"af02a5a3ff2c1e52a02c0f07ff02c7197e43e59c":["203e3fcf513c02ee2c07015f2ce277e26dc60907"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"6b53db710c6b8fb48bb3a2bab4df8d1dfbd7906c":["c1ee9437ba5a8297220428d48a6bb823d1fcd57b","80d0e6d59ae23f4a6f30eaf40bfb40742300287f"],"b06445ae1731e049327712db0454e5643ca9b7fe":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["66b61ab77ab36893d701d693f1b6df2a383bb7b5"],"d6b7c6630218ed9693cdb8643276513f9f0043f4":["949847c0040cd70a68222d526cb0da7bf6cbb3c2"],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["b470f36a9372c97283360b1304eacbde22df6c0d"],"949847c0040cd70a68222d526cb0da7bf6cbb3c2":["9cdbc2cadeaf282528fe4d1c06e9f8bee38ccec4"],"14d66d86a8b184a86bcaebcf6e15fcef486e0876":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"8da3c22a3b1a00ae6e2664f3ac0d82cfa3a8f666":["92c3afe284adc763569ac804e312451e680313f6"],"e072d0b1fc19e0533d8ce432eed245196bca6fde":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["8da3c22a3b1a00ae6e2664f3ac0d82cfa3a8f666"],"b0267c69e2456a3477a1ad785723f2135da3117e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","950882a2bd2a5f9dc16a154871584eaa643d882a"],"5ee0394b8176abd7c90a4be8c05465be1879db79":["1926100d9b67becc9701c54266fee3ba7878a5f0"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"203e3fcf513c02ee2c07015f2ce277e26dc60907":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","14d66d86a8b184a86bcaebcf6e15fcef486e0876"],"1926100d9b67becc9701c54266fee3ba7878a5f0":["fe1dc1107e70a3ffaa5d6ce6801458a59923b1b5"],"d60c1bb96a28a26d197c36299f7b6c9c5da617a1":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895"],"518db79298f3afbc39f3b6b4fb1fb8d71cae93f2":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"28288370235ed02234a64753cdbf0c6ec096304a":["fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef"],"92c3afe284adc763569ac804e312451e680313f6":["518db79298f3afbc39f3b6b4fb1fb8d71cae93f2"],"c2a23476693f2bd9a4b44cc3187c429a2e21dac2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b470f36a9372c97283360b1304eacbde22df6c0d":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":[],"950882a2bd2a5f9dc16a154871584eaa643d882a":["5a207d19eac354d649c3f0e2cce070017c78125e","6bfe104fc023fadc9e709f8d17403d2cc61133fe","1e6acbaae7af722f17204ceccf0f7db5753eccf3","b470f36a9372c97283360b1304eacbde22df6c0d"],"8a428f5314daaabf8eab7c50bdc3bc14e6cd1aa2":["c2a23476693f2bd9a4b44cc3187c429a2e21dac2"],"5faf65b6692f15cca0f87bf8666c87899afc619f":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","b0267c69e2456a3477a1ad785723f2135da3117e"],"fdc3f2b9a4e1c1aacfa53b304c4e42c13a1677ef":["845b760a99e5f369fcd0a5d723a87b8def6a3f56"],"2a5eff83eba6305c34151d77c8a71495fb0b7808":["d6b7c6630218ed9693cdb8643276513f9f0043f4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","1e6acbaae7af722f17204ceccf0f7db5753eccf3","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","80d0e6d59ae23f4a6f30eaf40bfb40742300287f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}