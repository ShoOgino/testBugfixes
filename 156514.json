{"path":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","commits":[{"id":"36c0f6c09668001b298edab167cfc244c906de1a","date":1352953421,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","pathOld":"/dev/null","sourceNew":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      DocValues dv = ireader.leaves().get(0).reader().docValues(\"dv\");\n      assertEquals(new BytesRef(\"hello world\"), dv.getSource().getBytes(hits.scoreDocs[i].doc, new BytesRef()));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ce73f585d17f53055185a19beb46db23d76e0ad9","date":1353077110,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","sourceNew":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      DocValues dv = ireader.leaves().get(0).reader().docValues(\"dv\");\n      assertEquals(new BytesRef(\"hello world\"), dv.getSource().getBytes(hits.scoreDocs[i].doc, new BytesRef()));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    ireader.close();\n    directory.close();\n    \n    //nocommit fails with Lucene41 Codec since \"dv\" is created with var len but is in fact fixed len\n  }\n\n","sourceOld":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      DocValues dv = ireader.leaves().get(0).reader().docValues(\"dv\");\n      assertEquals(new BytesRef(\"hello world\"), dv.getSource().getBytes(hits.scoreDocs[i].doc, new BytesRef()));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7cd329bd749496f6c58b586a6c0dd0dc8201206f","date":1353092226,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","sourceNew":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv\", random().nextBoolean());\n      dv.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n    \n    //nocommit fails with Lucene41 Codec since \"dv\" is created with var len but is in fact fixed len\n  }\n\n","sourceOld":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      DocValues dv = ireader.leaves().get(0).reader().docValues(\"dv\");\n      assertEquals(new BytesRef(\"hello world\"), dv.getSource().getBytes(hits.scoreDocs[i].doc, new BytesRef()));\n    }\n\n    // Test simple phrase query\n    PhraseQuery phraseQuery = new PhraseQuery();\n    phraseQuery.add(new Term(\"fieldname\", \"to\"));\n    phraseQuery.add(new Term(\"fieldname\", \"be\"));\n    assertEquals(1, isearcher.search(phraseQuery, null, 1).totalHits);\n\n    ireader.close();\n    directory.close();\n    \n    //nocommit fails with Lucene41 Codec since \"dv\" is created with var len but is in fact fixed len\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4d374b2bebd0d52acaa61038fbf23068620fba7","date":1353240004,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","sourceNew":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv\");\n      dv.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n    \n    //nocommit fails with Lucene41 Codec since \"dv\" is created with var len but is in fact fixed len\n  }\n\n","sourceOld":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv\", random().nextBoolean());\n      dv.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n    \n    //nocommit fails with Lucene41 Codec since \"dv\" is created with var len but is in fact fixed len\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1ed65f3455364344c6d2ff76ea5421aac754eae7","date":1353261762,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","sourceNew":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv\");\n      dv.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n    \n    //nocommit fails with Lucene41 Codec since \"dv\" is created with var len but is in fact fixed len\n  }\n\n","sourceOld":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    // Store the index in memory:\n    Directory directory = newDirectory();\n    // To store an index on disk, use this instead:\n    // Directory directory = FSDirectory.open(new File(\"/tmp/testindex\"));\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv\");\n      dv.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n    \n    //nocommit fails with Lucene41 Codec since \"dv\" is created with var len but is in fact fixed len\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d751a328c5ac3a5d629d3c22667ca1617652e83e","date":1357735254,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","sourceNew":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv\");\n      dv.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv\");\n      dv.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n    \n    //nocommit fails with Lucene41 Codec since \"dv\" is created with var len but is in fact fixed len\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef","date":1358808656,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","sourceNew":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new BinaryDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv\");\n      dv.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new StraightBytesDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv\");\n      dv.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2ec08217282b5e9df023dcdff55c745ff68b1c7d","date":1359392781,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#testBytes().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/TestDemoDocValue#testDemoBytes().mjava","sourceNew":"  public void testBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    conf.setCodec(getCodec());\n    IndexWriter iwriter = new IndexWriter(directory, conf);\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new BinaryDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv\");\n      dv.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testDemoBytes() throws IOException {\n    Analyzer analyzer = new MockAnalyzer(random());\n\n    Directory directory = newDirectory();\n    // we don't use RandomIndexWriter because it might add more docvalues than we expect !!!!1\n    IndexWriter iwriter = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    Document doc = new Document();\n    String longTerm = \"longtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongtermlongterm\";\n    String text = \"This is the text to be indexed. \" + longTerm;\n    doc.add(newTextField(\"fieldname\", text, Field.Store.YES));\n    doc.add(new BinaryDocValuesField(\"dv\", new BytesRef(\"hello world\")));\n    iwriter.addDocument(doc);\n    iwriter.close();\n    \n    // Now search the index:\n    IndexReader ireader = DirectoryReader.open(directory); // read-only=true\n    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n    assertEquals(1, isearcher.search(new TermQuery(new Term(\"fieldname\", longTerm)), 1).totalHits);\n    Query query = new TermQuery(new Term(\"fieldname\", \"text\"));\n    TopDocs hits = isearcher.search(query, null, 1);\n    assertEquals(1, hits.totalHits);\n    BytesRef scratch = new BytesRef();\n    // Iterate through the results:\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      StoredDocument hitDoc = isearcher.doc(hits.scoreDocs[i].doc);\n      assertEquals(text, hitDoc.get(\"fieldname\"));\n      assert ireader.leaves().size() == 1;\n      BinaryDocValues dv = ireader.leaves().get(0).reader().getBinaryDocValues(\"dv\");\n      dv.get(hits.scoreDocs[i].doc, scratch);\n      assertEquals(new BytesRef(\"hello world\"), scratch);\n    }\n\n    ireader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ce73f585d17f53055185a19beb46db23d76e0ad9":["36c0f6c09668001b298edab167cfc244c906de1a"],"d751a328c5ac3a5d629d3c22667ca1617652e83e":["1ed65f3455364344c6d2ff76ea5421aac754eae7"],"ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef":["d751a328c5ac3a5d629d3c22667ca1617652e83e"],"1ed65f3455364344c6d2ff76ea5421aac754eae7":["a4d374b2bebd0d52acaa61038fbf23068620fba7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7cd329bd749496f6c58b586a6c0dd0dc8201206f":["ce73f585d17f53055185a19beb46db23d76e0ad9"],"a4d374b2bebd0d52acaa61038fbf23068620fba7":["7cd329bd749496f6c58b586a6c0dd0dc8201206f"],"36c0f6c09668001b298edab167cfc244c906de1a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2ec08217282b5e9df023dcdff55c745ff68b1c7d":["ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef"]},"commit2Childs":{"ce73f585d17f53055185a19beb46db23d76e0ad9":["7cd329bd749496f6c58b586a6c0dd0dc8201206f"],"d751a328c5ac3a5d629d3c22667ca1617652e83e":["ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef"],"1ed65f3455364344c6d2ff76ea5421aac754eae7":["d751a328c5ac3a5d629d3c22667ca1617652e83e"],"ac7f2e023a71df327ed9bc0bea2230ce5c59b2ef":["2ec08217282b5e9df023dcdff55c745ff68b1c7d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["36c0f6c09668001b298edab167cfc244c906de1a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7cd329bd749496f6c58b586a6c0dd0dc8201206f":["a4d374b2bebd0d52acaa61038fbf23068620fba7"],"a4d374b2bebd0d52acaa61038fbf23068620fba7":["1ed65f3455364344c6d2ff76ea5421aac754eae7"],"36c0f6c09668001b298edab167cfc244c906de1a":["ce73f585d17f53055185a19beb46db23d76e0ad9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"2ec08217282b5e9df023dcdff55c745ff68b1c7d":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","2ec08217282b5e9df023dcdff55c745ff68b1c7d"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}