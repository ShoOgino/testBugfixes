{"path":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamOffsetStrategy#convertTermsToAutomata(BytesRef[],CharacterRunAutomaton[]).mjava","commits":[{"id":"f2e9861e4a2b724d9fc51b618714c579491b78d7","date":1479244606,"type":1,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamOffsetStrategy#convertTermsToAutomata(BytesRef[],CharacterRunAutomaton[]).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/AnalysisOffsetStrategy#convertTermsToAutomata(BytesRef[],CharacterRunAutomaton[]).mjava","sourceNew":"  private static CharacterRunAutomaton[] convertTermsToAutomata(BytesRef[] terms, CharacterRunAutomaton[] automata) {\n    CharacterRunAutomaton[] newAutomata = new CharacterRunAutomaton[terms.length + automata.length];\n    for (int i = 0; i < terms.length; i++) {\n      String termString = terms[i].utf8ToString();\n      newAutomata[i] = new CharacterRunAutomaton(Automata.makeString(termString)) {\n        @Override\n        public String toString() {\n          return termString;\n        }\n      };\n    }\n    // Append existing automata (that which is used for MTQs)\n    System.arraycopy(automata, 0, newAutomata, terms.length, automata.length);\n    return newAutomata;\n  }\n\n","sourceOld":"  private static CharacterRunAutomaton[] convertTermsToAutomata(BytesRef[] terms, CharacterRunAutomaton[] automata) {\n    CharacterRunAutomaton[] newAutomata = new CharacterRunAutomaton[terms.length + automata.length];\n    for (int i = 0; i < terms.length; i++) {\n      newAutomata[i] = MultiTermHighlighting.makeStringMatchAutomata(terms[i]);\n    }\n    // Append existing automata (that which is used for MTQs)\n    System.arraycopy(automata, 0, newAutomata, terms.length, automata.length);\n    return newAutomata;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1ef55e1fff7ff44354432770ad8bc19be1fcc75","date":1479266056,"type":1,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamOffsetStrategy#convertTermsToAutomata(BytesRef[],CharacterRunAutomaton[]).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/AnalysisOffsetStrategy#convertTermsToAutomata(BytesRef[],CharacterRunAutomaton[]).mjava","sourceNew":"  private static CharacterRunAutomaton[] convertTermsToAutomata(BytesRef[] terms, CharacterRunAutomaton[] automata) {\n    CharacterRunAutomaton[] newAutomata = new CharacterRunAutomaton[terms.length + automata.length];\n    for (int i = 0; i < terms.length; i++) {\n      String termString = terms[i].utf8ToString();\n      newAutomata[i] = new CharacterRunAutomaton(Automata.makeString(termString)) {\n        @Override\n        public String toString() {\n          return termString;\n        }\n      };\n    }\n    // Append existing automata (that which is used for MTQs)\n    System.arraycopy(automata, 0, newAutomata, terms.length, automata.length);\n    return newAutomata;\n  }\n\n","sourceOld":"  private static CharacterRunAutomaton[] convertTermsToAutomata(BytesRef[] terms, CharacterRunAutomaton[] automata) {\n    CharacterRunAutomaton[] newAutomata = new CharacterRunAutomaton[terms.length + automata.length];\n    for (int i = 0; i < terms.length; i++) {\n      newAutomata[i] = MultiTermHighlighting.makeStringMatchAutomata(terms[i]);\n    }\n    // Append existing automata (that which is used for MTQs)\n    System.arraycopy(automata, 0, newAutomata, terms.length, automata.length);\n    return newAutomata;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c2a55d7ebf9e9ced797f40d5154d602029a9791d","date":1561151156,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamOffsetStrategy#convertTermsToAutomata(BytesRef[],CharacterRunAutomaton[]).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamOffsetStrategy#convertTermsToAutomata(BytesRef[],CharacterRunAutomaton[]).mjava","sourceNew":"  //TODO this is inefficient; instead build a union automata just for terms part.\n  private static CharacterRunAutomaton[] convertTermsToAutomata(BytesRef[] terms, CharacterRunAutomaton[] automata) {\n    CharacterRunAutomaton[] newAutomata = new CharacterRunAutomaton[terms.length + automata.length];\n    for (int i = 0; i < terms.length; i++) {\n      String termString = terms[i].utf8ToString();\n      newAutomata[i] = new CharacterRunAutomaton(Automata.makeString(termString)) {\n        @Override\n        public String toString() {\n          return termString;\n        }\n      };\n    }\n    // Append existing automata (that which is used for MTQs)\n    System.arraycopy(automata, 0, newAutomata, terms.length, automata.length);\n    return newAutomata;\n  }\n\n","sourceOld":"  private static CharacterRunAutomaton[] convertTermsToAutomata(BytesRef[] terms, CharacterRunAutomaton[] automata) {\n    CharacterRunAutomaton[] newAutomata = new CharacterRunAutomaton[terms.length + automata.length];\n    for (int i = 0; i < terms.length; i++) {\n      String termString = terms[i].utf8ToString();\n      newAutomata[i] = new CharacterRunAutomaton(Automata.makeString(termString)) {\n        @Override\n        public String toString() {\n          return termString;\n        }\n      };\n    }\n    // Append existing automata (that which is used for MTQs)\n    System.arraycopy(automata, 0, newAutomata, terms.length, automata.length);\n    return newAutomata;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d35c63123a7e255b58f8cf3948eb9a6128100a32","date":1574872099,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamOffsetStrategy#convertTermsToMatchers(BytesRef[],CharArrayMatcher[]).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/TokenStreamOffsetStrategy#convertTermsToAutomata(BytesRef[],CharacterRunAutomaton[]).mjava","sourceNew":"  //TODO this is inefficient; instead build a union automata just for terms part.\n  private static CharArrayMatcher[] convertTermsToMatchers(BytesRef[] terms, CharArrayMatcher[] matchers) {\n    CharArrayMatcher[] newAutomata = new CharArrayMatcher[terms.length + matchers.length];\n    for (int i = 0; i < terms.length; i++) {\n      String termString = terms[i].utf8ToString();\n      CharacterRunAutomaton a = new CharacterRunAutomaton(Automata.makeString(termString));\n      newAutomata[i] = LabelledCharArrayMatcher.wrap(termString, a::run);\n    }\n    // Append existing automata (that which is used for MTQs)\n    System.arraycopy(matchers, 0, newAutomata, terms.length, matchers.length);\n    return newAutomata;\n  }\n\n","sourceOld":"  //TODO this is inefficient; instead build a union automata just for terms part.\n  private static CharacterRunAutomaton[] convertTermsToAutomata(BytesRef[] terms, CharacterRunAutomaton[] automata) {\n    CharacterRunAutomaton[] newAutomata = new CharacterRunAutomaton[terms.length + automata.length];\n    for (int i = 0; i < terms.length; i++) {\n      String termString = terms[i].utf8ToString();\n      newAutomata[i] = new CharacterRunAutomaton(Automata.makeString(termString)) {\n        @Override\n        public String toString() {\n          return termString;\n        }\n      };\n    }\n    // Append existing automata (that which is used for MTQs)\n    System.arraycopy(automata, 0, newAutomata, terms.length, automata.length);\n    return newAutomata;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c2a55d7ebf9e9ced797f40d5154d602029a9791d":["f2e9861e4a2b724d9fc51b618714c579491b78d7"],"f2e9861e4a2b724d9fc51b618714c579491b78d7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f2e9861e4a2b724d9fc51b618714c579491b78d7"],"d35c63123a7e255b58f8cf3948eb9a6128100a32":["c2a55d7ebf9e9ced797f40d5154d602029a9791d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d35c63123a7e255b58f8cf3948eb9a6128100a32"]},"commit2Childs":{"c2a55d7ebf9e9ced797f40d5154d602029a9791d":["d35c63123a7e255b58f8cf3948eb9a6128100a32"],"f2e9861e4a2b724d9fc51b618714c579491b78d7":["c2a55d7ebf9e9ced797f40d5154d602029a9791d","a1ef55e1fff7ff44354432770ad8bc19be1fcc75"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f2e9861e4a2b724d9fc51b618714c579491b78d7","a1ef55e1fff7ff44354432770ad8bc19be1fcc75"],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":[],"d35c63123a7e255b58f8cf3948eb9a6128100a32":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}