{"path":"src/java/org/apache/solr/update/DirectUpdateHandler2#doDeletions().mjava","commits":[{"id":"0c3e228bf650e96f3002a8fb73dd0c13d55af077","date":1138253849,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/update/DirectUpdateHandler2#doDeletions().mjava","pathOld":"/dev/null","sourceNew":"  //\n  // do all needed deletions.\n  // call in a synchronized context.\n  //\n  protected void doDeletions() throws IOException {\n\n    if (pset.size() > 0) { // optimization: only open searcher if there is something to delete...\n      log.info(\"DirectUpdateHandler2 deleting and removing dups for \" + pset.size() +\" ids\");\n      int numDeletes=0;\n\n      closeWriter();\n      openSearcher();\n      IndexReader reader = searcher.getReader();\n      TermDocs tdocs = reader.termDocs();\n      String fieldname = idField.getName();\n\n      for (Map.Entry<String,Integer> entry : pset.entrySet()) {\n        String id = entry.getKey();\n        int saveLast = entry.getValue();  // save the last \"saveLast\" documents\n\n        //expand our array that keeps track of docs if needed.\n        if (docnums==null || saveLast > docnums.length) {\n          docnums = new int[saveLast];\n        }\n\n        // initialize all docnums in the list to -1 (unused)\n        for (int i=0; i<saveLast; i++) {\n          docnums[i] = -1;\n        }\n\n        tdocs.seek(new Term(fieldname,id));\n\n        //\n        // record the docs for this term in the \"docnums\" array and wrap around\n        // at size \"saveLast\".  If we reuse a slot in the array, then we delete\n        // the doc that was there from the index.\n        //\n        int pos=0;\n        while (tdocs.next()) {\n          if (saveLast==0) {\n            // special case - delete all the docs as we see them.\n            reader.delete(tdocs.doc());\n            numDeletes++;\n            continue;\n          }\n\n          int prev=docnums[pos];\n          docnums[pos]=tdocs.doc();\n          if (prev != -1) {\n            reader.delete(prev);\n            numDeletes++;\n          }\n\n          if (++pos >= saveLast) pos=0;\n        }\n      }\n\n      // should we ever shrink it again, or just clear it?\n      pset.clear();\n      log.info(\"DirectUpdateHandler2 docs deleted=\" + numDeletes);\n      numDocsDeleted.addAndGet(numDeletes);\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c7040334a42400ca67824559be90a1f2f2c9e63","date":1142276541,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/update/DirectUpdateHandler2#doDeletions().mjava","pathOld":"src/java/org/apache/solr/update/DirectUpdateHandler2#doDeletions().mjava","sourceNew":"  //\n  // do all needed deletions.\n  // call in a synchronized context.\n  //\n  protected void doDeletions() throws IOException {\n\n    if (pset.size() > 0) { // optimization: only open searcher if there is something to delete...\n      log.info(\"DirectUpdateHandler2 deleting and removing dups for \" + pset.size() +\" ids\");\n      int numDeletes=0;\n\n      closeWriter();\n      openSearcher();\n      IndexReader reader = searcher.getReader();\n      TermDocs tdocs = reader.termDocs();\n      String fieldname = idField.getName();\n\n      for (Map.Entry<String,Integer> entry : pset.entrySet()) {\n        String id = entry.getKey();\n        int saveLast = entry.getValue();  // save the last \"saveLast\" documents\n\n        //expand our array that keeps track of docs if needed.\n        if (docnums==null || saveLast > docnums.length) {\n          docnums = new int[saveLast];\n        }\n\n        // initialize all docnums in the list to -1 (unused)\n        for (int i=0; i<saveLast; i++) {\n          docnums[i] = -1;\n        }\n\n        tdocs.seek(new Term(fieldname,id));\n\n        //\n        // record the docs for this term in the \"docnums\" array and wrap around\n        // at size \"saveLast\".  If we reuse a slot in the array, then we delete\n        // the doc that was there from the index.\n        //\n        int pos=0;\n        while (tdocs.next()) {\n          if (saveLast==0) {\n            // special case - delete all the docs as we see them.\n            reader.deleteDocument(tdocs.doc());\n            numDeletes++;\n            continue;\n          }\n\n          int prev=docnums[pos];\n          docnums[pos]=tdocs.doc();\n          if (prev != -1) {\n            reader.deleteDocument(prev);\n            numDeletes++;\n          }\n\n          if (++pos >= saveLast) pos=0;\n        }\n      }\n\n      // should we ever shrink it again, or just clear it?\n      pset.clear();\n      log.info(\"DirectUpdateHandler2 docs deleted=\" + numDeletes);\n      numDocsDeleted.addAndGet(numDeletes);\n    }\n\n  }\n\n","sourceOld":"  //\n  // do all needed deletions.\n  // call in a synchronized context.\n  //\n  protected void doDeletions() throws IOException {\n\n    if (pset.size() > 0) { // optimization: only open searcher if there is something to delete...\n      log.info(\"DirectUpdateHandler2 deleting and removing dups for \" + pset.size() +\" ids\");\n      int numDeletes=0;\n\n      closeWriter();\n      openSearcher();\n      IndexReader reader = searcher.getReader();\n      TermDocs tdocs = reader.termDocs();\n      String fieldname = idField.getName();\n\n      for (Map.Entry<String,Integer> entry : pset.entrySet()) {\n        String id = entry.getKey();\n        int saveLast = entry.getValue();  // save the last \"saveLast\" documents\n\n        //expand our array that keeps track of docs if needed.\n        if (docnums==null || saveLast > docnums.length) {\n          docnums = new int[saveLast];\n        }\n\n        // initialize all docnums in the list to -1 (unused)\n        for (int i=0; i<saveLast; i++) {\n          docnums[i] = -1;\n        }\n\n        tdocs.seek(new Term(fieldname,id));\n\n        //\n        // record the docs for this term in the \"docnums\" array and wrap around\n        // at size \"saveLast\".  If we reuse a slot in the array, then we delete\n        // the doc that was there from the index.\n        //\n        int pos=0;\n        while (tdocs.next()) {\n          if (saveLast==0) {\n            // special case - delete all the docs as we see them.\n            reader.delete(tdocs.doc());\n            numDeletes++;\n            continue;\n          }\n\n          int prev=docnums[pos];\n          docnums[pos]=tdocs.doc();\n          if (prev != -1) {\n            reader.delete(prev);\n            numDeletes++;\n          }\n\n          if (++pos >= saveLast) pos=0;\n        }\n      }\n\n      // should we ever shrink it again, or just clear it?\n      pset.clear();\n      log.info(\"DirectUpdateHandler2 docs deleted=\" + numDeletes);\n      numDocsDeleted.addAndGet(numDeletes);\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c065faf385411ac4ff02bdc763de7dfd8aa1c9f","date":1163033034,"type":3,"author":"Mike Klaas","isMerge":false,"pathNew":"src/java/org/apache/solr/update/DirectUpdateHandler2#doDeletions().mjava","pathOld":"src/java/org/apache/solr/update/DirectUpdateHandler2#doDeletions().mjava","sourceNew":"  //\n  // do all needed deletions.\n  // call with iwCommit lock held\n  //\n  protected void doDeletions() throws IOException {\n    int[] docnums = new int[0];\n\n    if (pset.size() > 0) { // optimization: only open searcher if there is something to delete...\n      log.info(\"DirectUpdateHandler2 deleting and removing dups for \" + pset.size() +\" ids\");\n      int numDeletes=0;\n\n      closeWriter();\n      openSearcher();\n      IndexReader reader = searcher.getReader();\n      TermDocs tdocs = reader.termDocs();\n      String fieldname = idField.getName();\n\n      for (Map.Entry<String,Integer> entry : pset.entrySet()) {\n        String id = entry.getKey();\n        int saveLast = entry.getValue();  // save the last \"saveLast\" documents\n\n        //expand our array that keeps track of docs if needed.\n        if (docnums==null || saveLast > docnums.length) {\n          docnums = new int[saveLast];\n        }\n\n        // initialize all docnums in the list to -1 (unused)\n        for (int i=0; i<saveLast; i++) {\n          docnums[i] = -1;\n        }\n\n        tdocs.seek(new Term(fieldname,id));\n\n        //\n        // record the docs for this term in the \"docnums\" array and wrap around\n        // at size \"saveLast\".  If we reuse a slot in the array, then we delete\n        // the doc that was there from the index.\n        //\n        int pos=0;\n        while (tdocs.next()) {\n          if (saveLast==0) {\n            // special case - delete all the docs as we see them.\n            reader.deleteDocument(tdocs.doc());\n            numDeletes++;\n            continue;\n          }\n\n          int prev=docnums[pos];\n          docnums[pos]=tdocs.doc();\n          if (prev != -1) {\n            reader.deleteDocument(prev);\n            numDeletes++;\n          }\n\n          if (++pos >= saveLast) pos=0;\n        }\n      }\n\n      // should we ever shrink it again, or just clear it?\n      pset.clear();\n      log.info(\"DirectUpdateHandler2 docs deleted=\" + numDeletes);\n      numDocsDeleted.addAndGet(numDeletes);\n    }\n\n  }\n\n","sourceOld":"  //\n  // do all needed deletions.\n  // call in a synchronized context.\n  //\n  protected void doDeletions() throws IOException {\n\n    if (pset.size() > 0) { // optimization: only open searcher if there is something to delete...\n      log.info(\"DirectUpdateHandler2 deleting and removing dups for \" + pset.size() +\" ids\");\n      int numDeletes=0;\n\n      closeWriter();\n      openSearcher();\n      IndexReader reader = searcher.getReader();\n      TermDocs tdocs = reader.termDocs();\n      String fieldname = idField.getName();\n\n      for (Map.Entry<String,Integer> entry : pset.entrySet()) {\n        String id = entry.getKey();\n        int saveLast = entry.getValue();  // save the last \"saveLast\" documents\n\n        //expand our array that keeps track of docs if needed.\n        if (docnums==null || saveLast > docnums.length) {\n          docnums = new int[saveLast];\n        }\n\n        // initialize all docnums in the list to -1 (unused)\n        for (int i=0; i<saveLast; i++) {\n          docnums[i] = -1;\n        }\n\n        tdocs.seek(new Term(fieldname,id));\n\n        //\n        // record the docs for this term in the \"docnums\" array and wrap around\n        // at size \"saveLast\".  If we reuse a slot in the array, then we delete\n        // the doc that was there from the index.\n        //\n        int pos=0;\n        while (tdocs.next()) {\n          if (saveLast==0) {\n            // special case - delete all the docs as we see them.\n            reader.deleteDocument(tdocs.doc());\n            numDeletes++;\n            continue;\n          }\n\n          int prev=docnums[pos];\n          docnums[pos]=tdocs.doc();\n          if (prev != -1) {\n            reader.deleteDocument(prev);\n            numDeletes++;\n          }\n\n          if (++pos >= saveLast) pos=0;\n        }\n      }\n\n      // should we ever shrink it again, or just clear it?\n      pset.clear();\n      log.info(\"DirectUpdateHandler2 docs deleted=\" + numDeletes);\n      numDocsDeleted.addAndGet(numDeletes);\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"978a45c0ae33fbcb8e6e9a632cacf0e030fd9aae","date":1210454197,"type":4,"author":"Yonik Seeley","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/solr/update/DirectUpdateHandler2#doDeletions().mjava","sourceNew":null,"sourceOld":"  //\n  // do all needed deletions.\n  // call with iwCommit lock held\n  //\n  protected void doDeletions() throws IOException {\n    int[] docnums = new int[0];\n\n    if (pset.size() > 0) { // optimization: only open searcher if there is something to delete...\n      log.info(\"DirectUpdateHandler2 deleting and removing dups for \" + pset.size() +\" ids\");\n      int numDeletes=0;\n\n      closeWriter();\n      openSearcher();\n      IndexReader reader = searcher.getReader();\n      TermDocs tdocs = reader.termDocs();\n      String fieldname = idField.getName();\n\n      for (Map.Entry<String,Integer> entry : pset.entrySet()) {\n        String id = entry.getKey();\n        int saveLast = entry.getValue();  // save the last \"saveLast\" documents\n\n        //expand our array that keeps track of docs if needed.\n        if (docnums==null || saveLast > docnums.length) {\n          docnums = new int[saveLast];\n        }\n\n        // initialize all docnums in the list to -1 (unused)\n        for (int i=0; i<saveLast; i++) {\n          docnums[i] = -1;\n        }\n\n        tdocs.seek(new Term(fieldname,id));\n\n        //\n        // record the docs for this term in the \"docnums\" array and wrap around\n        // at size \"saveLast\".  If we reuse a slot in the array, then we delete\n        // the doc that was there from the index.\n        //\n        int pos=0;\n        while (tdocs.next()) {\n          if (saveLast==0) {\n            // special case - delete all the docs as we see them.\n            reader.deleteDocument(tdocs.doc());\n            numDeletes++;\n            continue;\n          }\n\n          int prev=docnums[pos];\n          docnums[pos]=tdocs.doc();\n          if (prev != -1) {\n            reader.deleteDocument(prev);\n            numDeletes++;\n          }\n\n          if (++pos >= saveLast) pos=0;\n        }\n      }\n\n      // should we ever shrink it again, or just clear it?\n      pset.clear();\n      log.info(\"DirectUpdateHandler2 docs deleted=\" + numDeletes);\n      numDocsDeleted.addAndGet(numDeletes);\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4c065faf385411ac4ff02bdc763de7dfd8aa1c9f":["7c7040334a42400ca67824559be90a1f2f2c9e63"],"0c3e228bf650e96f3002a8fb73dd0c13d55af077":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"7c7040334a42400ca67824559be90a1f2f2c9e63":["0c3e228bf650e96f3002a8fb73dd0c13d55af077"],"978a45c0ae33fbcb8e6e9a632cacf0e030fd9aae":["4c065faf385411ac4ff02bdc763de7dfd8aa1c9f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"4c065faf385411ac4ff02bdc763de7dfd8aa1c9f":["978a45c0ae33fbcb8e6e9a632cacf0e030fd9aae"],"0c3e228bf650e96f3002a8fb73dd0c13d55af077":["7c7040334a42400ca67824559be90a1f2f2c9e63"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["0c3e228bf650e96f3002a8fb73dd0c13d55af077"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7c7040334a42400ca67824559be90a1f2f2c9e63":["4c065faf385411ac4ff02bdc763de7dfd8aa1c9f"],"978a45c0ae33fbcb8e6e9a632cacf0e030fd9aae":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["978a45c0ae33fbcb8e6e9a632cacf0e030fd9aae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}