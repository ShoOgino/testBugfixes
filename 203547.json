{"path":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","commits":[{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndLiveDocs#getReaderForMerge(IOContext).mjava","sourceNew":"  /**\n   * Returns a reader for merge. This method applies field updates if there are\n   * any and marks that this segment is currently merging.\n   */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n    assert Thread.holdsLock(writer);\n    // must execute these two statements as atomic operation, otherwise we\n    // could lose updates if e.g. another thread calls writeFieldUpdates in\n    // between, or the updates are applied to the obtained reader, but then\n    // re-applied in IW.commitMergedDeletes (unnecessary work and potential\n    // bugs).\n    isMerging = true;\n    return getReader(context);\n  }\n\n","sourceOld":"  /**\n   * Returns a reader for merge. This method applies field updates if there are\n   * any and marks that this segment is currently merging.\n   */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n    assert Thread.holdsLock(writer);\n    // must execute these two statements as atomic operation, otherwise we\n    // could lose updates if e.g. another thread calls writeFieldUpdates in\n    // between, or the updates are applied to the obtained reader, but then\n    // re-applied in IW.commitMergedDeletes (unnecessary work and potential\n    // bugs).\n    isMerging = true;\n    return getReader(context);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // This ensures any newly resolved doc value updates while we are merging are\n    // saved for re-applying after this segment is done merging:\n    isMerging = true;\n\n    assert mergingDVUpdates.isEmpty();\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.decRef();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /**\n   * Returns a reader for merge. This method applies field updates if there are\n   * any and marks that this segment is currently merging.\n   */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n    assert Thread.holdsLock(writer);\n    // must execute these two statements as atomic operation, otherwise we\n    // could lose updates if e.g. another thread calls writeFieldUpdates in\n    // between, or the updates are applied to the obtained reader, but then\n    // re-applied in IW.commitMergedDeletes (unnecessary work and potential\n    // bugs).\n    isMerging = true;\n    return getReader(context);\n  }\n\n","bugFix":null,"bugIntro":["36d84416fc00253f9e834f8dba14fa89b298e64e","636c73dfa97dd282a3089d4239620475f2633519"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // This ensures any newly resolved doc value updates while we are merging are\n    // saved for re-applying after this segment is done merging:\n    isMerging = true;\n\n    assert mergingDVUpdates.isEmpty();\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.decRef();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /**\n   * Returns a reader for merge. This method applies field updates if there are\n   * any and marks that this segment is currently merging.\n   */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n    assert Thread.holdsLock(writer);\n    // must execute these two statements as atomic operation, otherwise we\n    // could lose updates if e.g. another thread calls writeFieldUpdates in\n    // between, or the updates are applied to the obtained reader, but then\n    // re-applied in IW.commitMergedDeletes (unnecessary work and potential\n    // bugs).\n    isMerging = true;\n    return getReader(context);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // This ensures any newly resolved doc value updates while we are merging are\n    // saved for re-applying after this segment is done merging:\n    isMerging = true;\n\n    assert mergingDVUpdates.isEmpty();\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.decRef();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /**\n   * Returns a reader for merge. This method applies field updates if there are\n   * any and marks that this segment is currently merging.\n   */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n    assert Thread.holdsLock(writer);\n    // must execute these two statements as atomic operation, otherwise we\n    // could lose updates if e.g. another thread calls writeFieldUpdates in\n    // between, or the updates are applied to the obtained reader, but then\n    // re-applied in IW.commitMergedDeletes (unnecessary work and potential\n    // bugs).\n    isMerging = true;\n    return getReader(context);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"636c73dfa97dd282a3089d4239620475f2633519","date":1499025533,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.decRef();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // This ensures any newly resolved doc value updates while we are merging are\n    // saved for re-applying after this segment is done merging:\n    isMerging = true;\n\n    assert mergingDVUpdates.isEmpty();\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.decRef();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","bugFix":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35","date":1499066739,"type":3,"author":"Adrien Grand","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.decRef();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // This ensures any newly resolved doc value updates while we are merging are\n    // saved for re-applying after this segment is done merging:\n    isMerging = true;\n\n    assert mergingDVUpdates.isEmpty();\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.decRef();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30c8e5574b55d57947e989443dfde611646530ee","date":1499131153,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.decRef();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // This ensures any newly resolved doc value updates while we are merging are\n    // saved for re-applying after this segment is done merging:\n    isMerging = true;\n\n    assert mergingDVUpdates.isEmpty();\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.decRef();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14d66d86a8b184a86bcaebcf6e15fcef486e0876","date":1521539412,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.close();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.decRef();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","date":1521731438,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.close();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.decRef();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d60c1bb96a28a26d197c36299f7b6c9c5da617a1","date":1522484702,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeletes.numPendingDeletes() + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n      Bits liveDocs = pendingDeletes.getLiveDocs();\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        pendingDeletes.onNewReader(newReader, info);\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.close();\n        }\n      }\n      reader = newReader;\n    }\n\n    pendingDeletes.liveDocsShared();\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.close();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"aa5e39259dfd4a68287c824d3b7e1bc9097dc895","date":1522505041,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeletes.numPendingDeletes() + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n      Bits liveDocs = pendingDeletes.getLiveDocs();\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        pendingDeletes.onNewReader(newReader, info);\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.close();\n        }\n      }\n      reader = newReader;\n    }\n\n    pendingDeletes.liveDocsShared();\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeleteCount + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.close();\n        }\n      }\n      reader = newReader;\n    }\n\n    liveDocsShared = true;\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9ae87c7be37e537f40fa3bb2c35fa4a368d12a72","date":1523453225,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeletes.numPendingDeletes() + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n\n    markAsShared();\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeletes.numPendingDeletes() + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n      Bits liveDocs = pendingDeletes.getLiveDocs();\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        pendingDeletes.onNewReader(newReader, info);\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.close();\n        }\n      }\n      reader = newReader;\n    }\n\n    pendingDeletes.liveDocsShared();\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43345f1452f9510f8aaadae6156fe0c834e7d957","date":1523483670,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeletes.numPendingDeletes() + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n\n    markAsShared();\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeletes.numPendingDeletes() + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n      Bits liveDocs = pendingDeletes.getLiveDocs();\n      assert liveDocs != null;\n      \n      // Create a new reader with the latest live docs:\n      SegmentReader newReader = new SegmentReader(info, reader, liveDocs, info.info.maxDoc() - delCount);\n      boolean success = false;\n      try {\n        reader.decRef();\n        pendingDeletes.onNewReader(newReader, info);\n        success = true;\n      } finally {\n        if (success == false) {\n          newReader.close();\n        }\n      }\n      reader = newReader;\n    }\n\n    pendingDeletes.liveDocsShared();\n\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"36d84416fc00253f9e834f8dba14fa89b298e64e","date":1525428963,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeletes.numPendingDeletes() + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n\n    markAsShared();\n    assert verifyDocCounts();\n\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized SegmentReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeletes.numPendingDeletes() + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n\n    markAsShared();\n    assert verifyDocCounts();\n\n    return reader;\n  }\n\n","bugFix":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"13bce432480722e4f48bce0da3623dab44dd8d9c","date":1525873214,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeletes.numPendingDeletes() + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n    assert verifyDocCounts();\n\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeletes.numPendingDeletes() + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n\n    markAsShared();\n    assert verifyDocCounts();\n\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aef2a94da918b657d107b616a643e1759db43b6a","date":1527706131,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    if (pendingDeletes.needsRefresh(reader)) {\n      // beware of zombies:\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n    assert pendingDeletes.verifyDocCounts(reader);\n\n\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    int delCount = pendingDeletes.numPendingDeletes() + info.getDelCount();\n    if (delCount != reader.numDeletedDocs()) {\n      // beware of zombies:\n      assert delCount > reader.numDeletedDocs(): \"delCount=\" + delCount + \" reader.numDeletedDocs()=\" + reader.numDeletedDocs();\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n    assert verifyDocCounts();\n\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8f2203cb8ae87188877cfbf6ad170c5738a0aad5","date":1528117512,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    if (pendingDeletes.needsRefresh(reader)) {\n      // beware of zombies:\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n    assert pendingDeletes.verifyDocCounts(reader);\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    if (pendingDeletes.needsRefresh(reader)) {\n      // beware of zombies:\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n    assert pendingDeletes.verifyDocCounts(reader);\n\n\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    if (pendingDeletes.needsRefresh(reader)) {\n      // beware of zombies:\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n    assert pendingDeletes.verifyDocCounts(reader);\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    if (pendingDeletes.needsRefresh(reader)) {\n      // beware of zombies:\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n    assert pendingDeletes.verifyDocCounts(reader);\n\n\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    if (pendingDeletes.needsRefresh(reader)) {\n      // beware of zombies:\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n    assert pendingDeletes.verifyDocCounts(reader);\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    if (pendingDeletes.needsRefresh(reader)) {\n      // beware of zombies:\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n    assert pendingDeletes.verifyDocCounts(reader);\n\n\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c2a23476693f2bd9a4b44cc3187c429a2e21dac2","date":1593289545,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/ReadersAndUpdates#getReaderForMerge(IOContext).mjava","sourceNew":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergePolicy.MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    if (pendingDeletes.needsRefresh(reader)) {\n      // beware of zombies:\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n    assert pendingDeletes.verifyDocCounts(reader);\n    return new MergePolicy.MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","sourceOld":"  /** Returns a reader for merge, with the latest doc values updates and deletions. */\n  synchronized MergeReader getReaderForMerge(IOContext context) throws IOException {\n\n    // We must carry over any still-pending DV updates because they were not\n    // successfully written, e.g. because there was a hole in the delGens,\n    // or they arrived after we wrote all DVs for merge but before we set\n    // isMerging here:\n    for (Map.Entry<String, List<DocValuesFieldUpdates>> ent : pendingDVUpdates.entrySet()) {\n      List<DocValuesFieldUpdates> mergingUpdates = mergingDVUpdates.get(ent.getKey());\n      if (mergingUpdates == null) {\n        mergingUpdates = new ArrayList<>();\n        mergingDVUpdates.put(ent.getKey(), mergingUpdates);\n      }\n      mergingUpdates.addAll(ent.getValue());\n    }\n    \n    SegmentReader reader = getReader(context);\n    if (pendingDeletes.needsRefresh(reader)) {\n      // beware of zombies:\n      assert pendingDeletes.getLiveDocs() != null;\n      reader = createNewReaderWithLatestLiveDocs(reader);\n    }\n    assert pendingDeletes.verifyDocCounts(reader);\n    return new MergeReader(reader, pendingDeletes.getHardLiveDocs());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["636c73dfa97dd282a3089d4239620475f2633519","14d66d86a8b184a86bcaebcf6e15fcef486e0876"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"36d84416fc00253f9e834f8dba14fa89b298e64e":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"30c8e5574b55d57947e989443dfde611646530ee":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","636c73dfa97dd282a3089d4239620475f2633519"],"aa5e39259dfd4a68287c824d3b7e1bc9097dc895":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","d60c1bb96a28a26d197c36299f7b6c9c5da617a1"],"d60c1bb96a28a26d197c36299f7b6c9c5da617a1":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895","9ae87c7be37e537f40fa3bb2c35fa4a368d12a72"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"28288370235ed02234a64753cdbf0c6ec096304a":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"c2a23476693f2bd9a4b44cc3187c429a2e21dac2":["8f2203cb8ae87188877cfbf6ad170c5738a0aad5"],"13bce432480722e4f48bce0da3623dab44dd8d9c":["36d84416fc00253f9e834f8dba14fa89b298e64e"],"636c73dfa97dd282a3089d4239620475f2633519":["28288370235ed02234a64753cdbf0c6ec096304a"],"9ae87c7be37e537f40fa3bb2c35fa4a368d12a72":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["aef2a94da918b657d107b616a643e1759db43b6a","8f2203cb8ae87188877cfbf6ad170c5738a0aad5"],"6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35":["28288370235ed02234a64753cdbf0c6ec096304a","636c73dfa97dd282a3089d4239620475f2633519"],"8f2203cb8ae87188877cfbf6ad170c5738a0aad5":["aef2a94da918b657d107b616a643e1759db43b6a"],"aef2a94da918b657d107b616a643e1759db43b6a":["13bce432480722e4f48bce0da3623dab44dd8d9c"],"f592209545c71895260367152601e9200399776d":["aef2a94da918b657d107b616a643e1759db43b6a","8f2203cb8ae87188877cfbf6ad170c5738a0aad5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c2a23476693f2bd9a4b44cc3187c429a2e21dac2"],"14d66d86a8b184a86bcaebcf6e15fcef486e0876":["636c73dfa97dd282a3089d4239620475f2633519"]},"commit2Childs":{"6815b5b5d6334b2245dd7be2f8b6cca949bf7f43":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895","d60c1bb96a28a26d197c36299f7b6c9c5da617a1"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"36d84416fc00253f9e834f8dba14fa89b298e64e":["13bce432480722e4f48bce0da3623dab44dd8d9c"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"30c8e5574b55d57947e989443dfde611646530ee":[],"aa5e39259dfd4a68287c824d3b7e1bc9097dc895":["43345f1452f9510f8aaadae6156fe0c834e7d957","9ae87c7be37e537f40fa3bb2c35fa4a368d12a72"],"d60c1bb96a28a26d197c36299f7b6c9c5da617a1":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["36d84416fc00253f9e834f8dba14fa89b298e64e"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["30c8e5574b55d57947e989443dfde611646530ee"],"28288370235ed02234a64753cdbf0c6ec096304a":["636c73dfa97dd282a3089d4239620475f2633519","6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35"],"c2a23476693f2bd9a4b44cc3187c429a2e21dac2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"13bce432480722e4f48bce0da3623dab44dd8d9c":["aef2a94da918b657d107b616a643e1759db43b6a"],"636c73dfa97dd282a3089d4239620475f2633519":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43","30c8e5574b55d57947e989443dfde611646530ee","6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35","14d66d86a8b184a86bcaebcf6e15fcef486e0876"],"9ae87c7be37e537f40fa3bb2c35fa4a368d12a72":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35":[],"8f2203cb8ae87188877cfbf6ad170c5738a0aad5":["c2a23476693f2bd9a4b44cc3187c429a2e21dac2","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"aef2a94da918b657d107b616a643e1759db43b6a":["b70042a8a492f7054d480ccdd2be9796510d4327","8f2203cb8ae87188877cfbf6ad170c5738a0aad5","f592209545c71895260367152601e9200399776d"],"f592209545c71895260367152601e9200399776d":[],"14d66d86a8b184a86bcaebcf6e15fcef486e0876":["6815b5b5d6334b2245dd7be2f8b6cca949bf7f43"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["30c8e5574b55d57947e989443dfde611646530ee","b70042a8a492f7054d480ccdd2be9796510d4327","6324f236dd5a5430f2ff91ebd6cb3f0ae8d34a35","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}