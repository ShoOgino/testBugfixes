{"path":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","commits":[{"id":"043c298cb215f13ba7b9b81d20760704e8f93d66","date":1107566743,"type":1,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","pathOld":"sandbox/contributions/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","sourceNew":"\tpublic void testMaxSizeHighlight() throws Exception\n\t{\n\t\tdoSearching(\"meat\");\n\t\tHighlighter highlighter =\n\t\t\tnew Highlighter(this,new QueryScorer(query));\n\t\thighlighter.setMaxDocBytesToAnalyze(30);\n\t\tTokenStream tokenStream=analyzer.tokenStream(FIELD_NAME,new StringReader(texts[0]));\n\t\tString result = highlighter.getBestFragment(tokenStream,texts[0]);\n\t\tassertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \" +\n\t\t\t\"us from finding matches for this record\" + numHighlights +\n\t\t\t \" found\", numHighlights == 0);\n\t}\n\n","sourceOld":"\tpublic void testMaxSizeHighlight() throws Exception\n\t{\n\t\tdoSearching(\"meat\");\n\t\tHighlighter highlighter =\n\t\t\tnew Highlighter(this,new QueryScorer(query));\n\t\thighlighter.setMaxDocBytesToAnalyze(30);\n\t\tTokenStream tokenStream=analyzer.tokenStream(FIELD_NAME,new StringReader(texts[0]));\n\t\tString result = highlighter.getBestFragment(tokenStream,texts[0]);\n\t\tassertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \" +\n\t\t\t\"us from finding matches for this record\" + numHighlights +\n\t\t\t \" found\", numHighlights == 0);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b4cf21055ce3298c85f04952b1aa208983470c4","date":1108840132,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","sourceNew":"\tpublic void testMaxSizeHighlight() throws Exception\n\t{\n\t\tdoSearching(\"meat\");\n\t\tHighlighter highlighter =\n\t\t\tnew Highlighter(this,new QueryScorer(query));\n\t\thighlighter.setMaxDocBytesToAnalyze(30);\n\t\tTokenStream tokenStream=analyzer.tokenStream(FIELD_NAME,new StringReader(texts[0]));\n\t\tString result = highlighter.getBestFragment(tokenStream,texts[0]);\n\t\tassertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \" +\n\t\t\t\"us from finding matches for this record: \" + numHighlights +\n\t\t\t \" found\", numHighlights == 0);\n\t}\n\n","sourceOld":"\tpublic void testMaxSizeHighlight() throws Exception\n\t{\n\t\tdoSearching(\"meat\");\n\t\tHighlighter highlighter =\n\t\t\tnew Highlighter(this,new QueryScorer(query));\n\t\thighlighter.setMaxDocBytesToAnalyze(30);\n\t\tTokenStream tokenStream=analyzer.tokenStream(FIELD_NAME,new StringReader(texts[0]));\n\t\tString result = highlighter.getBestFragment(tokenStream,texts[0]);\n\t\tassertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \" +\n\t\t\t\"us from finding matches for this record\" + numHighlights +\n\t\t\t \" found\", numHighlights == 0);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"00baa0cad99f9a7efd382b1e817c2f6b9384220a","date":1140555918,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","sourceNew":"\tpublic void testMaxSizeHighlight() throws Exception\n\t{\n\t\tdoSearching(\"meat\");\n\t\tHighlighter highlighter =\n\t\t\tnew Highlighter(this,new QueryScorer(query));\n\t\thighlighter.setMaxDocBytesToAnalyze(30);\n\t\tTokenStream tokenStream=analyzer.tokenStream(FIELD_NAME,new StringReader(texts[0]));\n\t\thighlighter.getBestFragment(tokenStream,texts[0]);\n\t\tassertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \" +\n\t\t\t\"us from finding matches for this record: \" + numHighlights +\n\t\t\t \" found\", numHighlights == 0);\n\t}\n\n","sourceOld":"\tpublic void testMaxSizeHighlight() throws Exception\n\t{\n\t\tdoSearching(\"meat\");\n\t\tHighlighter highlighter =\n\t\t\tnew Highlighter(this,new QueryScorer(query));\n\t\thighlighter.setMaxDocBytesToAnalyze(30);\n\t\tTokenStream tokenStream=analyzer.tokenStream(FIELD_NAME,new StringReader(texts[0]));\n\t\tString result = highlighter.getBestFragment(tokenStream,texts[0]);\n\t\tassertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \" +\n\t\t\t\"us from finding matches for this record: \" + numHighlights +\n\t\t\t \" found\", numHighlights == 0);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"296b8b38a87feb478921f77834a2302dfe77641c","date":1209506838,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","sourceNew":"  public void testMaxSizeHighlight() throws Exception {\n    TestHighlightRunner helper = new TestHighlightRunner() {\n\n      public void run() throws Exception {\n        numHighlights = 0;\n        doSearching(\"meat\");\n        TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(texts[0]));\n        Highlighter highlighter = getHighlighter(query, FIELD_NAME, tokenStream,\n            HighlighterTest.this);// new Highlighter(this, new\n        // QueryScorer(query));\n        highlighter.setMaxDocBytesToAnalyze(30);\n\n        highlighter.getBestFragment(tokenStream, texts[0]);\n        assertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \"\n            + \"us from finding matches for this record: \" + numHighlights + \" found\",\n            numHighlights == 0);\n      }\n    };\n\n    helper.start();\n  }\n\n","sourceOld":"\tpublic void testMaxSizeHighlight() throws Exception\n\t{\n\t\tdoSearching(\"meat\");\n\t\tHighlighter highlighter =\n\t\t\tnew Highlighter(this,new QueryScorer(query));\n\t\thighlighter.setMaxDocBytesToAnalyze(30);\n\t\tTokenStream tokenStream=analyzer.tokenStream(FIELD_NAME,new StringReader(texts[0]));\n\t\thighlighter.getBestFragment(tokenStream,texts[0]);\n\t\tassertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \" +\n\t\t\t\"us from finding matches for this record: \" + numHighlights +\n\t\t\t \" found\", numHighlights == 0);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"943c3f9cf96b8df37f4273d66a66182e2a669467","date":1249394171,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","sourceNew":"  public void testMaxSizeHighlight() throws Exception {\n    TestHighlightRunner helper = new TestHighlightRunner() {\n\n      public void run() throws Exception {\n        numHighlights = 0;\n        doSearching(\"meat\");\n        TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(texts[0]));\n        Highlighter highlighter = getHighlighter(query, FIELD_NAME, tokenStream,\n            HighlighterTest.this);// new Highlighter(this, new\n        // QueryTermScorer(query));\n        highlighter.setMaxDocBytesToAnalyze(30);\n\n        highlighter.getBestFragment(tokenStream, texts[0]);\n        assertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \"\n            + \"us from finding matches for this record: \" + numHighlights + \" found\",\n            numHighlights == 0);\n      }\n    };\n\n    helper.start();\n  }\n\n","sourceOld":"  public void testMaxSizeHighlight() throws Exception {\n    TestHighlightRunner helper = new TestHighlightRunner() {\n\n      public void run() throws Exception {\n        numHighlights = 0;\n        doSearching(\"meat\");\n        TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(texts[0]));\n        Highlighter highlighter = getHighlighter(query, FIELD_NAME, tokenStream,\n            HighlighterTest.this);// new Highlighter(this, new\n        // QueryScorer(query));\n        highlighter.setMaxDocBytesToAnalyze(30);\n\n        highlighter.getBestFragment(tokenStream, texts[0]);\n        assertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \"\n            + \"us from finding matches for this record: \" + numHighlights + \" found\",\n            numHighlights == 0);\n      }\n    };\n\n    helper.start();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d57eb7c98c08c03af6e4cd83509df31c81ac16af","date":1257684312,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","sourceNew":"  public void testMaxSizeHighlight() throws Exception {\n    TestHighlightRunner helper = new TestHighlightRunner() {\n\n      @Override\n      public void run() throws Exception {\n        numHighlights = 0;\n        doSearching(\"meat\");\n        TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(texts[0]));\n        Highlighter highlighter = getHighlighter(query, FIELD_NAME, tokenStream,\n            HighlighterTest.this);// new Highlighter(this, new\n        // QueryTermScorer(query));\n        highlighter.setMaxDocBytesToAnalyze(30);\n\n        highlighter.getBestFragment(tokenStream, texts[0]);\n        assertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \"\n            + \"us from finding matches for this record: \" + numHighlights + \" found\",\n            numHighlights == 0);\n      }\n    };\n\n    helper.start();\n  }\n\n","sourceOld":"  public void testMaxSizeHighlight() throws Exception {\n    TestHighlightRunner helper = new TestHighlightRunner() {\n\n      public void run() throws Exception {\n        numHighlights = 0;\n        doSearching(\"meat\");\n        TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(texts[0]));\n        Highlighter highlighter = getHighlighter(query, FIELD_NAME, tokenStream,\n            HighlighterTest.this);// new Highlighter(this, new\n        // QueryTermScorer(query));\n        highlighter.setMaxDocBytesToAnalyze(30);\n\n        highlighter.getBestFragment(tokenStream, texts[0]);\n        assertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \"\n            + \"us from finding matches for this record: \" + numHighlights + \" found\",\n            numHighlights == 0);\n      }\n    };\n\n    helper.start();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2aa9553aad4bb588f33e036ce51485a850a2917","date":1257895368,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","sourceNew":"  public void testMaxSizeHighlight() throws Exception {\n    TestHighlightRunner helper = new TestHighlightRunner() {\n\n      @Override\n      public void run() throws Exception {\n        numHighlights = 0;\n        doSearching(\"meat\");\n        TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(texts[0]));\n        Highlighter highlighter = getHighlighter(query, FIELD_NAME, tokenStream,\n            HighlighterTest.this);// new Highlighter(this, new\n        // QueryTermScorer(query));\n        highlighter.setMaxDocCharsToAnalyze(30);\n\n        highlighter.getBestFragment(tokenStream, texts[0]);\n        assertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \"\n            + \"us from finding matches for this record: \" + numHighlights + \" found\",\n            numHighlights == 0);\n      }\n    };\n\n    helper.start();\n  }\n\n","sourceOld":"  public void testMaxSizeHighlight() throws Exception {\n    TestHighlightRunner helper = new TestHighlightRunner() {\n\n      @Override\n      public void run() throws Exception {\n        numHighlights = 0;\n        doSearching(\"meat\");\n        TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(texts[0]));\n        Highlighter highlighter = getHighlighter(query, FIELD_NAME, tokenStream,\n            HighlighterTest.this);// new Highlighter(this, new\n        // QueryTermScorer(query));\n        highlighter.setMaxDocBytesToAnalyze(30);\n\n        highlighter.getBestFragment(tokenStream, texts[0]);\n        assertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \"\n            + \"us from finding matches for this record: \" + numHighlights + \" found\",\n            numHighlights == 0);\n      }\n    };\n\n    helper.start();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testMaxSizeHighlight().mjava","sourceNew":"  public void testMaxSizeHighlight() throws Exception {\n    TestHighlightRunner helper = new TestHighlightRunner() {\n\n      @Override\n      public void run() throws Exception {\n        numHighlights = 0;\n        doSearching(\"meat\");\n        TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(texts[0]));\n        Highlighter highlighter = getHighlighter(query, FIELD_NAME, tokenStream,\n            HighlighterTest.this);// new Highlighter(this, new\n        // QueryTermScorer(query));\n        highlighter.setMaxDocCharsToAnalyze(30);\n\n        highlighter.getBestFragment(tokenStream, texts[0]);\n        assertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \"\n            + \"us from finding matches for this record: \" + numHighlights + \" found\",\n            numHighlights == 0);\n      }\n    };\n\n    helper.start();\n  }\n\n","sourceOld":"  public void testMaxSizeHighlight() throws Exception {\n    TestHighlightRunner helper = new TestHighlightRunner() {\n\n      @Override\n      public void run() throws Exception {\n        numHighlights = 0;\n        doSearching(\"meat\");\n        TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(texts[0]));\n        Highlighter highlighter = getHighlighter(query, FIELD_NAME, tokenStream,\n            HighlighterTest.this);// new Highlighter(this, new\n        // QueryTermScorer(query));\n        highlighter.setMaxDocCharsToAnalyze(30);\n\n        highlighter.getBestFragment(tokenStream, texts[0]);\n        assertTrue(\"Setting MaxDocBytesToAnalyze should have prevented \"\n            + \"us from finding matches for this record: \" + numHighlights + \" found\",\n            numHighlights == 0);\n      }\n    };\n\n    helper.start();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"00baa0cad99f9a7efd382b1e817c2f6b9384220a":["4b4cf21055ce3298c85f04952b1aa208983470c4"],"f2aa9553aad4bb588f33e036ce51485a850a2917":["d57eb7c98c08c03af6e4cd83509df31c81ac16af"],"4b4cf21055ce3298c85f04952b1aa208983470c4":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d57eb7c98c08c03af6e4cd83509df31c81ac16af":["943c3f9cf96b8df37f4273d66a66182e2a669467"],"943c3f9cf96b8df37f4273d66a66182e2a669467":["296b8b38a87feb478921f77834a2302dfe77641c"],"296b8b38a87feb478921f77834a2302dfe77641c":["00baa0cad99f9a7efd382b1e817c2f6b9384220a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["f2aa9553aad4bb588f33e036ce51485a850a2917"]},"commit2Childs":{"00baa0cad99f9a7efd382b1e817c2f6b9384220a":["296b8b38a87feb478921f77834a2302dfe77641c"],"4b4cf21055ce3298c85f04952b1aa208983470c4":["00baa0cad99f9a7efd382b1e817c2f6b9384220a"],"f2aa9553aad4bb588f33e036ce51485a850a2917":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["4b4cf21055ce3298c85f04952b1aa208983470c4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"d57eb7c98c08c03af6e4cd83509df31c81ac16af":["f2aa9553aad4bb588f33e036ce51485a850a2917"],"943c3f9cf96b8df37f4273d66a66182e2a669467":["d57eb7c98c08c03af6e4cd83509df31c81ac16af"],"296b8b38a87feb478921f77834a2302dfe77641c":["943c3f9cf96b8df37f4273d66a66182e2a669467"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}