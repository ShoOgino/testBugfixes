{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymGraphFilter#testRandomSyns().mjava","commits":[{"id":"24a98f5fdd23e04f85819dbc63b47a12f7c44311","date":1482439157,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymGraphFilter#testRandomSyns().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandomSyns() throws Exception {\n    int synCount = atLeast(10);\n    double bias = random().nextDouble();\n    boolean dedup = random().nextBoolean();\n\n    boolean flatten = random().nextBoolean();\n\n    SynonymMap.Builder b = new SynonymMap.Builder(dedup);\n    List<OneSyn> syns = new ArrayList<>();\n    // Makes random syns from random a / b tokens, mapping to random x / y tokens\n    if (VERBOSE) {\n      System.out.println(\"TEST: make \" + synCount + \" syns\");\n      System.out.println(\"  bias for a over b=\" + bias);\n      System.out.println(\"  dedup=\" + dedup);\n      System.out.println(\"  flatten=\" + flatten);\n    }\n\n    int maxSynLength = 0;\n\n    for(int i=0;i<synCount;i++) {\n      OneSyn syn = new OneSyn();\n      syn.in = randomBinaryChars(1, 5, bias, 'a');\n      syn.out = randomBinaryChars(1, 5, 0.5, 'x');\n      syn.keepOrig = random().nextBoolean();\n      syns.add(syn);\n\n      maxSynLength = Math.max(maxSynLength, syn.in.length);\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + syn);\n      }\n      add(b, toTokenString(syn.in), toTokenString(syn.out), syn.keepOrig);\n    }\n\n    // Compute max allowed lookahead for flatten filter:\n    int maxFlattenLookahead = 0;\n    if (flatten) {\n      for(int i=0;i<synCount;i++) {\n        OneSyn syn1 = syns.get(i);\n        int count = syn1.out.length;\n        boolean keepOrig = syn1.keepOrig;\n        for(int j=0;j<synCount;j++) {\n          OneSyn syn2 = syns.get(i);\n          keepOrig |= syn2.keepOrig;\n          if (syn1.in.equals(syn2.in)) {\n            count += syn2.out.length;\n          }\n        }\n\n        if (keepOrig) {\n          count += syn1.in.length;\n        }\n\n        maxFlattenLookahead = Math.max(maxFlattenLookahead, count);\n      }\n    }\n\n    // Only used w/ VERBOSE:\n    Analyzer aNoFlattened;\n    if (VERBOSE) {\n      aNoFlattened = getAnalyzer(b, true);\n    } else {\n      aNoFlattened = null;\n    }\n\n    Analyzer a;\n    if (flatten) {\n      a = getFlattenAnalyzer(b, true);\n    } else {\n      a = getAnalyzer(b, true);\n    }\n\n    int iters = atLeast(20);\n    for(int iter=0;iter<iters;iter++) {\n\n      String doc = toTokenString(randomBinaryChars(50, 100, bias, 'a'));\n      //String doc = toTokenString(randomBinaryChars(10, 50, bias, 'a'));\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\"+  iter + \" doc=\" + doc);\n      }\n      Automaton expected = slowSynFilter(doc, syns, flatten);\n      if (VERBOSE) {\n        System.out.println(\"  expected:\\n\" + expected.toDot());\n        if (flatten) {\n          Automaton unflattened = toAutomaton(aNoFlattened.tokenStream(\"field\", new StringReader(doc)));\n          System.out.println(\"  actual unflattened:\\n\" + unflattened.toDot());\n        }\n      }\n      Automaton actual = toAutomaton(a.tokenStream(\"field\", new StringReader(doc)));\n      if (VERBOSE) {\n        System.out.println(\"  actual:\\n\" + actual.toDot());\n      }\n\n      assertTrue(\"maxLookaheadUsed=\" + synFilter.getMaxLookaheadUsed() + \" maxSynLength=\" + maxSynLength,\n                 synFilter.getMaxLookaheadUsed() <= maxSynLength);\n      if (flatten) {\n        assertTrue(\"flatten maxLookaheadUsed=\" + flattenFilter.getMaxLookaheadUsed() + \" maxFlattenLookahead=\" + maxFlattenLookahead,\n                   flattenFilter.getMaxLookaheadUsed() <= maxFlattenLookahead);\n      }\n\n      checkAnalysisConsistency(random(), a, random().nextBoolean(), doc);\n      // We can easily have a non-deterministic automaton at this point, e.g. if\n      // more than one syn matched at given point, or if the syn mapped to an\n      // output token that also happens to be in the input:\n      try {\n        actual = Operations.determinize(actual, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      try {\n        expected = Operations.determinize(expected, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      assertTrue(approxEquals(actual, expected));\n      assertTrue(Operations.sameLanguage(actual, expected));\n    }\n\n    a.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymGraphFilter#testRandomSyns().mjava","pathOld":"/dev/null","sourceNew":"  public void testRandomSyns() throws Exception {\n    int synCount = atLeast(10);\n    double bias = random().nextDouble();\n    boolean dedup = random().nextBoolean();\n\n    boolean flatten = random().nextBoolean();\n\n    SynonymMap.Builder b = new SynonymMap.Builder(dedup);\n    List<OneSyn> syns = new ArrayList<>();\n    // Makes random syns from random a / b tokens, mapping to random x / y tokens\n    if (VERBOSE) {\n      System.out.println(\"TEST: make \" + synCount + \" syns\");\n      System.out.println(\"  bias for a over b=\" + bias);\n      System.out.println(\"  dedup=\" + dedup);\n      System.out.println(\"  flatten=\" + flatten);\n    }\n\n    int maxSynLength = 0;\n\n    for(int i=0;i<synCount;i++) {\n      OneSyn syn = new OneSyn();\n      syn.in = randomBinaryChars(1, 5, bias, 'a');\n      syn.out = randomBinaryChars(1, 5, 0.5, 'x');\n      syn.keepOrig = random().nextBoolean();\n      syns.add(syn);\n\n      maxSynLength = Math.max(maxSynLength, syn.in.length);\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + syn);\n      }\n      add(b, toTokenString(syn.in), toTokenString(syn.out), syn.keepOrig);\n    }\n\n    // Compute max allowed lookahead for flatten filter:\n    int maxFlattenLookahead = 0;\n    if (flatten) {\n      for(int i=0;i<synCount;i++) {\n        OneSyn syn1 = syns.get(i);\n        int count = syn1.out.length;\n        boolean keepOrig = syn1.keepOrig;\n        for(int j=0;j<synCount;j++) {\n          OneSyn syn2 = syns.get(i);\n          keepOrig |= syn2.keepOrig;\n          if (syn1.in.equals(syn2.in)) {\n            count += syn2.out.length;\n          }\n        }\n\n        if (keepOrig) {\n          count += syn1.in.length;\n        }\n\n        maxFlattenLookahead = Math.max(maxFlattenLookahead, count);\n      }\n    }\n\n    // Only used w/ VERBOSE:\n    Analyzer aNoFlattened;\n    if (VERBOSE) {\n      aNoFlattened = getAnalyzer(b, true);\n    } else {\n      aNoFlattened = null;\n    }\n\n    Analyzer a;\n    if (flatten) {\n      a = getFlattenAnalyzer(b, true);\n    } else {\n      a = getAnalyzer(b, true);\n    }\n\n    int iters = atLeast(20);\n    for(int iter=0;iter<iters;iter++) {\n\n      String doc = toTokenString(randomBinaryChars(50, 100, bias, 'a'));\n      //String doc = toTokenString(randomBinaryChars(10, 50, bias, 'a'));\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\"+  iter + \" doc=\" + doc);\n      }\n      Automaton expected = slowSynFilter(doc, syns, flatten);\n      if (VERBOSE) {\n        System.out.println(\"  expected:\\n\" + expected.toDot());\n        if (flatten) {\n          Automaton unflattened = toAutomaton(aNoFlattened.tokenStream(\"field\", new StringReader(doc)));\n          System.out.println(\"  actual unflattened:\\n\" + unflattened.toDot());\n        }\n      }\n      Automaton actual = toAutomaton(a.tokenStream(\"field\", new StringReader(doc)));\n      if (VERBOSE) {\n        System.out.println(\"  actual:\\n\" + actual.toDot());\n      }\n\n      assertTrue(\"maxLookaheadUsed=\" + synFilter.getMaxLookaheadUsed() + \" maxSynLength=\" + maxSynLength,\n                 synFilter.getMaxLookaheadUsed() <= maxSynLength);\n      if (flatten) {\n        assertTrue(\"flatten maxLookaheadUsed=\" + flattenFilter.getMaxLookaheadUsed() + \" maxFlattenLookahead=\" + maxFlattenLookahead,\n                   flattenFilter.getMaxLookaheadUsed() <= maxFlattenLookahead);\n      }\n\n      checkAnalysisConsistency(random(), a, random().nextBoolean(), doc);\n      // We can easily have a non-deterministic automaton at this point, e.g. if\n      // more than one syn matched at given point, or if the syn mapped to an\n      // output token that also happens to be in the input:\n      try {\n        actual = Operations.determinize(actual, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      try {\n        expected = Operations.determinize(expected, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      assertTrue(approxEquals(actual, expected));\n      assertTrue(Operations.sameLanguage(actual, expected));\n    }\n\n    a.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","date":1579652839,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymGraphFilter#testRandomSyns().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymGraphFilter#testRandomSyns().mjava","sourceNew":"  public void testRandomSyns() throws Exception {\n    int synCount = atLeast(10);\n    double bias = random().nextDouble();\n    boolean dedup = random().nextBoolean();\n\n    boolean flatten = random().nextBoolean();\n\n    SynonymMap.Builder b = new SynonymMap.Builder(dedup);\n    List<OneSyn> syns = new ArrayList<>();\n    // Makes random syns from random a / b tokens, mapping to random x / y tokens\n    if (VERBOSE) {\n      System.out.println(\"TEST: make \" + synCount + \" syns\");\n      System.out.println(\"  bias for a over b=\" + bias);\n      System.out.println(\"  dedup=\" + dedup);\n      System.out.println(\"  flatten=\" + flatten);\n    }\n\n    int maxSynLength = 0;\n\n    for(int i=0;i<synCount;i++) {\n      OneSyn syn = new OneSyn();\n      syn.in = randomBinaryChars(1, 5, bias, 'a');\n      syn.out = randomBinaryChars(1, 5, 0.5, 'x');\n      syn.keepOrig = random().nextBoolean();\n      syns.add(syn);\n\n      maxSynLength = Math.max(maxSynLength, syn.in.length);\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + syn);\n      }\n      add(b, toTokenString(syn.in), toTokenString(syn.out), syn.keepOrig);\n    }\n\n    // Compute max allowed lookahead for flatten filter:\n    int maxFlattenLookahead = 0;\n    if (flatten) {\n      for(int i=0;i<synCount;i++) {\n        OneSyn syn1 = syns.get(i);\n        int count = syn1.out.length;\n        boolean keepOrig = syn1.keepOrig;\n        for(int j=0;j<synCount;j++) {\n          OneSyn syn2 = syns.get(i);\n          keepOrig |= syn2.keepOrig;\n          if (syn1.in.equals(syn2.in)) {\n            count += syn2.out.length;\n          }\n        }\n\n        if (keepOrig) {\n          count += syn1.in.length;\n        }\n\n        maxFlattenLookahead = Math.max(maxFlattenLookahead, count);\n      }\n    }\n\n    // Only used w/ VERBOSE:\n    Analyzer aNoFlattened;\n    if (VERBOSE) {\n      aNoFlattened = getAnalyzer(b, true);\n    } else {\n      aNoFlattened = null;\n    }\n\n    Analyzer a;\n    if (flatten) {\n      a = getFlattenAnalyzer(b, true);\n    } else {\n      a = getAnalyzer(b, true);\n    }\n\n    int iters = atLeast(10);\n    for(int iter=0;iter<iters;iter++) {\n\n      String doc = toTokenString(randomBinaryChars(50, 100, bias, 'a'));\n      //String doc = toTokenString(randomBinaryChars(10, 50, bias, 'a'));\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\"+  iter + \" doc=\" + doc);\n      }\n      Automaton expected = slowSynFilter(doc, syns, flatten);\n      if (VERBOSE) {\n        System.out.println(\"  expected:\\n\" + expected.toDot());\n        if (flatten) {\n          Automaton unflattened = toAutomaton(aNoFlattened.tokenStream(\"field\", new StringReader(doc)));\n          System.out.println(\"  actual unflattened:\\n\" + unflattened.toDot());\n        }\n      }\n      Automaton actual = toAutomaton(a.tokenStream(\"field\", new StringReader(doc)));\n      if (VERBOSE) {\n        System.out.println(\"  actual:\\n\" + actual.toDot());\n      }\n\n      assertTrue(\"maxLookaheadUsed=\" + synFilter.getMaxLookaheadUsed() + \" maxSynLength=\" + maxSynLength,\n                 synFilter.getMaxLookaheadUsed() <= maxSynLength);\n      if (flatten) {\n        assertTrue(\"flatten maxLookaheadUsed=\" + flattenFilter.getMaxLookaheadUsed() + \" maxFlattenLookahead=\" + maxFlattenLookahead,\n                   flattenFilter.getMaxLookaheadUsed() <= maxFlattenLookahead);\n      }\n\n      checkAnalysisConsistency(random(), a, random().nextBoolean(), doc);\n      // We can easily have a non-deterministic automaton at this point, e.g. if\n      // more than one syn matched at given point, or if the syn mapped to an\n      // output token that also happens to be in the input:\n      try {\n        actual = Operations.determinize(actual, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      try {\n        expected = Operations.determinize(expected, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      assertTrue(approxEquals(actual, expected));\n      assertTrue(Operations.sameLanguage(actual, expected));\n    }\n\n    a.close();\n  }\n\n","sourceOld":"  public void testRandomSyns() throws Exception {\n    int synCount = atLeast(10);\n    double bias = random().nextDouble();\n    boolean dedup = random().nextBoolean();\n\n    boolean flatten = random().nextBoolean();\n\n    SynonymMap.Builder b = new SynonymMap.Builder(dedup);\n    List<OneSyn> syns = new ArrayList<>();\n    // Makes random syns from random a / b tokens, mapping to random x / y tokens\n    if (VERBOSE) {\n      System.out.println(\"TEST: make \" + synCount + \" syns\");\n      System.out.println(\"  bias for a over b=\" + bias);\n      System.out.println(\"  dedup=\" + dedup);\n      System.out.println(\"  flatten=\" + flatten);\n    }\n\n    int maxSynLength = 0;\n\n    for(int i=0;i<synCount;i++) {\n      OneSyn syn = new OneSyn();\n      syn.in = randomBinaryChars(1, 5, bias, 'a');\n      syn.out = randomBinaryChars(1, 5, 0.5, 'x');\n      syn.keepOrig = random().nextBoolean();\n      syns.add(syn);\n\n      maxSynLength = Math.max(maxSynLength, syn.in.length);\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + syn);\n      }\n      add(b, toTokenString(syn.in), toTokenString(syn.out), syn.keepOrig);\n    }\n\n    // Compute max allowed lookahead for flatten filter:\n    int maxFlattenLookahead = 0;\n    if (flatten) {\n      for(int i=0;i<synCount;i++) {\n        OneSyn syn1 = syns.get(i);\n        int count = syn1.out.length;\n        boolean keepOrig = syn1.keepOrig;\n        for(int j=0;j<synCount;j++) {\n          OneSyn syn2 = syns.get(i);\n          keepOrig |= syn2.keepOrig;\n          if (syn1.in.equals(syn2.in)) {\n            count += syn2.out.length;\n          }\n        }\n\n        if (keepOrig) {\n          count += syn1.in.length;\n        }\n\n        maxFlattenLookahead = Math.max(maxFlattenLookahead, count);\n      }\n    }\n\n    // Only used w/ VERBOSE:\n    Analyzer aNoFlattened;\n    if (VERBOSE) {\n      aNoFlattened = getAnalyzer(b, true);\n    } else {\n      aNoFlattened = null;\n    }\n\n    Analyzer a;\n    if (flatten) {\n      a = getFlattenAnalyzer(b, true);\n    } else {\n      a = getAnalyzer(b, true);\n    }\n\n    int iters = atLeast(20);\n    for(int iter=0;iter<iters;iter++) {\n\n      String doc = toTokenString(randomBinaryChars(50, 100, bias, 'a'));\n      //String doc = toTokenString(randomBinaryChars(10, 50, bias, 'a'));\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\"+  iter + \" doc=\" + doc);\n      }\n      Automaton expected = slowSynFilter(doc, syns, flatten);\n      if (VERBOSE) {\n        System.out.println(\"  expected:\\n\" + expected.toDot());\n        if (flatten) {\n          Automaton unflattened = toAutomaton(aNoFlattened.tokenStream(\"field\", new StringReader(doc)));\n          System.out.println(\"  actual unflattened:\\n\" + unflattened.toDot());\n        }\n      }\n      Automaton actual = toAutomaton(a.tokenStream(\"field\", new StringReader(doc)));\n      if (VERBOSE) {\n        System.out.println(\"  actual:\\n\" + actual.toDot());\n      }\n\n      assertTrue(\"maxLookaheadUsed=\" + synFilter.getMaxLookaheadUsed() + \" maxSynLength=\" + maxSynLength,\n                 synFilter.getMaxLookaheadUsed() <= maxSynLength);\n      if (flatten) {\n        assertTrue(\"flatten maxLookaheadUsed=\" + flattenFilter.getMaxLookaheadUsed() + \" maxFlattenLookahead=\" + maxFlattenLookahead,\n                   flattenFilter.getMaxLookaheadUsed() <= maxFlattenLookahead);\n      }\n\n      checkAnalysisConsistency(random(), a, random().nextBoolean(), doc);\n      // We can easily have a non-deterministic automaton at this point, e.g. if\n      // more than one syn matched at given point, or if the syn mapped to an\n      // output token that also happens to be in the input:\n      try {\n        actual = Operations.determinize(actual, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      try {\n        expected = Operations.determinize(expected, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      assertTrue(approxEquals(actual, expected));\n      assertTrue(Operations.sameLanguage(actual, expected));\n    }\n\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":["71da933d30aea361ccc224d6544c451cbf49916d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"71da933d30aea361ccc224d6544c451cbf49916d","date":1579874339,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymGraphFilter#testRandomSyns().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymGraphFilter#testRandomSyns().mjava","sourceNew":"  public void testRandomSyns() throws Exception {\n    int synCount = atLeast(10);\n    double bias = random().nextDouble();\n    boolean dedup = random().nextBoolean();\n\n    boolean flatten = random().nextBoolean();\n\n    SynonymMap.Builder b = new SynonymMap.Builder(dedup);\n    List<OneSyn> syns = new ArrayList<>();\n    // Makes random syns from random a / b tokens, mapping to random x / y tokens\n    if (VERBOSE) {\n      System.out.println(\"TEST: make \" + synCount + \" syns\");\n      System.out.println(\"  bias for a over b=\" + bias);\n      System.out.println(\"  dedup=\" + dedup);\n      System.out.println(\"  flatten=\" + flatten);\n    }\n\n    int maxSynLength = 0;\n\n    for(int i=0;i<synCount;i++) {\n      OneSyn syn = new OneSyn();\n      syn.in = randomBinaryChars(1, 5, bias, 'a');\n      syn.out = randomBinaryChars(1, 5, 0.5, 'x');\n      syn.keepOrig = random().nextBoolean();\n      syns.add(syn);\n\n      maxSynLength = Math.max(maxSynLength, syn.in.length);\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + syn);\n      }\n      add(b, toTokenString(syn.in), toTokenString(syn.out), syn.keepOrig);\n    }\n\n    // Compute max allowed lookahead for flatten filter:\n    int maxFlattenLookahead = 0;\n    if (flatten) {\n      for(int i=0;i<synCount;i++) {\n        OneSyn syn1 = syns.get(i);\n        int count = syn1.out.length;\n        boolean keepOrig = syn1.keepOrig;\n        for(int j=0;j<synCount;j++) {\n          OneSyn syn2 = syns.get(i);\n          keepOrig |= syn2.keepOrig;\n          if (syn1.in.equals(syn2.in)) {\n            count += syn2.out.length;\n          }\n        }\n\n        if (keepOrig) {\n          count += syn1.in.length;\n        }\n\n        maxFlattenLookahead = Math.max(maxFlattenLookahead, count);\n      }\n    }\n\n    // Only used w/ VERBOSE:\n    Analyzer aNoFlattened;\n    if (VERBOSE) {\n      aNoFlattened = getAnalyzer(b, true);\n    } else {\n      aNoFlattened = null;\n    }\n\n    Analyzer a;\n    if (flatten) {\n      a = getFlattenAnalyzer(b, true);\n    } else {\n      a = getAnalyzer(b, true);\n    }\n\n    int iters = atLeast(1);\n    for(int iter=0;iter<iters;iter++) {\n\n      String doc = toTokenString(randomBinaryChars(50, 100, bias, 'a'));\n      //String doc = toTokenString(randomBinaryChars(10, 50, bias, 'a'));\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\"+  iter + \" doc=\" + doc);\n      }\n      Automaton expected = slowSynFilter(doc, syns, flatten);\n      if (VERBOSE) {\n        System.out.println(\"  expected:\\n\" + expected.toDot());\n        if (flatten) {\n          Automaton unflattened = toAutomaton(aNoFlattened.tokenStream(\"field\", new StringReader(doc)));\n          System.out.println(\"  actual unflattened:\\n\" + unflattened.toDot());\n        }\n      }\n      Automaton actual = toAutomaton(a.tokenStream(\"field\", new StringReader(doc)));\n      if (VERBOSE) {\n        System.out.println(\"  actual:\\n\" + actual.toDot());\n      }\n\n      assertTrue(\"maxLookaheadUsed=\" + synFilter.getMaxLookaheadUsed() + \" maxSynLength=\" + maxSynLength,\n                 synFilter.getMaxLookaheadUsed() <= maxSynLength);\n      if (flatten) {\n        assertTrue(\"flatten maxLookaheadUsed=\" + flattenFilter.getMaxLookaheadUsed() + \" maxFlattenLookahead=\" + maxFlattenLookahead,\n                   flattenFilter.getMaxLookaheadUsed() <= maxFlattenLookahead);\n      }\n\n      checkAnalysisConsistency(random(), a, random().nextBoolean(), doc);\n      // We can easily have a non-deterministic automaton at this point, e.g. if\n      // more than one syn matched at given point, or if the syn mapped to an\n      // output token that also happens to be in the input:\n      try {\n        actual = Operations.determinize(actual, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      try {\n        expected = Operations.determinize(expected, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      assertTrue(approxEquals(actual, expected));\n      assertTrue(Operations.sameLanguage(actual, expected));\n    }\n\n    a.close();\n  }\n\n","sourceOld":"  public void testRandomSyns() throws Exception {\n    int synCount = atLeast(10);\n    double bias = random().nextDouble();\n    boolean dedup = random().nextBoolean();\n\n    boolean flatten = random().nextBoolean();\n\n    SynonymMap.Builder b = new SynonymMap.Builder(dedup);\n    List<OneSyn> syns = new ArrayList<>();\n    // Makes random syns from random a / b tokens, mapping to random x / y tokens\n    if (VERBOSE) {\n      System.out.println(\"TEST: make \" + synCount + \" syns\");\n      System.out.println(\"  bias for a over b=\" + bias);\n      System.out.println(\"  dedup=\" + dedup);\n      System.out.println(\"  flatten=\" + flatten);\n    }\n\n    int maxSynLength = 0;\n\n    for(int i=0;i<synCount;i++) {\n      OneSyn syn = new OneSyn();\n      syn.in = randomBinaryChars(1, 5, bias, 'a');\n      syn.out = randomBinaryChars(1, 5, 0.5, 'x');\n      syn.keepOrig = random().nextBoolean();\n      syns.add(syn);\n\n      maxSynLength = Math.max(maxSynLength, syn.in.length);\n\n      if (VERBOSE) {\n        System.out.println(\"  \" + syn);\n      }\n      add(b, toTokenString(syn.in), toTokenString(syn.out), syn.keepOrig);\n    }\n\n    // Compute max allowed lookahead for flatten filter:\n    int maxFlattenLookahead = 0;\n    if (flatten) {\n      for(int i=0;i<synCount;i++) {\n        OneSyn syn1 = syns.get(i);\n        int count = syn1.out.length;\n        boolean keepOrig = syn1.keepOrig;\n        for(int j=0;j<synCount;j++) {\n          OneSyn syn2 = syns.get(i);\n          keepOrig |= syn2.keepOrig;\n          if (syn1.in.equals(syn2.in)) {\n            count += syn2.out.length;\n          }\n        }\n\n        if (keepOrig) {\n          count += syn1.in.length;\n        }\n\n        maxFlattenLookahead = Math.max(maxFlattenLookahead, count);\n      }\n    }\n\n    // Only used w/ VERBOSE:\n    Analyzer aNoFlattened;\n    if (VERBOSE) {\n      aNoFlattened = getAnalyzer(b, true);\n    } else {\n      aNoFlattened = null;\n    }\n\n    Analyzer a;\n    if (flatten) {\n      a = getFlattenAnalyzer(b, true);\n    } else {\n      a = getAnalyzer(b, true);\n    }\n\n    int iters = atLeast(10);\n    for(int iter=0;iter<iters;iter++) {\n\n      String doc = toTokenString(randomBinaryChars(50, 100, bias, 'a'));\n      //String doc = toTokenString(randomBinaryChars(10, 50, bias, 'a'));\n\n      if (VERBOSE) {\n        System.out.println(\"TEST: iter=\"+  iter + \" doc=\" + doc);\n      }\n      Automaton expected = slowSynFilter(doc, syns, flatten);\n      if (VERBOSE) {\n        System.out.println(\"  expected:\\n\" + expected.toDot());\n        if (flatten) {\n          Automaton unflattened = toAutomaton(aNoFlattened.tokenStream(\"field\", new StringReader(doc)));\n          System.out.println(\"  actual unflattened:\\n\" + unflattened.toDot());\n        }\n      }\n      Automaton actual = toAutomaton(a.tokenStream(\"field\", new StringReader(doc)));\n      if (VERBOSE) {\n        System.out.println(\"  actual:\\n\" + actual.toDot());\n      }\n\n      assertTrue(\"maxLookaheadUsed=\" + synFilter.getMaxLookaheadUsed() + \" maxSynLength=\" + maxSynLength,\n                 synFilter.getMaxLookaheadUsed() <= maxSynLength);\n      if (flatten) {\n        assertTrue(\"flatten maxLookaheadUsed=\" + flattenFilter.getMaxLookaheadUsed() + \" maxFlattenLookahead=\" + maxFlattenLookahead,\n                   flattenFilter.getMaxLookaheadUsed() <= maxFlattenLookahead);\n      }\n\n      checkAnalysisConsistency(random(), a, random().nextBoolean(), doc);\n      // We can easily have a non-deterministic automaton at this point, e.g. if\n      // more than one syn matched at given point, or if the syn mapped to an\n      // output token that also happens to be in the input:\n      try {\n        actual = Operations.determinize(actual, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      try {\n        expected = Operations.determinize(expected, 50000);\n      } catch (TooComplexToDeterminizeException tctde) {\n        // Unfortunately the syns can easily create difficult-to-determinize graphs:\n        assertTrue(approxEquals(actual, expected));\n        continue;\n      }\n\n      assertTrue(approxEquals(actual, expected));\n      assertTrue(Operations.sameLanguage(actual, expected));\n    }\n\n    a.close();\n  }\n\n","bugFix":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["24a98f5fdd23e04f85819dbc63b47a12f7c44311"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"24a98f5fdd23e04f85819dbc63b47a12f7c44311":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71da933d30aea361ccc224d6544c451cbf49916d"],"71da933d30aea361ccc224d6544c451cbf49916d":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","24a98f5fdd23e04f85819dbc63b47a12f7c44311"]},"commit2Childs":{"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["71da933d30aea361ccc224d6544c451cbf49916d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["24a98f5fdd23e04f85819dbc63b47a12f7c44311","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"24a98f5fdd23e04f85819dbc63b47a12f7c44311":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"71da933d30aea361ccc224d6544c451cbf49916d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}