{"path":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#get(int).mjava","commits":[{"id":"eda61b1e90b490cc5837200e04c02639a0d272c7","date":1358795519,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#get(int).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Fields get(int doc) throws IOException {\n    ensureOpen();\n\n    // seek to the right place\n    {\n      final long startPointer = indexReader.getStartPointer(doc);\n      vectorsStream.seek(startPointer);\n    }\n\n    // decode\n    // - docBase: first doc ID of the chunk\n    // - chunkDocs: number of docs of the chunk\n    final int docBase = vectorsStream.readVInt();\n    final int chunkDocs = vectorsStream.readVInt();\n    if (doc < docBase || doc >= docBase + chunkDocs || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"docBase=\" + docBase + \",chunkDocs=\" + chunkDocs + \",doc=\" + doc);\n    }\n\n    final int skip; // number of fields to skip\n    final int numFields; // number of fields of the document we're looking for\n    final int totalFields; // total number of fields of the chunk (sum for all docs)\n    if (chunkDocs == 1) {\n      skip = 0;\n      numFields = totalFields = vectorsStream.readVInt();\n    } else {\n      reader.reset(vectorsStream, chunkDocs);\n      int sum = 0;\n      for (int i = docBase; i < doc; ++i) {\n        sum += reader.next();\n      }\n      skip = sum;\n      numFields = (int) reader.next();\n      sum += numFields;\n      for (int i = doc + 1; i < docBase + chunkDocs; ++i) {\n        sum += reader.next();\n      }\n      totalFields = sum;\n    }\n\n    if (numFields == 0) {\n      // no vectors\n      return null;\n    }\n\n    // read field numbers that have term vectors\n    final int[] fieldNums;\n    {\n      final int token = vectorsStream.readByte() & 0xFF;\n      assert token != 0; // means no term vectors, cannot happen since we checked for numFields == 0\n      final int bitsPerFieldNum = token & 0x1F;\n      int totalDistinctFields = token >>> 5;\n      if (totalDistinctFields == 0x07) {\n        totalDistinctFields += vectorsStream.readVInt();\n      }\n      ++totalDistinctFields;\n      final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalDistinctFields, bitsPerFieldNum, 1);\n      fieldNums = new int[totalDistinctFields];\n      for (int i = 0; i < totalDistinctFields; ++i) {\n        fieldNums[i] = (int) it.next();\n      }\n    }\n\n    // read field numbers and flags\n    final int[] fieldNumOffs = new int[numFields];\n    final PackedInts.Reader flags;\n    {\n      final int bitsPerOff = PackedInts.bitsRequired(fieldNums.length - 1);\n      final PackedInts.Reader allFieldNumOffs = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsPerOff);\n      switch (vectorsStream.readVInt()) {\n        case 0:\n          final PackedInts.Reader fieldFlags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, fieldNums.length, FLAGS_BITS);\n          PackedInts.Mutable f = PackedInts.getMutable(totalFields, FLAGS_BITS, PackedInts.COMPACT);\n          for (int i = 0; i < totalFields; ++i) {\n            final int fieldNumOff = (int) allFieldNumOffs.get(i);\n            assert fieldNumOff >= 0 && fieldNumOff < fieldNums.length;\n            final int fgs = (int) fieldFlags.get(fieldNumOff);\n            f.set(i, fgs);\n          }\n          flags = f;\n          break;\n        case 1:\n          flags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, FLAGS_BITS);\n          break;\n        default:\n          throw new AssertionError();\n      }\n      for (int i = 0; i < numFields; ++i) {\n        fieldNumOffs[i] = (int) allFieldNumOffs.get(skip + i);\n      }\n    }\n\n    // number of terms per field for all fields\n    final PackedInts.Reader numTerms;\n    final int totalTerms;\n    {\n      final int bitsRequired = vectorsStream.readVInt();\n      numTerms = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsRequired);\n      int sum = 0;\n      for (int i = 0; i < totalFields; ++i) {\n        sum += numTerms.get(i);\n      }\n      totalTerms = sum;\n    }\n\n    // term lengths\n    int docOff = 0, docLen = 0, totalLen;\n    final int[] fieldLengths = new int[numFields];\n    final int[][] prefixLengths = new int[numFields][];\n    final int[][] suffixLengths = new int[numFields][];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      int toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        toSkip += numTerms.get(i);\n      }\n      reader.skip(toSkip);\n      // read prefix lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldPrefixLengths = new int[termCount];\n        prefixLengths[i] = fieldPrefixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldPrefixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n      }\n      reader.skip(totalTerms - reader.ord());\n\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          docOff += reader.next();\n        }\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldSuffixLengths = new int[termCount];\n        suffixLengths[i] = fieldSuffixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldSuffixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n        fieldLengths[i] = sum(suffixLengths[i]);\n        docLen += fieldLengths[i];\n      }\n      totalLen = docOff + docLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          totalLen += reader.next();\n        }\n      }\n    }\n\n    // term freqs\n    final int[] termFreqs = new int[totalTerms];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      for (int i = 0; i < totalTerms; ) {\n        final LongsRef next = reader.next(totalTerms - i);\n        for (int k = 0; k < next.length; ++k) {\n          termFreqs[i++] = 1 + (int) next.longs[next.offset + k];\n        }\n      }\n    }\n\n    // total number of positions, offsets and payloads\n    int totalPositions = 0, totalOffsets = 0, totalPayloads = 0;\n    for (int i = 0, termIndex = 0; i < totalFields; ++i) {\n      final int f = (int) flags.get(i);\n      final int termCount = (int) numTerms.get(i);\n      for (int j = 0; j < termCount; ++j) {\n        final int freq = termFreqs[termIndex++];\n        if ((f & POSITIONS) != 0) {\n          totalPositions += freq;\n        }\n        if ((f & OFFSETS) != 0) {\n          totalOffsets += freq;\n        }\n        if ((f & PAYLOADS) != 0) {\n          totalPayloads += freq;\n        }\n      }\n      assert i != totalFields - 1 || termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    final int[][] positionIndex = positionIndex(skip, numFields, numTerms, termFreqs);\n    final int[][] positions, startOffsets, lengths;\n    if (totalPositions > 0) {\n      positions = readPositions(skip, numFields, flags, numTerms, termFreqs, POSITIONS, totalPositions, positionIndex);\n    } else {\n      positions = new int[numFields][];\n    }\n\n    if (totalOffsets > 0) {\n      // average number of chars per term\n      final float[] charsPerTerm = new float[fieldNums.length];\n      for (int i = 0; i < charsPerTerm.length; ++i) {\n        charsPerTerm[i] = Float.intBitsToFloat(vectorsStream.readInt());\n      }\n      startOffsets = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n      lengths = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fStartOffsets = startOffsets[i];\n        final int[] fPositions = positions[i];\n        // patch offsets from positions\n        if (fStartOffsets != null && fPositions != null) {\n          final float fieldCharsPerTerm = charsPerTerm[fieldNumOffs[i]];\n          for (int j = 0; j < startOffsets[i].length; ++j) {\n            fStartOffsets[j] += (int) (fieldCharsPerTerm * fPositions[j]);\n          }\n        }\n        if (fStartOffsets != null) {\n          final int[] fPrefixLengths = prefixLengths[i];\n          final int[] fSuffixLengths = suffixLengths[i];\n          final int[] fLengths = lengths[i];\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets and  patch lengths using term lengths\n            final int termLength = fPrefixLengths[j] + fSuffixLengths[j];\n            lengths[i][positionIndex[i][j]] += termLength;\n            for (int k = positionIndex[i][j] + 1; k < positionIndex[i][j + 1]; ++k) {\n              fStartOffsets[k] += fStartOffsets[k - 1];\n              fLengths[k] += termLength;\n            }\n          }\n        }\n      }\n    } else {\n      startOffsets = lengths = new int[numFields][];\n    }\n    if (totalPositions > 0) {\n      // delta-decode positions\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fPositions = positions[i];\n        final int[] fpositionIndex = positionIndex[i];\n        if (fPositions != null) {\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets\n            for (int k = fpositionIndex[j] + 1; k < fpositionIndex[j + 1]; ++k) {\n              fPositions[k] += fPositions[k - 1];\n            }\n          }\n        }\n      }\n    }\n\n    // payload lengths\n    final int[][] payloadIndex = new int[numFields][];\n    int totalPayloadLength = 0;\n    int payloadOff = 0;\n    int payloadLen = 0;\n    if (totalPayloads > 0) {\n      reader.reset(vectorsStream, totalPayloads);\n      // skip\n      int termIndex = 0;\n      for (int i = 0; i < skip; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int l = (int) reader.next();\n              payloadOff += l;\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength = payloadOff;\n      // read doc payload lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int f = (int) flags.get(skip + i);\n        final int termCount = (int) numTerms.get(skip + i);\n        if ((f & PAYLOADS) != 0) {\n          final int totalFreq = positionIndex[i][termCount];\n          payloadIndex[i] = new int[totalFreq + 1];\n          int posIdx = 0;\n          payloadIndex[i][posIdx] = payloadLen;\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int payloadLength = (int) reader.next();\n              payloadLen += payloadLength;\n              payloadIndex[i][posIdx+1] = payloadLen;\n              ++posIdx;\n            }\n          }\n          assert posIdx == totalFreq;\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength += payloadLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              totalPayloadLength += reader.next();\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      assert termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    // decompress data\n    final BytesRef suffixBytes = new BytesRef();\n    decompressor.decompress(vectorsStream, totalLen + totalPayloadLength, docOff + payloadOff, docLen + payloadLen, suffixBytes);\n    suffixBytes.length = docLen;\n    final BytesRef payloadBytes = new BytesRef(suffixBytes.bytes, suffixBytes.offset + docLen, payloadLen);\n\n    final int[] fieldFlags = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldFlags[i] = (int) flags.get(skip + i);\n    }\n\n    final int[] fieldNumTerms = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldNumTerms[i] = (int) numTerms.get(skip + i);\n    }\n\n    final int[][] fieldTermFreqs = new int[numFields][];\n    {\n      int termIdx = 0;\n      for (int i = 0; i < skip; ++i) {\n        termIdx += numTerms.get(i);\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        fieldTermFreqs[i] = new int[termCount];\n        for (int j = 0; j < termCount; ++j) {\n          fieldTermFreqs[i][j] = termFreqs[termIdx++];\n        }\n      }\n    }\n\n    assert sum(fieldLengths) == docLen : sum(fieldLengths) + \" != \" + docLen;\n\n    return new TVFields(fieldNums, fieldFlags, fieldNumOffs, fieldNumTerms, fieldLengths,\n        prefixLengths, suffixLengths, fieldTermFreqs,\n        positionIndex, positions, startOffsets, lengths,\n        payloadBytes, payloadIndex,\n        suffixBytes);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"07155cdd910937cdf6877e48884d5782845c8b8b","date":1358796205,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#get(int).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public Fields get(int doc) throws IOException {\n    ensureOpen();\n\n    // seek to the right place\n    {\n      final long startPointer = indexReader.getStartPointer(doc);\n      vectorsStream.seek(startPointer);\n    }\n\n    // decode\n    // - docBase: first doc ID of the chunk\n    // - chunkDocs: number of docs of the chunk\n    final int docBase = vectorsStream.readVInt();\n    final int chunkDocs = vectorsStream.readVInt();\n    if (doc < docBase || doc >= docBase + chunkDocs || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"docBase=\" + docBase + \",chunkDocs=\" + chunkDocs + \",doc=\" + doc);\n    }\n\n    final int skip; // number of fields to skip\n    final int numFields; // number of fields of the document we're looking for\n    final int totalFields; // total number of fields of the chunk (sum for all docs)\n    if (chunkDocs == 1) {\n      skip = 0;\n      numFields = totalFields = vectorsStream.readVInt();\n    } else {\n      reader.reset(vectorsStream, chunkDocs);\n      int sum = 0;\n      for (int i = docBase; i < doc; ++i) {\n        sum += reader.next();\n      }\n      skip = sum;\n      numFields = (int) reader.next();\n      sum += numFields;\n      for (int i = doc + 1; i < docBase + chunkDocs; ++i) {\n        sum += reader.next();\n      }\n      totalFields = sum;\n    }\n\n    if (numFields == 0) {\n      // no vectors\n      return null;\n    }\n\n    // read field numbers that have term vectors\n    final int[] fieldNums;\n    {\n      final int token = vectorsStream.readByte() & 0xFF;\n      assert token != 0; // means no term vectors, cannot happen since we checked for numFields == 0\n      final int bitsPerFieldNum = token & 0x1F;\n      int totalDistinctFields = token >>> 5;\n      if (totalDistinctFields == 0x07) {\n        totalDistinctFields += vectorsStream.readVInt();\n      }\n      ++totalDistinctFields;\n      final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalDistinctFields, bitsPerFieldNum, 1);\n      fieldNums = new int[totalDistinctFields];\n      for (int i = 0; i < totalDistinctFields; ++i) {\n        fieldNums[i] = (int) it.next();\n      }\n    }\n\n    // read field numbers and flags\n    final int[] fieldNumOffs = new int[numFields];\n    final PackedInts.Reader flags;\n    {\n      final int bitsPerOff = PackedInts.bitsRequired(fieldNums.length - 1);\n      final PackedInts.Reader allFieldNumOffs = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsPerOff);\n      switch (vectorsStream.readVInt()) {\n        case 0:\n          final PackedInts.Reader fieldFlags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, fieldNums.length, FLAGS_BITS);\n          PackedInts.Mutable f = PackedInts.getMutable(totalFields, FLAGS_BITS, PackedInts.COMPACT);\n          for (int i = 0; i < totalFields; ++i) {\n            final int fieldNumOff = (int) allFieldNumOffs.get(i);\n            assert fieldNumOff >= 0 && fieldNumOff < fieldNums.length;\n            final int fgs = (int) fieldFlags.get(fieldNumOff);\n            f.set(i, fgs);\n          }\n          flags = f;\n          break;\n        case 1:\n          flags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, FLAGS_BITS);\n          break;\n        default:\n          throw new AssertionError();\n      }\n      for (int i = 0; i < numFields; ++i) {\n        fieldNumOffs[i] = (int) allFieldNumOffs.get(skip + i);\n      }\n    }\n\n    // number of terms per field for all fields\n    final PackedInts.Reader numTerms;\n    final int totalTerms;\n    {\n      final int bitsRequired = vectorsStream.readVInt();\n      numTerms = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsRequired);\n      int sum = 0;\n      for (int i = 0; i < totalFields; ++i) {\n        sum += numTerms.get(i);\n      }\n      totalTerms = sum;\n    }\n\n    // term lengths\n    int docOff = 0, docLen = 0, totalLen;\n    final int[] fieldLengths = new int[numFields];\n    final int[][] prefixLengths = new int[numFields][];\n    final int[][] suffixLengths = new int[numFields][];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      int toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        toSkip += numTerms.get(i);\n      }\n      reader.skip(toSkip);\n      // read prefix lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldPrefixLengths = new int[termCount];\n        prefixLengths[i] = fieldPrefixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldPrefixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n      }\n      reader.skip(totalTerms - reader.ord());\n\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          docOff += reader.next();\n        }\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldSuffixLengths = new int[termCount];\n        suffixLengths[i] = fieldSuffixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldSuffixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n        fieldLengths[i] = sum(suffixLengths[i]);\n        docLen += fieldLengths[i];\n      }\n      totalLen = docOff + docLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          totalLen += reader.next();\n        }\n      }\n    }\n\n    // term freqs\n    final int[] termFreqs = new int[totalTerms];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      for (int i = 0; i < totalTerms; ) {\n        final LongsRef next = reader.next(totalTerms - i);\n        for (int k = 0; k < next.length; ++k) {\n          termFreqs[i++] = 1 + (int) next.longs[next.offset + k];\n        }\n      }\n    }\n\n    // total number of positions, offsets and payloads\n    int totalPositions = 0, totalOffsets = 0, totalPayloads = 0;\n    for (int i = 0, termIndex = 0; i < totalFields; ++i) {\n      final int f = (int) flags.get(i);\n      final int termCount = (int) numTerms.get(i);\n      for (int j = 0; j < termCount; ++j) {\n        final int freq = termFreqs[termIndex++];\n        if ((f & POSITIONS) != 0) {\n          totalPositions += freq;\n        }\n        if ((f & OFFSETS) != 0) {\n          totalOffsets += freq;\n        }\n        if ((f & PAYLOADS) != 0) {\n          totalPayloads += freq;\n        }\n      }\n      assert i != totalFields - 1 || termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    final int[][] positionIndex = positionIndex(skip, numFields, numTerms, termFreqs);\n    final int[][] positions, startOffsets, lengths;\n    if (totalPositions > 0) {\n      positions = readPositions(skip, numFields, flags, numTerms, termFreqs, POSITIONS, totalPositions, positionIndex);\n    } else {\n      positions = new int[numFields][];\n    }\n\n    if (totalOffsets > 0) {\n      // average number of chars per term\n      final float[] charsPerTerm = new float[fieldNums.length];\n      for (int i = 0; i < charsPerTerm.length; ++i) {\n        charsPerTerm[i] = Float.intBitsToFloat(vectorsStream.readInt());\n      }\n      startOffsets = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n      lengths = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fStartOffsets = startOffsets[i];\n        final int[] fPositions = positions[i];\n        // patch offsets from positions\n        if (fStartOffsets != null && fPositions != null) {\n          final float fieldCharsPerTerm = charsPerTerm[fieldNumOffs[i]];\n          for (int j = 0; j < startOffsets[i].length; ++j) {\n            fStartOffsets[j] += (int) (fieldCharsPerTerm * fPositions[j]);\n          }\n        }\n        if (fStartOffsets != null) {\n          final int[] fPrefixLengths = prefixLengths[i];\n          final int[] fSuffixLengths = suffixLengths[i];\n          final int[] fLengths = lengths[i];\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets and  patch lengths using term lengths\n            final int termLength = fPrefixLengths[j] + fSuffixLengths[j];\n            lengths[i][positionIndex[i][j]] += termLength;\n            for (int k = positionIndex[i][j] + 1; k < positionIndex[i][j + 1]; ++k) {\n              fStartOffsets[k] += fStartOffsets[k - 1];\n              fLengths[k] += termLength;\n            }\n          }\n        }\n      }\n    } else {\n      startOffsets = lengths = new int[numFields][];\n    }\n    if (totalPositions > 0) {\n      // delta-decode positions\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fPositions = positions[i];\n        final int[] fpositionIndex = positionIndex[i];\n        if (fPositions != null) {\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets\n            for (int k = fpositionIndex[j] + 1; k < fpositionIndex[j + 1]; ++k) {\n              fPositions[k] += fPositions[k - 1];\n            }\n          }\n        }\n      }\n    }\n\n    // payload lengths\n    final int[][] payloadIndex = new int[numFields][];\n    int totalPayloadLength = 0;\n    int payloadOff = 0;\n    int payloadLen = 0;\n    if (totalPayloads > 0) {\n      reader.reset(vectorsStream, totalPayloads);\n      // skip\n      int termIndex = 0;\n      for (int i = 0; i < skip; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int l = (int) reader.next();\n              payloadOff += l;\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength = payloadOff;\n      // read doc payload lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int f = (int) flags.get(skip + i);\n        final int termCount = (int) numTerms.get(skip + i);\n        if ((f & PAYLOADS) != 0) {\n          final int totalFreq = positionIndex[i][termCount];\n          payloadIndex[i] = new int[totalFreq + 1];\n          int posIdx = 0;\n          payloadIndex[i][posIdx] = payloadLen;\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int payloadLength = (int) reader.next();\n              payloadLen += payloadLength;\n              payloadIndex[i][posIdx+1] = payloadLen;\n              ++posIdx;\n            }\n          }\n          assert posIdx == totalFreq;\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength += payloadLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              totalPayloadLength += reader.next();\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      assert termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    // decompress data\n    final BytesRef suffixBytes = new BytesRef();\n    decompressor.decompress(vectorsStream, totalLen + totalPayloadLength, docOff + payloadOff, docLen + payloadLen, suffixBytes);\n    suffixBytes.length = docLen;\n    final BytesRef payloadBytes = new BytesRef(suffixBytes.bytes, suffixBytes.offset + docLen, payloadLen);\n\n    final int[] fieldFlags = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldFlags[i] = (int) flags.get(skip + i);\n    }\n\n    final int[] fieldNumTerms = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldNumTerms[i] = (int) numTerms.get(skip + i);\n    }\n\n    final int[][] fieldTermFreqs = new int[numFields][];\n    {\n      int termIdx = 0;\n      for (int i = 0; i < skip; ++i) {\n        termIdx += numTerms.get(i);\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        fieldTermFreqs[i] = new int[termCount];\n        for (int j = 0; j < termCount; ++j) {\n          fieldTermFreqs[i][j] = termFreqs[termIdx++];\n        }\n      }\n    }\n\n    assert sum(fieldLengths) == docLen : sum(fieldLengths) + \" != \" + docLen;\n\n    return new TVFields(fieldNums, fieldFlags, fieldNumOffs, fieldNumTerms, fieldLengths,\n        prefixLengths, suffixLengths, fieldTermFreqs,\n        positionIndex, positions, startOffsets, lengths,\n        payloadBytes, payloadIndex,\n        suffixBytes);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90f762b9c981401224de7f0a7c1ffc8fbc67574f","date":1366475889,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#get(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#get(int).mjava","sourceNew":"  @Override\n  public Fields get(int doc) throws IOException {\n    ensureOpen();\n\n    // seek to the right place\n    {\n      final long startPointer = indexReader.getStartPointer(doc);\n      vectorsStream.seek(startPointer);\n    }\n\n    // decode\n    // - docBase: first doc ID of the chunk\n    // - chunkDocs: number of docs of the chunk\n    final int docBase = vectorsStream.readVInt();\n    final int chunkDocs = vectorsStream.readVInt();\n    if (doc < docBase || doc >= docBase + chunkDocs || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"docBase=\" + docBase + \",chunkDocs=\" + chunkDocs + \",doc=\" + doc + \" (resource=\" + vectorsStream + \")\");\n    }\n\n    final int skip; // number of fields to skip\n    final int numFields; // number of fields of the document we're looking for\n    final int totalFields; // total number of fields of the chunk (sum for all docs)\n    if (chunkDocs == 1) {\n      skip = 0;\n      numFields = totalFields = vectorsStream.readVInt();\n    } else {\n      reader.reset(vectorsStream, chunkDocs);\n      int sum = 0;\n      for (int i = docBase; i < doc; ++i) {\n        sum += reader.next();\n      }\n      skip = sum;\n      numFields = (int) reader.next();\n      sum += numFields;\n      for (int i = doc + 1; i < docBase + chunkDocs; ++i) {\n        sum += reader.next();\n      }\n      totalFields = sum;\n    }\n\n    if (numFields == 0) {\n      // no vectors\n      return null;\n    }\n\n    // read field numbers that have term vectors\n    final int[] fieldNums;\n    {\n      final int token = vectorsStream.readByte() & 0xFF;\n      assert token != 0; // means no term vectors, cannot happen since we checked for numFields == 0\n      final int bitsPerFieldNum = token & 0x1F;\n      int totalDistinctFields = token >>> 5;\n      if (totalDistinctFields == 0x07) {\n        totalDistinctFields += vectorsStream.readVInt();\n      }\n      ++totalDistinctFields;\n      final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalDistinctFields, bitsPerFieldNum, 1);\n      fieldNums = new int[totalDistinctFields];\n      for (int i = 0; i < totalDistinctFields; ++i) {\n        fieldNums[i] = (int) it.next();\n      }\n    }\n\n    // read field numbers and flags\n    final int[] fieldNumOffs = new int[numFields];\n    final PackedInts.Reader flags;\n    {\n      final int bitsPerOff = PackedInts.bitsRequired(fieldNums.length - 1);\n      final PackedInts.Reader allFieldNumOffs = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsPerOff);\n      switch (vectorsStream.readVInt()) {\n        case 0:\n          final PackedInts.Reader fieldFlags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, fieldNums.length, FLAGS_BITS);\n          PackedInts.Mutable f = PackedInts.getMutable(totalFields, FLAGS_BITS, PackedInts.COMPACT);\n          for (int i = 0; i < totalFields; ++i) {\n            final int fieldNumOff = (int) allFieldNumOffs.get(i);\n            assert fieldNumOff >= 0 && fieldNumOff < fieldNums.length;\n            final int fgs = (int) fieldFlags.get(fieldNumOff);\n            f.set(i, fgs);\n          }\n          flags = f;\n          break;\n        case 1:\n          flags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, FLAGS_BITS);\n          break;\n        default:\n          throw new AssertionError();\n      }\n      for (int i = 0; i < numFields; ++i) {\n        fieldNumOffs[i] = (int) allFieldNumOffs.get(skip + i);\n      }\n    }\n\n    // number of terms per field for all fields\n    final PackedInts.Reader numTerms;\n    final int totalTerms;\n    {\n      final int bitsRequired = vectorsStream.readVInt();\n      numTerms = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsRequired);\n      int sum = 0;\n      for (int i = 0; i < totalFields; ++i) {\n        sum += numTerms.get(i);\n      }\n      totalTerms = sum;\n    }\n\n    // term lengths\n    int docOff = 0, docLen = 0, totalLen;\n    final int[] fieldLengths = new int[numFields];\n    final int[][] prefixLengths = new int[numFields][];\n    final int[][] suffixLengths = new int[numFields][];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      int toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        toSkip += numTerms.get(i);\n      }\n      reader.skip(toSkip);\n      // read prefix lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldPrefixLengths = new int[termCount];\n        prefixLengths[i] = fieldPrefixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldPrefixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n      }\n      reader.skip(totalTerms - reader.ord());\n\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          docOff += reader.next();\n        }\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldSuffixLengths = new int[termCount];\n        suffixLengths[i] = fieldSuffixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldSuffixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n        fieldLengths[i] = sum(suffixLengths[i]);\n        docLen += fieldLengths[i];\n      }\n      totalLen = docOff + docLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          totalLen += reader.next();\n        }\n      }\n    }\n\n    // term freqs\n    final int[] termFreqs = new int[totalTerms];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      for (int i = 0; i < totalTerms; ) {\n        final LongsRef next = reader.next(totalTerms - i);\n        for (int k = 0; k < next.length; ++k) {\n          termFreqs[i++] = 1 + (int) next.longs[next.offset + k];\n        }\n      }\n    }\n\n    // total number of positions, offsets and payloads\n    int totalPositions = 0, totalOffsets = 0, totalPayloads = 0;\n    for (int i = 0, termIndex = 0; i < totalFields; ++i) {\n      final int f = (int) flags.get(i);\n      final int termCount = (int) numTerms.get(i);\n      for (int j = 0; j < termCount; ++j) {\n        final int freq = termFreqs[termIndex++];\n        if ((f & POSITIONS) != 0) {\n          totalPositions += freq;\n        }\n        if ((f & OFFSETS) != 0) {\n          totalOffsets += freq;\n        }\n        if ((f & PAYLOADS) != 0) {\n          totalPayloads += freq;\n        }\n      }\n      assert i != totalFields - 1 || termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    final int[][] positionIndex = positionIndex(skip, numFields, numTerms, termFreqs);\n    final int[][] positions, startOffsets, lengths;\n    if (totalPositions > 0) {\n      positions = readPositions(skip, numFields, flags, numTerms, termFreqs, POSITIONS, totalPositions, positionIndex);\n    } else {\n      positions = new int[numFields][];\n    }\n\n    if (totalOffsets > 0) {\n      // average number of chars per term\n      final float[] charsPerTerm = new float[fieldNums.length];\n      for (int i = 0; i < charsPerTerm.length; ++i) {\n        charsPerTerm[i] = Float.intBitsToFloat(vectorsStream.readInt());\n      }\n      startOffsets = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n      lengths = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fStartOffsets = startOffsets[i];\n        final int[] fPositions = positions[i];\n        // patch offsets from positions\n        if (fStartOffsets != null && fPositions != null) {\n          final float fieldCharsPerTerm = charsPerTerm[fieldNumOffs[i]];\n          for (int j = 0; j < startOffsets[i].length; ++j) {\n            fStartOffsets[j] += (int) (fieldCharsPerTerm * fPositions[j]);\n          }\n        }\n        if (fStartOffsets != null) {\n          final int[] fPrefixLengths = prefixLengths[i];\n          final int[] fSuffixLengths = suffixLengths[i];\n          final int[] fLengths = lengths[i];\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets and  patch lengths using term lengths\n            final int termLength = fPrefixLengths[j] + fSuffixLengths[j];\n            lengths[i][positionIndex[i][j]] += termLength;\n            for (int k = positionIndex[i][j] + 1; k < positionIndex[i][j + 1]; ++k) {\n              fStartOffsets[k] += fStartOffsets[k - 1];\n              fLengths[k] += termLength;\n            }\n          }\n        }\n      }\n    } else {\n      startOffsets = lengths = new int[numFields][];\n    }\n    if (totalPositions > 0) {\n      // delta-decode positions\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fPositions = positions[i];\n        final int[] fpositionIndex = positionIndex[i];\n        if (fPositions != null) {\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets\n            for (int k = fpositionIndex[j] + 1; k < fpositionIndex[j + 1]; ++k) {\n              fPositions[k] += fPositions[k - 1];\n            }\n          }\n        }\n      }\n    }\n\n    // payload lengths\n    final int[][] payloadIndex = new int[numFields][];\n    int totalPayloadLength = 0;\n    int payloadOff = 0;\n    int payloadLen = 0;\n    if (totalPayloads > 0) {\n      reader.reset(vectorsStream, totalPayloads);\n      // skip\n      int termIndex = 0;\n      for (int i = 0; i < skip; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int l = (int) reader.next();\n              payloadOff += l;\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength = payloadOff;\n      // read doc payload lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int f = (int) flags.get(skip + i);\n        final int termCount = (int) numTerms.get(skip + i);\n        if ((f & PAYLOADS) != 0) {\n          final int totalFreq = positionIndex[i][termCount];\n          payloadIndex[i] = new int[totalFreq + 1];\n          int posIdx = 0;\n          payloadIndex[i][posIdx] = payloadLen;\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int payloadLength = (int) reader.next();\n              payloadLen += payloadLength;\n              payloadIndex[i][posIdx+1] = payloadLen;\n              ++posIdx;\n            }\n          }\n          assert posIdx == totalFreq;\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength += payloadLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              totalPayloadLength += reader.next();\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      assert termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    // decompress data\n    final BytesRef suffixBytes = new BytesRef();\n    decompressor.decompress(vectorsStream, totalLen + totalPayloadLength, docOff + payloadOff, docLen + payloadLen, suffixBytes);\n    suffixBytes.length = docLen;\n    final BytesRef payloadBytes = new BytesRef(suffixBytes.bytes, suffixBytes.offset + docLen, payloadLen);\n\n    final int[] fieldFlags = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldFlags[i] = (int) flags.get(skip + i);\n    }\n\n    final int[] fieldNumTerms = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldNumTerms[i] = (int) numTerms.get(skip + i);\n    }\n\n    final int[][] fieldTermFreqs = new int[numFields][];\n    {\n      int termIdx = 0;\n      for (int i = 0; i < skip; ++i) {\n        termIdx += numTerms.get(i);\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        fieldTermFreqs[i] = new int[termCount];\n        for (int j = 0; j < termCount; ++j) {\n          fieldTermFreqs[i][j] = termFreqs[termIdx++];\n        }\n      }\n    }\n\n    assert sum(fieldLengths) == docLen : sum(fieldLengths) + \" != \" + docLen;\n\n    return new TVFields(fieldNums, fieldFlags, fieldNumOffs, fieldNumTerms, fieldLengths,\n        prefixLengths, suffixLengths, fieldTermFreqs,\n        positionIndex, positions, startOffsets, lengths,\n        payloadBytes, payloadIndex,\n        suffixBytes);\n  }\n\n","sourceOld":"  @Override\n  public Fields get(int doc) throws IOException {\n    ensureOpen();\n\n    // seek to the right place\n    {\n      final long startPointer = indexReader.getStartPointer(doc);\n      vectorsStream.seek(startPointer);\n    }\n\n    // decode\n    // - docBase: first doc ID of the chunk\n    // - chunkDocs: number of docs of the chunk\n    final int docBase = vectorsStream.readVInt();\n    final int chunkDocs = vectorsStream.readVInt();\n    if (doc < docBase || doc >= docBase + chunkDocs || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"docBase=\" + docBase + \",chunkDocs=\" + chunkDocs + \",doc=\" + doc);\n    }\n\n    final int skip; // number of fields to skip\n    final int numFields; // number of fields of the document we're looking for\n    final int totalFields; // total number of fields of the chunk (sum for all docs)\n    if (chunkDocs == 1) {\n      skip = 0;\n      numFields = totalFields = vectorsStream.readVInt();\n    } else {\n      reader.reset(vectorsStream, chunkDocs);\n      int sum = 0;\n      for (int i = docBase; i < doc; ++i) {\n        sum += reader.next();\n      }\n      skip = sum;\n      numFields = (int) reader.next();\n      sum += numFields;\n      for (int i = doc + 1; i < docBase + chunkDocs; ++i) {\n        sum += reader.next();\n      }\n      totalFields = sum;\n    }\n\n    if (numFields == 0) {\n      // no vectors\n      return null;\n    }\n\n    // read field numbers that have term vectors\n    final int[] fieldNums;\n    {\n      final int token = vectorsStream.readByte() & 0xFF;\n      assert token != 0; // means no term vectors, cannot happen since we checked for numFields == 0\n      final int bitsPerFieldNum = token & 0x1F;\n      int totalDistinctFields = token >>> 5;\n      if (totalDistinctFields == 0x07) {\n        totalDistinctFields += vectorsStream.readVInt();\n      }\n      ++totalDistinctFields;\n      final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalDistinctFields, bitsPerFieldNum, 1);\n      fieldNums = new int[totalDistinctFields];\n      for (int i = 0; i < totalDistinctFields; ++i) {\n        fieldNums[i] = (int) it.next();\n      }\n    }\n\n    // read field numbers and flags\n    final int[] fieldNumOffs = new int[numFields];\n    final PackedInts.Reader flags;\n    {\n      final int bitsPerOff = PackedInts.bitsRequired(fieldNums.length - 1);\n      final PackedInts.Reader allFieldNumOffs = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsPerOff);\n      switch (vectorsStream.readVInt()) {\n        case 0:\n          final PackedInts.Reader fieldFlags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, fieldNums.length, FLAGS_BITS);\n          PackedInts.Mutable f = PackedInts.getMutable(totalFields, FLAGS_BITS, PackedInts.COMPACT);\n          for (int i = 0; i < totalFields; ++i) {\n            final int fieldNumOff = (int) allFieldNumOffs.get(i);\n            assert fieldNumOff >= 0 && fieldNumOff < fieldNums.length;\n            final int fgs = (int) fieldFlags.get(fieldNumOff);\n            f.set(i, fgs);\n          }\n          flags = f;\n          break;\n        case 1:\n          flags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, FLAGS_BITS);\n          break;\n        default:\n          throw new AssertionError();\n      }\n      for (int i = 0; i < numFields; ++i) {\n        fieldNumOffs[i] = (int) allFieldNumOffs.get(skip + i);\n      }\n    }\n\n    // number of terms per field for all fields\n    final PackedInts.Reader numTerms;\n    final int totalTerms;\n    {\n      final int bitsRequired = vectorsStream.readVInt();\n      numTerms = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsRequired);\n      int sum = 0;\n      for (int i = 0; i < totalFields; ++i) {\n        sum += numTerms.get(i);\n      }\n      totalTerms = sum;\n    }\n\n    // term lengths\n    int docOff = 0, docLen = 0, totalLen;\n    final int[] fieldLengths = new int[numFields];\n    final int[][] prefixLengths = new int[numFields][];\n    final int[][] suffixLengths = new int[numFields][];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      int toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        toSkip += numTerms.get(i);\n      }\n      reader.skip(toSkip);\n      // read prefix lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldPrefixLengths = new int[termCount];\n        prefixLengths[i] = fieldPrefixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldPrefixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n      }\n      reader.skip(totalTerms - reader.ord());\n\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          docOff += reader.next();\n        }\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldSuffixLengths = new int[termCount];\n        suffixLengths[i] = fieldSuffixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldSuffixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n        fieldLengths[i] = sum(suffixLengths[i]);\n        docLen += fieldLengths[i];\n      }\n      totalLen = docOff + docLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          totalLen += reader.next();\n        }\n      }\n    }\n\n    // term freqs\n    final int[] termFreqs = new int[totalTerms];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      for (int i = 0; i < totalTerms; ) {\n        final LongsRef next = reader.next(totalTerms - i);\n        for (int k = 0; k < next.length; ++k) {\n          termFreqs[i++] = 1 + (int) next.longs[next.offset + k];\n        }\n      }\n    }\n\n    // total number of positions, offsets and payloads\n    int totalPositions = 0, totalOffsets = 0, totalPayloads = 0;\n    for (int i = 0, termIndex = 0; i < totalFields; ++i) {\n      final int f = (int) flags.get(i);\n      final int termCount = (int) numTerms.get(i);\n      for (int j = 0; j < termCount; ++j) {\n        final int freq = termFreqs[termIndex++];\n        if ((f & POSITIONS) != 0) {\n          totalPositions += freq;\n        }\n        if ((f & OFFSETS) != 0) {\n          totalOffsets += freq;\n        }\n        if ((f & PAYLOADS) != 0) {\n          totalPayloads += freq;\n        }\n      }\n      assert i != totalFields - 1 || termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    final int[][] positionIndex = positionIndex(skip, numFields, numTerms, termFreqs);\n    final int[][] positions, startOffsets, lengths;\n    if (totalPositions > 0) {\n      positions = readPositions(skip, numFields, flags, numTerms, termFreqs, POSITIONS, totalPositions, positionIndex);\n    } else {\n      positions = new int[numFields][];\n    }\n\n    if (totalOffsets > 0) {\n      // average number of chars per term\n      final float[] charsPerTerm = new float[fieldNums.length];\n      for (int i = 0; i < charsPerTerm.length; ++i) {\n        charsPerTerm[i] = Float.intBitsToFloat(vectorsStream.readInt());\n      }\n      startOffsets = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n      lengths = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fStartOffsets = startOffsets[i];\n        final int[] fPositions = positions[i];\n        // patch offsets from positions\n        if (fStartOffsets != null && fPositions != null) {\n          final float fieldCharsPerTerm = charsPerTerm[fieldNumOffs[i]];\n          for (int j = 0; j < startOffsets[i].length; ++j) {\n            fStartOffsets[j] += (int) (fieldCharsPerTerm * fPositions[j]);\n          }\n        }\n        if (fStartOffsets != null) {\n          final int[] fPrefixLengths = prefixLengths[i];\n          final int[] fSuffixLengths = suffixLengths[i];\n          final int[] fLengths = lengths[i];\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets and  patch lengths using term lengths\n            final int termLength = fPrefixLengths[j] + fSuffixLengths[j];\n            lengths[i][positionIndex[i][j]] += termLength;\n            for (int k = positionIndex[i][j] + 1; k < positionIndex[i][j + 1]; ++k) {\n              fStartOffsets[k] += fStartOffsets[k - 1];\n              fLengths[k] += termLength;\n            }\n          }\n        }\n      }\n    } else {\n      startOffsets = lengths = new int[numFields][];\n    }\n    if (totalPositions > 0) {\n      // delta-decode positions\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fPositions = positions[i];\n        final int[] fpositionIndex = positionIndex[i];\n        if (fPositions != null) {\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets\n            for (int k = fpositionIndex[j] + 1; k < fpositionIndex[j + 1]; ++k) {\n              fPositions[k] += fPositions[k - 1];\n            }\n          }\n        }\n      }\n    }\n\n    // payload lengths\n    final int[][] payloadIndex = new int[numFields][];\n    int totalPayloadLength = 0;\n    int payloadOff = 0;\n    int payloadLen = 0;\n    if (totalPayloads > 0) {\n      reader.reset(vectorsStream, totalPayloads);\n      // skip\n      int termIndex = 0;\n      for (int i = 0; i < skip; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int l = (int) reader.next();\n              payloadOff += l;\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength = payloadOff;\n      // read doc payload lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int f = (int) flags.get(skip + i);\n        final int termCount = (int) numTerms.get(skip + i);\n        if ((f & PAYLOADS) != 0) {\n          final int totalFreq = positionIndex[i][termCount];\n          payloadIndex[i] = new int[totalFreq + 1];\n          int posIdx = 0;\n          payloadIndex[i][posIdx] = payloadLen;\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int payloadLength = (int) reader.next();\n              payloadLen += payloadLength;\n              payloadIndex[i][posIdx+1] = payloadLen;\n              ++posIdx;\n            }\n          }\n          assert posIdx == totalFreq;\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength += payloadLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              totalPayloadLength += reader.next();\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      assert termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    // decompress data\n    final BytesRef suffixBytes = new BytesRef();\n    decompressor.decompress(vectorsStream, totalLen + totalPayloadLength, docOff + payloadOff, docLen + payloadLen, suffixBytes);\n    suffixBytes.length = docLen;\n    final BytesRef payloadBytes = new BytesRef(suffixBytes.bytes, suffixBytes.offset + docLen, payloadLen);\n\n    final int[] fieldFlags = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldFlags[i] = (int) flags.get(skip + i);\n    }\n\n    final int[] fieldNumTerms = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldNumTerms[i] = (int) numTerms.get(skip + i);\n    }\n\n    final int[][] fieldTermFreqs = new int[numFields][];\n    {\n      int termIdx = 0;\n      for (int i = 0; i < skip; ++i) {\n        termIdx += numTerms.get(i);\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        fieldTermFreqs[i] = new int[termCount];\n        for (int j = 0; j < termCount; ++j) {\n          fieldTermFreqs[i][j] = termFreqs[termIdx++];\n        }\n      }\n    }\n\n    assert sum(fieldLengths) == docLen : sum(fieldLengths) + \" != \" + docLen;\n\n    return new TVFields(fieldNums, fieldFlags, fieldNumOffs, fieldNumTerms, fieldLengths,\n        prefixLengths, suffixLengths, fieldTermFreqs,\n        positionIndex, positions, startOffsets, lengths,\n        payloadBytes, payloadIndex,\n        suffixBytes);\n  }\n\n","bugFix":null,"bugIntro":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a70ce9bddc6f985feb8e5e182aebe20872328d4","date":1411172748,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#get(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#get(int).mjava","sourceNew":"  @Override\n  public Fields get(int doc) throws IOException {\n    ensureOpen();\n\n    // seek to the right place\n    {\n      final long startPointer = indexReader.getStartPointer(doc);\n      vectorsStream.seek(startPointer);\n    }\n\n    // decode\n    // - docBase: first doc ID of the chunk\n    // - chunkDocs: number of docs of the chunk\n    final int docBase = vectorsStream.readVInt();\n    final int chunkDocs = vectorsStream.readVInt();\n    if (doc < docBase || doc >= docBase + chunkDocs || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"docBase=\" + docBase + \",chunkDocs=\" + chunkDocs + \",doc=\" + doc, vectorsStream);\n    }\n\n    final int skip; // number of fields to skip\n    final int numFields; // number of fields of the document we're looking for\n    final int totalFields; // total number of fields of the chunk (sum for all docs)\n    if (chunkDocs == 1) {\n      skip = 0;\n      numFields = totalFields = vectorsStream.readVInt();\n    } else {\n      reader.reset(vectorsStream, chunkDocs);\n      int sum = 0;\n      for (int i = docBase; i < doc; ++i) {\n        sum += reader.next();\n      }\n      skip = sum;\n      numFields = (int) reader.next();\n      sum += numFields;\n      for (int i = doc + 1; i < docBase + chunkDocs; ++i) {\n        sum += reader.next();\n      }\n      totalFields = sum;\n    }\n\n    if (numFields == 0) {\n      // no vectors\n      return null;\n    }\n\n    // read field numbers that have term vectors\n    final int[] fieldNums;\n    {\n      final int token = vectorsStream.readByte() & 0xFF;\n      assert token != 0; // means no term vectors, cannot happen since we checked for numFields == 0\n      final int bitsPerFieldNum = token & 0x1F;\n      int totalDistinctFields = token >>> 5;\n      if (totalDistinctFields == 0x07) {\n        totalDistinctFields += vectorsStream.readVInt();\n      }\n      ++totalDistinctFields;\n      final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalDistinctFields, bitsPerFieldNum, 1);\n      fieldNums = new int[totalDistinctFields];\n      for (int i = 0; i < totalDistinctFields; ++i) {\n        fieldNums[i] = (int) it.next();\n      }\n    }\n\n    // read field numbers and flags\n    final int[] fieldNumOffs = new int[numFields];\n    final PackedInts.Reader flags;\n    {\n      final int bitsPerOff = PackedInts.bitsRequired(fieldNums.length - 1);\n      final PackedInts.Reader allFieldNumOffs = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsPerOff);\n      switch (vectorsStream.readVInt()) {\n        case 0:\n          final PackedInts.Reader fieldFlags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, fieldNums.length, FLAGS_BITS);\n          PackedInts.Mutable f = PackedInts.getMutable(totalFields, FLAGS_BITS, PackedInts.COMPACT);\n          for (int i = 0; i < totalFields; ++i) {\n            final int fieldNumOff = (int) allFieldNumOffs.get(i);\n            assert fieldNumOff >= 0 && fieldNumOff < fieldNums.length;\n            final int fgs = (int) fieldFlags.get(fieldNumOff);\n            f.set(i, fgs);\n          }\n          flags = f;\n          break;\n        case 1:\n          flags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, FLAGS_BITS);\n          break;\n        default:\n          throw new AssertionError();\n      }\n      for (int i = 0; i < numFields; ++i) {\n        fieldNumOffs[i] = (int) allFieldNumOffs.get(skip + i);\n      }\n    }\n\n    // number of terms per field for all fields\n    final PackedInts.Reader numTerms;\n    final int totalTerms;\n    {\n      final int bitsRequired = vectorsStream.readVInt();\n      numTerms = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsRequired);\n      int sum = 0;\n      for (int i = 0; i < totalFields; ++i) {\n        sum += numTerms.get(i);\n      }\n      totalTerms = sum;\n    }\n\n    // term lengths\n    int docOff = 0, docLen = 0, totalLen;\n    final int[] fieldLengths = new int[numFields];\n    final int[][] prefixLengths = new int[numFields][];\n    final int[][] suffixLengths = new int[numFields][];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      int toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        toSkip += numTerms.get(i);\n      }\n      reader.skip(toSkip);\n      // read prefix lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldPrefixLengths = new int[termCount];\n        prefixLengths[i] = fieldPrefixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldPrefixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n      }\n      reader.skip(totalTerms - reader.ord());\n\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          docOff += reader.next();\n        }\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldSuffixLengths = new int[termCount];\n        suffixLengths[i] = fieldSuffixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldSuffixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n        fieldLengths[i] = sum(suffixLengths[i]);\n        docLen += fieldLengths[i];\n      }\n      totalLen = docOff + docLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          totalLen += reader.next();\n        }\n      }\n    }\n\n    // term freqs\n    final int[] termFreqs = new int[totalTerms];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      for (int i = 0; i < totalTerms; ) {\n        final LongsRef next = reader.next(totalTerms - i);\n        for (int k = 0; k < next.length; ++k) {\n          termFreqs[i++] = 1 + (int) next.longs[next.offset + k];\n        }\n      }\n    }\n\n    // total number of positions, offsets and payloads\n    int totalPositions = 0, totalOffsets = 0, totalPayloads = 0;\n    for (int i = 0, termIndex = 0; i < totalFields; ++i) {\n      final int f = (int) flags.get(i);\n      final int termCount = (int) numTerms.get(i);\n      for (int j = 0; j < termCount; ++j) {\n        final int freq = termFreqs[termIndex++];\n        if ((f & POSITIONS) != 0) {\n          totalPositions += freq;\n        }\n        if ((f & OFFSETS) != 0) {\n          totalOffsets += freq;\n        }\n        if ((f & PAYLOADS) != 0) {\n          totalPayloads += freq;\n        }\n      }\n      assert i != totalFields - 1 || termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    final int[][] positionIndex = positionIndex(skip, numFields, numTerms, termFreqs);\n    final int[][] positions, startOffsets, lengths;\n    if (totalPositions > 0) {\n      positions = readPositions(skip, numFields, flags, numTerms, termFreqs, POSITIONS, totalPositions, positionIndex);\n    } else {\n      positions = new int[numFields][];\n    }\n\n    if (totalOffsets > 0) {\n      // average number of chars per term\n      final float[] charsPerTerm = new float[fieldNums.length];\n      for (int i = 0; i < charsPerTerm.length; ++i) {\n        charsPerTerm[i] = Float.intBitsToFloat(vectorsStream.readInt());\n      }\n      startOffsets = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n      lengths = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fStartOffsets = startOffsets[i];\n        final int[] fPositions = positions[i];\n        // patch offsets from positions\n        if (fStartOffsets != null && fPositions != null) {\n          final float fieldCharsPerTerm = charsPerTerm[fieldNumOffs[i]];\n          for (int j = 0; j < startOffsets[i].length; ++j) {\n            fStartOffsets[j] += (int) (fieldCharsPerTerm * fPositions[j]);\n          }\n        }\n        if (fStartOffsets != null) {\n          final int[] fPrefixLengths = prefixLengths[i];\n          final int[] fSuffixLengths = suffixLengths[i];\n          final int[] fLengths = lengths[i];\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets and  patch lengths using term lengths\n            final int termLength = fPrefixLengths[j] + fSuffixLengths[j];\n            lengths[i][positionIndex[i][j]] += termLength;\n            for (int k = positionIndex[i][j] + 1; k < positionIndex[i][j + 1]; ++k) {\n              fStartOffsets[k] += fStartOffsets[k - 1];\n              fLengths[k] += termLength;\n            }\n          }\n        }\n      }\n    } else {\n      startOffsets = lengths = new int[numFields][];\n    }\n    if (totalPositions > 0) {\n      // delta-decode positions\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fPositions = positions[i];\n        final int[] fpositionIndex = positionIndex[i];\n        if (fPositions != null) {\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets\n            for (int k = fpositionIndex[j] + 1; k < fpositionIndex[j + 1]; ++k) {\n              fPositions[k] += fPositions[k - 1];\n            }\n          }\n        }\n      }\n    }\n\n    // payload lengths\n    final int[][] payloadIndex = new int[numFields][];\n    int totalPayloadLength = 0;\n    int payloadOff = 0;\n    int payloadLen = 0;\n    if (totalPayloads > 0) {\n      reader.reset(vectorsStream, totalPayloads);\n      // skip\n      int termIndex = 0;\n      for (int i = 0; i < skip; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int l = (int) reader.next();\n              payloadOff += l;\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength = payloadOff;\n      // read doc payload lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int f = (int) flags.get(skip + i);\n        final int termCount = (int) numTerms.get(skip + i);\n        if ((f & PAYLOADS) != 0) {\n          final int totalFreq = positionIndex[i][termCount];\n          payloadIndex[i] = new int[totalFreq + 1];\n          int posIdx = 0;\n          payloadIndex[i][posIdx] = payloadLen;\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int payloadLength = (int) reader.next();\n              payloadLen += payloadLength;\n              payloadIndex[i][posIdx+1] = payloadLen;\n              ++posIdx;\n            }\n          }\n          assert posIdx == totalFreq;\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength += payloadLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              totalPayloadLength += reader.next();\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      assert termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    // decompress data\n    final BytesRef suffixBytes = new BytesRef();\n    decompressor.decompress(vectorsStream, totalLen + totalPayloadLength, docOff + payloadOff, docLen + payloadLen, suffixBytes);\n    suffixBytes.length = docLen;\n    final BytesRef payloadBytes = new BytesRef(suffixBytes.bytes, suffixBytes.offset + docLen, payloadLen);\n\n    final int[] fieldFlags = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldFlags[i] = (int) flags.get(skip + i);\n    }\n\n    final int[] fieldNumTerms = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldNumTerms[i] = (int) numTerms.get(skip + i);\n    }\n\n    final int[][] fieldTermFreqs = new int[numFields][];\n    {\n      int termIdx = 0;\n      for (int i = 0; i < skip; ++i) {\n        termIdx += numTerms.get(i);\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        fieldTermFreqs[i] = new int[termCount];\n        for (int j = 0; j < termCount; ++j) {\n          fieldTermFreqs[i][j] = termFreqs[termIdx++];\n        }\n      }\n    }\n\n    assert sum(fieldLengths) == docLen : sum(fieldLengths) + \" != \" + docLen;\n\n    return new TVFields(fieldNums, fieldFlags, fieldNumOffs, fieldNumTerms, fieldLengths,\n        prefixLengths, suffixLengths, fieldTermFreqs,\n        positionIndex, positions, startOffsets, lengths,\n        payloadBytes, payloadIndex,\n        suffixBytes);\n  }\n\n","sourceOld":"  @Override\n  public Fields get(int doc) throws IOException {\n    ensureOpen();\n\n    // seek to the right place\n    {\n      final long startPointer = indexReader.getStartPointer(doc);\n      vectorsStream.seek(startPointer);\n    }\n\n    // decode\n    // - docBase: first doc ID of the chunk\n    // - chunkDocs: number of docs of the chunk\n    final int docBase = vectorsStream.readVInt();\n    final int chunkDocs = vectorsStream.readVInt();\n    if (doc < docBase || doc >= docBase + chunkDocs || docBase + chunkDocs > numDocs) {\n      throw new CorruptIndexException(\"docBase=\" + docBase + \",chunkDocs=\" + chunkDocs + \",doc=\" + doc + \" (resource=\" + vectorsStream + \")\");\n    }\n\n    final int skip; // number of fields to skip\n    final int numFields; // number of fields of the document we're looking for\n    final int totalFields; // total number of fields of the chunk (sum for all docs)\n    if (chunkDocs == 1) {\n      skip = 0;\n      numFields = totalFields = vectorsStream.readVInt();\n    } else {\n      reader.reset(vectorsStream, chunkDocs);\n      int sum = 0;\n      for (int i = docBase; i < doc; ++i) {\n        sum += reader.next();\n      }\n      skip = sum;\n      numFields = (int) reader.next();\n      sum += numFields;\n      for (int i = doc + 1; i < docBase + chunkDocs; ++i) {\n        sum += reader.next();\n      }\n      totalFields = sum;\n    }\n\n    if (numFields == 0) {\n      // no vectors\n      return null;\n    }\n\n    // read field numbers that have term vectors\n    final int[] fieldNums;\n    {\n      final int token = vectorsStream.readByte() & 0xFF;\n      assert token != 0; // means no term vectors, cannot happen since we checked for numFields == 0\n      final int bitsPerFieldNum = token & 0x1F;\n      int totalDistinctFields = token >>> 5;\n      if (totalDistinctFields == 0x07) {\n        totalDistinctFields += vectorsStream.readVInt();\n      }\n      ++totalDistinctFields;\n      final PackedInts.ReaderIterator it = PackedInts.getReaderIteratorNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalDistinctFields, bitsPerFieldNum, 1);\n      fieldNums = new int[totalDistinctFields];\n      for (int i = 0; i < totalDistinctFields; ++i) {\n        fieldNums[i] = (int) it.next();\n      }\n    }\n\n    // read field numbers and flags\n    final int[] fieldNumOffs = new int[numFields];\n    final PackedInts.Reader flags;\n    {\n      final int bitsPerOff = PackedInts.bitsRequired(fieldNums.length - 1);\n      final PackedInts.Reader allFieldNumOffs = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsPerOff);\n      switch (vectorsStream.readVInt()) {\n        case 0:\n          final PackedInts.Reader fieldFlags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, fieldNums.length, FLAGS_BITS);\n          PackedInts.Mutable f = PackedInts.getMutable(totalFields, FLAGS_BITS, PackedInts.COMPACT);\n          for (int i = 0; i < totalFields; ++i) {\n            final int fieldNumOff = (int) allFieldNumOffs.get(i);\n            assert fieldNumOff >= 0 && fieldNumOff < fieldNums.length;\n            final int fgs = (int) fieldFlags.get(fieldNumOff);\n            f.set(i, fgs);\n          }\n          flags = f;\n          break;\n        case 1:\n          flags = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, FLAGS_BITS);\n          break;\n        default:\n          throw new AssertionError();\n      }\n      for (int i = 0; i < numFields; ++i) {\n        fieldNumOffs[i] = (int) allFieldNumOffs.get(skip + i);\n      }\n    }\n\n    // number of terms per field for all fields\n    final PackedInts.Reader numTerms;\n    final int totalTerms;\n    {\n      final int bitsRequired = vectorsStream.readVInt();\n      numTerms = PackedInts.getReaderNoHeader(vectorsStream, PackedInts.Format.PACKED, packedIntsVersion, totalFields, bitsRequired);\n      int sum = 0;\n      for (int i = 0; i < totalFields; ++i) {\n        sum += numTerms.get(i);\n      }\n      totalTerms = sum;\n    }\n\n    // term lengths\n    int docOff = 0, docLen = 0, totalLen;\n    final int[] fieldLengths = new int[numFields];\n    final int[][] prefixLengths = new int[numFields][];\n    final int[][] suffixLengths = new int[numFields][];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      int toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        toSkip += numTerms.get(i);\n      }\n      reader.skip(toSkip);\n      // read prefix lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldPrefixLengths = new int[termCount];\n        prefixLengths[i] = fieldPrefixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldPrefixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n      }\n      reader.skip(totalTerms - reader.ord());\n\n      reader.reset(vectorsStream, totalTerms);\n      // skip\n      toSkip = 0;\n      for (int i = 0; i < skip; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          docOff += reader.next();\n        }\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        final int[] fieldSuffixLengths = new int[termCount];\n        suffixLengths[i] = fieldSuffixLengths;\n        for (int j = 0; j < termCount; ) {\n          final LongsRef next = reader.next(termCount - j);\n          for (int k = 0; k < next.length; ++k) {\n            fieldSuffixLengths[j++] = (int) next.longs[next.offset + k];\n          }\n        }\n        fieldLengths[i] = sum(suffixLengths[i]);\n        docLen += fieldLengths[i];\n      }\n      totalLen = docOff + docLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        for (int j = 0; j < numTerms.get(i); ++j) {\n          totalLen += reader.next();\n        }\n      }\n    }\n\n    // term freqs\n    final int[] termFreqs = new int[totalTerms];\n    {\n      reader.reset(vectorsStream, totalTerms);\n      for (int i = 0; i < totalTerms; ) {\n        final LongsRef next = reader.next(totalTerms - i);\n        for (int k = 0; k < next.length; ++k) {\n          termFreqs[i++] = 1 + (int) next.longs[next.offset + k];\n        }\n      }\n    }\n\n    // total number of positions, offsets and payloads\n    int totalPositions = 0, totalOffsets = 0, totalPayloads = 0;\n    for (int i = 0, termIndex = 0; i < totalFields; ++i) {\n      final int f = (int) flags.get(i);\n      final int termCount = (int) numTerms.get(i);\n      for (int j = 0; j < termCount; ++j) {\n        final int freq = termFreqs[termIndex++];\n        if ((f & POSITIONS) != 0) {\n          totalPositions += freq;\n        }\n        if ((f & OFFSETS) != 0) {\n          totalOffsets += freq;\n        }\n        if ((f & PAYLOADS) != 0) {\n          totalPayloads += freq;\n        }\n      }\n      assert i != totalFields - 1 || termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    final int[][] positionIndex = positionIndex(skip, numFields, numTerms, termFreqs);\n    final int[][] positions, startOffsets, lengths;\n    if (totalPositions > 0) {\n      positions = readPositions(skip, numFields, flags, numTerms, termFreqs, POSITIONS, totalPositions, positionIndex);\n    } else {\n      positions = new int[numFields][];\n    }\n\n    if (totalOffsets > 0) {\n      // average number of chars per term\n      final float[] charsPerTerm = new float[fieldNums.length];\n      for (int i = 0; i < charsPerTerm.length; ++i) {\n        charsPerTerm[i] = Float.intBitsToFloat(vectorsStream.readInt());\n      }\n      startOffsets = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n      lengths = readPositions(skip, numFields, flags, numTerms, termFreqs, OFFSETS, totalOffsets, positionIndex);\n\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fStartOffsets = startOffsets[i];\n        final int[] fPositions = positions[i];\n        // patch offsets from positions\n        if (fStartOffsets != null && fPositions != null) {\n          final float fieldCharsPerTerm = charsPerTerm[fieldNumOffs[i]];\n          for (int j = 0; j < startOffsets[i].length; ++j) {\n            fStartOffsets[j] += (int) (fieldCharsPerTerm * fPositions[j]);\n          }\n        }\n        if (fStartOffsets != null) {\n          final int[] fPrefixLengths = prefixLengths[i];\n          final int[] fSuffixLengths = suffixLengths[i];\n          final int[] fLengths = lengths[i];\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets and  patch lengths using term lengths\n            final int termLength = fPrefixLengths[j] + fSuffixLengths[j];\n            lengths[i][positionIndex[i][j]] += termLength;\n            for (int k = positionIndex[i][j] + 1; k < positionIndex[i][j + 1]; ++k) {\n              fStartOffsets[k] += fStartOffsets[k - 1];\n              fLengths[k] += termLength;\n            }\n          }\n        }\n      }\n    } else {\n      startOffsets = lengths = new int[numFields][];\n    }\n    if (totalPositions > 0) {\n      // delta-decode positions\n      for (int i = 0; i < numFields; ++i) {\n        final int[] fPositions = positions[i];\n        final int[] fpositionIndex = positionIndex[i];\n        if (fPositions != null) {\n          for (int j = 0, end = (int) numTerms.get(skip + i); j < end; ++j) {\n            // delta-decode start offsets\n            for (int k = fpositionIndex[j] + 1; k < fpositionIndex[j + 1]; ++k) {\n              fPositions[k] += fPositions[k - 1];\n            }\n          }\n        }\n      }\n    }\n\n    // payload lengths\n    final int[][] payloadIndex = new int[numFields][];\n    int totalPayloadLength = 0;\n    int payloadOff = 0;\n    int payloadLen = 0;\n    if (totalPayloads > 0) {\n      reader.reset(vectorsStream, totalPayloads);\n      // skip\n      int termIndex = 0;\n      for (int i = 0; i < skip; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int l = (int) reader.next();\n              payloadOff += l;\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength = payloadOff;\n      // read doc payload lengths\n      for (int i = 0; i < numFields; ++i) {\n        final int f = (int) flags.get(skip + i);\n        final int termCount = (int) numTerms.get(skip + i);\n        if ((f & PAYLOADS) != 0) {\n          final int totalFreq = positionIndex[i][termCount];\n          payloadIndex[i] = new int[totalFreq + 1];\n          int posIdx = 0;\n          payloadIndex[i][posIdx] = payloadLen;\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              final int payloadLength = (int) reader.next();\n              payloadLen += payloadLength;\n              payloadIndex[i][posIdx+1] = payloadLen;\n              ++posIdx;\n            }\n          }\n          assert posIdx == totalFreq;\n        }\n        termIndex += termCount;\n      }\n      totalPayloadLength += payloadLen;\n      for (int i = skip + numFields; i < totalFields; ++i) {\n        final int f = (int) flags.get(i);\n        final int termCount = (int) numTerms.get(i);\n        if ((f & PAYLOADS) != 0) {\n          for (int j = 0; j < termCount; ++j) {\n            final int freq = termFreqs[termIndex + j];\n            for (int k = 0; k < freq; ++k) {\n              totalPayloadLength += reader.next();\n            }\n          }\n        }\n        termIndex += termCount;\n      }\n      assert termIndex == totalTerms : termIndex + \" \" + totalTerms;\n    }\n\n    // decompress data\n    final BytesRef suffixBytes = new BytesRef();\n    decompressor.decompress(vectorsStream, totalLen + totalPayloadLength, docOff + payloadOff, docLen + payloadLen, suffixBytes);\n    suffixBytes.length = docLen;\n    final BytesRef payloadBytes = new BytesRef(suffixBytes.bytes, suffixBytes.offset + docLen, payloadLen);\n\n    final int[] fieldFlags = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldFlags[i] = (int) flags.get(skip + i);\n    }\n\n    final int[] fieldNumTerms = new int[numFields];\n    for (int i = 0; i < numFields; ++i) {\n      fieldNumTerms[i] = (int) numTerms.get(skip + i);\n    }\n\n    final int[][] fieldTermFreqs = new int[numFields][];\n    {\n      int termIdx = 0;\n      for (int i = 0; i < skip; ++i) {\n        termIdx += numTerms.get(i);\n      }\n      for (int i = 0; i < numFields; ++i) {\n        final int termCount = (int) numTerms.get(skip + i);\n        fieldTermFreqs[i] = new int[termCount];\n        for (int j = 0; j < termCount; ++j) {\n          fieldTermFreqs[i][j] = termFreqs[termIdx++];\n        }\n      }\n    }\n\n    assert sum(fieldLengths) == docLen : sum(fieldLengths) + \" != \" + docLen;\n\n    return new TVFields(fieldNums, fieldFlags, fieldNumOffs, fieldNumTerms, fieldLengths,\n        prefixLengths, suffixLengths, fieldTermFreqs,\n        positionIndex, positions, startOffsets, lengths,\n        payloadBytes, payloadIndex,\n        suffixBytes);\n  }\n\n","bugFix":["90f762b9c981401224de7f0a7c1ffc8fbc67574f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"90f762b9c981401224de7f0a7c1ffc8fbc67574f":["eda61b1e90b490cc5837200e04c02639a0d272c7"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["90f762b9c981401224de7f0a7c1ffc8fbc67574f"],"eda61b1e90b490cc5837200e04c02639a0d272c7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"07155cdd910937cdf6877e48884d5782845c8b8b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","eda61b1e90b490cc5837200e04c02639a0d272c7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"]},"commit2Childs":{"90f762b9c981401224de7f0a7c1ffc8fbc67574f":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"eda61b1e90b490cc5837200e04c02639a0d272c7":["90f762b9c981401224de7f0a7c1ffc8fbc67574f","07155cdd910937cdf6877e48884d5782845c8b8b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["eda61b1e90b490cc5837200e04c02639a0d272c7","07155cdd910937cdf6877e48884d5782845c8b8b"],"07155cdd910937cdf6877e48884d5782845c8b8b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["07155cdd910937cdf6877e48884d5782845c8b8b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}