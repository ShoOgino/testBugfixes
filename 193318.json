{"path":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws CorruptIndexException, IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.perThread;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","sourceOld":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws CorruptIndexException, IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.perThread;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f64b5c281a42c5a4634b39a4fcb8f21a0cba1600","date":1329061481,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws CorruptIndexException, IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","sourceOld":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws CorruptIndexException, IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.perThread;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","sourceOld":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws CorruptIndexException, IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33e9fa3b49f4a365a04fdfc8a32dbcd0df798f5a","date":1341524239,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-IndexDocument],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  boolean updateDocuments(final Iterable<? extends IndexDocument> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","sourceOld":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","sourceOld":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws CorruptIndexException, IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":5,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-IndexDocument],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  boolean updateDocuments(final Iterable<? extends IndexDocument> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","sourceOld":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException {\n    boolean maybeMerge = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      if (!perThread.isActive()) {\n        ensureOpen();\n        assert false: \"perThread is not active but we are still open\";\n      }\n       \n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      try {\n        final int docCount = dwpt.updateDocuments(docs, analyzer, delTerm);\n        numDocsInRAM.addAndGet(docCount);\n      } finally {\n        if (dwpt.checkAndResetHasAborted()) {\n          flushControl.doOnAbort(perThread);\n        }\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThread.unlock();\n    }\n\n    return postUpdate(flushingDWPT, maybeMerge);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-IndexDocument],Analyzer,Term).mjava","sourceNew":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    return postUpdate(flushingDWPT, hasEvents);\n  }\n\n","sourceOld":"  boolean updateDocuments(final Iterable<? extends IndexDocument> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    return postUpdate(flushingDWPT, hasEvents);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f6df47cbfd656ea50ca2996361f7954531ee18b","date":1464133540,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  long updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                       final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    final long seqNo;\n\n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        seqNo = dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    if (postUpdate(flushingDWPT, hasEvents)) {\n      return -seqNo;\n    } else {\n      return seqNo;\n    }\n  }\n\n","sourceOld":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    return postUpdate(flushingDWPT, hasEvents);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6483e4260c08168709c02238ae083a51519a28dd","date":1465117546,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  long updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                       final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    final long seqNo;\n\n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        seqNo = dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    if (postUpdate(flushingDWPT, hasEvents)) {\n      return -seqNo;\n    } else {\n      return seqNo;\n    }\n  }\n\n","sourceOld":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    return postUpdate(flushingDWPT, hasEvents);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"191128ac5b85671b1671e2c857437694283b6ebf","date":1465297861,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  long updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                       final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    final long seqNo;\n\n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        seqNo = dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    if (postUpdate(flushingDWPT, hasEvents)) {\n      return -seqNo;\n    } else {\n      return seqNo;\n    }\n  }\n\n","sourceOld":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    return postUpdate(flushingDWPT, hasEvents);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"730b7b729dd280f1fec51e6b252f24c4de2a68e1","date":1465891767,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  long updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                       final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    long seqNo;\n\n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        seqNo = dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n\n      assert seqNo > perThread.lastSeqNo: \"seqNo=\" + seqNo + \" lastSeqNo=\" + perThread.lastSeqNo;\n      perThread.lastSeqNo = seqNo;\n\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    if (postUpdate(flushingDWPT, hasEvents)) {\n      seqNo = -seqNo;\n    }\n    return seqNo;\n  }\n\n","sourceOld":"  long updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                       final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    final long seqNo;\n\n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        seqNo = dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    if (postUpdate(flushingDWPT, hasEvents)) {\n      return -seqNo;\n    } else {\n      return seqNo;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","date":1465913303,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  long updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                       final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    long seqNo;\n\n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        seqNo = dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n\n      assert seqNo > perThread.lastSeqNo: \"seqNo=\" + seqNo + \" lastSeqNo=\" + perThread.lastSeqNo;\n      perThread.lastSeqNo = seqNo;\n\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    if (postUpdate(flushingDWPT, hasEvents)) {\n      seqNo = -seqNo;\n    }\n    return seqNo;\n  }\n\n","sourceOld":"  long updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                       final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    final long seqNo;\n\n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        seqNo = dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    if (postUpdate(flushingDWPT, hasEvents)) {\n      return -seqNo;\n    } else {\n      return seqNo;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  long updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                       final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    long seqNo;\n\n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        seqNo = dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n\n      assert seqNo > perThread.lastSeqNo: \"seqNo=\" + seqNo + \" lastSeqNo=\" + perThread.lastSeqNo;\n      perThread.lastSeqNo = seqNo;\n\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    if (postUpdate(flushingDWPT, hasEvents)) {\n      seqNo = -seqNo;\n    }\n    return seqNo;\n  }\n\n","sourceOld":"  boolean updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                          final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    \n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    return postUpdate(flushingDWPT, hasEvents);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"110125c995236a7f61057dd04b039ed2d267f3a1","date":1521014987,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,DocumentsWriterDeleteQueue.Node[#]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriter#updateDocuments(Iterable[#-extends-Iterable[#-extends-IndexableField]],Analyzer,Term).mjava","sourceNew":"  long updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                       final DocumentsWriterDeleteQueue.Node<?> delNode) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    long seqNo;\n\n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        seqNo = dwpt.updateDocuments(docs, analyzer, delNode);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delNode != null && delNode.isDelete();\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n\n      assert seqNo > perThread.lastSeqNo: \"seqNo=\" + seqNo + \" lastSeqNo=\" + perThread.lastSeqNo;\n      perThread.lastSeqNo = seqNo;\n\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    if (postUpdate(flushingDWPT, hasEvents)) {\n      seqNo = -seqNo;\n    }\n    return seqNo;\n  }\n\n","sourceOld":"  long updateDocuments(final Iterable<? extends Iterable<? extends IndexableField>> docs, final Analyzer analyzer,\n                       final Term delTerm) throws IOException, AbortingException {\n    boolean hasEvents = preUpdate();\n\n    final ThreadState perThread = flushControl.obtainAndLock();\n    final DocumentsWriterPerThread flushingDWPT;\n    long seqNo;\n\n    try {\n      // This must happen after we've pulled the ThreadState because IW.close\n      // waits for all ThreadStates to be released:\n      ensureOpen();\n      ensureInitialized(perThread);\n      assert perThread.isInitialized();\n      final DocumentsWriterPerThread dwpt = perThread.dwpt;\n      final int dwptNumDocs = dwpt.getNumDocsInRAM();\n      try {\n        seqNo = dwpt.updateDocuments(docs, analyzer, delTerm);\n      } catch (AbortingException ae) {\n        flushControl.doOnAbort(perThread);\n        dwpt.abort();\n        throw ae;\n      } finally {\n        // We don't know how many documents were actually\n        // counted as indexed, so we must subtract here to\n        // accumulate our separate counter:\n        numDocsInRAM.addAndGet(dwpt.getNumDocsInRAM() - dwptNumDocs);\n      }\n      final boolean isUpdate = delTerm != null;\n      flushingDWPT = flushControl.doAfterDocument(perThread, isUpdate);\n\n      assert seqNo > perThread.lastSeqNo: \"seqNo=\" + seqNo + \" lastSeqNo=\" + perThread.lastSeqNo;\n      perThread.lastSeqNo = seqNo;\n\n    } finally {\n      perThreadPool.release(perThread);\n    }\n\n    if (postUpdate(flushingDWPT, hasEvents)) {\n      seqNo = -seqNo;\n    }\n    return seqNo;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"730b7b729dd280f1fec51e6b252f24c4de2a68e1":["191128ac5b85671b1671e2c857437694283b6ebf"],"6483e4260c08168709c02238ae083a51519a28dd":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","0f6df47cbfd656ea50ca2996361f7954531ee18b"],"191128ac5b85671b1671e2c857437694283b6ebf":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","6483e4260c08168709c02238ae083a51519a28dd"],"110125c995236a7f61057dd04b039ed2d267f3a1":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"f64b5c281a42c5a4634b39a4fcb8f21a0cba1600":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"1d028314cced5858683a1bb4741423d0f934257b":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","33e9fa3b49f4a365a04fdfc8a32dbcd0df798f5a"],"33e9fa3b49f4a365a04fdfc8a32dbcd0df798f5a":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["f64b5c281a42c5a4634b39a4fcb8f21a0cba1600","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["f64b5c281a42c5a4634b39a4fcb8f21a0cba1600"],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["191128ac5b85671b1671e2c857437694283b6ebf","730b7b729dd280f1fec51e6b252f24c4de2a68e1"],"0f6df47cbfd656ea50ca2996361f7954531ee18b":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["110125c995236a7f61057dd04b039ed2d267f3a1"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["1d028314cced5858683a1bb4741423d0f934257b"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["f64b5c281a42c5a4634b39a4fcb8f21a0cba1600"],"730b7b729dd280f1fec51e6b252f24c4de2a68e1":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"6483e4260c08168709c02238ae083a51519a28dd":["191128ac5b85671b1671e2c857437694283b6ebf"],"191128ac5b85671b1671e2c857437694283b6ebf":["730b7b729dd280f1fec51e6b252f24c4de2a68e1","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"110125c995236a7f61057dd04b039ed2d267f3a1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"f64b5c281a42c5a4634b39a4fcb8f21a0cba1600":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"1d028314cced5858683a1bb4741423d0f934257b":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"33e9fa3b49f4a365a04fdfc8a32dbcd0df798f5a":["1d028314cced5858683a1bb4741423d0f934257b"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["110125c995236a7f61057dd04b039ed2d267f3a1","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["1d028314cced5858683a1bb4741423d0f934257b","33e9fa3b49f4a365a04fdfc8a32dbcd0df798f5a","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"0f6df47cbfd656ea50ca2996361f7954531ee18b":["6483e4260c08168709c02238ae083a51519a28dd"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["6483e4260c08168709c02238ae083a51519a28dd","191128ac5b85671b1671e2c857437694283b6ebf","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","0f6df47cbfd656ea50ca2996361f7954531ee18b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}