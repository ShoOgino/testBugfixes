{"path":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","commits":[{"id":"dd745d580729e528151b58aeda87ef82f1b95c9b","date":1248369082,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","pathOld":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","sourceNew":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        final Token reusableToken = new Token();\n        final Token reusableSampleToken = new Token();\n        Token nextToken;\n        Token nextSampleToken;\n        for (;;)\n        {\n          nextToken = in.next(reusableToken);\n\n            if (nextToken == null)\n            {\n                break;\n            }\n\n            nextSampleToken = sample.next(reusableSampleToken);\n            assertEquals(\n                \"1251\",\n                nextToken.term(),\n                nextSampleToken == null\n                ? null\n                : nextSampleToken.term());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","sourceOld":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        final Token reusableToken = new Token();\n        final Token reusableSampleToken = new Token();\n        Token nextToken;\n        Token nextSampleToken;\n        for (;;)\n        {\n          nextToken = in.next(reusableToken);\n\n            if (nextToken == null)\n            {\n                break;\n            }\n\n            nextSampleToken = sample.next(reusableSampleToken);\n            assertEquals(\n                \"1251\",\n                nextToken.term(),\n                nextSampleToken == null\n                ? null\n                : nextSampleToken.term());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b5756469957918cac40a831acec9cf01c8c2bb3","date":1249167152,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","sourceNew":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        TermAttribute text = (TermAttribute) in.getAttribute(TermAttribute.class);\n        TermAttribute sampleText = (TermAttribute) sample.getAttribute(TermAttribute.class);\n\n        for (;;)\n        {\n          if (in.incrementToken() == false)\n            break;\n\n            boolean nextSampleToken = sample.incrementToken();\n            assertEquals(\n                \"1251\",\n                text.term(),\n                nextSampleToken == false\n                ? null\n                : sampleText.term());\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","sourceOld":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        final Token reusableToken = new Token();\n        final Token reusableSampleToken = new Token();\n        Token nextToken;\n        Token nextSampleToken;\n        for (;;)\n        {\n          nextToken = in.next(reusableToken);\n\n            if (nextToken == null)\n            {\n                break;\n            }\n\n            nextSampleToken = sample.next(reusableSampleToken);\n            assertEquals(\n                \"1251\",\n                nextToken.term(),\n                nextSampleToken == null\n                ? null\n                : nextSampleToken.term());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","sourceNew":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        TermAttribute text = in.getAttribute(TermAttribute.class);\n        TermAttribute sampleText = sample.getAttribute(TermAttribute.class);\n\n        for (;;)\n        {\n          if (in.incrementToken() == false)\n            break;\n\n            boolean nextSampleToken = sample.incrementToken();\n            assertEquals(\n                \"1251\",\n                text.term(),\n                nextSampleToken == false\n                ? null\n                : sampleText.term());\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","sourceOld":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        TermAttribute text = (TermAttribute) in.getAttribute(TermAttribute.class);\n        TermAttribute sampleText = (TermAttribute) sample.getAttribute(TermAttribute.class);\n\n        for (;;)\n        {\n          if (in.incrementToken() == false)\n            break;\n\n            boolean nextSampleToken = sample.incrementToken();\n            assertEquals(\n                \"1251\",\n                text.term(),\n                nextSampleToken == false\n                ? null\n                : sampleText.term());\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db07cbc50e33371ac44b6829104a06d485c5fe70","date":1254424809,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","sourceNew":null,"sourceOld":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        TermAttribute text = in.getAttribute(TermAttribute.class);\n        TermAttribute sampleText = sample.getAttribute(TermAttribute.class);\n\n        for (;;)\n        {\n          if (in.incrementToken() == false)\n            break;\n\n            boolean nextSampleToken = sample.incrementToken();\n            assertEquals(\n                \"1251\",\n                text.term(),\n                nextSampleToken == false\n                ? null\n                : sampleText.term());\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dd745d580729e528151b58aeda87ef82f1b95c9b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9b5756469957918cac40a831acec9cf01c8c2bb3":["dd745d580729e528151b58aeda87ef82f1b95c9b"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"db07cbc50e33371ac44b6829104a06d485c5fe70":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["db07cbc50e33371ac44b6829104a06d485c5fe70"]},"commit2Childs":{"dd745d580729e528151b58aeda87ef82f1b95c9b":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["dd745d580729e528151b58aeda87ef82f1b95c9b"],"9b5756469957918cac40a831acec9cf01c8c2bb3":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["db07cbc50e33371ac44b6829104a06d485c5fe70"],"db07cbc50e33371ac44b6829104a06d485c5fe70":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}