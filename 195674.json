{"path":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","commits":[{"id":"744b111b17d15d490a648eb021bfa240e7f11556","date":1487008069,"type":0,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","pathOld":"/dev/null","sourceNew":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-10033\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"022a4de90e0479b604264ca9c2e134c996454ab3","date":1487118265,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","pathOld":"/dev/null","sourceNew":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-10033\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b49c0eb9ef7bc25609a89e7986ce7e6eeb9c9d96","date":1487122334,"type":4,"author":"Noble Paul","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","sourceNew":null,"sourceOld":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-10033\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"897b06b1364bd1f658a8be7591e43f0851458e7f","date":1487123008,"type":0,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","pathOld":"/dev/null","sourceNew":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-10033\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["7679cc7d5b465ec8936979698cedf5fdbd71c95c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0b21c0ef4cefc9a6c012a77388d894c9d2ceda12","date":1501539735,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","sourceNew":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-11174\n    boolean zeros = mincount <= 0;\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n\n    if (zeros && ft.isPointField()) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Cannot use \" + FacetParams.FACET_MINCOUNT + \"=0 on field \" + sf.getName() + \" which is Points-based\");\n    }\n\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","sourceOld":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-10033\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29100f1cf3406ddc394298904704d022872303d5","date":1501594929,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","sourceNew":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-10033\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","sourceOld":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-11174\n    boolean zeros = mincount <= 0;\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n\n    if (zeros && ft.isPointField()) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Cannot use \" + FacetParams.FACET_MINCOUNT + \"=0 on field \" + sf.getName() + \" which is Points-based\");\n    }\n\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"36294de1b3009c52225da73c7d7e5ad8cf7ab100","date":1501615974,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","sourceNew":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-11174\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","sourceOld":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-10033\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","sourceNew":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-11174\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","sourceOld":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-10033\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"95904004e26fe5b84dcda2fa112ebf7cc9721a60","date":1560149781,"type":3,"author":"Tim Underwood","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","sourceNew":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-11174\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1, count = longs.docValueCount(); i < count; i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","sourceOld":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-11174\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1; i < longs.docValueCount(); i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7679cc7d5b465ec8936979698cedf5fdbd71c95c","date":1566227764,"type":3,"author":"Munendra S N","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/NumericFacets#getCountsMultiValued(SolrIndexSearcher,DocSet,String,int,int,int,boolean,String).mjava","sourceNew":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-11174\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1, count = longs.docValueCount(); i < count; i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    if (limit == 0) {\n      NamedList<Integer> result = new NamedList<>();\n      return finalize(result, missingCount, missing);\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    return finalize(result, missingCount, missing);\n  }\n\n","sourceOld":"  private static NamedList<Integer> getCountsMultiValued(SolrIndexSearcher searcher, DocSet docs, String fieldName, int offset, int limit, int mincount, boolean missing, String sort) throws IOException {\n    // If facet.mincount=0 with PointFields the only option is to get the values from DocValues\n    // not currently supported. See SOLR-11174\n    mincount = Math.max(mincount, 1);\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n    final FieldType ft = sf.getType();\n    assert sf.multiValued();\n    final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n\n    // 1. accumulate\n    final HashTable hashTable = new HashTable(false);\n    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n    LeafReaderContext ctx = null;\n    SortedNumericDocValues longs = null;\n    int missingCount = 0;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n        longs = DocValues.getSortedNumeric(ctx.reader(), fieldName);\n      }\n      int valuesDocID = longs.docID();\n      if (valuesDocID < doc - ctx.docBase) {\n        valuesDocID = longs.advance(doc - ctx.docBase);\n      }\n      if (valuesDocID == doc - ctx.docBase) {\n        long l = longs.nextValue(); // This document must have at least one value\n        hashTable.add(l, 1);\n        for (int i = 1, count = longs.docValueCount(); i < count; i++) {\n          long lnew = longs.nextValue();\n          if (lnew > l) { // Skip the value if it's equal to the last one, we don't want to double-count it\n            hashTable.add(lnew, 1);\n          }\n          l = lnew;\n         }\n        \n      } else {\n        ++missingCount;\n      }\n    }\n\n    // 2. select top-k facet values\n    final int pqSize = limit < 0 ? hashTable.size : Math.min(offset + limit, hashTable.size);\n    final PriorityQueue<Entry> pq;\n    if (FacetParams.FACET_SORT_COUNT.equals(sort) || FacetParams.FACET_SORT_COUNT_LEGACY.equals(sort)) {\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          if (a.count < b.count || (a.count == b.count && a.bits > b.bits)) {\n            return true;\n          } else {\n            return false;\n          }\n        }\n      };\n    } else {\n      // sort=index\n      pq = new PriorityQueue<Entry>(pqSize) {\n        @Override\n        protected boolean lessThan(Entry a, Entry b) {\n          return a.bits > b.bits;\n        }\n      };\n    }\n    Entry e = null;\n    for (int i = 0; i < hashTable.bits.length; ++i) {\n      if (hashTable.counts[i] >= mincount) {\n        if (e == null) {\n          e = new Entry();\n        }\n        e.bits = hashTable.bits[i];\n        e.count = hashTable.counts[i];\n        e = pq.insertWithOverflow(e);\n      }\n    }\n\n    // 4. build the NamedList\n    final NamedList<Integer> result = new NamedList<>(Math.max(pq.size() - offset + 1, 1));\n    final Deque<Entry> counts = new ArrayDeque<>(pq.size() - offset);\n    while (pq.size() > offset) {\n      counts.addFirst(pq.pop());\n    }\n    \n    for (Entry entry : counts) {\n      result.add(bitsToStringValue(ft, entry.bits), entry.count); // TODO: convert to correct value\n    }\n    \n    // Once facet.mincount=0 is supported we'll need to add logic similar to the SingleValue case, but obtaining values\n    // with count 0 from DocValues\n\n    if (missing) {\n      result.add(null, missingCount);\n    }\n    return result;\n  }\n\n","bugFix":["897b06b1364bd1f658a8be7591e43f0851458e7f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b49c0eb9ef7bc25609a89e7986ce7e6eeb9c9d96":["022a4de90e0479b604264ca9c2e134c996454ab3"],"36294de1b3009c52225da73c7d7e5ad8cf7ab100":["29100f1cf3406ddc394298904704d022872303d5"],"29100f1cf3406ddc394298904704d022872303d5":["0b21c0ef4cefc9a6c012a77388d894c9d2ceda12"],"022a4de90e0479b604264ca9c2e134c996454ab3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","744b111b17d15d490a648eb021bfa240e7f11556"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["897b06b1364bd1f658a8be7591e43f0851458e7f","36294de1b3009c52225da73c7d7e5ad8cf7ab100"],"897b06b1364bd1f658a8be7591e43f0851458e7f":["b49c0eb9ef7bc25609a89e7986ce7e6eeb9c9d96"],"7679cc7d5b465ec8936979698cedf5fdbd71c95c":["95904004e26fe5b84dcda2fa112ebf7cc9721a60"],"95904004e26fe5b84dcda2fa112ebf7cc9721a60":["36294de1b3009c52225da73c7d7e5ad8cf7ab100"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0b21c0ef4cefc9a6c012a77388d894c9d2ceda12":["897b06b1364bd1f658a8be7591e43f0851458e7f"],"744b111b17d15d490a648eb021bfa240e7f11556":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7679cc7d5b465ec8936979698cedf5fdbd71c95c"]},"commit2Childs":{"b49c0eb9ef7bc25609a89e7986ce7e6eeb9c9d96":["897b06b1364bd1f658a8be7591e43f0851458e7f"],"36294de1b3009c52225da73c7d7e5ad8cf7ab100":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","95904004e26fe5b84dcda2fa112ebf7cc9721a60"],"022a4de90e0479b604264ca9c2e134c996454ab3":["b49c0eb9ef7bc25609a89e7986ce7e6eeb9c9d96"],"29100f1cf3406ddc394298904704d022872303d5":["36294de1b3009c52225da73c7d7e5ad8cf7ab100"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"897b06b1364bd1f658a8be7591e43f0851458e7f":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","0b21c0ef4cefc9a6c012a77388d894c9d2ceda12"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["022a4de90e0479b604264ca9c2e134c996454ab3","744b111b17d15d490a648eb021bfa240e7f11556"],"7679cc7d5b465ec8936979698cedf5fdbd71c95c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"95904004e26fe5b84dcda2fa112ebf7cc9721a60":["7679cc7d5b465ec8936979698cedf5fdbd71c95c"],"0b21c0ef4cefc9a6c012a77388d894c9d2ceda12":["29100f1cf3406ddc394298904704d022872303d5"],"744b111b17d15d490a648eb021bfa240e7f11556":["022a4de90e0479b604264ca9c2e134c996454ab3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}