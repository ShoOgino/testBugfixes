{"path":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicPrefixTerms().mjava","commits":[{"id":"3e8715d826e588419327562287d5d6a8040d63d6","date":1427987148,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicPrefixTerms().mjava","pathOld":"/dev/null","sourceNew":"  // Non-numeric, simple prefix query\n  public void testBasicPrefixTerms() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(TestUtil.randomSimpleString(random()));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new BinaryDocValuesField(\"field\", new BytesRef(term)));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: now force merge\");\n      }\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: r=\" + r);\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      String prefix;\n      if (random().nextInt(100) == 42) {\n        prefix = \"\";\n      } else {\n        prefix = TestUtil.randomSimpleString(random(), 1, 4);\n      }\n      BytesRef prefixBR = new BytesRef(prefix);\n      if (VERBOSE) {\n        System.out.println(\"  prefix=\" + prefix);\n      }\n\n      CompiledAutomaton ca = new CompiledAutomaton(PrefixQuery.toAutomaton(prefixBR), true, false, Integer.MAX_VALUE, true);\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      BinaryDocValues docValues = MultiDocValues.getBinaryValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), prefixBR);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: got term=\" + te.term().utf8ToString() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(null, postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          assertTrue(\"prefixBR=\" + prefixBR + \" docBR=\" + docValues.get(docID), StringHelper.startsWith(docValues.get(docID), prefixBR));\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, prefix);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, prefix + (char) ('z'+1));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            String s = docValues.get(i).utf8ToString();\n            if (s.startsWith(prefix)) {\n              System.out.println(\"MISSING: docID=\" + i + \" term=\" + s);\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2638f781be724518ff6c2263d14a48cf6e68017","date":1427989059,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicPrefixTerms().mjava","pathOld":"/dev/null","sourceNew":"  // Non-numeric, simple prefix query\n  public void testBasicPrefixTerms() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(TestUtil.randomSimpleString(random()));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new BinaryDocValuesField(\"field\", new BytesRef(term)));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: now force merge\");\n      }\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: r=\" + r);\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      String prefix;\n      if (random().nextInt(100) == 42) {\n        prefix = \"\";\n      } else {\n        prefix = TestUtil.randomSimpleString(random(), 1, 4);\n      }\n      BytesRef prefixBR = new BytesRef(prefix);\n      if (VERBOSE) {\n        System.out.println(\"  prefix=\" + prefix);\n      }\n\n      CompiledAutomaton ca = new CompiledAutomaton(PrefixQuery.toAutomaton(prefixBR), true, false, Integer.MAX_VALUE, true);\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      BinaryDocValues docValues = MultiDocValues.getBinaryValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), prefixBR);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: got term=\" + te.term().utf8ToString() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(null, postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          assertTrue(\"prefixBR=\" + prefixBR + \" docBR=\" + docValues.get(docID), StringHelper.startsWith(docValues.get(docID), prefixBR));\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, prefix);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, prefix + (char) ('z'+1));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            String s = docValues.get(i).utf8ToString();\n            if (s.startsWith(prefix)) {\n              System.out.println(\"MISSING: docID=\" + i + \" term=\" + s);\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicPrefixTerms().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicPrefixTerms().mjava","sourceNew":"  // Non-numeric, simple prefix query\n  public void testBasicPrefixTerms() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(TestUtil.randomSimpleString(random()));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new BinaryDocValuesField(\"field\", new BytesRef(term)));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: now force merge\");\n      }\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: r=\" + r);\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      String prefix;\n      if (random().nextInt(100) == 42) {\n        prefix = \"\";\n      } else {\n        prefix = TestUtil.randomSimpleString(random(), 1, 4);\n      }\n      BytesRef prefixBR = new BytesRef(prefix);\n      if (VERBOSE) {\n        System.out.println(\"  prefix=\" + prefix);\n      }\n\n      CompiledAutomaton ca = new CompiledAutomaton(PrefixQuery.toAutomaton(prefixBR), true, false, Integer.MAX_VALUE, true);\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      BinaryDocValues docValues = MultiDocValues.getBinaryValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), prefixBR);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: got term=\" + te.term().utf8ToString() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          assertTrue(\"prefixBR=\" + prefixBR + \" docBR=\" + docValues.get(docID), StringHelper.startsWith(docValues.get(docID), prefixBR));\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, prefix);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, prefix + (char) ('z'+1));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            String s = docValues.get(i).utf8ToString();\n            if (s.startsWith(prefix)) {\n              System.out.println(\"MISSING: docID=\" + i + \" term=\" + s);\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Non-numeric, simple prefix query\n  public void testBasicPrefixTerms() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(TestUtil.randomSimpleString(random()));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new BinaryDocValuesField(\"field\", new BytesRef(term)));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: now force merge\");\n      }\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: r=\" + r);\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      String prefix;\n      if (random().nextInt(100) == 42) {\n        prefix = \"\";\n      } else {\n        prefix = TestUtil.randomSimpleString(random(), 1, 4);\n      }\n      BytesRef prefixBR = new BytesRef(prefix);\n      if (VERBOSE) {\n        System.out.println(\"  prefix=\" + prefix);\n      }\n\n      CompiledAutomaton ca = new CompiledAutomaton(PrefixQuery.toAutomaton(prefixBR), true, false, Integer.MAX_VALUE, true);\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      BinaryDocValues docValues = MultiDocValues.getBinaryValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), prefixBR);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: got term=\" + te.term().utf8ToString() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(null, postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          assertTrue(\"prefixBR=\" + prefixBR + \" docBR=\" + docValues.get(docID), StringHelper.startsWith(docValues.get(docID), prefixBR));\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, prefix);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, prefix + (char) ('z'+1));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            String s = docValues.get(i).utf8ToString();\n            if (s.startsWith(prefix)) {\n              System.out.println(\"MISSING: docID=\" + i + \" term=\" + s);\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a1862266772deb28cdcb7d996b64d2177022687","date":1453077824,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicPrefixTerms().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicPrefixTerms().mjava","sourceNew":"  // Non-numeric, simple prefix query\n  public void testBasicPrefixTerms() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(TestUtil.randomSimpleString(random()));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new BinaryDocValuesField(\"field\", new BytesRef(term)));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: now force merge\");\n      }\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: r=\" + r);\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      String prefix;\n      if (random().nextInt(100) == 42) {\n        prefix = \"\";\n      } else {\n        prefix = TestUtil.randomSimpleString(random(), 1, 4);\n      }\n      BytesRef prefixBR = new BytesRef(prefix);\n      if (VERBOSE) {\n        System.out.println(\"  prefix=\" + prefix);\n      }\n\n      CompiledAutomaton ca = new CompiledAutomaton(PrefixQuery.toAutomaton(prefixBR), true, false, Integer.MAX_VALUE, true);\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      BinaryDocValues docValues = MultiDocValues.getBinaryValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), prefixBR);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: got term=\" + te.term().utf8ToString() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          assertTrue(\"prefixBR=\" + prefixBR + \" docBR=\" + docValues.get(docID), StringHelper.startsWith(docValues.get(docID), prefixBR));\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, prefix);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, prefix + (char) ('z'+1));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            String s = docValues.get(i).utf8ToString();\n            if (s.startsWith(prefix)) {\n              System.out.println(\"MISSING: docID=\" + i + \" term=\" + s);\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Non-numeric, simple prefix query\n  public void testBasicPrefixTerms() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(TestUtil.randomSimpleString(random()));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new BinaryDocValuesField(\"field\", new BytesRef(term)));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: now force merge\");\n      }\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: r=\" + r);\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      String prefix;\n      if (random().nextInt(100) == 42) {\n        prefix = \"\";\n      } else {\n        prefix = TestUtil.randomSimpleString(random(), 1, 4);\n      }\n      BytesRef prefixBR = new BytesRef(prefix);\n      if (VERBOSE) {\n        System.out.println(\"  prefix=\" + prefix);\n      }\n\n      CompiledAutomaton ca = new CompiledAutomaton(PrefixQuery.toAutomaton(prefixBR), true, false, Integer.MAX_VALUE, true);\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      BinaryDocValues docValues = MultiDocValues.getBinaryValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), prefixBR);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: got term=\" + te.term().utf8ToString() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          assertTrue(\"prefixBR=\" + prefixBR + \" docBR=\" + docValues.get(docID), StringHelper.startsWith(docValues.get(docID), prefixBR));\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, prefix);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, prefix + (char) ('z'+1));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            String s = docValues.get(i).utf8ToString();\n            if (s.startsWith(prefix)) {\n              System.out.println(\"MISSING: docID=\" + i + \" term=\" + s);\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f","date":1466407389,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicPrefixTerms().mjava","sourceNew":null,"sourceOld":"  // Non-numeric, simple prefix query\n  public void testBasicPrefixTerms() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(TestUtil.randomSimpleString(random()));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new BinaryDocValuesField(\"field\", new BytesRef(term)));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: now force merge\");\n      }\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: r=\" + r);\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      String prefix;\n      if (random().nextInt(100) == 42) {\n        prefix = \"\";\n      } else {\n        prefix = TestUtil.randomSimpleString(random(), 1, 4);\n      }\n      BytesRef prefixBR = new BytesRef(prefix);\n      if (VERBOSE) {\n        System.out.println(\"  prefix=\" + prefix);\n      }\n\n      CompiledAutomaton ca = new CompiledAutomaton(PrefixQuery.toAutomaton(prefixBR), true, false, Integer.MAX_VALUE, true);\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      BinaryDocValues docValues = MultiDocValues.getBinaryValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), prefixBR);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: got term=\" + te.term().utf8ToString() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          assertTrue(\"prefixBR=\" + prefixBR + \" docBR=\" + docValues.get(docID), StringHelper.startsWith(docValues.get(docID), prefixBR));\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, prefix);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, prefix + (char) ('z'+1));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            String s = docValues.get(i).utf8ToString();\n            if (s.startsWith(prefix)) {\n              System.out.println(\"MISSING: docID=\" + i + \" term=\" + s);\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6aaba221b22442bdf0ef28770c25fe259dfb3f55","date":1466496193,"type":4,"author":"Noble Paul","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicPrefixTerms().mjava","sourceNew":null,"sourceOld":"  // Non-numeric, simple prefix query\n  public void testBasicPrefixTerms() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(TestUtil.randomSimpleString(random()));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new BinaryDocValuesField(\"field\", new BytesRef(term)));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: now force merge\");\n      }\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: r=\" + r);\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      String prefix;\n      if (random().nextInt(100) == 42) {\n        prefix = \"\";\n      } else {\n        prefix = TestUtil.randomSimpleString(random(), 1, 4);\n      }\n      BytesRef prefixBR = new BytesRef(prefix);\n      if (VERBOSE) {\n        System.out.println(\"  prefix=\" + prefix);\n      }\n\n      CompiledAutomaton ca = new CompiledAutomaton(PrefixQuery.toAutomaton(prefixBR), true, false, Integer.MAX_VALUE, true);\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      BinaryDocValues docValues = MultiDocValues.getBinaryValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), prefixBR);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: got term=\" + te.term().utf8ToString() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          assertTrue(\"prefixBR=\" + prefixBR + \" docBR=\" + docValues.get(docID), StringHelper.startsWith(docValues.get(docID), prefixBR));\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, prefix);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, prefix + (char) ('z'+1));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            String s = docValues.get(i).utf8ToString();\n            if (s.startsWith(prefix)) {\n              System.out.println(\"MISSING: docID=\" + i + \" term=\" + s);\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicPrefixTerms().mjava","sourceNew":null,"sourceOld":"  // Non-numeric, simple prefix query\n  public void testBasicPrefixTerms() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    while (terms.size() < numTerms) {\n      terms.add(TestUtil.randomSimpleString(random()));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new BinaryDocValuesField(\"field\", new BytesRef(term)));\n      w.addDocument(doc);\n    }\n\n    if (random().nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: now force merge\");\n      }\n      w.forceMerge(1);\n    }\n\n    IndexReader r = DirectoryReader.open(w);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: r=\" + r);\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n\n      String prefix;\n      if (random().nextInt(100) == 42) {\n        prefix = \"\";\n      } else {\n        prefix = TestUtil.randomSimpleString(random(), 1, 4);\n      }\n      BytesRef prefixBR = new BytesRef(prefix);\n      if (VERBOSE) {\n        System.out.println(\"  prefix=\" + prefix);\n      }\n\n      CompiledAutomaton ca = new CompiledAutomaton(PrefixQuery.toAutomaton(prefixBR), true, false, Integer.MAX_VALUE, true);\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      BinaryDocValues docValues = MultiDocValues.getBinaryValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), prefixBR);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: got term=\" + te.term().utf8ToString() + \" docFreq=\" + te.docFreq());\n        }\n        verifier.sawTerm(te.term());        \n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          assertTrue(\"prefixBR=\" + prefixBR + \" docBR=\" + docValues.get(docID), StringHelper.startsWith(docValues.get(docID), prefixBR));\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, prefix);\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, prefix + (char) ('z'+1));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      }\n      int expectedHits = endLoc-startLoc+1;\n      try {\n        verifier.finish(expectedHits, maxTermsAutoPrefix);\n      } catch (AssertionError ae) {\n        for(int i=0;i<numTerms;i++) {\n          if (verifier.allHits.get(i) == false) {\n            String s = docValues.get(i).utf8ToString();\n            if (s.startsWith(prefix)) {\n              System.out.println(\"MISSING: docID=\" + i + \" term=\" + s);\n            }\n          }\n        }\n\n        throw ae;\n      }\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0f4464508ee83288c8c4585b533f9faaa93aa314":["3e8715d826e588419327562287d5d6a8040d63d6"],"2a1862266772deb28cdcb7d996b64d2177022687":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"6aaba221b22442bdf0ef28770c25fe259dfb3f55":["2a1862266772deb28cdcb7d996b64d2177022687","25b8a027ba57951e63075a2ae9647c5c4a8c5c5f"],"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f":["2a1862266772deb28cdcb7d996b64d2177022687"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d2638f781be724518ff6c2263d14a48cf6e68017":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3e8715d826e588419327562287d5d6a8040d63d6"],"3e8715d826e588419327562287d5d6a8040d63d6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["2a1862266772deb28cdcb7d996b64d2177022687","6aaba221b22442bdf0ef28770c25fe259dfb3f55"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6aaba221b22442bdf0ef28770c25fe259dfb3f55"]},"commit2Childs":{"0f4464508ee83288c8c4585b533f9faaa93aa314":["2a1862266772deb28cdcb7d996b64d2177022687"],"2a1862266772deb28cdcb7d996b64d2177022687":["6aaba221b22442bdf0ef28770c25fe259dfb3f55","25b8a027ba57951e63075a2ae9647c5c4a8c5c5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"6aaba221b22442bdf0ef28770c25fe259dfb3f55":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f":["6aaba221b22442bdf0ef28770c25fe259dfb3f55"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d2638f781be724518ff6c2263d14a48cf6e68017","3e8715d826e588419327562287d5d6a8040d63d6"],"d2638f781be724518ff6c2263d14a48cf6e68017":[],"3e8715d826e588419327562287d5d6a8040d63d6":["0f4464508ee83288c8c4585b533f9faaa93aa314","d2638f781be724518ff6c2263d14a48cf6e68017"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d2638f781be724518ff6c2263d14a48cf6e68017","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}