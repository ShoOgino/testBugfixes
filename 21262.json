{"path":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","sourceNew":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    // SegmentMerger calls canReadRawDocs() first and should\n    // not call us if that returns false.\n    if (format < FORMAT_VERSION2)\n      throw new IllegalStateException(\"cannot read raw docs with older term vector formats\");\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","sourceOld":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    // SegmentMerger calls canReadRawDocs() first and should\n    // not call us if that returns false.\n    if (format < FORMAT_VERSION2)\n      throw new IllegalStateException(\"cannot read raw docs with older term vector formats\");\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6267e1ce56c2eec111425690cd04e251b6f14952","date":1275222352,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","sourceNew":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    // SegmentMerger calls canReadRawDocs() first and should\n    // not call us if that returns false.\n    if (format < FORMAT_UTF8_LENGTH_IN_BYTES)\n      throw new IllegalStateException(\"cannot read raw docs with older term vector formats\");\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","sourceOld":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    // SegmentMerger calls canReadRawDocs() first and should\n    // not call us if that returns false.\n    if (format < FORMAT_VERSION2)\n      throw new IllegalStateException(\"cannot read raw docs with older term vector formats\");\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c740bdcaf9781b9822969a3305e51cfa4eaaf673","date":1280775080,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","sourceNew":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","sourceOld":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    // SegmentMerger calls canReadRawDocs() first and should\n    // not call us if that returns false.\n    if (format < FORMAT_UTF8_LENGTH_IN_BYTES)\n      throw new IllegalStateException(\"cannot read raw docs with older term vector formats\");\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90dd9e0118d85e8451e26b0e3c18172a42d673ce","date":1280782731,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","sourceNew":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    // SegmentMerger calls canReadRawDocs() first and should\n    // not call us if that returns false.\n    if (format < FORMAT_UTF8_LENGTH_IN_BYTES)\n      throw new IllegalStateException(\"cannot read raw docs with older term vector formats\");\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","sourceOld":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5972dc9caad764a4e6e2e25f3e1a8de2489a8487","date":1280787041,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","sourceNew":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","sourceOld":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    // SegmentMerger calls canReadRawDocs() first and should\n    // not call us if that returns false.\n    if (format < FORMAT_UTF8_LENGTH_IN_BYTES)\n      throw new IllegalStateException(\"cannot read raw docs with older term vector formats\");\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","sourceNew":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","sourceOld":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    // SegmentMerger calls canReadRawDocs() first and should\n    // not call us if that returns false.\n    if (format < FORMAT_UTF8_LENGTH_IN_BYTES)\n      throw new IllegalStateException(\"cannot read raw docs with older term vector formats\");\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DefaultTermVectorsReader#rawDocs(int[],int[],int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#rawDocs(int[],int[],int,int).mjava","sourceNew":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","sourceOld":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"90dd9e0118d85e8451e26b0e3c18172a42d673ce":["c740bdcaf9781b9822969a3305e51cfa4eaaf673"],"6267e1ce56c2eec111425690cd04e251b6f14952":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"c740bdcaf9781b9822969a3305e51cfa4eaaf673":["6267e1ce56c2eec111425690cd04e251b6f14952"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cc749c053615f5871f3b95715fe292f34e70a53":["5972dc9caad764a4e6e2e25f3e1a8de2489a8487"],"5972dc9caad764a4e6e2e25f3e1a8de2489a8487":["90dd9e0118d85e8451e26b0e3c18172a42d673ce"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["6267e1ce56c2eec111425690cd04e251b6f14952","5972dc9caad764a4e6e2e25f3e1a8de2489a8487"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3cc749c053615f5871f3b95715fe292f34e70a53"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"90dd9e0118d85e8451e26b0e3c18172a42d673ce":["5972dc9caad764a4e6e2e25f3e1a8de2489a8487"],"6267e1ce56c2eec111425690cd04e251b6f14952":["c740bdcaf9781b9822969a3305e51cfa4eaaf673","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"c740bdcaf9781b9822969a3305e51cfa4eaaf673":["90dd9e0118d85e8451e26b0e3c18172a42d673ce"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"3cc749c053615f5871f3b95715fe292f34e70a53":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5972dc9caad764a4e6e2e25f3e1a8de2489a8487":["3cc749c053615f5871f3b95715fe292f34e70a53","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["6267e1ce56c2eec111425690cd04e251b6f14952"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}