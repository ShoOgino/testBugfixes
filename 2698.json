{"path":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","commits":[{"id":"e072d0b1fc19e0533d8ce432eed245196bca6fde","date":1379265112,"type":0,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"/dev/null","sourceNew":"  @Test\r\n  public void testManyReopensAndFields() throws Exception {\r\n    Directory dir = newDirectory();\r\n    final Random random = random();\r\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\r\n    LogMergePolicy lmp = newLogMergePolicy();\r\n    lmp.setMergeFactor(3); // merge often\r\n    conf.setMergePolicy(lmp);\r\n    IndexWriter writer = new IndexWriter(dir, conf);\r\n    \r\n    final boolean isNRT = random.nextBoolean();\r\n    DirectoryReader reader;\r\n    if (isNRT) {\r\n      reader = DirectoryReader.open(writer, true);\r\n    } else {\r\n      writer.commit();\r\n      reader = DirectoryReader.open(dir);\r\n    }\r\n    \r\n    final int numFields = random.nextInt(4) + 3; // 3-7\r\n    final long[] fieldValues = new long[numFields];\r\n    for (int i = 0; i < fieldValues.length; i++) {\r\n      fieldValues[i] = 1;\r\n    }\r\n    \r\n    int numRounds = atLeast(15);\r\n    int docID = 0;\r\n    for (int i = 0; i < numRounds; i++) {\r\n      int numDocs = atLeast(2);\r\n      //      System.out.println(\"round=\" + i + \", numDocs=\" + numDocs);\r\n      for (int j = 0; j < numDocs; j++) {\r\n        Document doc = new Document();\r\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\r\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\r\n        // add all fields with their current (updated value)\r\n        for (int f = 0; f < fieldValues.length; f++) {\r\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\r\n        }\r\n        writer.addDocument(doc);\r\n        ++docID;\r\n      }\r\n      \r\n      int fieldIdx = random.nextInt(fieldValues.length);\r\n      String updateField = \"f\" + fieldIdx;\r\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\r\n      //      System.out.println(\"+++ updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\r\n      \r\n      if (random.nextDouble() < 0.2) {\r\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\r\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\r\n        //        System.out.println(\"--- deleted document: doc-\" + deleteDoc);\r\n      }\r\n      \r\n      // verify reader\r\n      if (!isNRT) {\r\n        writer.commit();\r\n      }\r\n      \r\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\r\n      assertNotNull(newReader);\r\n      reader.close();\r\n      reader = newReader;\r\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\r\n      for (AtomicReaderContext context : reader.leaves()) {\r\n        AtomicReader r = context.reader();\r\n        //        System.out.println(((SegmentReader) r).getSegmentName());\r\n        Bits liveDocs = r.getLiveDocs();\r\n        for (int field = 0; field < fieldValues.length; field++) {\r\n          String f = \"f\" + field;\r\n          NumericDocValues ndv = r.getNumericDocValues(f);\r\n          assertNotNull(ndv);\r\n          int maxDoc = r.maxDoc();\r\n          for (int doc = 0; doc < maxDoc; doc++) {\r\n            if (liveDocs == null || liveDocs.get(doc)) {\r\n              //              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\r\n              assertEquals(\"invalid value for doc=\" + (doc + context.docBase) + \", field=\" + f, fieldValues[field], ndv.get(doc));\r\n            }\r\n          }\r\n        }\r\n      }\r\n      //      System.out.println();\r\n    }\r\n    \r\n    IOUtils.close(writer, reader, dir);\r\n  }\r\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4962e8a1c440950d757f5e295b4f6106ba2ab420","date":1379271654,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(2);\n      //      System.out.println(\"round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current (updated value)\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n      //      System.out.println(\"+++ updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n        //        System.out.println(\"--- deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n        //        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n              //              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertEquals(\"invalid value for doc=\" + (doc + context.docBase) + \", field=\" + f, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n      //      System.out.println();\n    }\n    \n    IOUtils.close(writer, reader, dir);\n  }\n\n","sourceOld":"  @Test\r\n  public void testManyReopensAndFields() throws Exception {\r\n    Directory dir = newDirectory();\r\n    final Random random = random();\r\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\r\n    LogMergePolicy lmp = newLogMergePolicy();\r\n    lmp.setMergeFactor(3); // merge often\r\n    conf.setMergePolicy(lmp);\r\n    IndexWriter writer = new IndexWriter(dir, conf);\r\n    \r\n    final boolean isNRT = random.nextBoolean();\r\n    DirectoryReader reader;\r\n    if (isNRT) {\r\n      reader = DirectoryReader.open(writer, true);\r\n    } else {\r\n      writer.commit();\r\n      reader = DirectoryReader.open(dir);\r\n    }\r\n    \r\n    final int numFields = random.nextInt(4) + 3; // 3-7\r\n    final long[] fieldValues = new long[numFields];\r\n    for (int i = 0; i < fieldValues.length; i++) {\r\n      fieldValues[i] = 1;\r\n    }\r\n    \r\n    int numRounds = atLeast(15);\r\n    int docID = 0;\r\n    for (int i = 0; i < numRounds; i++) {\r\n      int numDocs = atLeast(2);\r\n      //      System.out.println(\"round=\" + i + \", numDocs=\" + numDocs);\r\n      for (int j = 0; j < numDocs; j++) {\r\n        Document doc = new Document();\r\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\r\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\r\n        // add all fields with their current (updated value)\r\n        for (int f = 0; f < fieldValues.length; f++) {\r\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\r\n        }\r\n        writer.addDocument(doc);\r\n        ++docID;\r\n      }\r\n      \r\n      int fieldIdx = random.nextInt(fieldValues.length);\r\n      String updateField = \"f\" + fieldIdx;\r\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\r\n      //      System.out.println(\"+++ updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\r\n      \r\n      if (random.nextDouble() < 0.2) {\r\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\r\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\r\n        //        System.out.println(\"--- deleted document: doc-\" + deleteDoc);\r\n      }\r\n      \r\n      // verify reader\r\n      if (!isNRT) {\r\n        writer.commit();\r\n      }\r\n      \r\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\r\n      assertNotNull(newReader);\r\n      reader.close();\r\n      reader = newReader;\r\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\r\n      for (AtomicReaderContext context : reader.leaves()) {\r\n        AtomicReader r = context.reader();\r\n        //        System.out.println(((SegmentReader) r).getSegmentName());\r\n        Bits liveDocs = r.getLiveDocs();\r\n        for (int field = 0; field < fieldValues.length; field++) {\r\n          String f = \"f\" + field;\r\n          NumericDocValues ndv = r.getNumericDocValues(f);\r\n          assertNotNull(ndv);\r\n          int maxDoc = r.maxDoc();\r\n          for (int doc = 0; doc < maxDoc; doc++) {\r\n            if (liveDocs == null || liveDocs.get(doc)) {\r\n              //              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\r\n              assertEquals(\"invalid value for doc=\" + (doc + context.docBase) + \", field=\" + f, fieldValues[field], ndv.get(doc));\r\n            }\r\n          }\r\n        }\r\n      }\r\n      //      System.out.println();\r\n    }\r\n    \r\n    IOUtils.close(writer, reader, dir);\r\n  }\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"75e4e08ceec867127dcd9913a5ebbc46cf85a28d","date":1379651991,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current (updated value)\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n              //              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n    \n    IOUtils.close(writer, reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(2);\n      //      System.out.println(\"round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current (updated value)\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n      //      System.out.println(\"+++ updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n        //        System.out.println(\"--- deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n        //        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n              //              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertEquals(\"invalid value for doc=\" + (doc + context.docBase) + \", field=\" + f, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n      //      System.out.println();\n    }\n    \n    IOUtils.close(writer, reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cfb5dd418a6a344e7923487ef53e6f27ed5451ce","date":1381551530,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    final boolean[] fieldHasValue = new boolean[numFields];\n    Arrays.fill(fieldHasValue, true);\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current (updated value)\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      // if field's value was unset before, unset it from all new added documents too\n      for (int field = 0; field < fieldHasValue.length; field++) {\n        if (!fieldHasValue[field]) {\n          writer.updateNumericDocValue(new Term(\"key\", \"all\"), \"f\" + field, null);\n        }\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      if (random.nextBoolean()) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: unset field '\" + updateField + \"'\");\n        fieldHasValue[fieldIdx] = false;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, null);\n      } else {\n        fieldHasValue[fieldIdx] = true;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      }\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n              //              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              if (fieldHasValue[field]) {\n                assertTrue(docsWithField.get(doc));\n                assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n              } else {\n                assertFalse(docsWithField.get(doc));\n              }\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n    \n    IOUtils.close(writer, reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current (updated value)\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n              //              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n    \n    IOUtils.close(writer, reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe","date":1381909398,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    final boolean[] fieldHasValue = new boolean[numFields];\n    Arrays.fill(fieldHasValue, true);\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      // if field's value was unset before, unset it from all new added documents too\n      for (int field = 0; field < fieldHasValue.length; field++) {\n        if (!fieldHasValue[field]) {\n          writer.updateNumericDocValue(new Term(\"key\", \"all\"), \"f\" + field, null);\n        }\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      if (random.nextBoolean()) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: unset field '\" + updateField + \"'\");\n        fieldHasValue[fieldIdx] = false;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, null);\n      } else {\n        fieldHasValue[fieldIdx] = true;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      }\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              if (fieldHasValue[field]) {\n                assertTrue(docsWithField.get(doc));\n                assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n              } else {\n                assertFalse(docsWithField.get(doc));\n              }\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n    \n    IOUtils.close(writer, reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    final boolean[] fieldHasValue = new boolean[numFields];\n    Arrays.fill(fieldHasValue, true);\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current (updated value)\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      // if field's value was unset before, unset it from all new added documents too\n      for (int field = 0; field < fieldHasValue.length; field++) {\n        if (!fieldHasValue[field]) {\n          writer.updateNumericDocValue(new Term(\"key\", \"all\"), \"f\" + field, null);\n        }\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      if (random.nextBoolean()) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: unset field '\" + updateField + \"'\");\n        fieldHasValue[fieldIdx] = false;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, null);\n      } else {\n        fieldHasValue[fieldIdx] = true;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      }\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n              //              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              if (fieldHasValue[field]) {\n                assertTrue(docsWithField.get(doc));\n                assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n              } else {\n                assertFalse(docsWithField.get(doc));\n              }\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n    \n    IOUtils.close(writer, reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    final boolean[] fieldHasValue = new boolean[numFields];\n    Arrays.fill(fieldHasValue, true);\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      // if field's value was unset before, unset it from all new added documents too\n      for (int field = 0; field < fieldHasValue.length; field++) {\n        if (!fieldHasValue[field]) {\n          writer.updateNumericDocValue(new Term(\"key\", \"all\"), \"f\" + field, null);\n        }\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      if (random.nextBoolean()) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: unset field '\" + updateField + \"'\");\n        fieldHasValue[fieldIdx] = false;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, null);\n      } else {\n        fieldHasValue[fieldIdx] = true;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      }\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              if (fieldHasValue[field]) {\n                assertTrue(docsWithField.get(doc));\n                assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n              } else {\n                assertFalse(docsWithField.get(doc));\n              }\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    final boolean[] fieldHasValue = new boolean[numFields];\n    Arrays.fill(fieldHasValue, true);\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      // if field's value was unset before, unset it from all new added documents too\n      for (int field = 0; field < fieldHasValue.length; field++) {\n        if (!fieldHasValue[field]) {\n          writer.updateNumericDocValue(new Term(\"key\", \"all\"), \"f\" + field, null);\n        }\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      if (random.nextBoolean()) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: unset field '\" + updateField + \"'\");\n        fieldHasValue[fieldIdx] = false;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, null);\n      } else {\n        fieldHasValue[fieldIdx] = true;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      }\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              if (fieldHasValue[field]) {\n                assertTrue(docsWithField.get(doc));\n                assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n              } else {\n                assertFalse(docsWithField.get(doc));\n              }\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n    \n    IOUtils.close(writer, reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30d3ec601cbd11cf056b7336f0e03f688ebcd9f7","date":1401116050,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    final boolean[] fieldHasValue = new boolean[numFields];\n    Arrays.fill(fieldHasValue, true);\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      // if field's value was unset before, unset it from all new added documents too\n      for (int field = 0; field < fieldHasValue.length; field++) {\n        if (!fieldHasValue[field]) {\n          writer.updateNumericDocValue(new Term(\"key\", \"all\"), \"f\" + field, null);\n        }\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      if (random.nextBoolean()) {\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: unset field '\" + updateField + \"'\");\n        fieldHasValue[fieldIdx] = false;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, null);\n      } else {\n        fieldHasValue[fieldIdx] = true;\n        writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      }\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              if (fieldHasValue[field]) {\n                assertTrue(docsWithField.get(doc));\n                assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n              } else {\n                assertFalse(docsWithField.get(doc));\n              }\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (AtomicReaderContext context : reader.leaves()) {\n        AtomicReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a1862266772deb28cdcb7d996b64d2177022687","date":1453077824,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer, true);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertEquals(doc, ndv.advance(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.longValue());\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertEquals(doc, ndv.advance(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.longValue());\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertEquals(doc, ndv.advance(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.longValue());\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          Bits docsWithField = r.getDocsWithField(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertTrue(docsWithField.get(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.get(doc));\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    if (VERBOSE) {\n      System.out.println(\"TEST: isNRT=\" + isNRT);\n    }\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n      if (VERBOSE) {\n        System.out.println(\"TEST: round=\" + i + \", numDocs=\" + numDocs);\n      }\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.YES));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        if (VERBOSE) {\n          System.out.println(\"TEST add doc id=\" + docID);\n        }\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n\n      String updateField = \"f\" + fieldIdx;\n      if (VERBOSE) {\n        System.out.println(\"TEST: update field=\" + updateField + \" for all docs to value=\" + (fieldValues[fieldIdx]+1));\n      }\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(numDocs); // might also delete an already deleted document, ok!\n        if (VERBOSE) {\n          System.out.println(\"TEST: delete doc id=\" + deleteDoc);\n        }\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n      }\n      \n      // verify reader\n      if (isNRT == false) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now commit\");\n        }\n        writer.commit();\n      }\n      \n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n      if (VERBOSE) {\n        System.out.println(\"TEST: got reader maxDoc=\" + reader.maxDoc() + \" \" + reader);\n      }\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n              assertEquals(\"advanced to wrong doc in seg=\" + r, doc, ndv.advance(doc));\n              assertEquals(\"invalid value for docID=\" + doc + \" id=\" + r.document(doc).get(\"id\") + \", field=\" + f + \", reader=\" + r + \" doc=\" + r.document(doc), fieldValues[field], ndv.longValue());\n            }\n          }\n        }\n      }\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertEquals(doc, ndv.advance(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.longValue());\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    if (VERBOSE) {\n      System.out.println(\"TEST: isNRT=\" + isNRT);\n    }\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n      if (VERBOSE) {\n        System.out.println(\"TEST: round=\" + i + \", numDocs=\" + numDocs);\n      }\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.YES));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        if (VERBOSE) {\n          System.out.println(\"TEST add doc id=\" + docID);\n        }\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n\n      String updateField = \"f\" + fieldIdx;\n      if (VERBOSE) {\n        System.out.println(\"TEST: update field=\" + updateField + \" for all docs to value=\" + (fieldValues[fieldIdx]+1));\n      }\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(numDocs); // might also delete an already deleted document, ok!\n        if (VERBOSE) {\n          System.out.println(\"TEST: delete doc id=\" + deleteDoc);\n        }\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n      }\n      \n      // verify reader\n      if (isNRT == false) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now commit\");\n        }\n        writer.commit();\n      }\n      \n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n      if (VERBOSE) {\n        System.out.println(\"TEST: got reader maxDoc=\" + reader.maxDoc() + \" \" + reader);\n      }\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n              assertEquals(\"advanced to wrong doc in seg=\" + r, doc, ndv.advance(doc));\n              assertEquals(\"invalid value for docID=\" + doc + \" id=\" + r.document(doc).get(\"id\") + \", field=\" + f + \", reader=\" + r + \" doc=\" + r.document(doc), fieldValues[field], ndv.longValue());\n            }\n          }\n        }\n      }\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertEquals(doc, ndv.advance(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.longValue());\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNumericDocValuesUpdates#testManyReopensAndFields().mjava","sourceNew":"  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    if (VERBOSE) {\n      System.out.println(\"TEST: isNRT=\" + isNRT);\n    }\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n      if (VERBOSE) {\n        System.out.println(\"TEST: round=\" + i + \", numDocs=\" + numDocs);\n      }\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.YES));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        if (VERBOSE) {\n          System.out.println(\"TEST add doc id=\" + docID);\n        }\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n\n      String updateField = \"f\" + fieldIdx;\n      if (VERBOSE) {\n        System.out.println(\"TEST: update field=\" + updateField + \" for all docs to value=\" + (fieldValues[fieldIdx]+1));\n      }\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(numDocs); // might also delete an already deleted document, ok!\n        if (VERBOSE) {\n          System.out.println(\"TEST: delete doc id=\" + deleteDoc);\n        }\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n      }\n      \n      // verify reader\n      if (isNRT == false) {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now commit\");\n        }\n        writer.commit();\n      }\n      \n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n      if (VERBOSE) {\n        System.out.println(\"TEST: got reader maxDoc=\" + reader.maxDoc() + \" \" + reader);\n      }\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n              assertEquals(\"advanced to wrong doc in seg=\" + r, doc, ndv.advance(doc));\n              assertEquals(\"invalid value for docID=\" + doc + \" id=\" + r.document(doc).get(\"id\") + \", field=\" + f + \", reader=\" + r + \" doc=\" + r.document(doc), fieldValues[field], ndv.longValue());\n            }\n          }\n        }\n      }\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testManyReopensAndFields() throws Exception {\n    Directory dir = newDirectory();\n    final Random random = random();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    LogMergePolicy lmp = newLogMergePolicy();\n    lmp.setMergeFactor(3); // merge often\n    conf.setMergePolicy(lmp);\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final boolean isNRT = random.nextBoolean();\n    DirectoryReader reader;\n    if (isNRT) {\n      reader = DirectoryReader.open(writer);\n    } else {\n      writer.commit();\n      reader = DirectoryReader.open(dir);\n    }\n    \n    final int numFields = random.nextInt(4) + 3; // 3-7\n    final long[] fieldValues = new long[numFields];\n    for (int i = 0; i < fieldValues.length; i++) {\n      fieldValues[i] = 1;\n    }\n    \n    int numRounds = atLeast(15);\n    int docID = 0;\n    for (int i = 0; i < numRounds; i++) {\n      int numDocs = atLeast(5);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: round=\" + i + \", numDocs=\" + numDocs);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(new StringField(\"id\", \"doc-\" + docID, Store.NO));\n        doc.add(new StringField(\"key\", \"all\", Store.NO)); // update key\n        // add all fields with their current value\n        for (int f = 0; f < fieldValues.length; f++) {\n          doc.add(new NumericDocValuesField(\"f\" + f, fieldValues[f]));\n        }\n        writer.addDocument(doc);\n        ++docID;\n      }\n      \n      int fieldIdx = random.nextInt(fieldValues.length);\n      String updateField = \"f\" + fieldIdx;\n      writer.updateNumericDocValue(new Term(\"key\", \"all\"), updateField, ++fieldValues[fieldIdx]);\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: updated field '\" + updateField + \"' to value \" + fieldValues[fieldIdx]);\n      \n      if (random.nextDouble() < 0.2) {\n        int deleteDoc = random.nextInt(docID); // might also delete an already deleted document, ok!\n        writer.deleteDocuments(new Term(\"id\", \"doc-\" + deleteDoc));\n//        System.out.println(\"[\" + Thread.currentThread().getName() + \"]: deleted document: doc-\" + deleteDoc);\n      }\n      \n      // verify reader\n      if (!isNRT) {\n        writer.commit();\n      }\n      \n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopen reader: \" + reader);\n      DirectoryReader newReader = DirectoryReader.openIfChanged(reader);\n      assertNotNull(newReader);\n      reader.close();\n      reader = newReader;\n//      System.out.println(\"[\" + Thread.currentThread().getName() + \"]: reopened reader: \" + reader);\n      assertTrue(reader.numDocs() > 0); // we delete at most one document per round\n      for (LeafReaderContext context : reader.leaves()) {\n        LeafReader r = context.reader();\n//        System.out.println(((SegmentReader) r).getSegmentName());\n        Bits liveDocs = r.getLiveDocs();\n        for (int field = 0; field < fieldValues.length; field++) {\n          String f = \"f\" + field;\n          NumericDocValues ndv = r.getNumericDocValues(f);\n          assertNotNull(ndv);\n          int maxDoc = r.maxDoc();\n          for (int doc = 0; doc < maxDoc; doc++) {\n            if (liveDocs == null || liveDocs.get(doc)) {\n//              System.out.println(\"doc=\" + (doc + context.docBase) + \" f='\" + f + \"' vslue=\" + ndv.get(doc));\n              assertEquals(doc, ndv.advance(doc));\n              assertEquals(\"invalid value for doc=\" + doc + \", field=\" + f + \", reader=\" + r, fieldValues[field], ndv.longValue());\n            }\n          }\n        }\n      }\n//      System.out.println();\n    }\n\n    writer.close();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["30d3ec601cbd11cf056b7336f0e03f688ebcd9f7"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["4962e8a1c440950d757f5e295b4f6106ba2ab420"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cfb5dd418a6a344e7923487ef53e6f27ed5451ce":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"28288370235ed02234a64753cdbf0c6ec096304a":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["2a1862266772deb28cdcb7d996b64d2177022687","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"2a1862266772deb28cdcb7d996b64d2177022687":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["cfb5dd418a6a344e7923487ef53e6f27ed5451ce"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["2a1862266772deb28cdcb7d996b64d2177022687","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["2a1862266772deb28cdcb7d996b64d2177022687"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"30d3ec601cbd11cf056b7336f0e03f688ebcd9f7":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"4962e8a1c440950d757f5e295b4f6106ba2ab420":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["28288370235ed02234a64753cdbf0c6ec096304a"]},"commit2Childs":{"e072d0b1fc19e0533d8ce432eed245196bca6fde":["4962e8a1c440950d757f5e295b4f6106ba2ab420"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"75e4e08ceec867127dcd9913a5ebbc46cf85a28d":["cfb5dd418a6a344e7923487ef53e6f27ed5451ce"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"cfb5dd418a6a344e7923487ef53e6f27ed5451ce":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["2a1862266772deb28cdcb7d996b64d2177022687"],"28288370235ed02234a64753cdbf0c6ec096304a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"2a1862266772deb28cdcb7d996b64d2177022687":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e072d0b1fc19e0533d8ce432eed245196bca6fde"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"30d3ec601cbd11cf056b7336f0e03f688ebcd9f7":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["30d3ec601cbd11cf056b7336f0e03f688ebcd9f7"],"4962e8a1c440950d757f5e295b4f6106ba2ab420":["75e4e08ceec867127dcd9913a5ebbc46cf85a28d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}