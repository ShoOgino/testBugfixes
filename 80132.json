{"path":"contrib/gdata-server/src/core/java/org/apache/lucene/gdata/storage/lucenestorage/StorageQuery#getLatestFeedQuery(String,int,int,ProvidedService).mjava","commits":[{"id":"5824af871ba6863399636aa5989bfc0ef2ea448c","date":1166013128,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"contrib/gdata-server/src/core/java/org/apache/lucene/gdata/storage/lucenestorage/StorageQuery#getLatestFeedQuery(String,int,int,ProvidedService).mjava","pathOld":"contrib/gdata-server/src/java/org/apache/lucene/gdata/storage/lucenestorage/StorageQuery#getLatestFeedQuery(String,int,int,ProvidedService).mjava","sourceNew":"    /**\n     * This method fetches the latest feed entries from the storage. Feed\n     * usually requested via a search query or as a simple query to the REST\n     * interface.\n     * <p>\n     * The REST interface requests all the entries from a Storage. The Storage\n     * retrieves the entries corresponding to the parameters specified. This\n     * method first requests the latest entries or updated entries from the\n     * {@link StorageBuffer}. If the buffer already contains enough entries\n     * for the the specified result count the entries will be returned. If not,\n     * the underlying lucene index will be searcher for all documents of the\n     * specified feed sorted by storing timestamp desc.\n     * </p>\n     * <p>\n     * The entries will be searched in a feed context specified by the given\n     * feed ID\n     * </p>\n     * \n     * \n     * @param feedId -\n     *            the requested feed, this id will be used to retrieve the\n     *            entries.\n     * @param resultCount -\n     *            how many entries are requested\n     * @param startIndex -\n     *            the offset of the entry to start from.\n     * @param config -\n     *            the FeedInstanceConfiguration containing extension profile used\n     *            to create the entry instances\n     * @return - an ordered list of {@link BaseEntry} objects, or an empty list\n     *         if no entries could be found\n     * @throws IOException -\n     *             if the index could not be queries or the entries could not be\n     *             build\n     * @throws ParseException -\n     *             if an entry could not be parsed while building it from the\n     *             Lucene Document.\n     */\n    // TODO check input parameter\n    @SuppressWarnings(\"unchecked\")\n    public BaseFeed getLatestFeedQuery(final String feedId,\n            final int resultCount, final int startIndex,\n            final ProvidedService config) throws IOException, ParseException {\n        DateTime updated = null;\n        Hits feedHits = storageFeedQuery(feedId);\n        if (feedHits.length() == 0)\n            return null;\n        BaseFeed retVal = buildFeedFromLuceneDocument(feedHits.doc(0), config);\n\n        List<BaseEntry> returnList = new ArrayList<BaseEntry>(resultCount);\n        List<StorageEntryWrapper> bufferedWrapperList = this.buffer\n                .getSortedEntries(feedId);\n        int alreadyAdded = 0;\n        int offset = startIndex - 1;\n\n        if (bufferedWrapperList != null\n                && bufferedWrapperList.size() >= startIndex) {\n            updated = bufferedWrapperList.get(0).getEntry().getUpdated();\n            for (; alreadyAdded < resultCount; alreadyAdded++) {\n                if ((bufferedWrapperList.size() - offset) > 0) {\n                    StorageEntryWrapper wrappedEntry = bufferedWrapperList\n                            .get(offset++);\n                    returnList.add(wrappedEntry.getEntry());\n                } else\n                    break;\n            }\n            // reset offset\n            offset = startIndex - 1;\n            if (alreadyAdded == resultCount) {\n                retVal.getEntries().addAll(returnList);\n                retVal.setUpdated(updated);\n                return retVal;\n            }\n        } else {\n            /*\n             * if the buffer size is less than the start index the buffer size must\n             * be considered. Sublists would not be a repeatable read part of\n             * the whole list\n             */\n            if (bufferedWrapperList != null)\n                offset = startIndex - 1 - bufferedWrapperList.size();\n        }\n\n        Hits hits = storageFeedQuery(feedId, this.timeStampSort);\n        if (hits.length() > 0) {\n\n            for (; (offset < hits.length()) && (alreadyAdded < resultCount); offset++, alreadyAdded++) {\n                Document doc = hits.doc(offset);\n                BaseEntry entry = buildEntryFromLuceneDocument(doc, config);\n                returnList.add(entry);\n            }\n            if (updated == null) {\n                try {\n                    long updatedTimeStamp = Long.parseLong(hits.doc(0).get(\n                            StorageEntryWrapper.FIELD_TIMESTAMP));\n                    updated = new DateTime(updatedTimeStamp);\n                } catch (Exception e) {\n                    LOG.warn(\"could not create DateTime -- \" + e.getMessage(),\n                            e);\n                    updated = buildEntryFromLuceneDocument(hits.doc(0), config)\n                            .getUpdated();\n                }\n            }\n        }\n        retVal.setUpdated(updated);\n        retVal.getEntries().addAll(returnList);\n        return retVal;\n    }\n\n","sourceOld":"    /**\n     * This method fetches the latest feed entries from the storage. Feed\n     * usually requested via a search query or as a simple query to the REST\n     * interface.\n     * <p>\n     * The REST interface requests all the entries from a Storage. The Storage\n     * retrieves the entries corresponding to the parameters specified. This\n     * method first requests the latest entries or updated entries from the\n     * {@link StorageBuffer}. If the buffer already contains enough entries\n     * for the the specified result count the entries will be returned. If not,\n     * the underlying lucene index will be searcher for all documents of the\n     * specified feed sorted by storing timestamp desc.\n     * </p>\n     * <p>\n     * The entries will be searched in a feed context specified by the given\n     * feed ID\n     * </p>\n     * \n     * \n     * @param feedId -\n     *            the requested feed, this id will be used to retrieve the\n     *            entries.\n     * @param resultCount -\n     *            how many entries are requested\n     * @param startIndex -\n     *            the offset of the entry to start from.\n     * @param config -\n     *            the FeedInstanceConfiguration containing extension profile used\n     *            to create the entry instances\n     * @return - an ordered list of {@link BaseEntry} objects, or an empty list\n     *         if no entries could be found\n     * @throws IOException -\n     *             if the index could not be queries or the entries could not be\n     *             build\n     * @throws ParseException -\n     *             if an entry could not be parsed while building it from the\n     *             Lucene Document.\n     */\n    // TODO check input parameter\n    @SuppressWarnings(\"unchecked\")\n    public BaseFeed getLatestFeedQuery(final String feedId,\n            final int resultCount, final int startIndex,\n            final ProvidedService config) throws IOException, ParseException {\n        DateTime updated = null;\n        Hits feedHits = storageFeedQuery(feedId);\n        if (feedHits.length() == 0)\n            return null;\n        BaseFeed retVal = buildFeedFromLuceneDocument(feedHits.doc(0), config);\n\n        List<BaseEntry> returnList = new ArrayList<BaseEntry>(resultCount);\n        List<StorageEntryWrapper> bufferedWrapperList = this.buffer\n                .getSortedEntries(feedId);\n        int alreadyAdded = 0;\n        int offset = startIndex - 1;\n\n        if (bufferedWrapperList != null\n                && bufferedWrapperList.size() >= startIndex) {\n            updated = bufferedWrapperList.get(0).getEntry().getUpdated();\n            for (; alreadyAdded < resultCount; alreadyAdded++) {\n                if ((bufferedWrapperList.size() - offset) > 0) {\n                    StorageEntryWrapper wrappedEntry = bufferedWrapperList\n                            .get(offset++);\n                    returnList.add(wrappedEntry.getEntry());\n                } else\n                    break;\n            }\n            // reset offset\n            offset = startIndex - 1;\n            if (alreadyAdded == resultCount) {\n                retVal.getEntries().addAll(returnList);\n                retVal.setUpdated(updated);\n                return retVal;\n            }\n        } else {\n            /*\n             * if the buffer size is less than the start index the buffer size must\n             * be considered. Sublists would not be a repeatable read part of\n             * the whole list\n             */\n            if (bufferedWrapperList != null)\n                offset = startIndex - 1 - bufferedWrapperList.size();\n        }\n\n        Hits hits = storageFeedQuery(feedId, this.timeStampSort);\n        if (hits.length() > 0) {\n\n            for (; (offset < hits.length()) && (alreadyAdded < resultCount); offset++, alreadyAdded++) {\n                Document doc = hits.doc(offset);\n                BaseEntry entry = buildEntryFromLuceneDocument(doc, config);\n                returnList.add(entry);\n            }\n            if (updated == null) {\n                try {\n                    long updatedTimeStamp = Long.parseLong(hits.doc(0).get(\n                            StorageEntryWrapper.FIELD_TIMESTAMP));\n                    updated = new DateTime(updatedTimeStamp);\n                } catch (Exception e) {\n                    LOG.warn(\"could not create DateTime -- \" + e.getMessage(),\n                            e);\n                    updated = buildEntryFromLuceneDocument(hits.doc(0), config)\n                            .getUpdated();\n                }\n            }\n        }\n        retVal.setUpdated(updated);\n        retVal.getEntries().addAll(returnList);\n        return retVal;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4055ae1e0f6bbe8fa4c1069a11adee5e57b518fe","date":1166036663,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"contrib/gdata-server/src/core/src/java/org/apache/lucene/gdata/storage/lucenestorage/StorageQuery#getLatestFeedQuery(String,int,int,ProvidedService).mjava","pathOld":"contrib/gdata-server/src/core/java/org/apache/lucene/gdata/storage/lucenestorage/StorageQuery#getLatestFeedQuery(String,int,int,ProvidedService).mjava","sourceNew":"    /**\n     * This method fetches the latest feed entries from the storage. Feed\n     * usually requested via a search query or as a simple query to the REST\n     * interface.\n     * <p>\n     * The REST interface requests all the entries from a Storage. The Storage\n     * retrieves the entries corresponding to the parameters specified. This\n     * method first requests the latest entries or updated entries from the\n     * {@link StorageBuffer}. If the buffer already contains enough entries\n     * for the the specified result count the entries will be returned. If not,\n     * the underlying lucene index will be searcher for all documents of the\n     * specified feed sorted by storing timestamp desc.\n     * </p>\n     * <p>\n     * The entries will be searched in a feed context specified by the given\n     * feed ID\n     * </p>\n     * \n     * \n     * @param feedId -\n     *            the requested feed, this id will be used to retrieve the\n     *            entries.\n     * @param resultCount -\n     *            how many entries are requested\n     * @param startIndex -\n     *            the offset of the entry to start from.\n     * @param config -\n     *            the FeedInstanceConfiguration containing extension profile used\n     *            to create the entry instances\n     * @return - an ordered list of {@link BaseEntry} objects, or an empty list\n     *         if no entries could be found\n     * @throws IOException -\n     *             if the index could not be queries or the entries could not be\n     *             build\n     * @throws ParseException -\n     *             if an entry could not be parsed while building it from the\n     *             Lucene Document.\n     */\n    // TODO check input parameter\n    @SuppressWarnings(\"unchecked\")\n    public BaseFeed getLatestFeedQuery(final String feedId,\n            final int resultCount, final int startIndex,\n            final ProvidedService config) throws IOException, ParseException {\n        DateTime updated = null;\n        Hits feedHits = storageFeedQuery(feedId);\n        if (feedHits.length() == 0)\n            return null;\n        BaseFeed retVal = buildFeedFromLuceneDocument(feedHits.doc(0), config);\n\n        List<BaseEntry> returnList = new ArrayList<BaseEntry>(resultCount);\n        List<StorageEntryWrapper> bufferedWrapperList = this.buffer\n                .getSortedEntries(feedId);\n        int alreadyAdded = 0;\n        int offset = startIndex - 1;\n\n        if (bufferedWrapperList != null\n                && bufferedWrapperList.size() >= startIndex) {\n            updated = bufferedWrapperList.get(0).getEntry().getUpdated();\n            for (; alreadyAdded < resultCount; alreadyAdded++) {\n                if ((bufferedWrapperList.size() - offset) > 0) {\n                    StorageEntryWrapper wrappedEntry = bufferedWrapperList\n                            .get(offset++);\n                    returnList.add(wrappedEntry.getEntry());\n                } else\n                    break;\n            }\n            // reset offset\n            offset = startIndex - 1;\n            if (alreadyAdded == resultCount) {\n                retVal.getEntries().addAll(returnList);\n                retVal.setUpdated(updated);\n                return retVal;\n            }\n        } else {\n            /*\n             * if the buffer size is less than the start index the buffer size must\n             * be considered. Sublists would not be a repeatable read part of\n             * the whole list\n             */\n            if (bufferedWrapperList != null)\n                offset = startIndex - 1 - bufferedWrapperList.size();\n        }\n\n        Hits hits = storageFeedQuery(feedId, this.timeStampSort);\n        if (hits.length() > 0) {\n\n            for (; (offset < hits.length()) && (alreadyAdded < resultCount); offset++, alreadyAdded++) {\n                Document doc = hits.doc(offset);\n                BaseEntry entry = buildEntryFromLuceneDocument(doc, config);\n                returnList.add(entry);\n            }\n            if (updated == null) {\n                try {\n                    long updatedTimeStamp = Long.parseLong(hits.doc(0).get(\n                            StorageEntryWrapper.FIELD_TIMESTAMP));\n                    updated = new DateTime(updatedTimeStamp);\n                } catch (Exception e) {\n                    LOG.warn(\"could not create DateTime -- \" + e.getMessage(),\n                            e);\n                    updated = buildEntryFromLuceneDocument(hits.doc(0), config)\n                            .getUpdated();\n                }\n            }\n        }\n        retVal.setUpdated(updated);\n        retVal.getEntries().addAll(returnList);\n        return retVal;\n    }\n\n","sourceOld":"    /**\n     * This method fetches the latest feed entries from the storage. Feed\n     * usually requested via a search query or as a simple query to the REST\n     * interface.\n     * <p>\n     * The REST interface requests all the entries from a Storage. The Storage\n     * retrieves the entries corresponding to the parameters specified. This\n     * method first requests the latest entries or updated entries from the\n     * {@link StorageBuffer}. If the buffer already contains enough entries\n     * for the the specified result count the entries will be returned. If not,\n     * the underlying lucene index will be searcher for all documents of the\n     * specified feed sorted by storing timestamp desc.\n     * </p>\n     * <p>\n     * The entries will be searched in a feed context specified by the given\n     * feed ID\n     * </p>\n     * \n     * \n     * @param feedId -\n     *            the requested feed, this id will be used to retrieve the\n     *            entries.\n     * @param resultCount -\n     *            how many entries are requested\n     * @param startIndex -\n     *            the offset of the entry to start from.\n     * @param config -\n     *            the FeedInstanceConfiguration containing extension profile used\n     *            to create the entry instances\n     * @return - an ordered list of {@link BaseEntry} objects, or an empty list\n     *         if no entries could be found\n     * @throws IOException -\n     *             if the index could not be queries or the entries could not be\n     *             build\n     * @throws ParseException -\n     *             if an entry could not be parsed while building it from the\n     *             Lucene Document.\n     */\n    // TODO check input parameter\n    @SuppressWarnings(\"unchecked\")\n    public BaseFeed getLatestFeedQuery(final String feedId,\n            final int resultCount, final int startIndex,\n            final ProvidedService config) throws IOException, ParseException {\n        DateTime updated = null;\n        Hits feedHits = storageFeedQuery(feedId);\n        if (feedHits.length() == 0)\n            return null;\n        BaseFeed retVal = buildFeedFromLuceneDocument(feedHits.doc(0), config);\n\n        List<BaseEntry> returnList = new ArrayList<BaseEntry>(resultCount);\n        List<StorageEntryWrapper> bufferedWrapperList = this.buffer\n                .getSortedEntries(feedId);\n        int alreadyAdded = 0;\n        int offset = startIndex - 1;\n\n        if (bufferedWrapperList != null\n                && bufferedWrapperList.size() >= startIndex) {\n            updated = bufferedWrapperList.get(0).getEntry().getUpdated();\n            for (; alreadyAdded < resultCount; alreadyAdded++) {\n                if ((bufferedWrapperList.size() - offset) > 0) {\n                    StorageEntryWrapper wrappedEntry = bufferedWrapperList\n                            .get(offset++);\n                    returnList.add(wrappedEntry.getEntry());\n                } else\n                    break;\n            }\n            // reset offset\n            offset = startIndex - 1;\n            if (alreadyAdded == resultCount) {\n                retVal.getEntries().addAll(returnList);\n                retVal.setUpdated(updated);\n                return retVal;\n            }\n        } else {\n            /*\n             * if the buffer size is less than the start index the buffer size must\n             * be considered. Sublists would not be a repeatable read part of\n             * the whole list\n             */\n            if (bufferedWrapperList != null)\n                offset = startIndex - 1 - bufferedWrapperList.size();\n        }\n\n        Hits hits = storageFeedQuery(feedId, this.timeStampSort);\n        if (hits.length() > 0) {\n\n            for (; (offset < hits.length()) && (alreadyAdded < resultCount); offset++, alreadyAdded++) {\n                Document doc = hits.doc(offset);\n                BaseEntry entry = buildEntryFromLuceneDocument(doc, config);\n                returnList.add(entry);\n            }\n            if (updated == null) {\n                try {\n                    long updatedTimeStamp = Long.parseLong(hits.doc(0).get(\n                            StorageEntryWrapper.FIELD_TIMESTAMP));\n                    updated = new DateTime(updatedTimeStamp);\n                } catch (Exception e) {\n                    LOG.warn(\"could not create DateTime -- \" + e.getMessage(),\n                            e);\n                    updated = buildEntryFromLuceneDocument(hits.doc(0), config)\n                            .getUpdated();\n                }\n            }\n        }\n        retVal.setUpdated(updated);\n        retVal.getEntries().addAll(returnList);\n        return retVal;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4055ae1e0f6bbe8fa4c1069a11adee5e57b518fe":["5824af871ba6863399636aa5989bfc0ef2ea448c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5824af871ba6863399636aa5989bfc0ef2ea448c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4055ae1e0f6bbe8fa4c1069a11adee5e57b518fe"]},"commit2Childs":{"4055ae1e0f6bbe8fa4c1069a11adee5e57b518fe":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5824af871ba6863399636aa5989bfc0ef2ea448c"],"5824af871ba6863399636aa5989bfc0ef2ea448c":["4055ae1e0f6bbe8fa4c1069a11adee5e57b518fe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}