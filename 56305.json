{"path":"lucene/misc/src/test/org/apache/lucene/index/SorterTestBase#createIndex(Directory,int,Random).mjava","commits":[{"id":"82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e","date":1419346542,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/test/org/apache/lucene/index/SorterTestBase#createIndex(Directory,int,Random).mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/sorter/SorterTestBase#createIndex(Directory,int,Random).mjava","sourceNew":"  /** Creates an unsorted index; subclasses then sort this index and open sortedReader. */\n  private static void createIndex(Directory dir, int numDocs, Random random) throws IOException {\n    List<Integer> ids = new ArrayList<>();\n    for (int i = 0; i < numDocs; i++) {\n      ids.add(Integer.valueOf(i * 10));\n    }\n    // shuffle them for indexing\n    Collections.shuffle(ids, random);\n    if (VERBOSE) {\n      System.out.println(\"Shuffled IDs for indexing: \" + Arrays.toString(ids.toArray()));\n    }\n    \n    PositionsTokenStream positions = new PositionsTokenStream();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    conf.setMaxBufferedDocs(4); // create some segments\n    conf.setSimilarity(new NormsSimilarity(conf.getSimilarity())); // for testing norms field\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, conf);\n    writer.setDoRandomForceMerge(false);\n    for (int id : ids) {\n      writer.addDocument(doc(id, positions));\n    }\n    // delete some documents\n    writer.commit();\n    for (Integer id : ids) {\n      if (random.nextDouble() < 0.2) {\n        if (VERBOSE) {\n          System.out.println(\"delete doc_id \" + id);\n        }\n        writer.deleteDocuments(new Term(ID_FIELD, id.toString()));\n      }\n    }\n    writer.close();\n  }\n\n","sourceOld":"  /** Creates an unsorted index; subclasses then sort this index and open sortedReader. */\n  private static void createIndex(Directory dir, int numDocs, Random random) throws IOException {\n    List<Integer> ids = new ArrayList<>();\n    for (int i = 0; i < numDocs; i++) {\n      ids.add(Integer.valueOf(i * 10));\n    }\n    // shuffle them for indexing\n    Collections.shuffle(ids, random);\n    if (VERBOSE) {\n      System.out.println(\"Shuffled IDs for indexing: \" + Arrays.toString(ids.toArray()));\n    }\n    \n    PositionsTokenStream positions = new PositionsTokenStream();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    conf.setMaxBufferedDocs(4); // create some segments\n    conf.setSimilarity(new NormsSimilarity(conf.getSimilarity())); // for testing norms field\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, conf);\n    writer.setDoRandomForceMerge(false);\n    for (int id : ids) {\n      writer.addDocument(doc(id, positions));\n    }\n    // delete some documents\n    writer.commit();\n    for (Integer id : ids) {\n      if (random.nextDouble() < 0.2) {\n        if (VERBOSE) {\n          System.out.println(\"delete doc_id \" + id);\n        }\n        writer.deleteDocuments(new Term(ID_FIELD, id.toString()));\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ceaef6cfc68c8ab22a684192e469a8280f9e6e70","date":1462354657,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#createIndex().mjava","pathOld":"lucene/misc/src/test/org/apache/lucene/index/SorterTestBase#createIndex(Directory,int,Random).mjava","sourceNew":"  @BeforeClass\n  public static void createIndex() throws Exception {\n    dir = newFSDirectory(createTempDir());\n    int numDocs = atLeast(100);\n\n    List<Integer> ids = new ArrayList<>();\n    for (int i = 0; i < numDocs; i++) {\n      ids.add(Integer.valueOf(i * 10));\n    }\n    // shuffle them for indexing\n    Collections.shuffle(ids, random());\n    if (VERBOSE) {\n      System.out.println(\"Shuffled IDs for indexing: \" + Arrays.toString(ids.toArray()));\n    }\n    \n    PositionsTokenStream positions = new PositionsTokenStream();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    // nocommit:\n    conf.setCodec(new SimpleTextCodec());\n    conf.setMaxBufferedDocs(4); // create some segments\n    conf.setSimilarity(new NormsSimilarity(conf.getSimilarity())); // for testing norms field\n    // nocommit\n    conf.setMergeScheduler(new SerialMergeScheduler());\n    // sort the index by id (as integer, in NUMERIC_DV_FIELD)\n    conf.setIndexSort(new Sort(new SortField(NUMERIC_DV_FIELD, SortField.Type.INT)));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    writer.setDoRandomForceMerge(false);\n    for (int id : ids) {\n      writer.addDocument(doc(id, positions));\n    }\n    // delete some documents\n    writer.commit();\n    // nocommit need thread safety test too\n    for (Integer id : ids) {\n      if (random().nextDouble() < 0.2) {\n        if (VERBOSE) {\n          System.out.println(\"delete doc_id \" + id);\n        }\n        writer.deleteDocuments(new Term(ID_FIELD, id.toString()));\n      }\n    }\n    \n    sortedReader = writer.getReader();\n    writer.close();\n    \n    TestUtil.checkReader(sortedReader);\n  }\n\n","sourceOld":"  /** Creates an unsorted index; subclasses then sort this index and open sortedReader. */\n  private static void createIndex(Directory dir, int numDocs, Random random) throws IOException {\n    List<Integer> ids = new ArrayList<>();\n    for (int i = 0; i < numDocs; i++) {\n      ids.add(Integer.valueOf(i * 10));\n    }\n    // shuffle them for indexing\n    Collections.shuffle(ids, random);\n    if (VERBOSE) {\n      System.out.println(\"Shuffled IDs for indexing: \" + Arrays.toString(ids.toArray()));\n    }\n    \n    PositionsTokenStream positions = new PositionsTokenStream();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    conf.setMaxBufferedDocs(4); // create some segments\n    conf.setSimilarity(new NormsSimilarity(conf.getSimilarity())); // for testing norms field\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, conf);\n    writer.setDoRandomForceMerge(false);\n    for (int id : ids) {\n      writer.addDocument(doc(id, positions));\n    }\n    // delete some documents\n    writer.commit();\n    for (Integer id : ids) {\n      if (random.nextDouble() < 0.2) {\n        if (VERBOSE) {\n          System.out.println(\"delete doc_id \" + id);\n        }\n        writer.deleteDocuments(new Term(ID_FIELD, id.toString()));\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d33e731a93d4b57e662ff094f64f94a745422d4","date":1463128289,"type":4,"author":"Mike McCandless","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/misc/src/test/org/apache/lucene/index/SorterTestBase#createIndex(Directory,int,Random).mjava","sourceNew":null,"sourceOld":"  /** Creates an unsorted index; subclasses then sort this index and open sortedReader. */\n  private static void createIndex(Directory dir, int numDocs, Random random) throws IOException {\n    List<Integer> ids = new ArrayList<>();\n    for (int i = 0; i < numDocs; i++) {\n      ids.add(Integer.valueOf(i * 10));\n    }\n    // shuffle them for indexing\n    Collections.shuffle(ids, random);\n    if (VERBOSE) {\n      System.out.println(\"Shuffled IDs for indexing: \" + Arrays.toString(ids.toArray()));\n    }\n    \n    PositionsTokenStream positions = new PositionsTokenStream();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    conf.setMaxBufferedDocs(4); // create some segments\n    conf.setSimilarity(new NormsSimilarity(conf.getSimilarity())); // for testing norms field\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, conf);\n    writer.setDoRandomForceMerge(false);\n    for (int id : ids) {\n      writer.addDocument(doc(id, positions));\n    }\n    // delete some documents\n    writer.commit();\n    for (Integer id : ids) {\n      if (random.nextDouble() < 0.2) {\n        if (VERBOSE) {\n          System.out.println(\"delete doc_id \" + id);\n        }\n        writer.deleteDocuments(new Term(ID_FIELD, id.toString()));\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ad30c6a479e764150a3316e57263319775f1df2","date":1463395403,"type":4,"author":"Karl Wright","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/misc/src/test/org/apache/lucene/index/SorterTestBase#createIndex(Directory,int,Random).mjava","sourceNew":null,"sourceOld":"  /** Creates an unsorted index; subclasses then sort this index and open sortedReader. */\n  private static void createIndex(Directory dir, int numDocs, Random random) throws IOException {\n    List<Integer> ids = new ArrayList<>();\n    for (int i = 0; i < numDocs; i++) {\n      ids.add(Integer.valueOf(i * 10));\n    }\n    // shuffle them for indexing\n    Collections.shuffle(ids, random);\n    if (VERBOSE) {\n      System.out.println(\"Shuffled IDs for indexing: \" + Arrays.toString(ids.toArray()));\n    }\n    \n    PositionsTokenStream positions = new PositionsTokenStream();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    conf.setMaxBufferedDocs(4); // create some segments\n    conf.setSimilarity(new NormsSimilarity(conf.getSimilarity())); // for testing norms field\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, conf);\n    writer.setDoRandomForceMerge(false);\n    for (int id : ids) {\n      writer.addDocument(doc(id, positions));\n    }\n    // delete some documents\n    writer.commit();\n    for (Integer id : ids) {\n      if (random.nextDouble() < 0.2) {\n        if (VERBOSE) {\n          System.out.println(\"delete doc_id \" + id);\n        }\n        writer.deleteDocuments(new Term(ID_FIELD, id.toString()));\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":4,"author":"Noble Paul","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/misc/src/test/org/apache/lucene/index/SorterTestBase#createIndex(Directory,int,Random).mjava","sourceNew":null,"sourceOld":"  /** Creates an unsorted index; subclasses then sort this index and open sortedReader. */\n  private static void createIndex(Directory dir, int numDocs, Random random) throws IOException {\n    List<Integer> ids = new ArrayList<>();\n    for (int i = 0; i < numDocs; i++) {\n      ids.add(Integer.valueOf(i * 10));\n    }\n    // shuffle them for indexing\n    Collections.shuffle(ids, random);\n    if (VERBOSE) {\n      System.out.println(\"Shuffled IDs for indexing: \" + Arrays.toString(ids.toArray()));\n    }\n    \n    PositionsTokenStream positions = new PositionsTokenStream();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    conf.setMaxBufferedDocs(4); // create some segments\n    conf.setSimilarity(new NormsSimilarity(conf.getSimilarity())); // for testing norms field\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, conf);\n    writer.setDoRandomForceMerge(false);\n    for (int id : ids) {\n      writer.addDocument(doc(id, positions));\n    }\n    // delete some documents\n    writer.commit();\n    for (Integer id : ids) {\n      if (random.nextDouble() < 0.2) {\n        if (VERBOSE) {\n          System.out.println(\"delete doc_id \" + id);\n        }\n        writer.deleteDocuments(new Term(ID_FIELD, id.toString()));\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/misc/src/test/org/apache/lucene/index/SorterTestBase#createIndex(Directory,int,Random).mjava","sourceNew":null,"sourceOld":"  /** Creates an unsorted index; subclasses then sort this index and open sortedReader. */\n  private static void createIndex(Directory dir, int numDocs, Random random) throws IOException {\n    List<Integer> ids = new ArrayList<>();\n    for (int i = 0; i < numDocs; i++) {\n      ids.add(Integer.valueOf(i * 10));\n    }\n    // shuffle them for indexing\n    Collections.shuffle(ids, random);\n    if (VERBOSE) {\n      System.out.println(\"Shuffled IDs for indexing: \" + Arrays.toString(ids.toArray()));\n    }\n    \n    PositionsTokenStream positions = new PositionsTokenStream();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random));\n    conf.setMaxBufferedDocs(4); // create some segments\n    conf.setSimilarity(new NormsSimilarity(conf.getSimilarity())); // for testing norms field\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, conf);\n    writer.setDoRandomForceMerge(false);\n    for (int id : ids) {\n      writer.addDocument(doc(id, positions));\n    }\n    // delete some documents\n    writer.commit();\n    for (Integer id : ids) {\n      if (random.nextDouble() < 0.2) {\n        if (VERBOSE) {\n          System.out.println(\"delete doc_id \" + id);\n        }\n        writer.deleteDocuments(new Term(ID_FIELD, id.toString()));\n      }\n    }\n    writer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0ad30c6a479e764150a3316e57263319775f1df2":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e","3d33e731a93d4b57e662ff094f64f94a745422d4"],"82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e","ceaef6cfc68c8ab22a684192e469a8280f9e6e70"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e","d470c8182e92b264680e34081b75e70a9f2b3c89"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e","0ad30c6a479e764150a3316e57263319775f1df2"]},"commit2Childs":{"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["3d33e731a93d4b57e662ff094f64f94a745422d4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e"],"0ad30c6a479e764150a3316e57263319775f1df2":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e":["ceaef6cfc68c8ab22a684192e469a8280f9e6e70","0ad30c6a479e764150a3316e57263319775f1df2","3d33e731a93d4b57e662ff094f64f94a745422d4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d470c8182e92b264680e34081b75e70a9f2b3c89"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["0ad30c6a479e764150a3316e57263319775f1df2"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d470c8182e92b264680e34081b75e70a9f2b3c89":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}